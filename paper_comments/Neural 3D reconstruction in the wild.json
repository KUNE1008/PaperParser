{
    "title": "Neural 3D reconstruction in the wild",
    "id": 42,
    "valid_pdf_number": "16/30",
    "matched_pdf_number": "13/16",
    "matched_rate": 0.8125,
    "citations": {
        "Hexplane: A fast representation for dynamic scenes": {
            "authors": [
                "Ang Cao",
                "Justin Johnson"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_HexPlane_A_Fast_Representation_for_Dynamic_Scenes_CVPR_2023_paper.pdf",
            "ref_texts": "[67] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. ACM SIGGRAPH 2022 Conference Proceedings , 2022. 2",
            "ref_ids": [
                "67"
            ],
            "1": "Using neural networks to implicitly represent 3D scenes [39, 46, 62, 63, 67, 75] has achieved exciting progress recently.",
            "2": "NeRF [42] and its variants [2, 3, 40, 44, 69, 71, 80, 87] show impressive results on novel view synthesis [9, 75, 82, 94] and many other applications including 3D reconstruction [38, 67, 85, 89, 95], semantic segmentation [25,55,93], generative model [5,6,10, 45,58,77], and 3D content creation [1,22,30,48,53,72,86]."
        },
        "Tensor4d: Efficient neural 4d decomposition for high-fidelity dynamic reconstruction and rendering": {
            "authors": [
                "Ruizhi Shao",
                "Zerong Zheng",
                "Hanzhang Tu",
                "Boning Liu",
                "Hongwen Zhang",
                "Yebin Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shao_Tensor4D_Efficient_Neural_4D_Decomposition_for_High-Fidelity_Dynamic_Reconstruction_and_CVPR_2023_paper.pdf",
            "ref_texts": ""
        },
        "Eslam: Efficient dense slam system based on hybrid representation of signed distance fields": {
            "authors": [
                "Mohammad Mahdi",
                "Camilla Carta",
                "Francois Fleuret"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Johari_ESLAM_Efficient_Dense_SLAM_System_Based_on_Hybrid_Representation_of_CVPR_2023_paper.pdf",
            "ref_texts": "[62] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 1",
            "ref_ids": [
                "62"
            ],
            "1": "Following the advent of Neural Radiance Fields (NeRF) [37] and the demonstration of their capacity to reason about the geometry of a large-scale scene [8, 13, 20, 22, 26, 75, 78] and reconstruct 3D surfaces [1, 29, 47, 48, 62, 71, 72, 82, 85], novel NeRF-based dense SLAM methods have been developed."
        },
        "Looking Through the Glass: Neural Surface Reconstruction Against High Specular Reflections": {
            "authors": [
                "Jiaxiong Qiu",
                "Tao Jiang",
                "Yifan Zhu",
                "Xin Yin",
                "Ming Cheng",
                "Bo Ren"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Looking_Through_the_Glass_Neural_Surface_Reconstruction_Against_High_Specular_CVPR_2023_paper.pdf",
            "ref_texts": "[41] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 3",
            "ref_ids": [
                "41"
            ],
            "1": "29, 39, 47] and 3D reconstruction [7, 10, 30, 31, 33, 41, 44\u2013\n46,48,51,52]."
        },
        "Neural Scene Chronology": {
            "authors": [
                "Haotong Lin",
                "Qianqian Wang",
                "Ruojin Cai",
                "Sida Peng",
                "Hadar Averbuch",
                "Xiaowei Zhou",
                "Noah Snavely"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Neural_Scene_Chronology_CVPR_2023_paper.pdf",
            "ref_texts": "[48] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3D reconstruction in the wild. In SIGGRAPH , 2022. 3",
            "ref_ids": [
                "48"
            ],
            "1": "[48] build on NeRF-W to reconstruct 3D meshes from a collection of Internet photos."
        },
        "Multi-Space Neural Radiance Fields": {
            "authors": [
                "Xin Yin",
                "Jiaxiong Qiu",
                "Ming Cheng",
                "Bo Ren"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_Multi-Space_Neural_Radiance_Fields_CVPR_2023_paper.pdf",
            "ref_texts": "[35] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 1",
            "ref_ids": [
                "35"
            ],
            "1": "Since its first presentation [25], many efforts have been investigated to enhance the method, such as extending to unbounded scenes [2, 50], handling moving objects [29, 30, 37], or reconstructing from pictures in the wild [6, 21, 35, 49]."
        },
        "Fast Monocular Scene Reconstruction with Global-Sparse Local-Dense Grids": {
            "authors": [
                "Wei Dong",
                "Christopher Choy",
                "Charles Loop",
                "Or Litany",
                "Yuke Zhu",
                "Anima Anandkumar"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_Fast_Monocular_Scene_Reconstruction_With_Global-Sparse_Local-Dense_Grids_CVPR_2023_paper.pdf",
            "ref_texts": "[37] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings, pages 1\u20139, 2022. 3",
            "ref_ids": [
                "37"
            ],
            "1": "In view of this, implicit SDF representations [37, 43,47,48] are used to replace density, where surfaces are better-defined at zero-crossings."
        },
        "Neuralangelo: High-Fidelity Neural Surface Reconstruction": {
            "authors": [
                "Zhaoshuo Li",
                "Thomas Muller",
                "Alex Evans",
                "Russell H. Taylor",
                "Mathias Unberath",
                "Yu Liu",
                "Hsuan Lin"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Neuralangelo_High-Fidelity_Neural_Surface_Reconstruction_CVPR_2023_paper.pdf",
            "ref_texts": "[31] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 3",
            "ref_ids": [
                "31"
            ],
            "1": "The use of monocular depth and segmentation as auxiliary data has also been explored with unconstrained image collections [31] or using scene representations with hash encodings [44].",
            "2": "In contrast, our work Neuralangelo builds upon hash encodings [23] to recover surfaces but without the need for auxiliary inputs used in prior work [3, 5, 31, 44, 45]."
        },
        "Towards Unbiased Volume Rendering of Neural Implicit Surfaces With Geometry Priors": {
            "authors": [
                "Yongqiang Zhang",
                "Zhipeng Hu",
                "Haoqian Wu",
                "Minda Zhao",
                "Lincheng Li",
                "Zhengxia Zou",
                "Changjie Fan"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Towards_Unbiased_Volume_Rendering_of_Neural_Implicit_Surfaces_With_Geometry_CVPR_2023_paper.pdf",
            "ref_texts": "[21] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 2",
            "ref_ids": [
                "21"
            ],
            "1": "Recent works improve the geometric network and build connections between density-based representation and surface-based representation [2, 17, 21, 24, 32], which can extract more accurate and smooth surfaces."
        },
        "PersonNeRF: Personalized Reconstruction from Photo Collections": {
            "authors": [
                "Yi Weng",
                "Pratul P. Srinivasan",
                "Brian Curless",
                "Ira Kemelmacher"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Weng_PersonNeRF_Personalized_Reconstruction_From_Photo_Collections_CVPR_2023_paper.pdf",
            "ref_texts": "[40] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 2",
            "ref_ids": [
                "40"
            ],
            "1": "Recently, this problem has been revisited withneural rendering [19, 30, 40, 43, 44]."
        },
        "Sphere-Guided Training of Neural Implicit Surfaces": {
            "authors": [
                "Andreea Dogaru",
                "Timotei Ardelean",
                "Savva Ignatyev",
                "Egor Zakharov",
                "Evgeny Burnaev"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Dogaru_Sphere-Guided_Training_of_Neural_Implicit_Surfaces_CVPR_2023_paper.pdf",
            "ref_texts": "[30] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3D reconstruction in the wild. In SIGGRAPH Conference Proceedings , 2022. 2",
            "ref_ids": [
                "30"
            ],
            "1": "Closely related to our work are Neural Sparse V oxel Fields [16] and Neural 3D Reconstruction in the Wild [30] systems.",
            "2": "Compared to [30], our method does not employ the initialization using a sparse point-cloud, and it trains the guiding reconstruction from scratch."
        },
        "TMO: Textured Mesh Acquisition of Objects with a Mobile Device by using Differentiable Rendering": {
            "authors": [
                "Jaehoon Choi",
                "Dongki Jung",
                "Taejae Lee",
                "Sangwook Kim",
                "Youngdong Jung",
                "Dinesh Manocha",
                "Donghwan Lee"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_TMO_Textured_Mesh_Acquisition_of_Objects_With_a_Mobile_Device_CVPR_2023_paper.pdf",
            "ref_texts": "[50] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 2, 4",
            "ref_ids": [
                "50"
            ],
            "1": "Our 3D geometry reconstruction process adopts a neural implicit representation [50, 55] for surface reconstruction with volumetric rendering.",
            "2": "(6) In the second stage, inspired by [50], we adopt a sparse voxel octree to guide the sampling process and capture fine details."
        },
        "Seeing Through the Glass: Neural 3D Reconstruction of Object Inside a Transparent Container": {
            "authors": [
                "Jinguang Tong",
                "Sundaram Muthu",
                "Fahira Afzal",
                "Chuong Nguyen",
                "Hongdong Li"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tong_Seeing_Through_the_Glass_Neural_3D_Reconstruction_of_Object_Inside_CVPR_2023_paper.pdf",
            "ref_texts": "[29] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pages 1\u20139, 2022. 2",
            "ref_ids": [
                "29"
            ],
            "1": "Recently, neural implicit representation methods [21,22, 28, 29, 31] achieve state-of-the-art performance in the task of novel view synthesis and 3D reconstruction showing promising ability to encode the appearance and geometry."
        },
        "HIVE: HIerarchical Volume Encoding for Neural Implicit Surface Reconstruction": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=LnQn5-rN-LR",
            "ref_texts": "3530127 . Zak Murez, Tarrence van As, James Bartolozzi, Ayan Sinha, Vijay Badrinarayanan, and Andrew Rabinovich. Atlas: End-to-end 3d scene reconstruction from posed images. In Proceedings of the European Conference on Computer Vision , pp. 414\u2013431. Springer, 2020. Michael Niemeyer, Lars Mescheder, Michael Oechsle, and Andreas Geiger. Differentiable volumetric rendering: Learning implicit 3d representations without 3d supervision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 3504\u20133515, 2020. Michael Oechsle, Songyou Peng, and Andreas Geiger. Unisurf: Unifying neural implicit surfaces and radiance fields for multi-view reconstruction. In Proceedings of the International Conference on Computer Vision , pp. 5589\u20135599, 2021. Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas Geiger. Convolutional occupancy networks. In Proceedings of the European Conference on Computer Vision , 2020. Leonid I Rudin and Stanley Osher. Total variation based image restoration with free local constraints. InProceedings of 1st international conference on image processing , volume 1, pp. 31\u201335. IEEE, 1994. Paul-Edouard Sarlin, Daniel DeTone, Tomasz Malisiewicz, and Andrew Rabinovich. Superglue: Learning feature matching with graph neural networks. In CVPR , pp. 4938\u20134947, 2020. Johannes L Sch \u00a8onberger, Enliang Zheng, Jan-Michael Frahm, and Marc Pollefeys. Pixelwise view selection for unstructured multi-view stereo. In Proceedings of the European Conference on Computer Vision , pp. 501\u2013518. Springer, 2016. Johannes Lutz Sch \u00a8onberger and Jan-Michael Frahm. Structure-from-motion revisited. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2016. Christoph Strecha, Wolfgang V on Hansen, Luc Van Gool, Pascal Fua, and Ulrich Thoennessen. On benchmarking camera calibration and multi-view stereo for high resolution imagery. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 1\u20138. Ieee, 2008. Cheng Sun, Min Sun, and Hwann-Tzong Chen. Direct voxel grid optimization: Super-fast convergence for radiance fields reconstruction. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 5459\u20135469, 2022a. Jiaming Sun, Yiming Xie, Linghao Chen, Xiaowei Zhou, and Hujun Bao. Neuralrecon: Real-time coherent 3d reconstruction from monocular video. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 15598\u201315607, 2021. Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH 2022 Conference Proceedings , pp. 1\u20139, 2022b."
        },
        "View transformation and novel view synthesis based on deep learning": {
            "authors": [],
            "url": "https://repository.lboro.ac.uk/articles/thesis/View_transformation_and_novel_view_synthesis_based_on_deep_learning/22310221/1/files/39687793.pdf",
            "ref_texts": ""
        },
        "Neural mesh reconstruction": {
            "authors": [],
            "url": "https://summit.sfu.ca/_flysystem/fedora/2023-06/etd22528.pdf",
            "ref_texts": "[231] Jiaming Sun, Xi Chen, Qianqian Wang, Zhengqi Li, Hadar Averbuch-Elor, Xiaowei Zhou, and Noah Snavely. Neural 3d reconstruction in the wild. In ACM SIGGRAPH",
            "ref_ids": [
                "231"
            ],
            "1": "\u201cNeural 3D Reconstruction in the Wild\u201d [231] follows NeuS [250] and \u201cNeRF in the Wild\u201d (NeRF-W) [161] to reconstruct scenes from Internet photo collections in the presence of varying illumination."
        }
    }
}