{
    "title": "Learning to estimate 3D human pose and shape from a single color image",
    "id": 3,
    "valid_pdf_number": "375/463",
    "matched_pdf_number": "307/375",
    "matched_rate": 0.8186666666666667,
    "citations": {
        "Review of artificial intelligence techniques in imaging data acquisition, segmentation, and diagnosis for COVID-19": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.02731",
            "ref_texts": ""
        },
        "End-to-end human pose and mesh reconstruction with transformers": {
            "authors": [
                "Kevin Lin",
                "Lijuan Wang",
                "Zicheng Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "34"
            ],
            "1": "Methods in the first category use a parametric model like SMPL [24] and learn to predict shape and pose coefficients [12,21,34,17,19,29,39,18].",
            "2": "Since it is challenging to regress the pose and shape coefficients directly from an input image, recent works further propose to leverage various human body priors such as human skeletons [21,34] or segmentation maps [29], and explore different optimization strategies [19,17,46,12] and temporal information [18] to improve reconstruction.",
            "3": "MPVE: Mean-Per-Vertex-Error (MPVE) [34] measures the Euclidean distances between the ground truth vertices and the predicted vertices."
        },
        "Vibe: Video inference for human body pose and shape estimation": {
            "authors": [
                "Muhammed Kocabas",
                "Nikos Athanasiou",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Kocabas_VIBE_Video_Inference_for_Human_Body_Pose_and_Shape_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[48] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , 2018. 1,3,6",
            "ref_ids": [
                "48"
            ],
            "1": "Introduction Tremendous progress has been made on estimating 3D human pose and shape from a single image [11,21,25,29, 35,36,38,45,48].",
            "2": "Recently, deep neural networks are trained to directly regress the parameters of the SMPL body model from pixels [21,29,45,48,55,57].",
            "3": "Due to the lack of in-the-wild 3D ground-truth labels, these methods use weak supervision signals obtained from a 2D keypoint reprojection loss [29,55,57], use body/part segmentation as an intermediate representation [45,48], or employ a human in the loop [38].",
            "4": "[48] 75."
        },
        "Learning to reconstruct 3D human pose and shape via model-fitting in the loop": {
            "authors": [
                "Nikos Kolotouros",
                "Georgios Pavlakos",
                "Michael J. Black",
                "Kostas Daniilidis"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Kolotouros_Learning_to_Reconstruct_3D_Human_Pose_and_Shape_via_Model-Fitting_ICCV_2019_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1,2,3,6,8",
            "ref_ids": [
                "27"
            ],
            "1": "Among others, 3D model-based human pose estimation has initiated similar discussions, since both optimization-based [4,18] and regression-based approaches [15,24,27] have had significant success recently.",
            "2": "On the other hand, recent deep learning advances have shifted the spotlight towards purely regressionbased methods, using deep networks to regress the parameters of the model directly from images [15,24,27].",
            "3": "Finally, and most crucially in terms of performance, our network is trained with explicit 3D supervision, in the form of model parameters and full shape instead of weaker 2D reprojection errors as in previous works [15,27].",
            "4": "More recently, works have demonstrated fits for more expressive models in the multi-view [14], as well as the singleview setting [27,41].",
            "5": "This information can be used as input [37], intermediate representation [24,27], or as supervision, by enforcing different reprojection losses [15,24,27,34,37].",
            "6": "[27] used an initial prediction from their network to initialize and anchor the SMPLify optimization routine.",
            "7": "64 SMPLify on [27] 92.",
            "8": "[27] 75."
        },
        "Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization": {
            "authors": [
                "Shunsuke Saito",
                "Zeng Huang",
                "Ryota Natsume",
                "Shigeo Morishima",
                "Angjoo Kanazawa",
                "Hao Li"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Saito_PIFu_Pixel-Aligned_Implicit_Function_for_High-Resolution_Clothed_Human_Digitization_ICCV_2019_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.[44] Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael J Black. Clothcap: Seamless 4d clothing capture and retargeting. ACM Transactions on Graphics , 36(4):73, 2017.",
            "ref_ids": [
                "43",
                "44"
            ],
            "1": "Recent methods involve deep neural networks to improve the robustness of pose and shape parameters estimations for highly challenging images [27,43].",
            "2": "The use of motion cues has also been introduced as additional priors [44,60].",
            "3": "[44] Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael J Black."
        },
        "Expressive body capture: 3d hands, face, and body from a single image": {
            "authors": [
                "Georgios Pavlakos",
                "Vasileios Choutas",
                "Nima Ghorbani",
                "Timo Bolkart",
                "Ahmed A. A",
                "Dimitrios Tzionas",
                "Michael J. Black"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Pavlakos_Expressive_Body_Capture_3D_Hands_Face_and_Body_From_a_CVPR_2019_paper.pdf",
            "ref_texts": "[62] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1,2,3,6",
            "ref_ids": [
                "62"
            ],
            "1": "of the major joints and rough 3D pose directly from single images [10,37,59,62].",
            "2": "Several methods use deep learning to regress the parameters of SMPL from a single image [37,59,62].",
            "3": "Several methods estimate the SMPL model from a single image [37,41,59,62].",
            "4": "The pseudo ground-truth meshes allow to use a stricter vertexto-vertex (v2v) error metric [48,62], in contrast to the common paradigm of reporting 3D joint error, which does not capture surface errors and rotations along the bones."
        },
        "PARE: Part attention regressor for 3D human body estimation": {
            "authors": [
                "Muhammed Kocabas",
                "Hao P. Huang",
                "Otmar Hilliges",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Kocabas_PARE_Part_Attention_Regressor_for_3D_Human_Body_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1, 2",
            "ref_ids": [
                "40"
            ],
            "1": "The task is to take a single image [24, 29, 40] or video sequence [25, 27, 35] as input and to regress the parameters of a human body model such as SMPL [33] as output.",
            "2": "Powered by deep CNNs, this task has seen rapid progress [24, 27, 29, 40].",
            "3": "The visualization reveals that methods like SPIN\n[40] are highly sensitive to localized part occlusion.",
            "4": "In contrast, deep neural networks regress SMPL parameters directly from pixels [16, 24, 38, 40, 50, 51].",
            "5": "body/part segmentation [38, 40, 57], 2D sparse keypoints [45, 57], or leverage a human in the loop [31]."
        },
        "Animatable neural radiance fields for modeling dynamic human bodies": {
            "authors": [
                "Sida Peng",
                "Junting Dong",
                "Qianqian Wang",
                "Shangzhan Zhang",
                "Qing Shuai",
                "Xiaowei Zhou",
                "Hujun Bao"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Peng_Animatable_Neural_Radiance_Fields_for_Modeling_Dynamic_Human_Bodies_ICCV_2021_paper.pdf",
            "ref_texts": "[48] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "48"
            ],
            "1": "Based on SMPL, some works [48, 24, 27, 21, 13] reconstruct an animated human mesh from sparse camera views."
        },
        "I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.03713",
            "ref_texts": "40. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "40"
            ],
            "1": "Recent deep convolutional neural network (CNN)-based studies [20,23,40] for the 3D human pose and mesh estimation are based on the model-based approach, which trains a network to estimate SMPL/MANO parameters from an input image.",
            "2": "[40] used 2D joint heatmaps and silhouette as cues for predicting accurate SMPL parameters.",
            "3": "9 Pavlakos [40] 75.",
            "4": "6M dataset All the previous works [20, 23, 24, 40] used SMPL parameters obtained by applying Mosh [27] on the marker data of Human3."
        },
        "Mesh graphormer": {
            "authors": [
                "Kevin Lin",
                "Lijuan Wang",
                "Zicheng Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Lin_Mesh_Graphormer_ICCV_2021_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "31"
            ],
            "1": "The vast majority of previous work [19, 14, 34, 7, 18, 21, 31] uses a parametric human model such as SMPL [24] and focuses on using the SMPL parameter space as a regression target."
        },
        "Monocular human pose estimation: A survey of deep learning-based methods": {
            "authors": [
                "Yucheng Chen",
                "Yingli Tian",
                "Mingyi He"
            ],
            "url": "https://arxiv.org/pdf/2006.01423",
            "ref_texts": "484\u2013494. Ouyang, W., Chu, X., Wang, X., 2014. Multi-source deep learning for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 2329\u20132336. Papandreou, G., Zhu, T., Chen, L.C., Gidaris, S., Tompson, J., Murphy, K., 2018. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. arXiv preprint arXiv:1803.08225 . Papandreou, G., Zhu, T., Kanazawa, N., Toshev, A., Tompson, J., Bregler, C., Murphy, K., 2017. Towards accurate multi-person pose estimation in the wild, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4903\u20134911. Pavlakos, G., Zhou, X., Daniilidis, K., 2018a. Ordinal depth supervision for 3d human pose estimation. arXiv preprint arXiv:1805.04095 . Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1263\u20131272. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K., 2018b. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 . Peng, X., Tang, Z., Yang, F., Feris, R.S., Metaxas, D., 2018. Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 2226\u20132234. Perez-Sala, X., Escalera, S., Angulo, C., Gonzalez, J., 2014. A survey on model based approaches for 2d and 3d visual human pose recovery. Sensors 14, 4189\u20134210. Pfister, T., Charles, J., Zisserman, A., 2015. Flowing convnets for human pose estimation in videos, in: Proc. IEEE International Conference on Computer Vision, pp. 1913\u20131921. Pfister, T., Simonyan, K., Charles, J., Zisserman, A., 2014. Deep convolutional neural networks for e flcient pose estimation in gesture videos, in: Proc. Asian Conference on Computer Vision, Springer. pp. 538\u2013552.Pishchulin, L., Insafutdinov, E., Tang, S., Andres, B., Andriluka, M., Gehler, P.V ., Schiele, B., 2016. Deepcut: Joint subset partition and labeling for multi person pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4929\u20134937. Pons-Moll, G., Romero, J., Mahmood, N., Black, M.J., 2015. Dyna: A model of dynamic human shape in motion. ACM Transactions on Graphics 34, 120. Popa, A.I., Zanfir, M., Sminchisescu, C., 2017. Deep multitask architecture for integrated 2d and 3d human sensing, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4714\u20134723. Poppe, R., 2007. Vision-based human motion analysis: An overview. Computer Vision and Image Understanding 108, 4\u201318. Qammaz, A., Argyros, A., 2019. Mocapnet: Ensemble of snn encoders for 3d human pose estimation in rgb images, in: Proc. British Machine VIsion Conference. Rafi, U., Leibe, B., Gall, J., Kostrikov, I., 2016. An e flcient convolutional network for human pose estimation, in: Proc. British Machine Vision Conference, p. 2. Ramakrishna, V ., Munoz, D., Hebert, M., Bagnell, J.A., Sheikh, Y ., 2014. Pose machines: Articulated pose estimation via inference machines, in: Proc. European Conference on Computer Vision, Springer. pp. 33\u201347. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks, in: Advances in neural information processing systems, pp. 91\u201399. Rhodin, H., Salzmann, M., Fua, P., 2018a. Unsupervised geometry-aware representation for 3d human pose estimation. arXiv:1804.01110 . Rhodin, H., Sp \u00a8orri, J., Katircioglu, I., Constantin, V ., Meyer, F., M \u00a8uller, E., Salzmann, M., Fua, P., 2018b. Learning monocular 3d human pose estimation from multi-view images, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 8437\u20138446. Rogez, G., Weinzaepfel, P., Schmid, C., 2017. Lcr-net: Localizationclassification-regression for human pose, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 3433\u20133441. Rohrbach, M., Amin, S., Andriluka, M., Schiele, B., 2012. A database for fine grained activity detection of cooking activities, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1194\u20131201. Sapp, B., Taskar, B., 2013. Modec: Multimodal decomposable models for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 3674\u20133681. Sapp, B., Weiss, D., Taskar, B., 2011. Parsing human motion with stretchable models, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1281\u20131288. Sarafianos, N., Boteanu, B., Ionescu, B., Kakadiaris, I.A., 2016. 3d human pose estimation: A review of the literature and analysis of covariates. Computer Vision and Image Understanding 152, 1\u201320. Shahroudy, A., Liu, J., Ng, T.T., Wang, G., 2016. Ntu rgb +d: A large scale dataset for 3d human activity analysis, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1010\u20131019. Shotton, J., Girshick, R., Fitzgibbon, A., Sharp, T., Cook, M., Finocchio, M., Moore, R., Kohli, P., Criminisi, A., Kipman, A., et al., 2012. E flcient human pose estimation from single depth images. IEEE transactions on pattern analysis and machine intelligence 35, 2821\u20132840. Sidenbladh, H., De la Torre, F., Black, M.J., 2000. A framework for modeling the appearance of 3d articulated figures, in: Proc. IEEE Conference on Automatic Face and Gesture Recognition, IEEE. pp. 368\u2013375. Sigal, L., Balan, A.O., Black, M.J., 2010. Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International journal of computer vision 87, 4. Sminchisescu, C., 2008. 3d human motion analysis in monocular video: techniques and challenges, in: Human Motion. Springer, pp. 185\u2013211. Sun, K., Xiao, B., Liu, D., Wang, J., 2019. Deep high-resolution representation learning for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition. Sun, X., Shang, J., Liang, S., Wei, Y ., 2017. Compositional human pose regression, in: Proc. IEEE International Conference on Computer Vision, p. 7. Sun, X., Xiao, B., Wei, F., Liang, S., Wei, Y ., 2018. Integral human pose regression, in: Proc. European Conference on Computer Vision, pp. 529\u2013"
        },
        "Pose2mesh: Graph convolutional network for 3d human pose and mesh recovery from a 2d human pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.09047",
            "ref_texts": "52. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018)",
            "ref_ids": [
                "52"
            ],
            "1": "The model-based approach trains a network to predict the model parameters and generates a human mesh by decoding them [5{7, 27, 31, 33, 47, 48, 52].",
            "2": "[52] proposed a system that could be only supervised by 2D joint coordinates and silhouette.",
            "3": "We only evaluate 14 joints out of 17 estimated joints following [27,31,32,52].",
            "4": "[52] 75.",
            "5": "6M deffned joints are evaluated following [27,31,32,52].",
            "6": "6M does not provide 3D mesh annotations, most of the previous 3D pose and mesh estimation papers [27,31,32,52] used the SMPL parameters obtained by Mosh method as the groundtruth for the supervision."
        },
        "Humor: 3d human motion model for robust pose estimation": {
            "authors": [
                "Davis Rempe",
                "Tolga Birdal",
                "Aaron Hertzmann",
                "Jimei Yang",
                "Srinath Sridhar",
                "Leonidas J. Guibas"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Rempe_HuMoR_3D_Human_Motion_Model_for_Robust_Pose_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[58] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "58"
            ],
            "1": "Deep learning approaches have shown success in regressing 3D shape and pose from a single image [39, 34, 58, 25, 24, 87, 16]."
        },
        "Recovering accurate 3d human pose in the wild using imus and a moving camera": {
            "authors": [
                "Roberto Henschel",
                "Michael Black",
                "Bodo Rosenhahn",
                "Gerard Pons"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Timo_von_Marcard_Recovering_Accurate_3D_ECCV_2018_paper.pdf",
            "ref_texts": "22. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning t o estimate 3D human pose and shape from a single color image. In: Proceedings of the I EEE Conference on Computer Vision and Pattern Recognition (2018)",
            "ref_ids": [
                "22"
            ],
            "1": "Some approaches directly predict the parameters of a body model (SMP L) from a single image using 2D supervision [10,22,40]."
        },
        "Convolutional mesh regression for single-image human shape reconstruction": {
            "authors": [
                "Nikos Kolotouros",
                "Georgios Pavlakos",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Kolotouros_Convolutional_Mesh_Regression_for_Single-Image_Human_Shape_Reconstruction_CVPR_2019_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1,3,5,7",
            "ref_ids": [
                "31"
            ],
            "1": "However, the slow running time, the reliance on a good initialization and the typical failures due to bad local minima have recently shifted the focus to learning-based approaches [15,18,28,31,39,43], that regress pose and shape directly from images.",
            "2": "Surface landmarks [18], pose keypoints and silhouettes [31], semantic part segmentation [28], or raw pixels [15] have all been considered as the network input.",
            "3": "[31] rely on a smaller number of keypoints and body silhouettes to regress the SMPL parameters.",
            "4": "They assist us in avoiding the SMPL parameter space, which has been reported to have issues with regression [24,31], while simultaneously allowing the explicit encoding of the graph structure in the network, so that we can leverage spatial locality and preserve the semantic correspondences.",
            "5": ", [31,24], it is challenging to regress the pose parameters \u03b8, which represent3D rotations in the axis-angle representation.",
            "6": "[31] 75.",
            "7": "64 SMPLify on [31] 92.",
            "8": "[31] do not use any Human3."
        },
        "Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation": {
            "authors": [
                "Jiefeng Li",
                "Chao Xu",
                "Zhicun Chen",
                "Siyuan Bian",
                "Lixin Yang",
                "Cewu Lu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_HybrIK_A_Hybrid_Analytical-Neural_Inverse_Kinematics_Solution_for_3D_Human_CVPR_2021_paper.pdf",
            "ref_texts": "[50] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2,8",
            "ref_ids": [
                "50"
            ],
            "1": "Since the mapping from RGB image to shape space and relative body-part rotation is hard to learn, many works use some form of intermediate representation to alleviate this problem, such as keypoints and silhouettes [50], semantic part segmentation [43] and 2D heatmap input [63].",
            "2": "[50] 75."
        },
        "Pymaf: 3d human pose and shape regression with pyramidal mesh alignment feedback loop": {
            "authors": [
                "Hongwen Zhang",
                "Yating Tian",
                "Xinchi Zhou",
                "Wanli Ouyang",
                "Yebin Liu",
                "Limin Wang",
                "Zhenan Sun"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_PyMAF_3D_Human_Pose_and_Shape_Regression_With_Pyramidal_Mesh_ICCV_2021_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1, 2, 6",
            "ref_ids": [
                "42"
            ],
            "1": "Alternatively, regression-based ones [22, 42, 27, 26] suggest to directly predict model parameters from images, which have shown very promising results, and yet still suffer from the coarse alignment between predicted meshes and image evidences.",
            "2": "Similar strategies are also exploited in regression-based methods [22, 42, 27, 26] to impose 2D supervisions upon the projection of estimated meshes in the training procedure.",
            "3": "Alternatively, taking advantage of the powerful nonlinear mapping capability of neural networks, recent regression-based approaches [22, 42, 40, 26, 9, 18, 8] have made significant advances in predicting human models directly from monocular images.",
            "4": "To mitigate the learning difficulty of the regressor, different network architectures have also been designed to leverage proxy representations such as silhouette [42, 54], 2D/3D joints [53, 42, 37], segmentation [40, 45] and dense correspondences [59, 66].",
            "5": "[42] 75.",
            "6": "64 SMPLify on [42] 92."
        },
        "Multi-garment net: Learning to dress 3d people from images": {
            "authors": [
                "Bharat Lal",
                "Garvita Tiwari",
                "Christian Theobalt",
                "Gerard Pons"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Bhatnagar_Multi-Garment_Net_Learning_to_Dress_3D_People_From_Images_ICCV_2019_paper.pdf",
            "ref_texts": "[46] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition , 2018. 2",
            "ref_ids": [
                "46"
            ],
            "1": "Since current statistical models can not represent clothing, most works [7, 26, 40, 68, 48, 32, 22, 67, 31, 50, 8, 33, 44, 46] are restricted to inferring body shape alone."
        },
        "Neural body fitting: Unifying deep learning and model based human pose and shape estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.05942",
            "ref_texts": "[38] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018. 1, 3, 4, 7",
            "ref_ids": [
                "38"
            ],
            "1": "Therefore, like us, a few recent works have proposed hybrid CNN architectures that are trained using model-based loss functions [56, 62, 22, 38].",
            "2": "A few recent works (concurrent to ours) integrate the SMPL [28] model within a network [62, 22, 38].",
            "3": "The approaches differ primarily in the proxy representation used to lift to 3D: RGB images [22], images and 2D keypoints [62] and 2D keypoints and silhouettes [38], and the kind of supervision (3D vs 2D) used for training.",
            "4": "Similar to [24, 38], we observed better performance by imposing the loss on the rotation matrix representation of \u0012rather than on its \u2018native\u2019 axis angle encoding as defined in SMPL.",
            "5": "[38] 75.",
            "6": "[38] do not use any data from Human3.",
            "7": "3\n[38] G."
        },
        "Learning 3d human dynamics from video": {
            "authors": [
                "Angjoo Kanazawa",
                "Jason Y. Zhang",
                "Panna Felsen",
                "Jitendra Malik"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Kanazawa_Learning_3D_Human_Dynamics_From_Video_CVPR_2019_paper.pdf",
            "ref_texts": "[40] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "40"
            ],
            "1": "Very recently, multiple approaches integrate the SMPL body model within a deep learning framework [50,48,40,30,39], where models are trained to directly infer the SMPL parameters.",
            "2": "These methods vary in the cues they use to infer the 3D pose and shape: RGB image [48,30], RGB image and 2D keypoints [50], keypoints and silhouettes [40], or keypoints and body part segmentations [39].",
            "3": "3\n[40] G."
        },
        "3d hand shape and pose estimation from a single rgb image": {
            "authors": [
                "Liuhao Ge",
                "Zhou Ren",
                "Yuncheng Li",
                "Zehao Xue",
                "Yingying Wang",
                "Jianfei Cai",
                "Junsong Yuan"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Ge_3D_Hand_Shape_and_Pose_Estimation_From_a_Single_RGB_CVPR_2019_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CVPR , 2018.",
            "ref_ids": [
                "37"
            ],
            "1": "One straightforward solution is to follow the common approach used in human body shape estimation [53, 48, 37, 22], namely to regress low-dimensional parameters of a predefined deformable hand model, e.",
            "2": "To address this issue, inspired by [5, 37], we propose a novel weaklysupervised method by leveraging depth map as a weak supervision for 3D mesh generation, since depth map can be easily captured by an RGB-D camera when collecting realworld training data.",
            "3": "Some methods regress SMPL parameters using CNNs with supervisions of silhouette and/or 2D keypoints [48, 37, 22]."
        },
        "Star: Sparse trained articulated human body regressor": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.08535",
            "ref_texts": "28. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 459{468 (2018)",
            "ref_ids": [
                "28"
            ],
            "1": "This makes it useful to reason about 3D human body pose and shape given sparse measurements, such as IMU accelerations [11,12,26], sparse mocap markers [22,25] or 2D key points in images and videos [3,14,15,16,28,33,36,38]."
        },
        "Learning joint reconstruction of hands and manipulated objects": {
            "authors": [
                "Yana Hasson",
                "Gul Varol",
                "Dimitrios Tzionas",
                "Igor Kalevatykh",
                "Michael J. Black",
                "Ivan Laptev",
                "Cordelia Schmid"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Hasson_Learning_Joint_Reconstruction_of_Hands_and_Manipulated_Objects_CVPR_2019_paper.pdf",
            "ref_texts": "[41] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "41"
            ],
            "1": "Differentiable hand model Following the methods that integrate the SMPL parametric body model [25] as a network layer [17,41], we integrate the MANO hand model [50] as a differentiable layer.",
            "2": "1,2\n[41] G."
        },
        "Selfrecon: Self reconstruction your digital avatar from monocular video": {
            "authors": [
                "Boyi Jiang",
                "Yang Hong",
                "Hujun Bao",
                "Juyong Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_SelfRecon_Self_Reconstruction_Your_Digital_Avatar_From_Monocular_Video_CVPR_2022_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013",
            "ref_ids": [
                "37"
            ],
            "1": "To represent human clothing, some methods add displacements on SMPL [31] vertices to model tight clothing [2,7,33,37]."
        },
        "Learning to dress 3d people in generative clothing": {
            "authors": [
                "Qianli Ma",
                "Jinlong Yang",
                "Anurag Ranjan",
                "Sergi Pujades",
                "Gerard Pons",
                "Siyu Tang",
                "Michael J. Black"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Ma_Learning_to_Dress_3D_People_in_Generative_Clothing_CVPR_2020_paper.pdf",
            "ref_texts": "[39] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1",
            "ref_ids": [
                "39"
            ],
            "1": "Deep learning methods reconstruct human shape from images, based on minimally dressed human models [5,23,26,27,30,36,38,39]."
        },
        "Putting people in their place: Monocular regression of 3d people in depth": {
            "authors": [
                "Yu Sun",
                "Wu Liu",
                "Qian Bao",
                "Yili Fu",
                "Tao Mei",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_Putting_People_in_Their_Place_Monocular_Regression_of_3D_People_CVPR_2022_paper.pdf",
            "ref_texts": ""
        },
        "Nasa neural articulated shape approximation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.03207.pdf%5C%22",
            "ref_texts": "40. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: CVPR (2018) 1",
            "ref_ids": [
                "40"
            ],
            "1": "Although parametric models of human body such as SMPL [33] have been integrated into neural network frameworks for self-supervision [27,38,40,55], these approaches depend heavily on polygonal mesh representations."
        },
        "Beyond static features for temporally consistent 3d human pose and shape from a video": {
            "authors": [
                "Hongsuk Choi",
                "Gyeongsik Moon",
                "Ju Yong",
                "Kyoung Mu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Choi_Beyond_Static_Features_for_Temporally_Consistent_3D_Human_Pose_and_CVPR_2021_paper.pdf",
            "ref_texts": "[26] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. CVPR , 2018. 1,3",
            "ref_ids": [
                "26"
            ],
            "1": "Most of the previous methods [6,11,15,16,22,26] attempt to recover 3D human pose and shape from a single image.",
            "2": "[26] used 2D joint heatmaps and silhouette as cues for predicting accurate SMPL parameters."
        },
        "Behave: Dataset and method for tracking human object interactions": {
            "authors": [
                "Bharat Lal",
                "Xianghui Xie",
                "Ilya A. Petrov",
                "Cristian Sminchisescu",
                "Christian Theobalt",
                "Gerard Pons"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Bhatnagar_BEHAVE_Dataset_and_Method_for_Tracking_Human_Object_Interactions_CVPR_2022_paper.pdf",
            "ref_texts": "[59] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition , 2018. 2",
            "ref_ids": [
                "59"
            ],
            "1": "Appearance modelling: Humans and objects without scene context Human reconstruction and performance capture Perceiving humans from monocular RGB data [12, 29, 31, 41, 43, 44, 58, 59, 64, 87] and under multiple views [37\u201340, 62] settings has been widely explored."
        },
        "Tex2shape: Detailed full human body geometry from a single image": {
            "authors": [
                "Thiemo Alldieck",
                "Gerard Pons",
                "Christian Theobalt",
                "Marcus Magnor"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Alldieck_Tex2Shape_Detailed_Full_Human_Body_Geometry_From_a_Single_Image_ICCV_2019_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition , 2018. 1,2",
            "ref_ids": [
                "36"
            ],
            "1": "While a large number of papers focus on recovering pose, and rough body shape from a single image [35,25,36, 9], much fewer papers focus on recovering detailed shapes.",
            "2": "In recent work, the SMPL [32] model has been integrated into network architectures [25, 36,35,48]."
        },
        "Simpoe: Simulated character control for 3d human pose estimation": {
            "authors": [
                "Ye Yuan",
                "En Wei",
                "Tomas Simon",
                "Kris Kitani",
                "Jason Saragih"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yuan_SimPoE_Simulated_Character_Control_for_3D_Human_Pose_Estimation_CVPR_2021_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "37"
            ],
            "1": "Alternatively, regression-based approaches use deep neural networks to directly regress the parameters of the SMPL model from an image [52,50,37,34,16,10], using weak supervision from 2D keypoints [52,50,16] or body part segmentation [34,37]."
        },
        "Deepcap: Monocular human performance capture using weak supervision": {
            "authors": [
                "Marc Habermann",
                "Weipeng Xu",
                "Michael Zollhofer",
                "Gerard Pons",
                "Christian Theobalt"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Habermann_DeepCap_Monocular_Human_Performance_Capture_Using_Weak_Supervision_CVPR_2020_paper.pdf",
            "ref_texts": "[62] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "62"
            ],
            "1": "An alternative is to regress model parameters directly [42,62,43].",
            "2": "2\n[62] G."
        },
        "Weakly-supervised mesh-convolutional hand reconstruction in the wild": {
            "authors": [
                "Dominik Kulon",
                "Riza Alp",
                "Iasonas Kokkinos",
                "Michael M. Bronstein",
                "Stefanos Zafeiriou"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Kulon_Weakly-Supervised_Mesh-Convolutional_Hand_Reconstruction_in_the_Wild_CVPR_2020_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "42"
            ],
            "1": "4991\n Body Mesh Recovery Approaches based on regressing MANO parameters described in the previous subsection originate from works on body mesh recovery [3,28,22,48, 42,50,41,39,21,55,25]."
        },
        "Exemplar fine-tuning for 3d human model fitting towards in-the-wild 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.03686",
            "ref_texts": "[50] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "50"
            ],
            "1": "Related Work Deep learning has significantly advanced 2D pose recognition [10,9,63,44,66,57], facilitating the more challenging task of 3D reconstruction [59,60,40,49,48,45,50,27, 35, 65, 11, 58, 56, 13, 43, 12], which is our focus.",
            "2": "Later approaches use instead deep neural networks, and differ mainly in the nature of their inputs and outputs [59,60,40,49,48,45,50,27,35,65,11,67,33,43].",
            "3": "Hence several papers combine 3D indoor datasets with 2D in-the-wild ones [65,35,60,50,45,27,33,58,56]."
        },
        "Single-shot multi-person 3d pose estimation from monocular rgb": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1712.03453",
            "ref_texts": "[42] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "42"
            ],
            "1": "Additional annotations to these 2D image datasets allow some degree of 3D reasoning, either through body joint depth ordering constraints [42] or dense shape correspondences [14].",
            "2": "Some works integrate SMPL within the CNN to exploit 3D and 2D annotations in an end-to-end fashion [39, 25, 42].",
            "3": "[42] G."
        },
        "Deep kinematics analysis for monocular 3d human pose estimation": {
            "authors": [
                "Jingwei Xu",
                "Zhenbo Yu",
                "Bingbing Ni",
                "Jiancheng Yang",
                "Xiaokang Yang",
                "Wenjun Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Deep_Kinematics_Analysis_for_Monocular_3D_Human_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "32"
            ],
            "1": "With the excellent feature extraction capacity of deep neural networks, many approaches [19, 31, 44, 42, 26, 32, 27, 10, 54, 6] utilize Deep Convolutional Neural Networks to estimate 3D poses from the images or other sources (e."
        },
        "XNect: Real-time multi-person 3D motion capture with a single RGB camera": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3386569.3392410",
            "ref_texts": "2018. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation. In 3DV. George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan Tompson, Chris Bregler, and Kevin Murphy. 2017. Towards Accurate Multi-person Pose Estimation in the Wild. In CVPR . Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A. A. Osman, Dimitrios Tzionas, and Michael J. Black. 2019. Expressive Body Capture: 3D Hands, Face, and Body from a Single Image. (2019). Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. 2018a. Ordinal Depth Supervision for 3D Human Pose Estimation. In CVPR . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In CVPR . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018b. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In CVPR . Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele. 2016. DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation. In CVPR . Leonid Pishchulin, Arjun Jain, Mykhaylo Andriluka, Thorsten Thorm\u00e4hlen, and Bernt Schiele. 2012. Articulated people detection and pose estimation: Reshaping the future. In CVPR . IEEE, 3178\u20133185. Gerard Pons-Moll, David J Fleet, and Bodo Rosenhahn. 2014. Posebits for monocular human pose estimation. In CVPR . 2337\u20132344. Alin-Ionut Popa, Mihai Zanfir, and Cristian Sminchisescu. 2017. Deep Multitask Architecture for Integrated 2D and 3D Human Sensing. In CVPR . Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh. 2012. Reconstructing 3d human pose from 2d image landmarks. In ECCV . Springer, 573\u2013586. Mir Rayat Imtiaz Hossain and James J Little. 2018. Exploiting temporal information for 3d human pose estimation. In Proceedings of the European Conference on Computer Vision (ECCV) . 68\u201384. Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. 2019. Regularized evolution for image classifier architecture search. 33 (2019), 4780\u20134789. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster R-CNN: Towards real-time object detection with region proposal networks. In NeurIPS . 91\u201399. Helge Rhodin, Christian Richardt, Dan Casas, Eldar Insafutdinov, Mohammad Shafiei, Hans-Peter Seidel, Bernt Schiele, and Christian Theobalt. 2016a. EgoCap: Egocentric Marker-less Motion Capture with Two Fisheye Cameras. TOG (Proc. SIGGRAPH Asia) (2016). Helge Rhodin, Nadia Robertini, Dan Casas, Christian Richardt, Hans-Peter Seidel, and Christian Theobalt. 2016b. General Automatic Human Shape and Motion Capture Using Volumetric Contour Cues. In ECCV . 509\u2013526. https://doi.org/10.1007/978-3-319-46454-1_31 Gregory Rogez, Philippe Weinzaepfel, and Cordelia Schmid. 2017. LCR-Net: Localization-Classification-Regression for Human Pose. In CVPR . Gr\u00e9gory Rogez, Philippe Weinzaepfel, and Cordelia Schmid. 2019. LCR-Net++: Multi-person 2D and 3D Pose Detection in Natural Images. PAMI (2019). Eduardo Romera, Jos\u00e9 M Alvarez, Luis M Bergasa, and Roberto Arroyo. 2018. Erfnet: Efficient residual factorized convnet for real-time semantic segmentation. IEEE Transactions on Intelligent Transportation Systems 19, 1 (2018), 263\u2013272. Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In CVPR . IEEE, 4510\u20134520. Nikolaos Sarafianos, Bogdan Boteanu, Bogdan Ionescu, and Ioannis A Kakadiaris. 2016.",
            "ref_ids": [
                "2018"
            ],
            "1": "[2018]; Huang et al .",
            "2": "[2018]; Mehta et al .",
            "3": "[2018]; Pavlakos et al .",
            "4": "[2018] compute dense correspondences from pixels to the surface of SMPL [2015], but they do not estimate 3D pose.",
            "5": "9 Hossain & Little [2018] 58."
        },
        "Resolving 3D human pose ambiguities with 3D scene constraints": {
            "authors": [
                "Mohamed Hassan",
                "Vasileios Choutas",
                "Dimitrios Tzionas",
                "Michael J. Black"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Hassan_Resolving_3D_Human_Pose_Ambiguities_With_3D_Scene_Constraints_ICCV_2019_paper.pdf",
            "ref_texts": "[50] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 2",
            "ref_ids": [
                "50"
            ],
            "1": "Recent methods based on deep learning, extend 3D human pose estimation to complex scenes [32,42,48,50] but the 3D accuracy is limited."
        },
        "Optimizing network structure for 3d human pose estimation": {
            "authors": [
                "Hai Ci",
                "Chunyu Wang",
                "Xiaoxuan Ma",
                "Yizhou Wang"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Ci_Optimizing_Network_Structure_for_3D_Human_Pose_Estimation_ICCV_2019_paper.pdf",
            "ref_texts": "[24] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "24"
            ],
            "1": ", [12,22,23,24,29,31, 33,38,39]) treat3D pose estimation as a supervised regression problem."
        },
        "GLAMR: Global occlusion-aware human mesh recovery with dynamic cameras": {
            "authors": [
                "Ye Yuan",
                "Umar Iqbal",
                "Pavlo Molchanov",
                "Kris Kitani",
                "Jan Kautz"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Yuan_GLAMR_Global_Occlusion-Aware_Human_Mesh_Recovery_With_Dynamic_Cameras_CVPR_2022_paper.pdf",
            "ref_texts": "[73] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "73"
            ]
        },
        "Semi-supervised 3d hand-object poses estimation with interactions in time": {
            "authors": [
                "Shaowei Liu",
                "Hanwen Jiang",
                "Jiarui Xu",
                "Sifei Liu",
                "Xiaolong Wang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "42"
            ],
            "1": "We use the weak-perspective camera model and use the SMPLify [42] for the optimization."
        },
        "Cross-attention of disentangled modalities for 3d human mesh recovery with transformers": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.13820",
            "ref_texts": "39.Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2018) 1, 4, 10",
            "ref_ids": [
                "39"
            ],
            "1": "To utilize such models for practical use, monocular methods [2,9,16,17,21 \u201323,25,26,36,39,43,47] estimate the 3D joints and vertices without using 3D scanners or stereo cameras.",
            "2": "The reconstruction methods in the parametric approach [2,9,12,16,17,21,22, 39,43,47] have shown stable performance in monocular 3D human mesh recovery.",
            "3": "2 Evaluation Metrics We evaluate our FastMETRO using three evaluation metrics: MPJPE [15], PA-MPJPE [49], MPVPE [39]."
        },
        "Denserac: Joint 3d pose and shape estimation by dense render-and-compare": {
            "authors": [
                "Yuanlu Xu",
                "Chun Zhu",
                "Tony Tung"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_DenseRaC_Joint_3D_Pose_and_Shape_Estimation_by_Dense_Render-and-Compare_ICCV_2019_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , 2018. 2,4,6,7",
            "ref_ids": [
                "42"
            ],
            "1": "In [51,42,22,39], SMPL is considered as the parametric representation of 3D human body and DNNs are developed to estimate such parameters endto-end.",
            "2": "Loss Terms Our model integrates a dense render-and-compare module with corresponding loss computations in the backward propagation, hence leveraging previous methods [42,22, 39,55].",
            "3": "(CVPR\u201918) [42] 75.",
            "4": "We compare our method with both task-oriented 3D pose state of the art [50,62,34,36,37,9,48,60,16] and four parametric body model based estimators [26,22,42,39]."
        },
        "Coherent reconstruction of multiple humans from a single image": {
            "authors": [
                "Wen Jiang",
                "Nikos Kolotouros",
                "Georgios Pavlakos",
                "Xiaowei Zhou",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Jiang_Coherent_Reconstruction_of_Multiple_Humans_From_a_Single_Image_CVPR_2020_paper.pdf",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "45"
            ],
            "1": "[45] use keypoints and silhouettes, 83\n Omran et al."
        },
        "Exploiting temporal context for 3D human pose estimation in the wild": {
            "authors": [
                "Anurag Arnab",
                "Carl Doersch",
                "Andrew Zisserman"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Arnab_Exploiting_Temporal_Context_for_3D_Human_Pose_Estimation_in_the_CVPR_2019_paper.pdf",
            "ref_texts": "[36] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1,2,7",
            "ref_ids": [
                "36"
            ],
            "1": "Despite its value, the temporal information in mocap datasets is discarded by all current leading 3D pose estimation algorithms [20,36,45,28] which use only single, ambiguous frames.",
            "2": "Moreover, this mesh representation also enables a direct mapping to body part segmentations [23,36,20].",
            "3": "This is done by either solving an optimisation problem to fit the model to the data [7,23,55,6] or by regressing the model parameters directly using a neural network [20,32,36,49] or random forest [23].",
            "4": "Direct regression methods, in contrast, train a neural network where the keypoint [20,32,36] or silhouette reprojection errors are used in its training objective [36,32].",
            "5": "[36] \u2013 75.",
            "6": "2,6\n3403\n\n[36] G."
        },
        "Holopose: Holistic 3d human reconstruction in-the-wild": {
            "authors": [
                "Riza Alp",
                "Iasonas Kokkinos"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Guler_HoloPose_Holistic_3D_Human_Reconstruction_In-The-Wild_CVPR_2019_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 , 2018. 1,2,4,6",
            "ref_ids": [
                "34"
            ],
            "1": "[50,20,23] and for humans in specific [6,24,55,51,52,9,34,54,31,19,60].",
            "2": "As in [51,34,54,31,19] we rely on a parameteric, differentiable human model of shape that allows us to describe the 3D human body surface in terms of a low-dimensional parameter vector, and incorporate it in a holistic system for monocular 3D pose estimation.",
            "3": "Building on this, and as done also in [51,52,9,34,54,31,19,60] we use multiple pose estimation cues to supervise the 3D reconstruction task, now bringing also DensePose [10] as a new supervision signal.",
            "4": "[34] 75."
        },
        "Differentiable rendering: A survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2006.12057",
            "ref_texts": "[10] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018.",
            "ref_ids": [
                "10"
            ],
            "1": "The applications of this process are broad, including image-based training of 3D object reconstruction [7], [8], [9], human pose estimation [10], [11], hand pose estimation [12], [13] and face reconstruction [14], [15].",
            "2": "Application Literature 3D object reconstruction [9], [20], [7], [8], [68], [22], [23], [69], [38], [41], [43], [62], [70], [71], [30], [72], [73], [74], [45] Body shape estimation [11], [10] Hand shape estimation [13], [75], [76] Face reconstruction [77] Object/camera pose estimation [78] Object part segmentation [79] Material estimation [17] Light/shading estimation [80], [81], [82], [83] Adversarial examples [84], [85], [86], [87], [88] Auto-labeling [46] Teeth modeling [89] ground-truth.",
            "3": "[10] .",
            "4": "[10] (Figure 7).",
            "5": "[10] G."
        },
        "Category-level articulated object pose estimation": {
            "authors": [
                "Xiaolong Li",
                "He Wang",
                "Li Yi",
                "Leonidas J. Guibas",
                "Lynn Abbott",
                "Shuran Song"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Category-Level_Articulated_Object_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[20] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "20"
            ],
            "1": "For human pose estimation, approaches have been developed using end-to-end networks to predict 3D joint locations directly [17,23,19], using dense correspondence maps between 2D images and 3D surface models [3], orestimating full 3D shape through 2D supervision [15, 20]."
        },
        "Human mesh recovery from monocular images via a skeleton-disentangled representation": {
            "authors": [
                "Yu Sun",
                "Yun Ye",
                "Wu Liu",
                "Wenpeng Gao",
                "Yili Fu",
                "Tao Mei"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Sun_Human_Mesh_Recovery_From_Monocular_Images_via_a_Skeleton-Disentangled_Representation_ICCV_2019_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR , 2018.",
            "ref_ids": [
                "27"
            ],
            "1": "Previous multi-stage approaches [17, 26, 27] first extract human body information (e.",
            "2": "We outperform previous approaches that output 3D meshes [15, 16, 27, 37] in terms of 3D joint error.",
            "3": "Recently proposed ConvNet-based methods [15, 26, 32, 27, 37, 17, 39, 36] have shown impressive 5350\n Figure 2.",
            "4": "The two-stage methods [26, 27, 17] first predict intermediate results, like human parsing [26], and then predict the SMPL parameters from them.",
            "5": "[27] developed two individual networks to infer pose and shape from silhouettes and keypoint locations separately.",
            "6": "In particular, inspired by [15, 27], angular pose \u03b8\u2208\u0398is converted from rotation vectors to 5353\n Figure 3."
        },
        "Pymaf-x: Towards well-aligned full-body model regression from monocular images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.06400",
            "ref_texts": "[19] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d inCVPR , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "19"
            ],
            "1": "These methods [1], [2], [3], [19] learn to predict model parameters directly from images in a data-driven manner.",
            "2": "Similar strategies are also exploited in regression-based methods [1], [2], [3], [19] to impose 2D supervisions upon the projection of estimated meshes in the training procedure.",
            "3": "Alternatively, taking advantage of the powerful nonlinear mapping capability of neural networks, recent regression-based approaches [1], [3], [15], [19], [28], [49], [50], [51] have made significant advances in predicting human models directly from monocular images.",
            "4": "To mitigate the learning difficulty of the regressor, different network architectures have also been designed to leverage proxy representations such as silhouette [19], [59], 2D/3D joints [4], [18], [19], [42], [49], [50], [52], [60], [61], segmentation [28], [62] and dense correspondences [29], [30].",
            "5": "[19] 75.",
            "6": "[19] G.",
            "7": "Following the common protocols [1], [19], [64], our experiments use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation."
        },
        "Sim2real transfer learning for 3d human pose estimation: motion to the rescue": {
            "authors": [
                "Carl Doersch",
                "Andrew Zisserman"
            ],
            "url": "https://proceedings.neurips.cc/paper/2019/file/d4a93297083a23cc099f7bd6a8621131-Paper.pdf",
            "ref_texts": "[57] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "57"
            ],
            "1": "Similar to our work, state-of-the-art approaches often rely on parametric body models to incorporate strong priors on 3D poses [5,7,8,22,24,34,40,43,52,57,74].",
            "2": "[57] G."
        },
        "3d human motion estimation via motion compression and refinement": {
            "authors": [
                "Zhengyi Luo",
                "Alireza Golestaneh",
                "Kris M. Kitani"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2020/papers/Luo_3D_Human_Motion_Estimation_via_Motion_Compression_and_Refinement_ACCV_2020_paper.pdf",
            "ref_texts": "25. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning t o Estimate 3D Human Pose and Shape from a Single Color Image. Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognitio n (2018) 459\u2013468",
            "ref_ids": [
                "25"
            ],
            "1": "Due to the lack of ground truth 3D labels, these methods use a weakly supervised approach to fit the 3D human body to 2D joint positions [8,23,24], body part segmentation [21,25], or dense pixel correspondence [6]."
        },
        "Pushing the envelope for rgb-based dense 3d hand pose estimation via neural rendering": {
            "authors": [
                "Seungryul Baek",
                "Kwang In",
                "Kyun Kim"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Baek_Pushing_the_Envelope_for_RGB-Based_Dense_3D_Hand_Pose_Estimation_CVPR_2019_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 2,3,4",
            "ref_ids": [
                "35"
            ]
        },
        "Detailed 2d-3d joint representation for human-object interaction": {
            "authors": [
                "Lu Li",
                "Xinpeng Liu",
                "Han Lu",
                "Shiyi Wang",
                "Junqi Liu",
                "Jiefeng Li",
                "Cewu Lu"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Detailed_2D-3D_Joint_Representation_for_Human-Object_Interaction_CVPR_2020_paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "47"
            ],
            "1": "Recently the single-view human body capture and reconstruction methods [45,26, 42,47,4] have made great progresses."
        },
        "Occluded human mesh recovery": {
            "authors": [
                "Rawal Khirodkar",
                "Shashank Tripathi",
                "Kris Kitani"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Khirodkar_Occluded_Human_Mesh_Recovery_CVPR_2022_paper.pdf",
            "ref_texts": "[50] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "50"
            ],
            "1": "While recent approaches [4,11,25,32,43,48,50, 66] perform particularly well in images containing a single person, human mesh recovery for complex real-world scenes with multiple occluded people remains a challenging task."
        },
        "Geo-pifu: Geometry and pixel aligned implicit functions for single-view human reconstruction": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2020/file/690f44c8c2b7ded579d01abe8fdb6110-Paper.pdf",
            "ref_texts": "[26] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "26"
            ],
            "1": "For example, [13,26,16,15,25] estimate or fit the shape and pose coefficients of a SMPL model from the input image."
        },
        "End-to-end hand mesh recovery from a monocular rgb image": {
            "authors": [
                "Xiong Zhang",
                "Qiang Li",
                "Hong Mo",
                "Wenbo Zhang",
                "Wen Zheng"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_End-to-End_Hand_Mesh_Recovery_From_a_Monocular_RGB_Image_ICCV_2019_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "This constraint plays an indispensable role in single RGB image based 3D reconstruction [4, 5, 17, 31, 49]."
        },
        "End-to-end model-based gait recognition": {
            "authors": [
                "Xiang Li",
                "Yasushi Makihara",
                "Chi Xu",
                "Yasushi Yagi",
                "Shiqi Yu",
                "Mingwu Ren"
            ],
            "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Li_End-to-end_Model-based_Gait_Recognition_ACCV_2020_paper.pdf",
            "ref_texts": "38. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning t o estimate 3d human pose and shape from a single color image. In: CVPR. (2018)",
            "ref_ids": [
                "38"
            ],
            "1": ", difficult y of human model fitting) is being resolved by recent advances in deep learn ing-based human model fitting [33,37,38].",
            "2": "[38] used a ConvNet to predict 2D pose heat maps and silhouettes from an RGB image, and then used these to infer the pose and shape parameters of the S MPL through two individual networks."
        },
        "3D dynamic scene graphs: Actionable spatial perception with places, objects, and humans": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2002.06289",
            "ref_texts": "[81] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018.",
            "ref_ids": [
                "81"
            ],
            "1": "While we refer the reader to [45, 46] for a broader review, it is worth mentioning that related work includes optimization-based approaches, which fit a 3D mesh to 2D image keypoints [11, 45, 54, 110, 112], and learning-based methods, which infer the mesh directly from pixel information [39, 45, 46, 79, 81, 99].",
            "2": "[81] G."
        },
        "Object-occluded human shape and pose estimation from a single color image": {
            "authors": [
                "Tianshu Zhang",
                "Buzhen Huang",
                "Yangang Wang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Object-Occluded_Human_Shape_and_Pose_Estimation_From_a_Single_Color_CVPR_2020_paper.pdf",
            "ref_texts": "[33] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InCVPR , 2018. 1,2",
            "ref_ids": [
                "33"
            ],
            "1": "In recent years, deep learning based techniques [17,33,51] have witnessed the rapid progress of recovering the full body human shape from single color images, though most of the existing approaches are addressed for the scenarios that human bod\u2217Contribute equally.",
            "2": "It goes through several stages, including SMPL parameters optimization via fitting to 2D visual cues [3,21], directly regressing the SMPL parameters with Convolutional Neural Network (CNN) [33,30], volumetric representation for 3D human shape [15,43], and 2D UV map representation for the human body geometry surface [51,54].",
            "3": "In order to accurately estimate the pose and shape of the human body from single RGB camera, [17,30,33,55] parameterized the mesh in terms of 3D joint angles and a low dimensional linear shape space.",
            "4": "2,5,7\n[33] G."
        },
        "Ditto: Building digital twins of articulated objects from interaction": {
            "authors": [
                "Zhenyu Jiang",
                "Chun Hsu",
                "Yuke Zhu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_Ditto_Building_Digital_Twins_of_Articulated_Objects_From_Interaction_CVPR_2022_paper.pdf",
            "ref_texts": "[39] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "39"
            ],
            "1": "Developing vision-based methods to automate the estimation [1, 17] and reconstruction [33] of articulated objects has been an active line of research, accelerated by new tools developed from the 3D vision community, including geometric deep learning [19, 37, 39] and implicit neural representations [10, 36]."
        },
        "Weakly supervised 3d human pose and shape reconstruction with normalizing flows": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.10350",
            "ref_texts": "33. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "33"
            ],
            "1": "[33] uses a difierentiable renderer (OpenDR) to compute a silhouette loss with a limited basin of attraction."
        },
        "Learning 3D shape feature for texture-insensitive person re-identification": {
            "authors": [
                "Jiaxing Chen",
                "Xinyang Jiang",
                "Fudong Wang",
                "Jun Zhang",
                "Feng Zheng",
                "Xing Sun",
                "Shi Zheng"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Learning_3D_Shape_Feature_for_Texture-Insensitive_Person_Re-Identification_CVPR_2021_paper.pdf",
            "ref_texts": ""
        },
        "Bcnet: Learning body and cloth shape from a single image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.00214",
            "ref_texts": "38. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 459{468 (2018)",
            "ref_ids": [
                "38"
            ],
            "1": "Several prior works [7,38,3,4] utilize the vertex displacements of body shape represented by SMPL to represent garment geometry.",
            "2": "Based on human body statistical model [32,5,21], many works can estimate naked body shape from image [23,27,38,36,9,14,54].",
            "3": "This design makes garment mesh independent with SMPL mesh and makes our garment model can support more garment topology than SMPL+D methods [7,38,3], if providing corresponding garment training data.",
            "4": "This strategy makes training more stable and continuous [27,37,38].",
            "5": "We compare the reconstruction accuracy of our method with SMPL+D based methods octopus [38] and MGN [7].",
            "6": "However, the reconstructed results by PIFu combine both 3We did not test [38,7] on this dataset as most of the samples are not A-pose."
        },
        "Chore: Contact, human and object reconstruction from a single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.02445",
            "ref_texts": "56. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: IEEE Conf. on Computer Vision and Pattern Recognition (2018)",
            "ref_ids": [
                "56"
            ],
            "1": "Learning-based approaches have also been used to directly regress model parameters such as pose and shape [3,26,38,40,43,54,56] as well as clothing [3,9,27\u201329,36,69]."
        },
        "Three-D Safari: Learning to Estimate Zebra Pose, Shape, and Texture from Images\" In the Wild\"": {
            "authors": [
                "Silvia Zuffi",
                "Angjoo Kanazawa",
                "Tanya Berger",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zuffi_Three-D_Safari_Learning_to_Estimate_Zebra_Pose_Shape_and_Texture_ICCV_2019_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 459\u2013468, 2018.",
            "ref_ids": [
                "23"
            ],
            "1": "[23] estimate 3D body pose and shape of the SMPL model using a two-stage architecture based on 2D keypoints and silhouettes.",
            "2": "[23], we observed that 5364\n a per-vertex loss improves training compared with naive parameter regression."
        },
        "Perceiving 3d human-object spatial arrangements from a single image in the wild": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.15649",
            "ref_texts": "53.Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "53"
            ],
            "1": "Another line of work develops a learning-based framework, using a feed-forward model to directly predict the parameters of the body model from a single image [61,53,30,47,63,44]."
        },
        "Fast and robust multi-person 3d pose estimation from multiple views": {
            "authors": [
                "Junting Dong",
                "Wen Jiang",
                "Qixing Huang",
                "Hujun Bao",
                "Xiaowei Zhou"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Dong_Fast_and_Robust_Multi-Person_3D_Pose_Estimation_From_Multiple_Views_CVPR_2019_paper.pdf",
            "ref_texts": "[33] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InCVPR , 2018. 3",
            "ref_ids": [
                "33"
            ],
            "1": "The advances in learning-based methods also make it possible to recover 3D human pose from a single RGB image, either lifting the detected 2D poses into 3D [28,47, 9,27] or directly regressing 3D poses [40,37,39,45,31] and even 3D body shapes from RGB [4,24,33].",
            "2": "2,6\n[33] G."
        },
        "Barc: Learning to regress 3d dog shape from images by exploiting breed information": {
            "authors": [
                "Nadine Ruegg",
                "Silvia Zuffi",
                "Konrad Schindler",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ruegg_BARC_Learning_To_Regress_3D_Dog_Shape_From_Images_by_CVPR_2022_paper.pdf",
            "ref_texts": "[15] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "15"
            ],
            "1": "Architecture Similar to [15,28], we use separate shape and pose branches."
        },
        "Hierarchical kinematic probability distributions for 3D human shape and pose estimation from images in the wild": {
            "authors": [
                "Akash Sengupta",
                "Ignas Budvytis",
                "Roberto Cipolla"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Sengupta_Hierarchical_Kinematic_Probability_Distributions_for_3D_Human_Shape_and_Pose_ICCV_2021_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1, 2, 4",
            "ref_ids": [
                "40"
            ],
            "1": "Several recent works [53, 20, 27, 26, 46, 63, 12, 37, 14, 40, 39, 54, 35, 52] use deep neural networks to regress a single body shape and pose solution, which can result in impressive 3D body reconstructions given sufficient visual evidence in the input image.",
            "2": "To overcome this, we follow [46, 52, 40, 47] and utilise synthetic data, randomly generated on-the-fly during training.",
            "3": "Inspired by [7], we use convolutional edge filters to close the large synthetic-to-real gap and show that using edge-based inputs yields better performance than commonly-used silhouettebased inputs [46, 52, 47, 40], due to improved robustness and capacity to retain visual shape information.",
            "4": "In contrast, model-based methods [20, 46, 37, 12, 53, 14, 40, 39, 59] regress 3D body model parameters [38, 32, 19, 1], which give a lowdimensional representation of a 3D human body.",
            "5": "Shape prediction accuracy may be improved using synthetic training data [46, 52, 40, 47] consisting of synthetic input proxy representations (PRs) paired with ground-truth body shape and pose.",
            "6": "PRs commonly consist of silhouettes and 2D joint heatmaps [46, 40, 47], necessitating accurate silhouette segmentations [25, 15] at test-time, which is not guaranteed for challenging in-thewild inputs.",
            "7": "Proxy representations [46, 40] are used to close the domain gap between synthetic training images and real test-time RGB images, since synthetic proxy representations are more similar to their real counterparts than synthetic RGB images are to real RGB images."
        },
        "Camera-space hand mesh recovery via semantic aggregation and adaptive 2d-1d registration": {
            "authors": [
                "Xingyu Chen",
                "Yufeng Liu",
                "Chongyang Ma",
                "Jianlong Chang",
                "Huayan Wang",
                "Tian Chen",
                "Xiaoyan Guo",
                "Pengfei Wan",
                "Wen Zheng"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Camera-Space_Hand_Mesh_Recovery_via_Semantic_Aggregation_and_Adaptive_2D-1D_CVPR_2021_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1,2,3",
            "ref_ids": [
                "33"
            ],
            "1": "reconstruction, including [16,17,20,21,23,27,30,31,32, 33,36,39], to name a few.",
            "2": "For example, 2D\n13274\n pose and silhouette have been used to facilitate 3D pose regression [9,20,27,33,42,43,44].",
            "3": "[33] utilized 2D pose to regress pose coefficients and used silhouette to estimate shape coefficients."
        },
        "C3dpo: Canonical 3d pose networks for non-rigid structure from motion": {
            "authors": [
                "David Novotny",
                "Nikhila Ravi",
                "Benjamin Graham",
                "Natalia Neverova",
                "Andrea Vedaldi"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Novotny_C3DPO_Canonical_3D_Pose_Networks_for_Non-Rigid_Structure_From_Motion_ICCV_2019_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proc. CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "30"
            ],
            "1": "This network is inspired by recent approaches [21, 16, 30, 10, 18] that accurately lift 2D keypoints to 3D given a single view of the object.",
            "2": "Besides the fully supervised methods [25, 26], several works have explored multi-view supervision [20, 29, 31], ordinal depth supervision [28], unpaired 2D-3D data [30, 36, 41, 15] or videos [17] to alleviate the need for full 2D-3D annotations."
        },
        "Texturepose: Supervising human mesh estimation with texture consistency": {
            "authors": [
                "Georgios Pavlakos",
                "Nikos Kolotouros",
                "Kostas Daniilidis"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Pavlakos_TexturePose_Supervising_Human_Mesh_Estimation_With_Texture_Consistency_ICCV_2019_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1,2,3,6,7",
            "ref_ids": [
                "35"
            ],
            "1": "Proposed methods [18,31,35,46,47,53] have focused on leveraging all the available sources of 2D an1\n803\n Input image i Predicted shape iCNN Texture map Ai Input image jCNN Predicted shape j Texture map Aj Surface points visible in both images Vij\u223c\n\u223c/vextenddouble/vextenddoubleVij\u2299/parenleftbig Ai\u2212Aj/parenrightbig/vextenddouble/vextenddouble Figure 2: Overview of the proposed texture consistency supervision.",
            "2": ", MoCap and body scans) can also be useful, by applying learned priors [18], or decomposing the task in different architectural components [31,35,53].",
            "3": "Recently, the trend has shifted to directly regressing the model parameters from a single image using deep networks [18,31,35,53].",
            "4": "Weak supervision provided by 2D annotations is typical, with different works employing 2D keypoints, silhouettes and semantic parts [18,31,35,46].",
            "5": "Previous works [18,35] typically employ this dataset because of the large number of 2D keypoint annotations.",
            "6": "[35] 75.",
            "7": "64 SMPLify on [35] 92.",
            "8": "sidering that strong non-parametric baselines [26,33] typically perform better than parametric approaches [18,35] (at least under the 3D joints metrics)."
        },
        "Accurate 3D body shape regression using metric and semantic attributes": {
            "authors": [
                "Vasileios Choutas",
                "Lea Muller",
                "Hao P. Huang",
                "Siyu Tang",
                "Dimitrios Tzionas",
                "Michael J. Black"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Choutas_Accurate_3D_Body_Shape_Regression_Using_Metric_and_Semantic_Attributes_CVPR_2022_paper.pdf",
            "ref_texts": "[44] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "44"
            ],
            "1": "Second, 2D shape cues for in-the-wild images, (bodypart segmentation masks [12,41,48], silhouettes [1,22,44]) are attractive, as these can be manually annotated or automatically detected [15, 18]."
        },
        "Detailed human avatars from monocular video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.01338",
            "ref_texts": "[60] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition , 2018. 1, 2",
            "ref_ids": [
                "60"
            ],
            "1": "Monocular RGB methods are typically restricted to prediciting the parameters of a statistical body model [58, 42, 60, 10, 5, 35].",
            "2": "Model based monocular methods [10, 23, 32, 5, 35, 66, 65] have recently been integrated with deep learning [58, 42, 60].",
            "3": "1, 2\n[60] G."
        },
        "Keypoint transformer: Solving joint identification in challenging hands and object interactions for accurate 3d pose estimation": {
            "authors": [
                "Shreyas Hampali",
                "Sayan Deb",
                "Mahdi Rad",
                "Vincent Lepetit"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Conference on Computer Vision and Pattern Recognition , 2018. 1, 5, 8",
            "ref_ids": [
                "40"
            ],
            "1": "Many approaches have been proposed, mostly based on direct prediction with different convolutional network architectures [15, 18, 29, 36, 44, 49, 61] of the 3D joint locations or angles, or relying on rendering for fine pose estimation and tracking [2, 12, 32, 40, 50].",
            "2": "Previous methods [14,15,19,38,40] have noted that regressing model parameters such as joint angles is less accurate in terms of joint error than regressing the joint locations directly.",
            "3": "5D representations are similar, the joint angle representation results in lower accuracy, in line with the observation from previous works [14, 15, 19, 38, 40]."
        },
        "Apollocar3d: A large 3d car instance understanding benchmark for autonomous driving": {
            "authors": [
                "Xibin Song",
                "Peng Wang",
                "Dingfu Zhou",
                "Rui Zhu",
                "Chenye Guan",
                "Yuchao Dai",
                "Hao Su",
                "Hongdong Li",
                "Ruigang Yang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Song_ApolloCar3D_A_Large_3D_Car_Instance_Understanding_Benchmark_for_Autonomous_CVPR_2019_paper.pdf",
            "ref_texts": "[48] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProc. IEEE Conf. Comp. Vis. Patt. Recogn. , June 2018.[49] P. Poirson, P. Ammirato, C.-Y . Fu, W. Liu, J. Kosecka, and A. C. Berg. Fast single shot detection and pose estimation. In3dv, pages 676\u2013684. IEEE, 2016.",
            "ref_ids": [
                "48",
                "49"
            ],
            "1": "impressive results with supervised [18, 69, 43, 46, 57, 54, 63, 70, 6, 32, 49, 38, 3, 66] or weakly supervised strategies [28, 48, 24].",
            "2": "Existing works consider to represent an object as a parameterized 3D bounding box [18, 54, 57, 49], coarse wire-frame skeletons [14, 32, 62, 69, 68], voxels [9], one-hot selection from a small set of exemplar models [3, 45, 1], and point clouds [17].",
            "3": "[48] G.",
            "4": "[49] P."
        },
        "Body meshes as points": {
            "authors": [
                "Jianfeng Zhang",
                "Dongdong Yu",
                "Jun Hao",
                "Xuecheng Nie",
                "Jiashi Feng"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Body_Meshes_as_Points_CVPR_2021_paper.pdf",
            "ref_texts": "[48] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018.[49] Alin-Ionut Popa, Mihai Zanfir, and Cristian Sminchisescu. Deep multitask architecture for integrated 2d and 3d human sensing. In CVPR , 2017.",
            "ref_ids": [
                "48",
                "49"
            ],
            "1": "Related Work Single-person 3D pose and shape Previous works estimate 3D poses in the form of body skeleton [37,40,60,74,49, 47,58,71,15] or non-parametric 3D shape [13,56,62].",
            "2": ", keypoints, silhouettes, etc) from images and then map it to SMPL parameters [48,44,61,27].",
            "3": "[49] Alin-Ionut Popa, Mihai Zanfir, and Cristian Sminchisescu."
        },
        "Detailed human shape estimation from a single image by hierarchical mesh deformation": {
            "authors": [
                "Hao Zhu",
                "Xinxin Zuo",
                "Sen Wang",
                "Xun Cao",
                "Ruigang Yang"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhu_Detailed_Human_Shape_Estimation_From_a_Single_Image_by_Hierarchical_CVPR_2019_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018. 1,2,3",
            "ref_ids": [
                "23"
            ],
            "1": "A large number of approaches [8,5,6,31,17, 32,23,16,21] have been proposed in which the human body shapes get reconstructed by predicting the parameters of a statistical body shape model, such as SMPL [20] and SCAPE [3].",
            "2": "[23] separated the SMPL parameters prediction network into two sub-networks.",
            "3": "However, like other human shape recovery methods [23,21,5] that utilize the SMPL model, the HMR method predicts the shape and pose parameters to generate a skinned mesh model with limited flexibility to closely fit the input image or express surface details."
        },
        "3d human mesh regression with dense correspondence": {
            "authors": [
                "Wang Zeng",
                "Wanli Ouyang",
                "Ping Luo",
                "Wentao Liu",
                "Xiaogang Wang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zeng_3D_Human_Mesh_Regression_With_Dense_Correspondence_CVPR_2020_paper.pdf",
            "ref_texts": "[26] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "26"
            ],
            "1": "Because of its compatibility with existing computer graphic engines and the efficiency to represent object surface in details with reasonable storage, 3D mesh representation has been widely adopted for 3D human body reconstruction [18, 4, 20, 8, 27, 38, 11, 26, 25, 37, 21, 39].",
            "2": "Due to this limitation, most existing 3D mesh based methods, either modelbased [18, 26, 25, 20] or model-free [21], have to ignore the correspondence between the mesh representation and pixel representation.",
            "3": "In order to mitigate the lack of robustness caused by the inadequacy of in-the-wild training data, some approaches employ intermediate representations, such as 2D joint heatmaps and silhouette [26], semantic segmentation map [25] or IUV image [36].",
            "4": "[26] 75.",
            "5": "67 SMPLify on [26] 92.",
            "6": "[26] G."
        },
        "Neural monocular 3d human motion capture with physical awareness": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3450626.3459825",
            "ref_texts": "2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Computer Vision and Pattern Recognition (CVPR) . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) . Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 2019. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Computer Vision and Pattern Recognition (CVPR) . Xue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel van de Panne. 2018a. Deepmimic: Example-guided deep reinforcement learning of physics-based character skills. ACM Transactions on Graphics (TOG) 37, 4 (2018). Xue Bin Peng, Angjoo Kanazawa, Jitendra Malik, Pieter Abbeel, and Sergey Levine.",
            "ref_ids": [
                "2017"
            ],
            "1": "[2017] estimate 3D human poses along with the inner and exterior forces from images for object lifting and walking."
        },
        "Learning to reconstruct people in clothing from a single RGB camera": {
            "authors": [
                "Thiemo Alldieck",
                "Marcus Magnor",
                "Bharat Lal",
                "Christian Theobalt",
                "Gerard Pons"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Alldieck_Learning_to_Reconstruct_People_in_Clothing_From_a_Single_RGB_CVPR_2019_paper.pdf",
            "ref_texts": "[55] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition , 2018. 1,3,5,6",
            "ref_ids": [
                "55"
            ],
            "1": "Some methods attempt to infer the shape parameters of a body model from a single image [41,53,10,24,8,32,86,39,55], but reconstructed detail is constrained to the model shape space, and thus does not capture personalized shape detail and clothing geometry.",
            "2": "Other recent works integrate the SMPL model, or a voxel representation [74], as a layer within a network architecture [41,55,53,73].",
            "3": "Similar to [53,43,55], we use differentiable SVD to force the predicted matrices to lie on the manifold of rotation matrices.",
            "4": "In other works [53,41,55] authors have assumed fixed distance to the cam1179\n era.",
            "5": "We use a similar training schedule for our pose branch as [55], where we first train the network using losses on the joints and pose parameters (LJ3D,L\u03b8,t) followed by training using losses on the vertices and pose parameters (LN3D,L\u03b8,t)."
        },
        "Frankmocap: Fast monocular 3d hand and body motion capture by regression and integration": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.08324",
            "ref_texts": "[39] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proc. CVPR , 2018. 2",
            "ref_ids": [
                "39"
            ],
            "1": "Various types of inputs are considered in these deep network approaches, including single RGB images [20], 2D keypoint heatmaps [39], body part segmentation [35] or densepose maps [44, 56]."
        },
        "Recovering 3d human mesh from monocular images: A survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.01923",
            "ref_texts": "[17] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d inCVPR , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "17"
            ],
            "1": "In recent years, the community has shifted its interests towards 3D mesh recovery of human bodies [13], [14], [15], [16], [17], [18], [19], [20], [21] along with expressive face and hands [22], [23], [24], [25], [26].",
            "2": "Alternatively, the regression-based paradigm [16], [17], [18], [43], [44] takes advantage of the powerful nonlinear mapping capability of neural networks and directly predicts model parameters from raw image pixels.",
            "3": "The majority of image-based human mesh recovery methods [16], [17], [18], [19], [20], [25], [44], [111], [114], [115], [116], [117], [118], [119], [120] choose to regress the parameters of the parametric models directly.",
            "4": "Intuitively, networks can directly regress a vector corresponding to joint rotations in axis angle [16], [17], [121], [122], [123], [124].",
            "5": "In this case, they are also referred to as \u201cproxy representation\u201d, such as silhouettes [17], [116], [142], segmentations [18], [118], [147], [148], 2D heatmaps [17], [116], [118], [128], [142], [149], 2D keypoint coordinates [150], optical flow [149], [151], IUV [122], [126], [139], 3D keypoint coordinates [111], [128], [150], and surface markers [137].",
            "6": "Compared to the synthesis of raw RGB images, proxy inputs lead to a smaller syntheticto-real domain gap which is more readily bridged by data augmentation [17], [116], [122], [149], [152].",
            "7": "We can supervise the pose parameters \u03b8in the form of axis angle [16], [117], [124], [154], rotation matrix [17], [18], [114], [115], [122], [123], [126], [155], or a6D representation [16], [17], [18].",
            "8": "Once mesh vertices are obtained, we can compute 3D joints using a pre-trained linear regressor and penalize the distance between regressed 3D joints and ground truth [16], [17], [18].",
            "9": "Given predicted mesh vertices and the corresponding ground truth vertices, we can also supervise the network with an additional 3D per-vertex loss [17], [116], [132], [135].",
            "10": "A direct strategy is regressing body model parameters on top of intermediate predictions, including 2D/3D joints [17], [25], [118], [142], [150], sihouettes [17], [142], semantic parts [18], [118], [148], and IUV [122], [126].",
            "11": "Pavlakos [17] design a two-branch network.",
            "12": "FramebasedSingle PersonOutput Typea) Template paramters : [16], [17], [18], [19], [20], [21], [25], [44], [106], [110], [111], [115], [116], [117], [118], [119], [122], [124], [126], [127], [141], [147], [154], [168] b) 3D vertex coordinates : GraphCMR [132], Pose2Mesh [150], I2L-MeshNet [133], PC-HMR [136], METRO [135], Graphormer [134] c) Voxels : BodyNet [130], DeepHuman [131] d) UV position maps : DenseBody [138], DecoMR [139], Zhang et al.",
            "13": "[17], STRAPS [116], Skeleton2Mesh [110] b) Segmentations : NBF [18], Rueegg et al.",
            "14": "[17], STRAPS [116], Zanfir et al.",
            "15": "[17], NBF [18], DenseRac [122], DaNet [126], Zanfir et al.",
            "16": "[140], PARE [20], THUNDR [137], HUND [148], Skeleton2Mesh [110] c) Multi-branch : Pavlakos [17], HoloPose [106], DaNet [126], HKMR [124], PARE [20] Multiple Persona) Top-down : Jiang et al.",
            "17": "Alignment2D Lossa) 2D keypoints : [13], [16], [17], [18], [19], [20], [21], [22], [23], [25], [43], [44], [99], [105], [118], [119], [121], [122], [126], [135], [177] b) Silhouettes : Balan et al.",
            "18": "[17], Zhang et al.",
            "19": "[155], DenseRac [122], DaNet [126], PyMAF [19]\n3D Lossa) Parameters : [16], [17], [18], [19], [20], [21], [22], [23], [25], [25], [44], [99], [118], [119], [121], [126], [177] b) 3D keypoints : [16], [17], [18], [19], [20], [21], [23], [25], [99], [111], [116], [119], [122], [126], [133], [134], [135], [177] c) Per-vertex : [17], [25], [115], [116], [118], [126], [132], [133], [134], [135] d) Surface (edge/normal) : Pose2Mesh [150], I2L-MeshNet [133] Physical PlausibilityContact/ InterpenetrationSMPLify [13], Zanfir et al.",
            "20": "[17] CVPR\u201918 Parameters [42] 75.",
            "21": "In general, ResNet-50 [157] serves as a generic convolutional backbone to extract features from images, except that [134], [135] use HRNet [158] and multi-stage pipelines [17], [18], [114], [140], [149] have multiple convolutional modules.",
            "22": "[17] G."
        },
        "S3: Neural shape, skeleton, and skinning fields for 3d human modeling": {
            "authors": [
                "Ze Yang",
                "Shenlong Wang",
                "Sivabalan Manivasagam",
                "Zeng Huang",
                "Chiu Ma",
                "Xinchen Yan",
                "Ersin Yumer",
                "Raquel Urtasun"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_S3_Neural_Shape_Skeleton_and_Skinning_Fields_for_3D_Human_CVPR_2021_paper.pdf",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "45"
            ],
            "1": "Later works proposed to estimate 3D pose and shape from a single image by minimizing the joint re-projection error [10,25], silhouettes re-projection error with a differentiable renderer [57,45]."
        },
        "mmMesh: Towards 3D real-time dynamic human mesh construction using millimeter-wave": {
            "authors": [
                "Hongfei Xue",
                "Yan Ju",
                "Chenglin Miao",
                "Yijiang Wang",
                "Shiyang Wang",
                "Aidong Zhang",
                "Lu Su"
            ],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3458864.3467679",
            "ref_texts": "[26] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings oftheIEEE Conference onComputer Vision andPattern Recognition. 459\u2013468.",
            "ref_ids": [
                "26"
            ],
            "1": "3D Human Mesh Construction: With the proliferation of deep learning, recent works explore various deep learning models to directly reconstruct 3D human mesh from images [6,17,20,26, 33,42,51], videos [4,11,18,33,40,45], point cloud [12,15,36,37], and wireless signals [48]."
        },
        "Who left the dogs out? 3d animal reconstruction with expectation maximization in the loop": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.11110",
            "ref_texts": "27. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: Proc. CVPR (2018)",
            "ref_ids": [
                "27"
            ],
            "1": "2 Training losses A common approach for training such an end-to-end system would be to supervise the prediction of (\u0012;ff;t;f ) with 3D ground truth annotations [20,14,27]."
        },
        "Photo wake-up: 3d character animation from a single photo": {
            "authors": [
                "Yi Weng",
                "Brian Curless",
                "Ira Kemelmacher"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Weng_Photo_Wake-Up_3D_Character_Animation_From_a_Single_Photo_CVPR_2019_paper.pdf",
            "ref_texts": "[43] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 , 2018. 2",
            "ref_ids": [
                "43"
            ],
            "1": "Further, using deep networks and the SMPL model, [49,29,43,42] present end-to-end frameworks for single view body pose and shape estimation.",
            "2": "2\n[43] G."
        },
        "Capturing humans in motion: Temporal-attentive 3D human pose and shape estimation from monocular video": {
            "authors": [
                "Li Wei",
                "Chun Lin",
                "Luh Liu",
                "Yuan Mark"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Wei_Capturing_Humans_in_Motion_Temporal-Attentive_3D_Human_Pose_and_Shape_CVPR_2022_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1, 2",
            "ref_ids": [
                "31"
            ],
            "1": "Different from 3D human pose and shape estimation from a single image [11, 17, 21, 29, 31], estimating it from monocular video is a more complex task [6,8,18,20,25,34].",
            "2": "[31] used 2D joint heatmaps and silhouette as cues to improve the accuracy of SMPL parameter estimation.",
            "3": "6\n[31] G."
        },
        "Compressed volumetric heatmaps for multi-person 3d pose estimation": {
            "authors": [
                "Matteo Fabbri",
                "Fabio Lanzi",
                "Simone Calderara",
                "Stefano Alletto",
                "Rita Cucchiara"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Fabbri_Compressed_Volumetric_Heatmaps_for_Multi-Person_3D_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 2",
            "ref_ids": [
                "30"
            ],
            "1": "Joint learning of 2D and 3D pose is also shown to be beneficial [22,6,50,54,44,27,14,30], often in conjunction with large-scale datasets that only provide 2D pose groundtruth and exploiting anatomical or structure priors."
        },
        "Hierarchical kinematic human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.04232",
            "ref_texts": "28. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR . IEEE, 2018.",
            "ref_ids": [
                "28"
            ],
            "1": "With the increasing adoption of parametric human models such as SMPL [9], several methods shifted focus to regressing the model parameters [27,5,28,29,30,31,32].",
            "2": "64 SMPLify+[28] 92."
        },
        "Learning to regress bodies from images using differentiable semantic rendering": {
            "authors": [
                "Sai Kumar",
                "Nikos Athanasiou",
                "Muhammed Kocabas",
                "Michael J. Black"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Dwivedi_Learning_To_Regress_Bodies_From_Images_Using_Differentiable_Semantic_Rendering_ICCV_2021_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 1, 2, 3, 7",
            "ref_ids": [
                "34"
            ],
            "1": "Introduction Estimating 3D human pose and shape from in-the-wild images has received great research interest [5, 14, 15, 18, 20, 30, 34, 54] because of its varied applications in animation, games, and the fashion industry.",
            "2": "To circumvent this problem, recent approaches [30, 34, 50] propose to use part-segmentations or silhouettes.",
            "3": "Laterwork uses 2D keypoints, background segmentation, and SMPL to extract 3D bodies from images [44], similar to [34] who use silhouettes for supervision.",
            "4": "[34] 75.",
            "5": "We perform significantly better than previous approaches that use ground-truth part-segmentation or silhouettes [30, 34, 52] compared to our weak supervision."
        },
        "Weakly-supervised discovery of geometry-aware representation for 3d human pose estimation": {
            "authors": [
                "Xipeng Chen",
                "Yee Lin",
                "Wentao Liu",
                "Chen Qian",
                "Liang Lin"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Weakly-Supervised_Discovery_of_Geometry-Aware_Representation_for_3D_Human_Pose_Estimation_CVPR_2019_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "23"
            ],
            "1": "Some approaches try to represent body shape through multiple view images acquired by synchronized cameras with the usage of view-consistency property [27], pre-defined parametric 3D model fitting [3, 23, 10], or by sequence with the usage of time-independent features [13].",
            "2": "[23] proposes to learn the parameters of the statistical model SMPL [16] to obtain 3D mesh from image with an end-to-end network, and regresses 3d coordinates from the mesh."
        },
        "Single image 3D object reconstruction based on deep learning: A review": {
            "authors": [
                "Kui Fu"
            ],
            "url": "https://bibbase.org/service/mendeley/bfbbf840-4c42-3914-a463-19024f50b30c/file/50ce3995-76fc-91ef-3ac9-84c5c9cff6e6/s11042_020_09722_8.pdf.pdf",
            "ref_texts": "81. Pavlakos G, Zhu L, Zhou X, Daniilidis K (2018) Learning to estimate 3D human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 459 \u2013468",
            "ref_ids": [
                "81"
            ],
            "1": "At present, some studies have used voxel-based and mesh-based methods to study the 3D human pose estimation of a single image [80,81]."
        },
        "A-nerf: Articulated neural radiance fields for learning human shape, appearance, and pose": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/65fc9fb4897a89789352e211ca2d398f-Paper.pdf",
            "ref_texts": "[45] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "45"
            ],
            "1": "It also enables optimization within the bounds of the learned prior [11,16,25] and weak-supervision when integrated in a differentiable form [27] into neural training processes [4,20,23,42,45,65].",
            "2": "[45] G."
        },
        "Motionet: 3d human motion reconstruction from monocular video with skeleton consistency": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2006.12075",
            "ref_texts": "\u201917). IEEE Computer Society, Washington, DC, USA, 1263\u20131272. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018b. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Proceedings of the 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR \u201918) . IEEE Computer Society, Washington, DC, USA. Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 2019. 3D human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR \u201919) . IEEE Computer Society, Washington, DC, USA. Dario Pavllo, David Grangier, and Michael Auli. 2018. QuaterNet: A Quaternion-based Recurrent Model for Human Motion. arXiv:cs.CV/1805.06485 Xue Bin Peng, Angjoo Kanazawa, Jitendra Malik, Pieter Abbeel, and Sergey Levine."
        },
        "Textured neural avatars": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/2b/50/6c/40d17447aa279f/US11367239.pdf",
            "ref_texts": " L. Liu , W. Xu , M. Zollhoefer , H. Kim , F. Bernard , M. Habermann , W. Wang , and C. Theobalt . Neural animation and reenactment of human actor videos . arXiv preprint arXiv : 1809.03658 , 2018 . S. Lombardi , J. Saragih , T. Simon , and Y. Sheikh . Deep appearance models for face rendering . ACM Transactions on Graphics (TOG ) , 37 (4 ) : 68 , 2018 M. Loper , N. Mahmood , J. Romero , G. Pons Moll , and M. J. Black . Smpl : A skinned multi person linear model . ACM Transactions on Graphics (TOG ) , 34 (6 ) : 248 , 2015 . M. Mori . The uncanny valley . Energy , 7 (4 ) : 33-35 , 1970 . F. Mueller , F. Bernard , O. Sotnychenko , D. Mehta , S. Sridhar , D. Casas , and C. Theobalt . Ganerated hands for realtime 3d hand tracking from monocular rgb . In the IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , Jun . 2018 . N. Neverova , R. A. Guler , and I. Kokkinos . Dense pose transfer . In the European Conference on Computer Vision (ECCV ) , Sep. 2018 . G. Pavlakos , L. Zhu , X. Zhou , and K. Daniilidis . Learning to estimate 3d human pose and shape from a single color image . In the IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , Jun . 2018 . G. Pons Moll , J. Romero , N. Mahmood , and M. J. Black . Dyna : A model of dynamic human shape in motion . ACM Transactions on Graphics (TOG ) , 34 (4 ) : 120 , 2015 . (56 ) References. Cited "
        },
        "Doublefusion: Real-time capture of human performances with inner body shapes from a single depth sensor": {
            "authors": [
                "Tao Yu",
                "Zerong Zheng",
                "Kaiwen Guo",
                "Jianhui Zhao",
                "Qionghai Dai",
                "Hao Li",
                "Gerard Pons",
                "Yebin Liu"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_DoubleFusion_Real-Time_Capture_CVPR_2018_paper.pdf"
        },
        "Through-wall human mesh recovery using radio signals": {
            "authors": [
                "Mingmin Zhao",
                "Yingcheng Liu",
                "Aniruddh Raghu",
                "Tianhong Li",
                "Hang Zhao",
                "Antonio Torralba",
                "Dina Katabi"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhao_Through-Wall_Human_Mesh_Recovery_Using_Radio_Signals_ICCV_2019_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3,7",
            "ref_ids": [
                "36"
            ],
            "1": "More recent work [23,36] captured 3D meshes from 2D images using adversarial loss, and Kanazawa et al.",
            "2": "8 cm [36]."
        },
        "Synthetic training for accurate 3d human pose and shape estimation in the wild": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.10013",
            "ref_texts": "[24] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "24"
            ],
            "1": "Recently, several deep-learning-based methods have been proposed [8, 15, 16, 22, 24, 27, 29, 32, 34].",
            "2": "Several approaches first predict a proxy representation from the input RGB image, such as surface keypoints [17, 24], silhouettes [24, 27], body part segmentations [22] or IUV maps [32, 34], and use this representation as the input to a regressor.",
            "3": "[24] 75."
        },
        "3d multi-bodies: Fitting sets of plausible 3d human models to ambiguous image data": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2020/file/ebf99bb5df6533b6dd9180a59034698d-Paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proc. CVPR , 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "More recently, methods have focused on regressing the parameters of the 3D models directly, in a feed-forward manner , generally by learning a deep neural network [42, 43, 30, 31, 17].",
            "2": "In most cases, the integration is done by using a deep regressor to initialize the optimization algorithm [37, 21, 33, 31, 44].",
            "3": "The final loss terms, introduced by prior work [18, 31, 19], penalize deviations between the predicted and ground truth SMPL parameters.",
            "4": "For completeness, we also compare to three more baselines that tackle the standard single-mesh prediction problem: HMR [17], GraphCMR [31], and SPIN [19], where the latter currently attain state-of-the-art performance on H36M/3DPW."
        },
        "xr-egopose: Egocentric 3d human pose from an hmd camera": {
            "authors": [
                "Denis Tome",
                "Patrick Peluse",
                "Lourdes Agapito",
                "Hernan Badino"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Tome_xR-EgoPose_Egocentric_3D_Human_Pose_From_an_HMD_Camera_ICCV_2019_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 2,5",
            "ref_ids": [
                "33"
            ],
            "1": "Recent advances are due to combining the 2D and 3D tasks into a joint estimation [41,42] and using weakly [54,48,50,9,33] or selfsupervised losses [49,38] or mixing 2D and 3D data for training [46].",
            "2": "Instead, similarly to [33], our approach regresses the 3D pose from heatmaps,not just 2D locations."
        },
        "Simulcap: Single-view human performance capture with cloth simulation": {
            "authors": [
                "Tao Yu",
                "Zerong Zheng",
                "Yuan Zhong",
                "Jianhui Zhao",
                "Qionghai Dai",
                "Gerard Pons",
                "Yebin Liu"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Yu_SimulCap__Single-View_Human_Performance_Capture_With_Cloth_Simulation_CVPR_2019_paper.pdf"
        },
        "Jiff: Jointly-aligned implicit face function for high quality single view clothed human reconstruction": {
            "authors": [
                "Yukang Cao",
                "Guanying Chen",
                "Kai Han",
                "Wenqi Yang",
                "Yee K. Wong"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Cao_JIFF_Jointly-Aligned_Implicit_Face_Function_for_High_Quality_Single_View_CVPR_2022_paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "47"
            ],
            "1": "Labels like body part segmentation [41], silhouette [47], and IUV map [64] have been employed to provide intermediate supervisions for training SMPL prediction models."
        },
        "Probabilistic 3D human shape and pose estimation from multiple unconstrained images in the wild": {
            "authors": [
                "Akash Sengupta",
                "Ignas Budvytis",
                "Roberto Cipolla"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Sengupta_Probabilistic_3D_Human_Shape_and_Pose_Estimation_From_Multiple_Unconstrained_CVPR_2021_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shapefrom a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "41"
            ],
            "1": "Recent solutions have focused on three types of inputs: i) single images [7,48,19,27,28, 57,36,45,38,41,50], ii) video [26,20,47,40,16] with temporal constraints on pose, camera viewpoint and background conditions and iii) multi-view images [32,46] with a fixed subject pose captured from multiple viewpoints.",
            "2": "Model-based approaches [19,57,38,41,48,10,12] predict the parameters of a 3D body model [33,39,2,18], which provides a useful prior over human body shape.",
            "3": "The use of silhouette and joint heatmap representations 16096\n as inputs instead of RGB images is inspired by [41,45] and allows us to train our distribution prediction network using a simple synthetic training framework (see Section 3.",
            "4": "Furthermore, adaptive weighting means that our network is able to train stably without additional \u201cglobal\u201d losses on 3D vertices or 3D joints, as is common in most other recent methods [45,41,27,19,57]."
        },
        "Learned vertex descent: A new direction for 3d human model fitting": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.06254",
            "ref_texts": "60. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR. pp. 459{468 (2018)",
            "ref_ids": [
                "60"
            ],
            "1": "keypoints [42], keypoints plus silhouette [60] or part segmentation maps [54]."
        },
        "Eventcap: Monocular 3d capture of high-speed human motions using an event camera": {
            "authors": [
                "Lan Xu",
                "Weipeng Xu",
                "Vladislav Golyanik",
                "Marc Habermann",
                "Lu Fang",
                "Christian Theobalt"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_EventCap_Monocular_3D_Capture_of_High-Speed_Human_Motions_Using_an_CVPR_2020_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , 2018. 2",
            "ref_ids": [
                "42"
            ],
            "1": "To solve this problem, recent works regress joint angles directly from the images [26,28,38,42,54]."
        },
        "Shape-aware human pose and shape reconstruction using multi-view images": {
            "authors": [
                "Junbang Liang",
                "Ming C. Lin"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Liang_Shape-Aware_Human_Pose_and_Shape_Reconstruction_Using_Multi-View_Images_ICCV_2019_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3,13",
            "ref_ids": [
                "33"
            ],
            "1": "Recent works [30,33,20] tackle the human body estimation problem using various approaches; our method offers better performance in either singleor multi-view inputs by comparison (see Appendix C)."
        },
        "Human body model fitting by learned gradient descent": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.08474",
            "ref_texts": "30.Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 459\u2013468 (2018)",
            "ref_ids": [
                "30"
            ],
            "1": "[30] Yes 75."
        },
        "Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation": {
            "authors": [
                "Bastian Wandt",
                "Bodo Rosenhahn"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.pdf",
            "ref_texts": "[29] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "29"
            ],
            "1": "Several works try to build an endto-end system which extracts the 3D pose from the image data [27,8,21,23,28,32,19,17,26,29,36,45].",
            "2": "1,2, 6\n[29] G."
        },
        "Delving deep into hybrid annotations for 3d human recovery in the wild": {
            "authors": [
                "Yu Rong",
                "Ziwei Liu",
                "Cheng Li",
                "Kaidi Cao",
                "Chen Change"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Rong_Delving_Deep_Into_Hybrid_Annotations_for_3D_Human_Recovery_in_ICCV_2019_paper.pdf",
            "ref_texts": "[21] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 1,2,5,7,8",
            "ref_ids": [
                "21"
            ],
            "1": "Recent studies [23,13,20,21] typically use a parametric model known 1Code and models are available at the project page: https:// penincillin.",
            "2": "Other recent works [13,20,21] share similar pipelines.",
            "3": "[21] propose to first predict the silhouette and 2D keypoints heatmaps and then use them as the input for the SMPL parameters estimator.",
            "4": "Following HMR [21], we use Mosh [16] to collect ground-truth SMPL parameters from raw 3D Mocap markers.",
            "5": "[21] as the metric, which computes the Euclidean distance between ground-truth SMPL vertices and the predicted SMPL vertices.",
            "6": "For UP-3D, we compare our model with both the optimization-based methods [14] and the learning-based methods [13,21,20].",
            "7": "[21] \u2013 117.",
            "8": "We use ResNet-18 as the backbone for \u201cOurs-3D\u201d and \u201cOurs-DC\u201d to guarantee a fair comparison, since models of previous works such as HMR [21] and NBF [20] are all based on ResNet-50 [9]."
        },
        "Bilevel online adaptation for out-of-domain human mesh reconstruction": {
            "authors": [
                "Shanyan Guan",
                "Jingwei Xu",
                "Yunbo Wang",
                "Bingbing Ni",
                "Xiaokang Yang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Guan_Bilevel_Online_Adaptation_for_Out-of-Domain_Human_Mesh_Reconstruction_CVPR_2021_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "43"
            ],
            "1": "We observe that previous models [21,38,25,26,1,59,15,43] are prone to overfit the training dataset and usually underperform in out-of-domain testing scenarios.",
            "2": "Recently, many approaches [21,38,25,26,1,59,15,43] use deep neural networks to regress the parameters of the SMPL model, which are efficient and accurate if large-scale data is available."
        },
        "Towards high performance human keypoint detection": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2002.00537",
            "ref_texts": "286 Paszke A, Gross S, Chintala S, Chanan G, Yang E, DeVito Z, Lin Z, Desmaison A, Antiga L, Lerer A (2017) Automatic differentiation in pytorch. In: Advances in neural information processing systems workshops Pavlakos G, Zhou X, Daniilidis K (2018a) Ordinal depth supervision for 3d human pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 7307\u20137316 Pavlakos G, Zhu L, Zhou X, Daniilidis K (2018b) Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 459\u2013468 Pishchulin L, Insafutdinov E, Tang S, Andres B, Andriluka M, Gehler PV , Schiele B (2016) Deepcut: Joint subset partition and labeling for multi person pose estimation. In: Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), pp 4929\u20134937 Ren S, He K, Girshick R, Sun J (2015) Faster r-cnn: Towards real-time object detection with region proposal networks. In: Advances in neural information processing systems, pp 91\u201399 Rhodin H, Salzmann M, Fua P (2018) Unsupervised geometry-aware representation for 3d human pose estimation. In: Proceedings of the European Conference on Computer Vision (ECCV), pp 750\u2013767 Rogez G, Rihan J, Orrite-Uru \u02dcnuela C, Torr PH (2012) Fast human pose detection using randomized hierarchical cascades of rejectors. International Journal of Computer Vision 99(1):25\u201352 Sun K, Xiao B, Liu D, Wang J (2019) Deep high-resolution representation learning for human pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 5693\u20135703 Sun X, Xiao B, Wei F, Liang S, Wei Y (2018) Integral human pose regression. In: Proceedings of the European Conference on Computer Vision (ECCV), pp 529\u2013545 Toshev A, Szegedy C (2014) Deeppose: Human pose estimation via deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 1653\u20131660 Varadarajan J, Subramanian R, Bul `o SR, Ahuja N, Lanz O, Ricci E (2018) Joint estimation of human pose and conversational groups from social scenes. International Journal of Computer Vision 126(2-4):410\u2013429 Wagemans J, Elder JH, Kubovy M, Palmer SE, Peterson MA, Singh M, von der Heydt R (2012) A century of gestalt psychology in visual perception: I. perceptual grouping and figure\u2013ground organization. Psychological bulletin 138(6):1172 Wang F, Li Y (2013) Beyond physical connections: Tree models in human pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp 596\u2013603 Xiao B, Wu H, Wei Y (2018) Simple baselines for human pose estimation and tracking. In: Proceedings of the European Conference on Computer Vision (ECCV), pp 466\u2013481 Yang Q, Yang R, Davis J, Nist \u00b4er D (2007) Spatial-depth super resolution for range images. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), IEEE, pp 1\u20138 Yang W, Li S, Ouyang W, Li H, Wang X (2017) Learning feature pyramids for human pose estimation. In: Proceedings of the IEEE International Conference on Computer Vision (ICCV), pp 1281\u20131290 Yang W, Ouyang W, Wang X, Ren J, Li H, Wang X (2018)"
        },
        "End-to-end model-based gait recognition using synchronized multi-view pose constraint": {
            "authors": [
                "Xiang Li",
                "Yasushi Makihara",
                "Chi Xu",
                "Yasushi Yagi"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021W/HTCV/papers/Li_End-to-End_Model-Based_Gait_Recognition_Using_Synchronized_Multi-View_Pose_Constraint_ICCVW_2021_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , June 2018. 3",
            "ref_ids": [
                "37"
            ],
            "1": "Most of them [37, 19] use learning-based regression models that focus on single-view images."
        },
        "Neural human video rendering by learning dynamic textures and rendering-to-video translation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2001.04947",
            "ref_texts": "[72] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inThe IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.",
            "ref_ids": [
                "72"
            ],
            "1": "Recently, even lighter approaches [66], [67], [68], [69], [70], [71], [72] have been developed to deal with the rising demand for human performance capture in commodity settings, e.",
            "2": "[72] G."
        },
        "Eventhpe: Event-based 3d human pose and shape estimation": {
            "authors": [
                "Shihao Zou",
                "Chuan Guo",
                "Xinxin Zuo",
                "Sen Wang",
                "Pengyu Wang",
                "Xiaoqin Hu",
                "Shoushun Chen",
                "Minglun Gong",
                "Li Cheng"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Zou_EventHPE_Event-Based_3D_Human_Pose_and_Shape_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "22"
            ],
            "1": "This is followed by [22, 29] that further incorporate rendered silhouettes and texture maps for improved performance."
        },
        "Human mesh recovery from multiple shots": {
            "authors": [
                "Georgios Pavlakos",
                "Jitendra Malik",
                "Angjoo Kanazawa"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Pavlakos_Human_Mesh_Recovery_From_Multiple_Shots_CVPR_2022_paper.pdf",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "45"
            ],
            "1": "Concurrently with HMR, other works have investigated decoupled regression approaches [9, 38, 41, 45, 56, 59, 65], where the intermediate feature representation is hardcoded, e."
        },
        "Motion capture from internet videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.07931",
            "ref_texts": "35. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "35"
            ],
            "1": "More recently, many works attempt to directly regress the model from images with a deep network [23,31,35,54,24,17,51]."
        },
        "Skeleton-aware 3d human shape reconstruction from point clouds": {
            "authors": [
                "Haiyong Jiang",
                "Jianfei Cai",
                "Jianmin Zheng"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Skeleton-Aware_3D_Human_Shape_Reconstruction_From_Point_Clouds_ICCV_2019_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 459\u2013468, 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "Emerging deep learning techniques make it possible to reconstruct human shape in an end-to-end fashion [42, 31, 16, 13, 20].",
            "2": "Fortunately, SMPL [21] offers a nice compact representation for 3D human shape, and it has been integrated with deep neural networks for 3D human reconstruction from RGB images in [31, 16].",
            "3": "That is, it is hard to directly regress SMPL parameters from image features according to [31, 16] or point cloud features according to our study.",
            "4": "3D Human Shape Reconstruction: With the proliferation of deep learning, recent works try to use a neural network to directly learn to reconstruct 3D human from point clouds [13, 20] or images [42, 31, 16, 5, 27, 1, 28].",
            "5": "Reconstruction from a single images [31, 16, 5] has also become feasible by leveraging parametric human models.",
            "6": "Firstly, human shape and pose are disentangled, which allows independent analysis or control of shape or pose [31, 16].",
            "7": "Lastly, SMPL is differentiable and thus can be easily integrated with neural networks [31, 16].",
            "8": "The pervious solutions [31, 16] directly predict SMPL parameters by MLP networks like Fig.",
            "9": "To evaluate the skeleton graph module (SGM), we construct a baseline named Ours-SGM+MLP by replacing SGM with a multi-layer perceptron, which is widely used in pose estimations [31, 16]."
        },
        "OSSO: Obtaining skeletal shape from outside": {
            "authors": [
                "Marilyn Keller",
                "Silvia Zuffi",
                "Michael J. Black",
                "Sergi Pujades"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Keller_OSSO_Obtaining_Skeletal_Shape_From_Outside_CVPR_2022_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "27"
            ],
            "1": "The literature of methods fitting 3D body models to 2D images is wide [5, 7, 11, 12, 16, 17, 26, 27, 35, 37, 39] and was recently surveyed [42]."
        },
        "H4D: human 4d modeling by learning neural compositional representation": {
            "authors": [
                "Boyan Jiang",
                "Yinda Zhang",
                "Xingkui Wei",
                "Xiangyang Xue",
                "Yanwei Fu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Jiang_H4D_Human_4D_Modeling_by_Learning_Neural_Compositional_Representation_CVPR_2022_paper.pdf",
            "ref_texts": "[48] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1, 2",
            "ref_ids": [
                "48"
            ],
            "1": "Introduction The vanilla SMPL based parametric representations have been extensively studied and widely utilized for modeling 3D human shapes, and thus shown critical impacts to many human-centric tasks, such as pose estimation [16,24,30,32, 34, 42] and body shape fitting [9, 18, 33, 48, 58].",
            "2": "Human Body Estimation For human shape and pose estimation [9, 16, 24, 32\u201334, 42, 48] or motion prediction [2, 3, 7, 10, 39, 40], most of works are based on SMPL or its extension [37, 47, 54]."
        },
        "Learning 3d human shape and pose from dense body parts": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.13344",
            "ref_texts": "[6] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "6"
            ],
            "1": "Recently, regressionbased approaches [4], [5], [6], [7] integrate the SMPL model within neural networks and predict model parameters directly in an end-to-end manner.",
            "2": "1(b), compared with other 2D representations [4], [6], [7], the IUV map \u000fH.",
            "3": "For the recovery of 3D human pose or human model, 2D joint positions [24], [25], [26], [27], silhouette [6], [28], [29], segmentation [7], depth maps [30], [31], joint heatmaps [4], [6], [32], volumetric representation [33], [34], [35], [36], and 3D orientation fields [37], [38] are adopted in literature as intermediate representations to facilitate the learning task.",
            "4": "[6] propose to predict the shape and pose parameters from the estimated silhouettes and joint locations respectively.",
            "5": "Here, we follow previous work [6], [7] to predict the rotation matrix representation of the pose parameters \u0012rather than the axis-angle representation defined in the SMPL model.",
            "6": "Following previous work [5], [6], [7], we also add additional constraint and regression objective for better performance.",
            "7": "Following the common protocols [5], [6], [33], we use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation.",
            "8": "Following previous work [6], [15], [34], for evaluating the reconstruction performance, we adopt the mean Per-vertex Error (PVE) as the primary metric, which is defined as the average point-to-point Euclidean distance between the predicted model vertices and the ground truth model vertices.",
            "9": "[6] 155.",
            "10": "[6] decompose the shape and pose prediction tasks, while their pose parameters are predicted from 2D joints positions.",
            "11": "[6] 127.",
            "12": "[6] 50 Titan X NBF [7] 110 Titan Xp BodyNet [34] 280 Modern GPU CMR [40] 33 RTX 2080 Ti DenseRaC [41] 75 Tesla V100 Ours 93 Titan Xp IEEE TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE 13 Table 7 Performance of approaches adopting different intermediate representations on the Human3.",
            "13": "[6] G."
        },
        "Learning Analytical Posterior Probability for Human Mesh Recovery": {
            "authors": [
                "Qi Fang",
                "Kang Chen",
                "Yinghui Fan",
                "Qing Shuai",
                "Jiefeng Li",
                "Weidong Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_Learning_Analytical_Posterior_Probability_for_Human_Mesh_Recovery_CVPR_2023_paper.pdf",
            "ref_texts": "[52] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "52"
            ],
            "1": ", 3D human keypoints [19, 36, 42], 2D heatmaps [52] or part segmentation [27]).",
            "2": "Indirect methods: Instead of regressing rotation representations from RGB images directly, plenty of works introduce proper intermediate or proxy representations, such as segmentation [27, 49, 68], IUV maps [64, 69, 70], keypoints [6, 14, 36, 52] or surface landmarks [30, 32, 42], to guide the learning of neural networks efficiently."
        },
        "Learning to disambiguate strongly interacting hands via probabilistic per-pixel part segmentation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.00434",
            "ref_texts": "[49] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "49"
            ],
            "1": "While prior work on hand[6, 66] and body-pose estimation [46, 49, 63] and handtracking [16, 40, 61] have leveraged some form of segmentation, most often silhouettes or per-pixel masks, this is typically done as a pre-processing step.",
            "2": "Segmentation has been used in 3D hand pose estimation, 3D human pose estimation and hand tracking and can be grouped into four categories: as a localization step [2, 25, 42, 43, 64, 66], as a training loss [3, 6], as an optimization term [8, 40, 61], or as an intermediate representation [9, 41, 46, 49, 63].",
            "3": "In 3D human pose and shape estimation, existing methods predict part segmentation maps [46, 63] or silhouettes [49] from RGB images and use the predicted masks as an intermediate representation.",
            "4": "In contrast to prior work, which separates the image-tosegmentation and segmentation-to-pose steps [46, 49, 63], we propose a holistic approach that is trained to jointly reason about the pixel-to-part assignment and 3D joint locations."
        },
        "Out-of-domain human mesh reconstruction via dynamic bilevel online adaptation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.04017",
            "ref_texts": "[10] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "10"
            ],
            "1": "Most existing models assume that training and testing videos are identically distributed [9,10,11,12,13,14,15,16].",
            "2": "Recently, many approaches [9,10,11,12,13,14,15,16] use deep neural networks to regress the parameters of the SMPL model, which are efficient and can produce more accurate reconstruction results if large-scale 3D data is available.",
            "3": "[10] G."
        },
        "DropKey for Vision Transformer": {
            "authors": [
                "Bonan Li",
                "Yinhan Hu",
                "Xuecheng Nie",
                "Congying Han",
                "Xiangjian Jiang",
                "Tiande Guo",
                "Luoqi Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Li_DropKey_for_Vision_Transformer_CVPR_2023_paper.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "22"
            ],
            "1": "We use Mean Per Vetex Error (MPVE) [22], Mean Per Joint Position Error (MPJPE) [14] and Procrustes Analysis MPJPE\n(PA-MPJPE) [38] as metrics."
        },
        "Movi: A large multipurpose motion and video dataset": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.01888",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "41"
            ],
            "1": "Introduction Recent advances in computer vision, in particular deep learning systems, have generated much interest in 2D human pose estimation [9, 55, 45, 14, 20, 26, 54, 51, 53, 29], 3D pose estimation [37, 43, 57, 47, 38, 52, 11, 39, 3, 41], human motion modelling [36, 17, 27, 23, 44, 22, 42, 19, 24, 4], 3D body reconstruction [30, 41, 40, 28], and activity recognition [50, 16, 60, 10, 58, 48, 7, 59, 31, 13, 15] that are based on video data."
        },
        "Playing for 3d human recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.07588.pdf?trk=public_post_comment-text",
            "ref_texts": "[36] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018, pp. 459\u2013468. 2",
            "ref_ids": [
                "36"
            ],
            "1": "The recent works are categorized into image-based [26], [36], [37], [38], [39], [40], [41], and video-based [42], [43], [44], [45], [46], [47] methods.",
            "2": "2\n[36] G."
        },
        "Mocapdeform: Monocular 3d human motion capture in deformable scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.08439",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018. 1, 2[41] Ronald Poppe. Vision-based human motion analysis: An overview. Computer Vision and Image Understanding (CVIU) , 108(1-2):4\u201318, 2007. 2",
            "ref_ids": [
                "40",
                "41"
            ],
            "1": "Introduction 3D human motion capture from monocular images is an active research area [27, 40, 55, 30, 44, 22, 6, 49, 7, 56, 1].",
            "2": "These limitations can be addressed by estimating parameters of pre-defined body models such as joint angles for kinematic skeletons [68, 30, 29], pose and shape parameters of parametric body models [2, 22, 40, 38, 25, 69], or template-based human performance capture methods [17, 60, 15, 16].",
            "3": "While significant progress in 3D human pose estimation was made over the last decades [11, 32, 41, 45], utilising scene constraints remains insufficiently explored [19, 43, 64, 42, 7, 47].",
            "4": "1, 2[41] Ronald Poppe."
        },
        "Adaptpose: Cross-dataset adaptation for 3d human pose estimation by learnable motion generation": {
            "authors": [
                "Mohsen Gholami",
                "Bastian Wandt",
                "Helge Rhodin",
                "Rabab Ward",
                "Jane Wang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Gholami_AdaptPose_Cross-Dataset_Adaptation_for_3D_Human_Pose_Estimation_by_Learnable_CVPR_2022_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "31"
            ],
            "1": "However, deep learning models are able to learn 2D to 3D correspondences and achieve impressively accurate results when trained and tested on similar datasets [1, 3, 6, 14, 27, 31, 32]."
        },
        "3d human shape and pose from a single low-resolution image with self-supervised learning": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.13666",
            "ref_texts": "40. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018) 2, 3",
            "ref_ids": [
                "40"
            ],
            "1": "made in this ffeld, it is often assumed that the input image is high-resolution and contains suflcient information for reconstructing the 3D human geometry in detail [1, 2, 6, 21, 22, 24, 25, 34, 40, 41, 42, 52].",
            "2": "Recent years have witnessed signiffcant progress in the ffeld of 3D human shape and pose estimation from a single image [1, 2, 3, 6, 9, 21, 22, 24, 25, 34, 40, 41, 42, 52, 50, 49].",
            "3": "The ffrst kind of approaches generally splits the 3D human estimation process into two stages: ffrst transforming the input image into new representations, such as human 2D keypoints [6, 40, 34, 2, 1, 9], human silhouettes [40, 2, 34], body part segmentations [1], UV mappings [3], and optical ow [9], and then regressing the 3D human parameters [29] from the transformed outputs of the last stage either with iterative optimization [6, 2] or neural networks [40, 1, 9, 34]."
        },
        "Hulc: 3d human motion capture with pose manifold sampling and dense contact guidance": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.05677",
            "ref_texts": "40. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Computer Vision and Pattern Recognition (CVPR) (2018) 1, 3",
            "ref_ids": [
                "40"
            ],
            "1": "1 Introduction 3D human motion capture (MoCap) from a single colour camera received a lot of attention over the past years [33, 32, 16, 17, 21, 41, 6, 55, 31, 44, 5, 30, 56, 34, 40, 36, 39, 62, 68, 9, 1, 61, 24, 50, 54, 22, 23, 25].",
            "2": "2 Related Works Most monocular MoCap approaches estimate 3D poses alone or along with the body shape from an input image or video [9, 16, 17, 21, 6, 55, 31, 44, 5, 14, 30, 56, 34, 40, 36, 39, 62, 68, 9, 1, 61, 24, 50, 54, 22, 25, 67]."
        },
        "Full-body awareness from partial observations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.06046",
            "ref_texts": "42. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "42"
            ],
            "1": "A number of recent methods [6,24,27,42,52,55] build this mesh by learning to predict parametric human body models such as 4 C.",
            "2": "To increase training breadth, some of these methods train on 2D keypoints [24,42] and utilize a shape prior."
        },
        "Appearance consensus driven self-supervised human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.01341",
            "ref_texts": "51.Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018) 2, 3, 4, 5, 9, 13",
            "ref_ids": [
                "51"
            ],
            "1": "However, the recent advances in deep learning has shifted the interest towards data-driven regression based methods [21,64], where a deep network directly regresses parameters of the human model for a given input image [48,51,69] in a single-shot computation.",
            "2": "In the absence of datasets having images with 3D pose and shape ground-truth (GT), several recent works leverage a variety of available paired 2D annotations [50,63] such as 2D landmarks or silhouettes [51]; alongside the unpaired 3D pose samples to instill the 3D pose priors [21] (i.",
            "3": "Model-based methods2D keypoint supervisionTemporal supervisionColored mesh prediction [21,26,27,51,48] Yes No No [62,4,23] Yes Yes No Ours(self-sup.",
            "4": "Both optimization [5,35,68] and regression [21,48,51,69] based approaches estimate the Appearance Consensus Driven Self-Supervised Human Mesh Recovery 5 body pose and shape that best describes the available 2D observations such as 2D keypoints [21], silhouettes [51], body/part segmentation [48] etc.",
            "5": "Almost all the prior works [21,51,50] utilize an unpaired human shape dataset to enforce plausibility of the shape predictions via adversarial prior.",
            "6": "[51] 75.",
            "7": "64 SMPLify on [51] 92."
        },
        "Structural knowledge distillation for efficient skeleton-based action recognition": {
            "authors": [],
            "url": "https://www.cse.sc.edu/~songwang/document/tip21c.pdf",
            "ref_texts": "[9] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , Jun. 2018, pp. 459\u2013468.",
            "ref_ids": [
                "9"
            ],
            "1": "Given that most videos are taken by RGB cameras, it is higher desirable to use human pose estimation algorithms to get skeletons from RGB videos [7]\u2013[9].",
            "2": "[9] G."
        },
        "Bio-lstm: A biomechanically inspired recurrent neural network for 3-d pedestrian pose and gait prediction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1809.03705",
            "ref_texts": "[20] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \\Learning to estimate 3d human pose and shape from a single color image,\" arXiv preprint arXiv:1805.04092 , 2018.",
            "ref_ids": [
                "20"
            ],
            "1": "Note that in some of the literature, the terms \\pose prediction\" and \\pose estimation\" are used interchangeably, both referring to the task of estimating a pose (usually skeleton-based joint locations) from a single image (the current frame) [19], [20].",
            "2": "The SMPL model has been used widely in image-to-pose estimation [19], [20], [35], yet DUet al.",
            "3": "[20] G."
        },
        "Facsimile: Fast and accurate scans from an image in less than a second": {
            "authors": [
                "David Smith",
                "Matthew Loper",
                "Xiaochen Hu",
                "Paris Mavroidis",
                "Javier Romero"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Smith_FACSIMILE_Fast_and_Accurate_Scans_From_an_Image_in_Less_ICCV_2019_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 , pages 459\u2013468, 2018.",
            "ref_ids": [
                "34"
            ],
            "1": "Some methods bottleneck through segmented images [21,15,38,10,33], others through estimated keypoints positions [7,26], and some through both [44,34,14,1]."
        },
        "Gravity-aware monocular 3d human-object reconstruction": {
            "authors": [
                "Rishabh Dabral",
                "Soshi Shimada",
                "Arjun Jain",
                "Christian Theobalt",
                "Vladislav Golyanik"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Dabral_Gravity-Aware_Monocular_3D_Human-Object_Reconstruction_ICCV_2021_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "32"
            ],
            "1": "Parametric body models provide strong priors on plausible shapes and poses, which can be leveraged for accurate human pose estimation [4, 16, 32, 17]."
        },
        "Multiview Human Body Reconstruction from Uncalibrated Cameras": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/33610fba262d7b6fed0810b89f55e147-Paper-Conference.pdf",
            "ref_texts": "[37] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "37"
            ],
            "1": "On the other hand, learning-based approaches [30,22] directly regress the model parameters from an image [21], or semantic representations such as 2D keypoint heatmaps and silhouettes [37], part segmentation [35], and dense correspondences [47].",
            "2": "[37] G."
        },
        "Flag3d: A 3d fitness activity dataset with language instruction": {
            "authors": [
                "Yansong Tang",
                "Jinpeng Liu",
                "Aoyang Liu",
                "Bin Yang",
                "Wenxun Dai",
                "Yongming Rao",
                "Jiwen Lu",
                "Jie Zhou",
                "Xiu Li"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_FLAG3D_A_3D_Fitness_Activity_Dataset_With_Language_Instruction_CVPR_2023_paper.pdf",
            "ref_texts": "[67] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "67"
            ],
            "1": "Current methods take keypoints [9, 66, 114], images [24, 25, 41, 42, 46, 61, 67], videos [17, 39, 54, 58, 60, 86] and point clouds [8, 30, 36, 49, 97] as inputs to recover the parametric human model under optimization [9, 44, 109] or regression [38,42,61,67,93] paradigm."
        },
        "Learning visibility for robust dense human body estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.10652",
            "ref_texts": "35. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR. pp. 459\u2013468 (2018) 3, 11",
            "ref_ids": [
                "35"
            ],
            "1": "Several recent works [13,35,31,34,17,19] train a deep neural network to directly regress SMPL parameters from an input image.",
            "2": "For quantitative evaluation, we calculate the common joint and vertex error metrics in the camera space and report them in millimeters (mm), including MPJPE (mean per-joint position error) [12], PA-MPJPE (Procrustes-aligned mean per-joint position error) [46], and MPVE (mean per-vertex error) [35]."
        },
        "Uncertainty-aware human mesh recovery from video by learning part-based 3d dynamics": {
            "authors": [
                "Hee Lee",
                "Whan Lee"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Lee_Uncertainty-Aware_Human_Mesh_Recovery_From_Video_by_Learning_Part-Based_3D_ICCV_2021_paper.pdf",
            "ref_texts": "[12] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "12"
            ],
            "1": "Recently, many studies have been proposed to directly regress the model parameters from the input image by utilizing the power of the DCNN, which have shown im12375\n pressive results [3, 12, 28, 32, 11, 36].",
            "2": "Recently, with rapidly developing power in neural networks, several attempts have been made to use DCNN to directly regress the SMPL parameters from pixels [33, 3, 28, 12, 22, 20, 13, 32].",
            "3": "They used a 2D keypoint reprojection loss [3, 22, 20], body/part segmentation [28, 12] as cues for weak supervision."
        },
        "Skeleton2mesh: Kinematics prior injected unsupervised human mesh recovery": {
            "authors": [
                "Zhenbo Yu",
                "Junjie Wang",
                "Jingwei Xu",
                "Bingbing Ni",
                "Chenglong Zhao",
                "Minsi Wang",
                "Wenjun Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Yu_Skeleton2Mesh_Kinematics_Prior_Injected_Unsupervised_Human_Mesh_Recovery_ICCV_2021_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018. 1,2",
            "ref_ids": [
                "42"
            ],
            "1": "[42] \u2713 \u2717 \u2717 \u2717 HMR [22] \u2717 \u2713 \u2717 \u2717 SPIN [27] \u2717 \u2713 \u2717 \u2713 PoseNet [48] \u2717 \u2717 \u2713 \u2717 Ours \u2717 \u2717 \u2717 \u2717 Table 1: Characteristic comparison of our method against previous model-based methods, in terms of supervision signals and the usage of optimized module.",
            "2": "Recent model-based methods [4,30,22, 49,42,26,48] can be simply divided into two categories: optimization-based methods and regression-based methods."
        },
        "A lightweight graph transformer network for human mesh reconstruction from 2d human pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.12696",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In CVPR .",
            "ref_ids": [
                "41"
            ],
            "1": "[41], and Omran et al."
        },
        "Detailed avatar recovery from single image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2108.02931",
            "ref_texts": "[47] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018.",
            "ref_ids": [
                "47"
            ],
            "1": "A large number of approaches [3], [10], [12], [15], [28], [29], [30], [32], [44], [47], [60], [62] have been proposed in which the human body shapes are reconstructed by predicting the parameters of a statistical skinned model, such as SMPL [38] and SCAPE [7].",
            "2": "Though several works [3], [12], [47] attempts to recover more details than a skinned model, they did not go far on the issue of detailed geometry recovery.",
            "3": "[47] have separated the SMPL parameters prediction network into two sub-networks.",
            "4": "However, like other human shape recovery methods [10], [44], [47] that utilize the SMPL model, the HMR method predicts the shape and pose parameters to generate a skinned mesh model with limited flexibility to closely fit the input image or express surface details.",
            "5": "[47] G."
        },
        "Normalgan: Learning detailed 3d human from a single rgb-d image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.15340",
            "ref_texts": "16. Pavlakos, G., Choutas, V., Ghorbani, N., Bolkart, T., Osman, A.A.A., Tzionas, D., Black, M.J.: Expressive body capture: 3d hands, face, and body from a single image. In: Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (Jun 2019), http://smpl-x.is.tue.mpg.de 17. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. Computer Vision and Pattern Recognition pp. 459{468 (2018)",
            "ref_ids": [
                "16"
            ],
            "1": "Primitive approaches require strong priors of parametric human models, which are widely used for human shape and pose estimation [5,13,16,19]."
        },
        "Neural scene decomposition for multi-person motion capture": {
            "authors": [
                "Helge Rhodin",
                "Victor Constantin",
                "Isinsu Katircioglu",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.pdf",
            "ref_texts": "[43] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Conference on Computer Vision and Pattern Recognition , 2018. 2",
            "ref_ids": [
                "43"
            ],
            "1": "This has been exploited via transfer learning [37], cross-modal vari-ational [58] and adversarial [81] learning both 2D and 3D pose estimation; minimizing the re-projection error of 3D poses to 2D labels in single [89,28,30] and multiple views [22,42]; annotating the joint depth order instead of the absolute position [44,40]; re-projection to silhouettes [60,73,23,43,74].",
            "2": "2\n[43] G."
        },
        "PSVT: End-to-End Multi-person 3D Pose and Shape Estimation with Progressive Video Transformers": {
            "authors": [
                "Zhongwei Qiu",
                "Qiansheng Yang",
                "Jian Wang",
                "Haocheng Feng",
                "Junyu Han",
                "Errui Ding",
                "Chang Xu",
                "Dongmei Fu",
                "Jingdong Wang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_PSVT_End-to-End_Multi-Person_3D_Pose_and_Shape_Estimation_With_Progressive_CVPR_2023_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "37"
            ],
            "1": "Based on SMPL model, 2D heatmaps and silhouettes are used as the prior information to improve mesh estimation by [37]."
        },
        "Self-supervised human depth estimation from monocular videos": {
            "authors": [
                "Feitong Tan",
                "Hao Zhu",
                "Zhaopeng Cui",
                "Siyu Zhu",
                "Marc Pollefeys",
                "Ping Tan"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_Self-Supervised_Human_Depth_Estimation_From_Monocular_Videos_CVPR_2020_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proc. of Computer Vision and Pattern Recognition , 2018. 1,2,3",
            "ref_ids": [
                "35"
            ],
            "1": "Many works have been proposed to estimate those parametric shape models from images [35,17,30,12,18].",
            "2": "These models can be fitted according to estimated skeleton joints [5,22] or be directly regressed as in [11,8,40,35,17,30,33,12,42,18].",
            "3": "1 Camera Model Adjustment State-of-the-art methods [35,17,30] for SMPL model estimation employ a weak-perspective camera model to facilitate the computation."
        },
        "Single image 3d hand reconstruction with mesh convolutions": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.01326",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CoRR , abs/1805.04092, 2018. URL http://arxiv.org/abs/1805.04092 .",
            "ref_ids": [
                "30"
            ],
            "1": "Recent model based 3D reconstruction systems [22, 29, 30] predict parameters of a statistical deformable model of the human body and a weak perspective camera for the alignment.",
            "2": "[30] train a neural network that consists of modules responsible for predicting the mask, landmarks, and model parameters."
        },
        "3D human shape reconstruction from a polarization image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.09268",
            "ref_texts": "30. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2018) 459{468",
            "ref_ids": [
                "30"
            ],
            "1": "Based on these low-dimensional human shape representations, a number of end-to-end deep learning methods [23,24,25,26,27,28,29,30,31,32,33,34,35,36,37] are subsequently developed to estimate human shapes directly from color images.",
            "2": "Deep learning based approaches are more commonplace in recent efiorts [28,29,30,31], which typically learn to predict the SMPL parameters by incorporating the constrains from 2/3D pose, silhouette, as well as adversarial 3D Human Shape Reconstruction from a Polarization Image 5 learning losses."
        },
        "3D human pose, shape and texture from low-resolution images and videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2103.06498",
            "ref_texts": "[9] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018. 1, 2",
            "ref_ids": [
                "9"
            ],
            "1": "Whereas significant progress has been made in this field, it is often assumed that the input image is high-resolution and contains sufficient information for reconstructing the 3D human geometry in detail [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12].",
            "2": "1 3D Human pose and shape Estimation Recent years have witnessed significant progress in the field of 3D human pose and shape estimation from a single image [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [25], [26], [27], [28], [29], [30], [31], [32].",
            "3": "The first kind of approaches generally splits the 3D human estimation process into two stages: first transforming the input image into new representations, such as human 2D keypoints [1], [2], [3], [8], [9], [26], human silhouettes [2], [8], [9], body part segmentations [1], [32], UV mappings [25], and optical flow [26], and then regressing the 3D human parameters [33] from the transformed outputs of the last stage either with iterative optimization [2], [3] or neural networks [1], [8], [9], [26].",
            "4": "1, 2\n[9] G."
        },
        "Kama: 3d keypoint aware body mesh articulation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.13502",
            "ref_texts": "[55] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "55"
            ],
            "1": "Most of the recent works adopt deep neural networks and directly regress the parameters of a parametric body model, SMPL [39], from images [12, 17, 25, 27, 28, 30, 32, 51, 55, 61, 67]."
        },
        "Layered-garment net: Generating multiple implicit garment layers from a single image": {
            "authors": [
                "Alakh Aggarwal",
                "Jikai Wang",
                "Steven Hogue",
                "Saifeng Ni",
                "Madhukar Budagavi",
                "Xiaohu Guo"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Aggarwal_Layered-Garment_Net_Generating_Multiple_Implicit_Garment_Layers_from_a_Single_ACCV_2022_paper.pdf",
            "ref_texts": "12. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE conference on computer vision and pattern recognition. (2018) 459\u2013468",
            "ref_ids": [
                "12"
            ],
            "1": "Many deep learning-based methods [11, 12] have since then come up, that estimate the shape and pose parameters of a human model."
        },
        "BodyMap: learning full-body dense correspondence map": {
            "authors": [
                "Anastasia Ianina",
                "Nikolaos Sarafianos",
                "Yuanlu Xu",
                "Ignacio Rocco",
                "Tony Tung"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ianina_BodyMap_Learning_Full-Body_Dense_Correspondence_Map_CVPR_2022_paper.pdf",
            "ref_texts": ""
        },
        "Reconstructing NBA players": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.13303",
            "ref_texts": "56. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 459{468 (2018)",
            "ref_ids": [
                "56"
            ],
            "1": "html Reconstructing NBA Players 5\n[38,56,39,42,55,29,76,41] trained a neural network to directly regress body shape parameters from images."
        },
        "Sequential 3D human pose and shape estimation from point clouds": {
            "authors": [
                "Kangkan Wang",
                "Jin Xie",
                "Guofeng Zhang",
                "Lei Liu",
                "Jian Yang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Sequential_3D_Human_Pose_and_Shape_Estimation_From_Point_Clouds_CVPR_2020_paper.pdf",
            "ref_texts": ""
        },
        "3D modeling and reconstruction of plants and trees: A cross-cutting review across computer graphics, vision, and plant phenotyping": {
            "authors": [],
            "url": "https://www.jstage.jst.go.jp/article/jsbbs/72/1/72_21074/_pdf",
            "ref_texts": "64. Palubicki, W., K. Horel , S. Longay , A. Runions , B. Lane , R. M\u011bch and P. Prusinkiewicz (2009) Self-organizing tree models for image synthesis. ACM Trans Graph 28: 58. Paulus, S. (2019) Measuring crops in 3D: Using geometry for plant phenotyping. Plant Methods 15: 103. Pavlakos, G., L. Zhu, X. Zhou and K. Daniilidis (2018) Learning to estimate 3D human pose and shape from a single color image. Proc IEEE Conf Comput Vis Pattern Recognit (CVPR), pp.\u202f459\u2013",
            "ref_ids": [
                "64"
            ]
        },
        "Leveraging photometric consistency over time for sparsely supervised hand-object reconstruction": {
            "authors": [
                "Yana Hasson",
                "Bugra Tekin",
                "Federica Bogo",
                "Ivan Laptev",
                "Marc Pollefeys",
                "Cordelia Schmid"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hasson_Leveraging_Photometric_Consistency_Over_Time_for_Sparsely_Supervised_Hand-Object_Reconstruction_CVPR_2020_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. 2,5, 6",
            "ref_ids": [
                "30"
            ],
            "1": "[17,30] fit such parametric models to CNN-regressed 2D joint positions to estimate hand poses from full-body images.",
            "2": "Following [18,22,30], the rotation for object and hand is predicted in the objectcentered coordinate system.",
            "3": "This experiment is in line with earlier reported results, where the estimation of individual keypoint locations outperformed regression of model parameters [18,29,30]."
        },
        "Densebody: Directly regressing dense 3d human pose and shape from a single color image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1903.10153",
            "ref_texts": "[31] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1, 3, 4, 5, 6, 8",
            "ref_ids": [
                "31"
            ],
            "1": "With the emergence of deep learning, many works tried to utilize CNNs to solve human pose and shape estimation in an end-to-end manner[14, 14, 31], and some of them have achieved better performance with faster running speed.",
            "2": "For instance, [26, 31] improved the performance with the help of joints or segmentation outputs.",
            "3": "In Pavlakos\u2019s method[31], 2D joint heatmaps and masks were used as intermediate representations to predict SMPL pose and shape parameters respectively.",
            "4": "When addressing the problem of human pose and shape estimation, the majority of works[26, 31, 14] utilized CNNs to regress the parameters of parametric models like SMPL[19].",
            "5": "However, the mapping from input image to the low-dimensional parameters is highly non-linear, and it\u2019s difficult to train the network with only parameter loss, thus additional losses[14, 26, 31] are combinely used.",
            "6": "(a) refers to [31].",
            "7": "[31] 75.",
            "8": "[31] 169.",
            "9": "[31] 117.",
            "10": "Method Running time HMR [14] 1270 NBF [26] 169 Bodynet [43] 1810 Pavlakos1[31] 50 Ours 5 Table 5.",
            "11": "Running time Inference runtime is also an important metric, and we make a comparison between our method and other four state-of-the-art works, HMR [14], NBF [26], Bodynet [43] and [31].",
            "12": "For method in [31], we use the running time result reported in the paper, which is evaluated on TITAN X.",
            "13": "6\n[31] G."
        },
        "Posenet3d: Learning temporally consistent 3d human pose via knowledge distillation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.03473",
            "ref_texts": "[52] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , 2018. 1, 2, 4",
            "ref_ids": [
                "52"
            ],
            "1": "To address these issues, previous 2D to 3D approaches have used various kinds of additional 3D supervision, including paired 2D-3D correspondences [40], unpaired 3D data [28], multi-view images [56] and synthetic data generated using motion capture (MoCap) sequences [52].",
            "2": "Gaussian Mixture Model) built using 3D MoCap sequences [2, 32], learned priors using 3D data via a discriminator [28], and synthetic 2D-3D pairings [52, 72].",
            "3": "Deep Learning with SMPL: Deep learning approaches such as [1, 28, 32, 39, 46, 50, 52, 60, 64] have utilized 2 SMPL to directly regress to the underlying shape and pose parameters by training a feed-forward network.",
            "4": "Approaches such as [52] have additionally used silhouettes to estimate shape and thus accurate shape prediction is not a goal of this paper.",
            "5": "2\n[52] G."
        },
        "Danet: Decompose-and-aggregate network for 3d human shape and pose estimation": {
            "authors": [],
            "url": "https://guolusjtu.github.io/guoluhomepage/paper/ACMMM2019.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "37"
            ],
            "1": "Recently, learning based approaches [19,34,37,50] integrate the SMPL model within neural networks and predict model parameters directly in an end-to-end manner.",
            "2": "2, compared with other 2D representations [34,37,50], the UVI map could provide more rich information, because it encodes the dense correspondence between foreground pixels on 2D image and vertexes on 3D mesh.",
            "3": "Similarly, for 3D human shape and pose estimation, silhouette [37], joint heatmap [37,50], segmentation [34] and 3D orientation field [54] have also been exploited in literature as proxy representations for estimating the 3D human shape and pose.",
            "4": "[37] propose to predict the shape and pose parameters from the estimated silhouettes and joint heatmaps respectively.",
            "5": "Here, we follow previous work [34,37] to predict the rotation matrix representation of the pose parameters \u03b8rather than the axis-angle representation defined in the SMPL model.",
            "6": "Following previous work [19,34,37], we also add additional constraint and regression objective for better performance.",
            "7": "Following the common protocols [19,36,37], we use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation.",
            "8": "Following previous work [37], we evaluate the reconstruction performance using the mean per-vertex error between the predicted and ground truth body mesh.",
            "9": "[37] decompose the shape and pose prediction tasks, while their pose parameters are predicted from 2D joints positions.",
            "10": "[37] 75.",
            "11": "[37] 127."
        },
        "D3d-hoi: Dynamic 3d human-object interactions from videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2108.08420",
            "ref_texts": "[26] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "26"
            ],
            "1": "On the other hand, regression-based methods [11, 25, 26] rely on deep neural networks and large amounts of training data [8, 23] to directly predict the 3D pose of the human."
        },
        "mmBody benchmark: 3D body reconstruction dataset and analysis for millimeter wave radar": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.05070",
            "ref_texts": "[39] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "39"
            ],
            "1": "2D/3D skeletons [11,33,38,50,52], the parameters of SMPL [19\u201321,24,39] is learned."
        },
        "Coarse-to-fine animal pose and shape estimation": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2021/file/6195f47dcff14b8f242aa333cdb2703e-Paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "23"
            ],
            "1": "[23] propose to employ a differentiable renderer to project the generated 3D meshes back to 2D image space such that the network can be trained with 2D supervision.",
            "2": "Existing works apply the L1[33] orL2distance [2,23] to compute the loss for silhouettes."
        },
        "BEDLAM: A Synthetic Dataset of Bodies Exhibiting Detailed Lifelike Animated Motion": {
            "authors": [
                "Michael J. Black",
                "Priyanka Patel",
                "Joachim Tesch",
                "Jinlong Yang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Black_BEDLAM_A_Synthetic_Dataset_of_Bodies_Exhibiting_Detailed_Lifelike_Animated_CVPR_2023_paper.pdf",
            "ref_texts": "[58] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "58"
            ],
            "1": "Since realistic clothes and textures are hard to generate, several methods render SMPL silhouettes or part segments and then learn to regress HPS from these [58,64,85]."
        },
        "Human parsing based texture transfer from single image to 3D human via cross-view consistency": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2020/file/a516a87cfcaef229b342c437fe2b95f7-Paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "However, most research works mainly focus on estimating the pose and shape of the human body [17,31,34,4,14] and very few works aim at addressing the texture generation problem."
        },
        "Craves: Controlling robotic arm with a vision-based economic system": {
            "authors": [
                "Yiming Zuo",
                "Weichao Qiu",
                "Lingxi Xie",
                "Fangwei Zhong",
                "Yizhou Wang",
                "Alan L. Yuille"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zuo_CRAVES_Controlling_Robotic_Arm_With_a_Vision-Based_Economic_System_CVPR_2019_paper.pdf"
        },
        "Monet: Multiview semi-supervised keypoint detection via epipolar divergence": {
            "authors": [
                "Yuan Yao",
                "Yasamin Jafarian",
                "Hyun Soo"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Yao_MONET_Multiview_Semi-Supervised_Keypoint_Detection_via_Epipolar_Divergence_ICCV_2019_paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 6",
            "ref_ids": [
                "47"
            ],
            "1": "We augment 3D prediction layers on CPM to regress the depth of keypoints [47]."
        },
        "Deep physics-aware inference of cloth deformation for monocular human performance capture": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.12866",
            "ref_texts": "[49] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image, 2018. 1",
            "ref_ids": [
                "49"
            ],
            "1": "Previous monocular methods have made a substantial progress in recovering the 3D unclothed body [30, 49, 31], hand pose [74, 43, 88], facial identity and expression [33, 67, 68] as well as jointly tracking all of those [48, 78, 29, 87]."
        },
        "Self-supervised Human Mesh Recovery with Cross-Representation Alignment": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.04596",
            "ref_texts": "38. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 459\u2013468 (2018) 2, 4",
            "ref_ids": [
                "38"
            ],
            "1": ", 2D landmarks and silhouettes [38, 42, 48, 51], ordinal depth relations [37], dense correspondences [7], or 3D skeletons [26].",
            "2": ", surface keypoints [48, 51], silhouettes [38], body part segmentations [34], IUV maps [54,59,60], and 3D markers [58].",
            "3": "Several works take steps to leverage a variety of easily obtained clues, such as paired 2D landmarks and silhouettes [38, 42, 48, 51], ordinal depth relations [37], DensePose [7], 3D skeleton [26]."
        },
        "Multi-Person 3D Pose and Shape Estimation via Inverse Kinematics and Refinement": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136650650.pdf",
            "ref_texts": "54. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "54"
            ],
            "1": "Some recent studies [34, 51, 54] use deep neural networks for SMPL parameters regression from images in a two-stage manner, which have been effective and can generate more accurate mesh reconstruction outputs in the presence of large-scale 3D datasets."
        },
        "Multi-view Shape Generation for a 3D Human-like Body": {
            "authors": [],
            "url": "https://scholar.archive.org/work/whbajfbxzfcvdlb6vyagmuprwu/access/wayback/https://dl.acm.org/doi/pdf/10.1145/3514248"
        },
        "A Repulsive Force Unit for Garment Collision Handling in Neural Networks": {
            "authors": [],
            "url": "https://qytan.com/files/refu.pdf",
            "ref_texts": "33. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR. pp. 459\u2013468 (2018)",
            "ref_ids": [
                "33"
            ],
            "1": "We use the following metrics in our comparisons with prior methods: MPVE [33] (Mean per-vertex error): Euclidean distance between the groundtruth and predicted garment vertices."
        },
        "A baseline for cross-database 3d human pose estimation": {
            "authors": [
                "Michal Rapczynski",
                "Philipp Werner",
                "Sebastian Handrich",
                "Ayoub Al"
            ],
            "url": "https://www.mdpi.com/1424-8220/21/11/3769/pdf",
            "ref_texts": "48. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 459\u2013468. [CrossRef]",
            "ref_ids": [
                "48"
            ],
            "1": "[48] 75."
        },
        "Handy: Towards a high fidelity 3D hand shape and appearance model": {
            "authors": [
                "Rolandos Alexandros",
                "Stylianos Ploumpis",
                "Stylianos Moschoglou",
                "Vasileios Triantafyllou",
                "Stefanos Zafeiriou"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Potamias_Handy_Towards_a_High_Fidelity_3D_Hand_Shape_and_Appearance_CVPR_2023_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "35"
            ],
            "1": "Initially, 3D pose estimation was considered as a fitting problem where a 3D parametric model was used to fit 2D keypoints [34,35]."
        },
        "Reducing footskate in human motion reconstruction with ground contact constraints": {
            "authors": [
                "Yuliang Zou",
                "Jimei Yang",
                "Duygu Ceylan",
                "Jianming Zhang",
                "Federico Perazzi",
                "Bin Huang"
            ],
            "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Zou_Reducing_Footskate_in_Human_Motion_Reconstruction_with_Ground_Contact_Constraints_WACV_2020_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 1,2",
            "ref_ids": [
                "32"
            ],
            "1": "Thanks to the success of deep learning methods and the availability of large-scale datasets, single-image-based 3D human pose and shape estimation has made significant progress in recent years [3,16,21,25,26,29,32,40,42,45].",
            "2": "Methods combining UV maps [2] or parametric body models [3,16,32,42] are thus proposed to provide more finegrained information."
        },
        "Complete 3D Human Reconstruction From a Single Incomplete Image": {
            "authors": [
                "Junying Wang",
                "Jae Shin",
                "Tuanfeng Y. Wang",
                "Krishna Kumar",
                "Ulrich Neumann"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Complete_3D_Human_Reconstruction_From_a_Single_Incomplete_Image_CVPR_2023_paper.pdf",
            "ref_texts": "[38] Georgios Pavlakos, Nikos Kolotouros, and Kostas Daniilidis. Texturepose: Supervising human mesh estimation with texture consistency. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pages 803\u2013812, 2019. 2[39] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "38",
                "39"
            ],
            "1": "These approaches [23 \u201325, 38, 39, 57, 58] can estimate SMPL [30] shapes and coefficients from a given image.",
            "2": "2, 3\n[38] Georgios Pavlakos, Nikos Kolotouros, and Kostas Daniilidis."
        },
        "IKOL: Inverse kinematics optimization layer for 3D human pose and shape estimation via Gauss-Newton differentiation": {
            "authors": [
                "Juze Zhang",
                "Ye Shi",
                "Yuexin Ma",
                "Lan Xu",
                "Jingyi Yu",
                "Jingya Wang"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/25454/25226",
            "ref_texts": "6059. Li, J.; Xu, C.; Chen, Z.; Bian, S.; Yang, L.; and Lu, C. 2021. Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation. In CVPR, 3383\u20133393. Liang, H.; He, Y .; Zhao, C.; Li, M.; Wang, J.; Yu, J.; and Xu, L. 2023. HybridCap: Inertia-aid Monocular Capture of Challenging Human Motions. AAAI. Lin, T.-Y .; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Doll \u00b4ar, P.; and Zitnick, C. L. 2014. Microsoft coco: Common objects in context. In ECCV, 740\u2013755. Springer. Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and Black, M. J. 2015. SMPL: A skinned multi-person linear model. TOG, 34(6): 1\u201316. Mehta, D.; Rhodin, H.; Casas, D.; Fua, P.; Sotnychenko, O.; Xu, W.; and Theobalt, C. 2017a. Monocular 3d human pose estimation in the wild using improved cnn supervision. In 3DV, 506\u2013516. IEEE. Mehta, D.; Sotnychenko, O.; Mueller, F.; Xu, W.; Elgharib, M.; Fua, P.; Seidel, H.-P.; Rhodin, H.; Pons-Moll, G.; and Theobalt, C. 2020. XNect: Real-time multi-person 3D motion capture with a single RGB camera. TOG, 39(4): 82\u20131. Mehta, D.; Sridhar, S.; Sotnychenko, O.; Rhodin, H.; Shafiei, M.; Seidel, H.-P.; Xu, W.; Casas, D.; and Theobalt, C. 2017b. Vnect: Real-time 3d human pose estimation with a single rgb camera. TOG, 36(4): 1\u201314. Moon, G.; and Lee, K. M. 2020. I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image. In ECCV, 752\u2013768. Springer. Omran, M.; Lassner, C.; Pons-Moll, G.; Gehler, P.; and Schiele, B. 2018. Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In 3DV, 484\u2013494. IEEE. Pavlakos, G.; Choutas, V .; Ghorbani, N.; Bolkart, T.; Osman, A. A.; Tzionas, D.; and Black, M. J. 2019. Expressive body capture: 3d hands, face, and body from a single image. In CVPR, 10975\u201310985. Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to estimate 3D human pose and shape from a single color image. In CVPR, 459\u2013468. Rol\u00b4\u0131nek, M.; Musil, V .; Paulus, A.; Vlastelica, M.; Michaelis, C.; and Martius, G. 2020a. Optimizing rankbased metrics with blackbox differentiation. In CVPR, 7620\u20137630.",
            "ref_ids": [
                "6059"
            ]
        },
        "MEBOW: Monocular estimation of body orientation in the wild": {
            "authors": [
                "Chenyan Wu",
                "Yukun Chen",
                "Jiajia Luo",
                "Chun Su",
                "Anuja Dawane",
                "Bikramjot Hanzra",
                "Zhuo Deng",
                "Bilan Liu",
                "James Z. Wang"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_MEBOW_Monocular_Estimation_of_Body_Orientation_in_the_Wild_CVPR_2020_paper.pdf",
            "ref_texts": "[38] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "38"
            ],
            "1": "Some other ideas complementary to the above idea for improving3-D pose estimation include: (1) enforcing extra prior knowledge such as a parameterized 3-D human mesh model [17, 24, 9, 23, 22, 35, 38], the ordinal depth [36], and temporal information (such as adjacent frame consistency) [25, 39]; and (2) leveraging images simultaneously captured from different views [40, 21], mainly for indoor dataset collected in a highly constrained environment (e."
        },
        "Everybody is unique: Towards unbiased human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.06239",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "33"
            ]
        },
        "Body size and depth disambiguation in multi-person reconstruction from single images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.01884",
            "ref_texts": "[43] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 4322[44] M. Ponzo. Intorno ad alcune illusioni nel campo delle sensazioni tattili, sull\u2019illusione di aristotele e fenomeni analoghi. Archiv f \u00a8ur die gesamte Psychologie , 16:307\u2013345, 1910. 4322",
            "ref_ids": [
                "43",
                "44"
            ],
            "1": "CV] 8 Dec 2021 Figure 2: Two examples of the Ponzo illusion [44] on the perception of the human height.",
            "2": "This observation, does indeed have psychological groundings on the geometrical-optical Ponzo illusion [44], that suggests that the human mind judges an object\u2019s size based on its background, in our case the ground floor, and the preconceived prior that humans have their feet on the ground (see Fig.",
            "3": "Due to its simplicity and robustness several works [21, 24, 43, 39, 41, 26, 5, 25, 60, 12, 65, 62] build upon the SMPL model to reconstruct human bodies from single images.",
            "4": "4322\n[43] G.",
            "5": "4322[44] M."
        },
        "Dual grid net: Hand mesh vertex regression from single depth maps": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.10695",
            "ref_texts": "[29] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "29"
            ],
            "1": "Data-driven methods have greatly advanced the field of 3D reconstruction of both shape and pose of the full human body [48, 56, 4, 28, 46, 29, 52, 19, 53], face [17, 21, 58, 35] and hands [50, 17, 22, 60, 6, 14].",
            "2": "For example, [28, 19, 29, 52, 60, 6, 22] directly estimate shape parameters and joint angles of the mesh.",
            "3": "[29] G."
        },
        "High Fidelity 3D Hand Shape Reconstruction via Scalable Graph Frequency Decomposition": {
            "authors": [
                "Tianyu Luan",
                "Yuanhao Zhai",
                "Jingjing Meng",
                "Zhong Li",
                "Zhang Chen",
                "Yi Xu",
                "Junsong Yuan"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Luan_High_Fidelity_3D_Hand_Shape_Reconstruction_via_Scalable_Graph_Frequency_CVPR_2023_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018. 4",
            "ref_ids": [
                "30"
            ],
            "1": "Conventional joint and vertex loss, such as the widely used pre-joint error loss [2, 4, 8, 14, 15, 33, 44, 47, 52] and mesh pre-vertex error loss [19, 30, 36, 45] commonly used in human body reconstruction, and Chamfer Distance Loss [1, 17, 26, 42] commonly used in object reconstruction and 3D point cloud estimation, all measure the error in the spatial domain."
        },
        "3D human pose and shape estimation through collaborative learning and multi-view model-fitting": {
            "authors": [
                "Zhongguo Li",
                "Magnus Oskarsson",
                "Anders Heyden"
            ],
            "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Li_3D_Human_Pose_and_Shape_Estimation_Through_Collaborative_Learning_and_WACV_2021_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In 2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "Regression-based methods [15,39,31,27,4] use deep neural networks that take all or subsets of pixels in the images and regresses the human body and shape parameters based on training on large datasets.",
            "2": "The training of the networks often relies on the annotation of 2D/3D joint points [18,15], dense pose [20], multi-view images [23], silhouettes [8,31], texture [29,2] and part segmentation [27].",
            "3": "[31] 75."
        },
        "3D Human Mesh Estimation from Virtual Markers": {
            "authors": [
                "Xiaoxuan Ma",
                "Jiajun Su",
                "Chunyu Wang",
                "Wentao Zhu",
                "Yizhou Wang"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_3D_Human_Mesh_Estimation_From_Virtual_Markers_CVPR_2023_paper.pdf",
            "ref_texts": ""
        },
        "Aligning silhouette topology for self-adaptive 3D human pose recovery": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/242c100dc94f871b6d7215b868a875f8-Paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2, 3, 7, 8",
            "ref_ids": [
                "47"
            ],
            "1": "At the same time, silhouettes have found a relegated use, mostly towards enforcing auxiliary shape-centric objectives [9,47].",
            "2": "Supervised human mesh recovery on monocular RGB images has been well explored in recent years, works such as [26,23,24,47] achieve impressive performance on standard benchmarks.",
            "3": "Most works [23,26,49,47,24,33,29,5] try to address the issue by utilizing manually annotated 2D supervision from in-the-wild datasets [22,1,35], and some additionally finetune their models by enforcing temporal [24,17] or multiview [34,49,17] constraints.",
            "4": "Due to such a viewpoint, even the weakly-supervised approaches [10,55,47] render themselves irrelevant towards extending to new unlabeled target 2 domains, as their methods implicitly assume access to significant amount of annotated samples from the final target domain.",
            "5": "[5, 23, 26] 3 7 7 7\n[34, 49, 17] 3 3 7 7\n[33, 15, 47, 55] 3 7 3 7 Ours 7 7 3 3Use of silhouettes.",
            "6": "A few works [55,47,30] formulate encoder-decoder based architectures with silhouette and 2D keypoint reconstruction as primary training objectives for their final regressor network.",
            "7": "In the presence of 2D pose ground-truth (GT), prior approaches [23, 47,5,33] aim to obtain the same representation for the prediction branch in order to employ a direct loss.",
            "8": "[47] 75.",
            "9": "[10], we deem ourselves comparable as other listed works [23,26,47,24] benefit from access to additional Real domain datasets such as LSP, LSP-Extended [22] and COCO [35]."
        },
        "Birds of a feather: Capturing avian shape models from images": {
            "authors": [
                "Yufu Wang",
                "Nikos Kolotouros",
                "Kostas Daniilidis",
                "Marc Badger"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Birds_of_a_Feather_Capturing_Avian_Shape_Models_From_Images_CVPR_2021_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and Michael J Black. Expressive body capture: 3d hands, face, and body from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 10975\u201310985, 2019. 2[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "41",
                "42"
            ],
            "1": "For human body, such models are learned from thousands of registered 3D scans [5,6,23,32,38,41, 52]; SMPL [32] being the most widely used.",
            "2": "Deep learning has made directly regressing model parameters possible [24,30,29,37,42].",
            "3": "6\n[41] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and Michael J Black."
        },
        "PoseExaminer: Automated Testing of Out-of-Distribution Robustness in Human Pose and Shape Estimation": {
            "authors": [
                "Qihao Liu",
                "Adam Kortylewski",
                "Alan L. Yuille"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PoseExaminer_Automated_Testing_of_Out-of-Distribution_Robustness_in_Human_Pose_and_CVPR_2023_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "36"
            ],
            "1": "Current methods typically follow one of two paradigms: Regression-based methods [12, 17, 19, 32, 36, 48, 51] directly estimate 3D human parameters from RGB images.",
            "2": "One solution is to use weak supervision such as 2D keypoints, silhouettes, and body part segmentation in the training either as auxiliary consistency loss [17, 36, 48, 51, 55] or intermediate representations [1, 32, 36]."
        },
        "A deeper look into deepcap": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.10563",
            "ref_texts": "[48] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d inCVPR , 2018.",
            "ref_ids": [
                "48"
            ],
            "1": "An alternative is to regress model parameters directly [47], [48], [49].",
            "2": "06584\n[48] G."
        },
        "Mosculp: Interactive visualization of shape and time": {
            "authors": [
                "First Author",
                "Second Author",
                "Third Author",
                "Fourth Author",
                "Fifth Author",
                "Sixth Author"
            ],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3242587.3242592",
            "ref_texts": "41. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to Estimate 3D HumanPose and Shape from a Single Color Image. In IEEE Conference on Computer Vision and Pattern Recognition.",
            "ref_ids": [
                "41"
            ],
            "1": "Various methods have been proposed to estimate 3D pose from a single image [6, 26, 40, 41, 39, 12, 48], or from a video [21, 22, 50, 36, 1]."
        },
        "Global-to-Local Modeling for Video-based 3D Human Pose and Shape Estimation": {
            "authors": [
                "Xiaolong Shen",
                "Zongxin Yang",
                "Xiaohan Wang",
                "Jianxin Ma",
                "Chang Zhou",
                "Yi Yang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shen_Global-to-Local_Modeling_for_Video-Based_3D_Human_Pose_and_Shape_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CVPR , 2018. 2",
            "ref_ids": [
                "36"
            ],
            "1": "Some methods [8, 17, 34, 36, 47] integrate prior knowledge, i."
        },
        "Collaborative regression of expressive bodies using moderation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.05301",
            "ref_texts": "[74] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "74"
            ],
            "1": "Related work Body reconstruction: For years, the community focused on the prediction of 2D or 3D landmarks for the body [17], face [15] and hands [86, 103], with a recent shift towards estimating 3D model parameters [13, 45, 47, 51, 69, 74, 91] or 3D surfaces [54, 61, 82, 83, 100].",
            "2": "One line of work simplifies the problem by using proxy representations like 2D joints [13, 32, 33, 40, 65, 74, 85, 97, 113], silhouettes [8, 40, 74], part labels [69, 81] or dense correspondences [78, 109].",
            "3": "These are then \u201clifted\u201d to 3D, either as part of an energy term [13, 40, 108] or using a regressor [65, 69, 74, 97].",
            "4": "To overcome ambiguities, they use priors such as known limb lengths [58], joint angle limits [9], or a statistical body model [13, 40, 69, 72, 74] like SMPL [62] or SMPL-X [72]."
        },
        "VoteHMR: Occlusion-aware voting network for robust 3D human mesh recovery from partial point clouds": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.08729",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to Estimate 3D Human Pose and Shape From a Single Color Image. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018 . IEEE Computer Society, Salt Lake City, 459\u2013468. https://doi.org/10.1109/CVPR.2018.00055",
            "ref_ids": [
                "31"
            ],
            "1": "1 Human Mesh Recovery from 2D Images Human mesh recovery has been extensively studied from RGB images, either by template-based approaches to fit the 2D annotations of the RGB images [18,21,29\u201331,39,40,42,45,47], such as keypoints [3], silhouettes [31], and dense annotations [11,38], or template-less approaches [30,31,41,58,59] that directly regress the 3D coordinates of vertices of the human meshes.",
            "2": "The resultant features are further fed into another FC layer to predict the global parameters \ud835\udf53\ud835\udc54\u2208R19, including \ud835\udf3d\u2208R10and a vectorized root rotation matrix vec(R(\ud835\udf3d0)), following the recent successes [27, 31, 56].",
            "3": "In order to achieve higher pose prediction accuracies, following [27,31,56], we directly predict the rotation matrix R\ud835\udc58\u2208R3\u00d73,\ud835\udc58=0,."
        },
        "Beyond weak perspective for monocular 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.06549",
            "ref_texts": "25. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "25"
            ],
            "1": "Namely, the skinned multi-person linear (SMPL) model [17], obtained by detailed 3D scans of a large number of individuals, provides a strong prior for this task, and has been widely used in the research community [11,24,25,27,28].",
            "2": "Recently, it has been shown that SMPL parameters can be directly inferred from an image with a deep neural network [11,24,25,27,28]."
        },
        "SeSDF: Self-evolved Signed Distance Field for Implicit 3D Clothed Human Reconstruction": {
            "authors": [
                "Yukang Cao",
                "Kai Han",
                "Yee K. Wong"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_SeSDF_Self-Evolved_Signed_Distance_Field_for_Implicit_3D_Clothed_Human_CVPR_2023_paper.pdf",
            "ref_texts": "[49] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , 2018. 2",
            "ref_ids": [
                "49"
            ],
            "1": "Examples include semantic segmentation [43, 64], human body silhouette [49], joints [16], motion dynamics [30, 33], texture consistency [48], and attention-regressor [31]."
        },
        "Learning anthropometry from rendered humans": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2101.02515",
            "ref_texts": "[29] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 1, 2",
            "ref_ids": [
                "29"
            ],
            "1": "Recent works [16, 6, 21, 20, 19, 29] consider to directly estimate human bodies from RGB images, but the works focus on 3D pose estimation.",
            "2": "A number of pose estimation methods also provide a 3D shape estimate [16, 6, 21, 20, 19, 29], but shape is only coarse and anthropometric measurements made on them are inaccurate (see our experiments).",
            "3": "[29] extend SMPLify [6] by neural network based parameter initialisation and iterative optimization."
        },
        "NIKI: Neural Inverse Kinematics with Invertible Neural Networks for 3D Human Pose and Shape Estimation": {
            "authors": [
                "Jiefeng Li",
                "Siyuan Bian",
                "Qi Liu",
                "Jiasheng Tang",
                "Fan Wang",
                "Cewu Lu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_NIKI_Neural_Inverse_Kinematics_With_Invertible_Neural_Networks_for_3D_CVPR_2023_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2",
            "ref_ids": [
                "42"
            ],
            "1": ", 2D keypoints [17] and body/part segmentation [42]."
        },
        "Proactive Multi-Camera Collaboration For 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.03767",
            "ref_texts": "3286\u20133295, 2018. Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou Wang. End-to-end active object tracking and its real-world deployment via reinforcement learning. IEEE Transactions on Pattern Analysis and Machine Intelligence , 42(6):1317\u20131332, 2019. Xiaoxuan Ma, Jiajun Su, Chunyu Wang, Hai Ci, and Yizhou Wang. Context modeling in 3d human pose estimation: A unified perspective. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6238\u20136247, 2021. Julieta Martinez, Rayat Hossain, Javier Romero, and James J Little. A simple yet effective baseline for 3d human pose estimation. In Proceedings of the IEEE International Conference on Computer Vision , pp. 2640\u20132649, 2017. Takashi Matsuyama, Shohei Nobuhara, Takeshi Takai, and Tony Tung. Active camera system for object tracking and multi-view observation. In 3D Video and Its Applications , pp. 45\u201385. Springer, 2012. Dushyant Mehta, Srinath Sridhar, Oleksandr Sotnychenko, Helge Rhodin, Mohammad Shafiei, HansPeter Seidel, Weipeng Xu, Dan Casas, and Christian Theobalt. Vnect: Real-time 3d human pose estimation with a single rgb camera. ACM Transactions on Graphics (TOG) , 36(4):1\u201314, 2017. Tobias N\u00e4geli, Samuel Oberholzer, Silvan Pl\u00fcss, Javier Alonso-Mora, and Otmar Hilliges. Flycon: real-time environment-independent multi-view human pose estimation with aerial vehicles. ACM Transactions on Graphics (TOG) , 37(6):1\u201314, 2018. Xuehai Pan, Mickel Liu, Fangwei Zhong, Yaodong Yang, Song-Chun Zhu, and Yizhou Wang. MATE: Benchmarking multi-agent reinforcement learning in distributed target coverage control. In Thirtysixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2022. URL https://openreview.net/forum?id=SyoUVEyzJbE . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 7025\u20137034, 2017a. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Harvesting multiple views for marker-less 3d human pose annotations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 6988\u20136997, 2017b. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 459\u2013468, 2018. Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7753\u20137762, 2019. Aleksis Pirinen, Erik G\u00e4rtner, and Cristian Sminchisescu. Domes to drones: Self-supervised active triangulation for 3d human pose reconstruction. Advances in Neural Information Processing Systems , 32, 2019. Haibo Qiu, Chunyu Wang, Jingdong Wang, Naiyan Wang, and Wenjun Zeng. Cross view fusion for 3d human pose estimation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 4342\u20134351, 2019. Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, and Yizhou Wang. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia , pp. 1221\u20131224, 2017."
        },
        "Multi-person implicit reconstruction from a single image": {
            "authors": [
                "Armin Mustafa",
                "Akin Caliskan",
                "Lourdes Agapito",
                "Adrian Hilton"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Mustafa_Multi-Person_Implicit_Reconstruction_From_a_Single_Image_CVPR_2021_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 06 2018. 2",
            "ref_ids": [
                "31"
            ],
            "1": "2D Joints and silhouettes were used for 3D shape estimation in [31] with the SMPL-X model [30] and [25,42,6] estimate tight fitting clothing on top of the SMPL model."
        },
        "Fashion is taking shape: Understanding clothing preference based on body shape from online sources": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1807.03235",
            "ref_texts": "[30] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InCVPR , 2018. 3",
            "ref_ids": [
                "30"
            ],
            "1": "Recent model based approaches leverage deep learning based 2D detections [8] \u2013 by either fitting a model to them at test time [7,3] or by using them to supervise bottom-up 3D shape predictors [30,21,38,37].",
            "2": "2, 3\n[30] G."
        },
        "LSTM-based network for human gait stability prediction in an intelligent robotic rollator": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.00252",
            "ref_texts": "[36] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "36"
            ],
            "1": "Recent approaches aim to solve the ambiguity of 2D-to-3D correspondences by learning 3D poses from single color images [36], [37].",
            "2": "[36] G."
        },
        "Fusion-SUNet: Spatial Layout Consistency for 3D Semantic Segmentation": {
            "authors": [
                "Maryam Jameela",
                "Gunho Sohn",
                "Sunghwan Yoo"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/PCV/papers/Jameela_Fusion-SUNet_Spatial_Layout_Consistency_for_3D_Semantic_Segmentation_CVPRW_2023_paper.pdf",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Computer Vision and Pattern Recognition , pages 459\u2013468. IEEE, 2018. 2",
            "ref_ids": [
                "25"
            ],
            "1": "We reviewed existing literature on utilizing hierarchical relationships for visual perception, such as detecting human motion, to understand the limitations and benefits of various semantic segmentation networks and establish a baseline for their deep neural network [36] [25].",
            "2": "3, 6\n[25] G."
        },
        "Re-identification supervised texture generation": {
            "authors": [
                "Jian Wang",
                "Yunshan Zhong",
                "Yachun Li",
                "Chi Zhang",
                "Yichen Wei"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Re-Identification_Supervised_Texture_Generation_CVPR_2019_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 , 2018. 3",
            "ref_ids": [
                "41"
            ],
            "1": "[47,15,41] predict SMPL parameters directly by a deep neuron network and get supervision from differentiable rendering of silhouettes."
        },
        "PLIKS: A Pseudo-Linear Inverse Kinematic Solver for 3D Human Body Estimation": {
            "authors": [
                "Karthik Shetty",
                "Annette Birkhold",
                "Srikrishna Jaganathan",
                "Norbert Strobel",
                "Markus Kowarschik",
                "Andreas Maier",
                "Bernhard Egger"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Shetty_PLIKS_A_Pseudo-Linear_Inverse_Kinematic_Solver_for_3D_Human_Body_CVPR_2023_paper.pdf",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "45"
            ],
            "1": "Regression-based techniques based on DNNs directly estimate the pose and shape parameters [10, 21, 42, 45, 52, 54]."
        },
        "Mulaycap: Multi-layer human performance capture using a monocular video camera": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.05815",
            "ref_texts": "[54] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d arXiv preprint arXiv:1805.04092 , 2018.",
            "ref_ids": [
                "54"
            ],
            "1": "[54] proposes a two-step deep learning framework, where the first step estimates key joints and silhouettes from input images, and the second step predicts the SMPL parameters.",
            "2": "[54] G."
        },
        "Human keypoint detection for close proximity human-robot interaction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.07742",
            "ref_texts": "[32] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to Estimate 3D Human Pose and Shape from a Single Color Image,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "32"
            ],
            "1": "Additional works in [31], [32] build on top of the 3D SMPL human body model for the human surface detection from a single RGB image.",
            "2": "[32] G."
        },
        "Temporaluv: Capturing loose clothing with temporally coherent uv coordinates": {
            "authors": [
                "You Xie",
                "Huiqi Mao",
                "Angela Yao",
                "Nils Thuerey"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Xie_TemporalUV_Capturing_Loose_Clothing_With_Temporally_Coherent_UV_Coordinates_CVPR_2022_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "29"
            ],
            "1": "Human body UV coordinates can be derived indirectly from estimates of 3D shape models [6, 19, 26, 29] like SMPL [23]."
        },
        "Multi-view consistency loss for improved single-image 3d reconstruction of clothed people": {
            "authors": [
                "Akin Caliskan",
                "Armin Mustafa",
                "Evren Imre",
                "Adrian Hilton"
            ],
            "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Caliskan_Multi-View_Consistency_Loss_for_Improved_Single-Image_3D_Reconstruction_of_Clothed_ACCV_2020_paper.pdf",
            "ref_texts": "12. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning t o estimate 3d human pose and shape from a single color image. In: Proceedings of the I EEE Conference on Computer Vision and Pattern Recognition. (2018) 459\u2013468",
            "ref_ids": [
                "12"
            ],
            "1": "1 illustrates common failures of ex isting single-view reconstruction approaches [13,14,12] where the reconstruct ed model does not accurately reconstruct the pose or shape from a different view .",
            "2": "Initial monocular human recons truction methods use parametric human model such as SMPL [29,30] to estimate the body and shape parameters in an iterative manner using either 2D joi nt locations and silhouettes [22] or 3D joints and mesh coordinates [12]."
        },
        "Dc-gnet: Deep mesh relation capturing graph convolution network for 3d human shape reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2108.12384",
            "ref_texts": ""
        },
        "Human pose and shape estimation from single polarization images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2108.06834",
            "ref_texts": "[21] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in CVPR , 2018.",
            "ref_ids": [
                "21"
            ],
            "1": "[21] G."
        },
        "Live stream temporally embedded 3d human body pose and shape estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.12537",
            "ref_texts": "[43] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "43"
            ],
            "1": "Some works presented intermediate representations including keypoint heatmaps, silhouette [43], and semantic segmentation [41] to split the whole mapping into two separate parts, which can be trained with broader supervisions."
        },
        "Implicit 3D Human Mesh Recovery using Consistency with Pose and Shape from Unseen-view": {
            "authors": [
                "Hanbyel Cho",
                "Yooshin Cho",
                "Jaesung Ahn",
                "Junmo Kim"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Implicit_3D_Human_Mesh_Recovery_Using_Consistency_With_Pose_and_CVPR_2023_paper.pdf",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018. 2",
            "ref_ids": [
                "45"
            ],
            "1": "Human Mesh Recovery Human mesh recovery works have been conducted based on two approaches: optimization-based approaches [3, 29] andregression-based approaches [19,41,45].",
            "2": "To avoid the issues of optimization-based methods, recent works have adopted regression-based approaches and utilized the powerful learning capability of deep neural networks [6, 9, 10, 14, 19, 25, 41, 45]."
        },
        "Robust Monocular 3D Human Motion With Lasso-Based Differential Kinematics": {
            "authors": [
                "Abed Malti"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/DynaVis/papers/Malti_Robust_Monocular_3D_Human_Motion_With_Lasso-Based_Differential_Kinematics_CVPRW_2023_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. arXiv:1805.04092 [cs] , May 2018. arXiv: 1805.04092. 2, 5, 6",
            "ref_ids": [
                "42",
                "cs"
            ],
            "1": "[36,38,42,44] used a convolutional neural network to infer 3D articulated pose from an image without using 2D joint locations as input.",
            "2": "Evaluation The proposed approach is compared to 4state-of-the-art methods that consist in [28],[49],[42] and[34].",
            "3": "[42] uses a ConvNet to regress the 75degrees of freedom of SMPL pose and 10parameters of SMPL shape.",
            "4": "1\n[42] 77.",
            "5": "8\n[42] 56.",
            "6": "8\n[42] 34.",
            "7": "3\n[42] 35.",
            "8": "[49] and[42] are not displayed because they showed performances similar to [28].",
            "9": "The results are as follows in term of MPJPE: [28]:70:4,[49]:74:9,[42]: 38:5,[34]:33:2andOurs :27:6.",
            "10": "06254 [cs] type: article.",
            "11": "03098 [cs] , May 2017.",
            "12": "09813 [cs] , Nov.",
            "13": "04092 [cs] , May 2018.",
            "14": "05677 [cs] type: article."
        },
        "Hifecap: Monocular high-fidelity and expressive capture of human performances": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.05665",
            "ref_texts": "[57] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "57"
            ],
            "1": "Prior monocular approaches were able to recover the pose and shape of a naked human body model [38, 39, 57], hands [10, 17, 23, 53, 82, 93, 94, 97], facial expression [41, 72, 73, 74, 77], or all of them [36, 58, 87, 98]; recovering cloth deformations remains out of their reach.",
            "2": "Other methods directly regress the body model parameters [38, 39, 57] or a coarse volumetric body shape [78], and can also jointly capture body pose with facial expressions and hand gestures [20, 58, 87, 98]."
        },
        "Dual Attention Poser: Dual Path Body Tracking Based on Attention": {
            "authors": [
                "Xinkang Zhang",
                "Xinrong Chen",
                "Xiaokun Dai",
                "Xinhan Di"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/CV4MR/papers/Zhang_Dual_Attention_Poser_Dual_Path_Body_Tracking_Based_on_Attention_CVPRW_2023_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "28"
            ],
            "1": "The prediction of 3D joints is produced through the application of joints positions [23] and volumetric heat-maps [28]."
        },
        "RaBit: Parametric Modeling of 3D Biped Cartoon Characters with a Topological-consistent Dataset": {
            "authors": [
                "Zhongjin Luo",
                "Shengcai Cai",
                "Jinguo Dong",
                "Ruibo Ming",
                "Liangdong Qiu",
                "Xiaohang Zhan",
                "Xiaoguang Han"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Luo_RaBit_Parametric_Modeling_of_3D_Biped_Cartoon_Characters_With_a_CVPR_2023_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "40"
            ],
            "1": ", a single image or sparse sketches) [6, 15, 24, 26, 40] and real-time pose retargeting [14, 29, 50]."
        },
        "An automated assessment system for embodied cognition in children: from motion data to executive functioning": {
            "authors": [
                "Alex Dillhoff",
                "Konstantinos Tsiakas",
                "Ashwin Ramesh",
                "Mohammad Zakizadehghariehali",
                "Benjamin Buchanan",
                "Morris Bell",
                "Vassilis Athitsos",
                "Fillia Makedon",
                "Yale University"
            ],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3361684.3361693",
            "ref_texts": "[18] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "ref_ids": [
                "18"
            ],
            "1": "Recent body pose estimation methods have shown excellent results on benchmarks featuring multiple persons with varying viewpoints and lighting [4,9,18]."
        },
        "Sampling is Matter: Point-guided 3D Human Mesh Reconstruction": {
            "authors": [
                "Jeonghwan Kim",
                "Gyeong Gwon",
                "Hyunwoo Park",
                "Hyukmin Kwon",
                "Mun Um",
                "Wonjun Kim"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Sampling_Is_Matter_Point-Guided_3D_Human_Mesh_Reconstruction_CVPR_2023_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 459\u2013468, 2018. 6",
            "ref_ids": [
                "30"
            ],
            "1": ", mean per joint position error (MPJPE) [11], Procrustes-aligned mean per joint position error (PA-MPJPE) [38], and mean per vertex position error (MPVPE) [30], which have been widely adopted for the performance comparison in this field."
        },
        "A deep learning approach for multi-view engagement estimation of children in a child-robot joint attention task": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.00253",
            "ref_texts": "[35] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.",
            "ref_ids": [
                "35"
            ],
            "1": "Works on 3D pose estimation are fewer, with most focusing only on color images [34], [35].",
            "2": "[35] G."
        },
        "Camera Motion Agnostic Method for Estimating 3D Human Poses": {
            "authors": [
                "Seong Hyun",
                "Ju Yong"
            ],
            "url": "https://www.mdpi.com/1424-8220/22/20/7975/pdf",
            "ref_texts": "19. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018.",
            "ref_ids": [
                "19"
            ],
            "1": "The global pose is generally defined on the basis of the camera coordinate system in existing methods [5,6,11,19,20]; thus, the estimated 3D human pose is coupled to the camera motion.",
            "2": "[5,6,19,23,24] belong to the model-based approach.",
            "3": "[19] used keypoints and silhouettes as an intermediate representation for predicting SMPL parameters.",
            "4": "Unlike existing methods [5,6,11,19,20], the proposed method generates a global human mesh defined in the world coordinate system by adding the translation to the 3D human mesh Mas follows: Mg(q,b,T) =M(q,b) +T, (1) where T2R3denotes the global translation, which is one of the outputs of the proposed method."
        },
        "Silhouette body measurement benchmarks": {
            "authors": [],
            "url": "https://trepo.tuni.fi/bitstream/handle/10024/143122/Silhouette_Body_Measurement_Benchmarks.pdf?sequence=1",
            "ref_texts": "[11] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in CVPR , 2018.",
            "ref_ids": [
                "11"
            ],
            "1": "Recently research on 3D pose estimation has been active [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], but shape recovery has received less attention.",
            "2": ": Human 3D pose recovery \u201cin the wild\u201d has recently gained momentum [5], [6], [7], [8], [9], [10], [11], [12], [13], [14].",
            "3": "A number of these methods also estimate body volume [9], [10], [11], [12], [13], [14], but only a few provide quantitative results [11], [14].",
            "4": "B ENCHMARK DATASETS The data used in the existing works can be divided to generated body shapes [5], [6], [7], [8], [9], [10], [11], [12], [13], [14] and fitted body shapes [19], [20], [21], [22].",
            "5": "[11] G."
        },
        "Towards Stable Human Pose Estimation via Cross-View Fusion and Foot Stabilization": {
            "authors": [
                "Jian Cao",
                "Qi Wang",
                "Bang Zhang",
                "Liefeng Bo"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhuo_Towards_Stable_Human_Pose_Estimation_via_Cross-View_Fusion_and_Foot_CVPR_2023_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "23"
            ],
            "1": "Using 2D information as an intermediate supervision is a common approach to alleviate the gap between image and 3D coefficients of SMPL [21,23,35].",
            "2": "[23] extract intermediate 2D keypoints and silhouette features to alleviate this problem."
        },
        "Unsupervised 3D shape coverage estimation with applications to colonoscopy": {
            "authors": [
                "Yochai Blau",
                "Daniel Freedman",
                "Valentin Dashinsky",
                "Roman Goldenberg",
                "Ehud Rivlin"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021W/CVAMD/papers/Blau_Unsupervised_3D_Shape_Coverage_Estimation_With_Applications_to_Colonoscopy_ICCVW_2021_paper.pdf",
            "ref_texts": "[50] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "50"
            ],
            "1": "Recently, deep learning methods have attempted to directly regress to model parameters in a one-shot fashion [25, 46, 50]."
        },
        "Canonical 3D Deformer Maps: Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2020/file/efe34c4e2190e97d1adc625902822b13-Paper.pdf",
            "ref_texts": "[46] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proc. CVPR , 2018.",
            "ref_ids": [
                "46"
            ],
            "1": "Multiple works [41,6,21,53,10,39,27,71,29, 47,67,55,61,45,46,30,34,53,39,50,46,62,47] take as input an existing parametric 3D model of the deformable object such as SMPL [41] or SCAPE [6] for humans bodies, or Basel [48] for faces andfit it to images ."
        },
        "Deep unsupervised 3D human body reconstruction from a sparse set of landmarks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2106.12282",
            "ref_texts": "[25] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "25"
            ],
            "1": "This is done by direct regression [12] or through intermediate representations [25, 23, 18, 32, 21].",
            "2": "3\n[25] G."
        },
        "Multi-hypothesis 3D human pose estimation metrics favor miscalibrated distributions": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.11179",
            "ref_texts": "625\u2013632, New York, NY , USA, August 2005. Association for Computing Machinery. Tuomas P. Oikarinen, Daniel C. Hannah, and Sohrob Kazerounian. Graphmdn: Leveraging graph structure and deep learning to solve inverse problems. arXiv [cs.LG] , Oct 2020. doi: 10.48550/ ARXIV .2010.13668. URL http://arxiv.org/abs/2010.13668 . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine volumetric prediction for Single-Image 3D human pose. November 2016. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Harvesting multiple views for marker-less 3d human pose annotations. In CVPR , 2017. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. May 2018. Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. The Semantic Web , pp."
        },
        "Humanmeshnet: Polygonal mesh recovery of humans": {
            "authors": [
                "Abbhinav Venkat",
                "Chaitanya Patel",
                "Yudhik Agrawal",
                "Avinash Sharma"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/3DRW/Venkat_HumanMeshNet_Polygonal_Mesh_Recovery_of_Humans_ICCVW_2019_paper.pdf",
            "ref_texts": "[20] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 , 2018. 2,3,5,6,8",
            "ref_ids": [
                "20"
            ],
            "1": "Recently, several end-to-end deep learning solutions for estimating the 3D parametric body model from a monocular image have been proposed [12,27,28,20,19,33].",
            "2": "To get around this complex mapping, several methods transform them to rotation matrices [19,20] or learn from the 2D/3D keypoint and silhouettes projections (a function of the parameters) [19,12,20].",
            "3": "Similarly, in [20], 2D heatmaps and silhouettes are predicted first, which are then used to predict the pose and shape parameters.",
            "4": "However, [30,20] show a good domain transfer to real data by training on the synthetic SURREAL dataset.",
            "5": "Most circumvent this issue, by avoiding 3D supervision altogether and projecting back to a silhouette or keypoints [12,20].",
            "6": "[20] 117.",
            "7": "[20] 151.",
            "8": "[20] 75.",
            "9": "69 HMR [12] P25 Pavlakos [20] 20 Direct Prediction [14] 2.",
            "10": "2,3,6\n[20] G."
        },
        "Estimating garment patterns from static scan data": {
            "authors": [],
            "url": "https://motionlab.kaist.ac.kr/wp-content/uploads/2021/05/scan2cloth_CGF_cam_readyreduced.pdf"
        },
        "Data-driven 3D reconstruction of dressed humans from sparse views": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.08013",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 4322",
            "ref_ids": [
                "41"
            ],
            "1": "Statistical human body models learned from 3D scans allow to infer the naked body shape from monocular depth images [3] or color images [4, 20, 19, 9, 27, 41, 28, 59].",
            "2": "More recent techniques tend to directly regress parameters of human body models with deep neural networks [27, 41, 59]."
        },
        "Gsir: Generalizable 3d shape interpretation and reconstruction": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123580494.pdf",
            "ref_texts": "42.Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: CVPR (2018)",
            "ref_ids": [
                "42"
            ],
            "1": "Among all ways to abstract object structures, a 3d skeleton is most common in use because of its simplicity, especially in human pose estimation [1,6,65,42]."
        },
        "Rendnet: Unified 2d/3d recognizer with latent space rendering": {
            "authors": [
                "Ruoxi Shi",
                "Xinyang Jiang",
                "Caihua Shan",
                "Yansen Wang",
                "Dongsheng Li"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Shi_RendNet_Unified_2D3D_Recognizer_With_Latent_Space_Rendering_CVPR_2022_paper.pdf",
            "ref_texts": ""
        },
        "3D upper body reconstruction with sparse soft sensors": {
            "authors": [
                "Zhiyong Chen",
                "Ronghui Wu",
                "Shihui Guo",
                "Xiangyang Liu",
                "Hongbo Fu",
                "Xiaogang Jin",
                "Minghong Liao"
            ],
            "url": "https://www.liebertpub.com/doi/pdf/10.1089/soro.2019.0187",
            "ref_texts": "27. Pavlakos G, Zhu L, Zhou X, et al. Learning to estimate 3D human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, June 18\u201323, 2018, pp. 459\u2013468. IEEE.",
            "ref_ids": [
                "27"
            ]
        },
        "MUG: Multi-human graph network for 3D mesh reconstruction from 2D pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.12583",
            "ref_texts": "34. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 459\u2013468 (2018)",
            "ref_ids": [
                "34"
            ],
            "1": "[34] exploited 2D joint heatmaps and silhouettes as a cue."
        },
        "Towards single 2D image-level self-supervision for 3D human pose and shape estimation": {
            "authors": [
                "Junuk Cha",
                "Muhammad Saqlain",
                "Changhwa Lee",
                "Seongyeong Lee",
                "Seungeun Lee",
                "Donguk Kim",
                "Hee Park",
                "Seungryul Baek"
            ],
            "url": "https://www.mdpi.com/2076-3417/11/20/9724/pdf",
            "ref_texts": "37. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201323 June 2018.",
            "ref_ids": [
                "37"
            ],
            "1": ", meshes): one is the optimizationbased methods [9,42,43], and the other is the regression-based methods [5\u20138,36,37].",
            "2": "[37] proposed a framework that estimates heatmaps related to pose parameters of SMPL and silhouettes related to shape parameters of SMPL simultaneously.",
            "3": "Weakly/Semi-Supervised Learning in 3D Human Mesh Estimation For most human pose estimation methods [36,37,43,47\u201350], supervised learning prevails; however, securing the 3D mesh ground truth is non-trivial.",
            "4": "6M dataset, we compare our method to recent fully/semi/weakly/self-supervised methods [5,36,37,43,47\u201350,64] that output the 3D human poses by protocol2 in Table 6.",
            "5": "We compared our method to state-ofthe-art optimized-based methods [9,37,65] and regression-based methods [5,49,50,64] in Table 8.",
            "6": "[37] 75.",
            "7": "64 SMPLify on [37] 92."
        },
        "Event-based human pose tracking by spiking spatiotemporal transformer": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.09681",
            "ref_texts": "[10] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "10"
            ],
            "1": "[10] G."
        },
        "Animatable implicit neural representations for creating realistic avatars from videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.08133",
            "ref_texts": "[32] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018.",
            "ref_ids": [
                "32"
            ],
            "1": "Based on SMPL, some works [32], [33], [34], [35], [36] reconstruct an animated human mesh from sparse camera views.",
            "2": "[32] G."
        },
        "Multi-initialization optimization network for accurate 3d human pose and shape estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2112.12917",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "32"
            ],
            "1": "[32] adopt joint heatmap and silhouette as intermediate representation and design two decoders to respectively predict the pose and shape parameter from the above two representations."
        },
        "Probabilistic estimation of 3D human shape and pose with a semantic local parametric model": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.15404",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "30"
            ],
            "1": "Model-based methods [4, 10, 11, 17, 22, 28, 30, 41, 50] regress 3D body model parameters [26, 29, 31], which give a low-dimensional representation of a 3D human body.",
            "2": "We adopt the training frameworks presented in [30, 37, 39, 40], which entail on-the-fly generation of synthetic training inputs and corresponding SMPL body shape and pose labels during training."
        },
        "Overview of 3d human pose estimation": {
            "authors": [],
            "url": "https://cdn.techscience.cn/ueditor/files/cmes/134-3/TSP_CMES_20857/TSP_CMES_20857.pdf",
            "ref_texts": "28. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K. (2018). Learning to estimate 3D human pose and shape from a single color image. CVPR, 2018, 459\u2013468. DOI 10.1109/CVPR.2018.00055.",
            "ref_ids": [
                "28"
            ]
        },
        "Multi-view Human Body Mesh Translator": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.01886",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "32"
            ],
            "1": "3 Experiments on HUMBI To compare proposed method with the state-of-the-art methods, we report the evaluation results in three standard metrics: Mean Per Joint Position Error (MPJPE) [11],Procrustes Analysis MPJPE\n(PA-MPJPE) [53] and Mean Per Vetex Error (MPVE) [32]."
        },
        "Real\u2010time 3D human pose and motion reconstruction from monocular RGB videos": {
            "authors": [
                "Anastasios Yiannakides",
                "Andreas Aristidou",
                "Yiorgos Chrysanthou"
            ],
            "url": "http://andreasaristidou.com/publications/papers/3dMotionReconstruction.pdf",
            "ref_texts": "10. Pavlakos G, Zhu L, Zhou X, Daniilidis K. Learning to estimate 3D human pose and shape from a single color image. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR '18); 2018 Jun 18\u201322; Salt Lake City, UT. Washington, DC: IEEEComputer Society; 2018.",
            "ref_ids": [
                "10"
            ]
        },
        "Progressive Multi-View Human Mesh Recovery with Self-Supervision": {
            "authors": [
                "Xuan Gong",
                "Liangchen Song",
                "Meng Zheng",
                "Benjamin Planche",
                "Terrence Chen",
                "Junsong Yuan",
                "David Doermann",
                "Ziyan Wu"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/25144/24916",
            "ref_texts": "2017. Harvesting multiple views for marker-less 3d human pose annotations. In CVPR, 6988\u20136997. Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to estimate 3D human pose and shape from a single color image. In CVPR, 459\u2013468. Pavllo, D.; Feichtenhofer, C.; Grangier, D.; and Auli, M.",
            "ref_ids": [
                "2017"
            ]
        },
        "Skeleton transformer networks: 3d human pose and skinned mesh from single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.11328",
            "ref_texts": "19. G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "19"
            ],
            "1": "Our technique outperforms previous techniques that iteratively optimizes joint angles [4] and perform regression of joint angles [19].",
            "2": "[19] Ours 106.",
            "3": ", the one using difierences between silhouettes [19]."
        },
        "Unified 3d mesh recovery of humans and animals by learning animal exercise": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.02450",
            "ref_texts": "[27] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018.",
            "ref_ids": [
                "27"
            ],
            "1": "[27] 75."
        },
        "Learning transferable 3D adversarial cloaks for deep trained detectors": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.11101",
            "ref_texts": "[20] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CoRR , abs/1805.04092, 2018. 3",
            "ref_ids": [
                "20"
            ],
            "1": "Differentiable rendering has been used in many 3D optimization tasks, such as pose estimation [36, 20], object reconstruction [6, 31], and texture fitting [14]."
        },
        "Humans in 4D: Reconstructing and Tracking Humans with Transformers": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.20091",
            "ref_texts": "[57] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "57"
            ],
            "1": "[57] 75."
        },
        "Tightcap: 3D human shape capture with clothing tightness field": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1904.02601",
            "ref_texts": "2018. OptCuts: Joint Optimization of Surface Cuts and Parameterization. ACM Transactions on Graphics (TOG) 37, 6 (2018). https://doi.org/10.1145/3272127.3275042 Zhong Li, Xin Chen, Wangyiteng Zhou, Yingliang Zhang, and Jingyi Yu. 2019. Pose2Body: Pose-Guided Human Parts Segmentation. In 2019 IEEE International Conference on Multimedia and Expo (ICME) . IEEE, 640\u2013645. Zhe Li, Tao Yu, Chuanyu Pan, Zerong Zheng, and Yebin Liu. 2020. Robust 3D Selfportraits in Seconds. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition . 1344\u20131353. Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, and Michael J Black. 2015. SMPL: A Skinned Multi-person Linear Model. ACM Transactions on Graphics (TOG) 34, 6 (2015), 248. Qianli Ma, Jinlong Yang, Anurag Ranjan, Sergi Pujades, Gerard Pons-Moll, Siyu Tang, and Michael Black. 2020. Learning to Dress 3D People in Generative Clothing. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE. Maxim Mikhnevich and Patrick Hebert. 2011. Shape from silhouette under varying lighting and multi-viewpoints. In 2011 Canadian Conference on Computer and Robot Vision . IEEE, 285\u2013292. Ryota Natsume, Shunsuke Saito, Zeng Huang, Weikai Chen, Chongyang Ma, Hao Li, and Shigeo Morishima. 2019. Siclope: Silhouette-based clothed people. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 4480\u20134490. Alexandros Neophytou and Adrian Hilton. 2014. A layered model of human body and garment deformation. In 2014 2nd International Conference on 3D Vision , Vol. 1. IEEE, 171\u2013178. Richard A Newcombe, Dieter Fox, and Steven M Seitz. 2015. Dynamicfusion: Reconstruction and Tracking of Non-rigid Scenes in Real-time. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 343\u2013352. Richard A Newcombe, Shahram Izadi, Otmar Hilliges, David Molyneaux, David Kim, Andrew J Davison, Pushmeet Kohi, Jamie Shotton, Steve Hodges, and Andrew Fitzgibbon. 2011a. KinectFusion: Real-time Dense Surface Mapping and Tracking. InProceedings of the IEEE International Symposium on Mixed and Augmented Reality . IEEE, 127\u2013136. Richard A Newcombe, Steven J Lovegrove, and Andrew J Davison. 2011b. DTAM: Dense Tracking and Mapping in Real-time. In Proceedings of the IEEE International Conference on Computer Vision . IEEE, 2320\u20132327. Alejandro Newell, Kaiyu Yang, and Jia Deng. 2016. Stacked Hourglass Networks for Human Pose Estimation. In Proceedings of the European Conference on Computer Vision . Springer, 483\u2013499. Anqi Pang, Xin Chen, Haimin Luo, Minye Wu, Jingyi Yu, and Lan Xu. 2021. Few-shot Neural Human Performance Rendering from Sparse RGBD Videos. arXiv preprint arXiv:2107.06505 (2021). Chaitanya Patel, Zhouyingcheng Liao, and Gerard Pons-Moll. 2020. TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . IEEE. Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A. A. Osman, Dimitrios Tzionas, and Michael J. Black. 2019. Expressive Body Capture: 3D Hands, Face, and Body from a Single Image. In Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 459\u2013468.Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter V Gehler, and Bernt Schiele. 2016. Deepcut: Joint Subset Partition and Labeling for Multi Person Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 4929\u20134937. Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael J Black. 2017. ClothCap: Seamless 4D Clothing Capture and Retargeting. ACM Transactions on Graphics (TOG) 36, 4 (2017), 73. Albert Pumarola, Jordi Sanchez, Gary Choi, Alberto Sanfeliu, and Francesc MorenoNoguer. 2019. 3DPeople: Modeling the Geometry of Dressed Humans. In International Conference on Computer Vision (ICCV) . Olaf Ronneberger, Philipp Fischer, and Thomas Brox. 2015. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention . Springer, 234\u2013241. Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, and Hao Li. 2019. PIFu: Pixel-aligned implicit function for high-resolution clothed human digitization. In Proceedings of the IEEE International Conference on Computer Vision . 2304\u20132314. Shunsuke Saito, Tomas Simon, Jason Saragih, and Hanbyul Joo. 2020. PIFuHD: MultiLevel Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "2018"
            ],
            "1": "[2019a, 2018, 2019b]; Lazova et al .",
            "2": "[2018] propose a statistical regression model for the variability of the clothing for capturing underlying shapes.",
            "3": "[2018] refine this similar generated body mesh by projecting body shape back to the 2D image for full-body pose and shape estimation.",
            "4": "[2018] and Zhang et al .",
            "5": "[2018], our multi-view silhouette based data term \ud835\udc38Smvmeasures the 2D point-to-plane misalignment: \ud835\udc38S mv(G)=\u2211\ufe01\n\ud835\udc57\u2208C\ud835\udc64C\n\ud835\udc57\n|vS\n\ud835\udc57|\u2211\ufe01\n\ud835\udc58\u2208vS\n\ud835\udc57\u2225nT\n\ud835\udc58\u00b7(\ud835\udc43\ud835\udc57(v\ud835\udc56(G))\u2212 p\ud835\udc58)\u22252\n2, (8) where vS\n\ud835\udc57is the vertex set of virtual silhouettes of the input scan and\ud835\udc43\ud835\udc57(\u00b7)is the projection function of the \ud835\udc57-th camera.",
            "6": "[2018] to prevent over-fitting to the 3D input scan.",
            "7": "[2018]; Xu et al.",
            "8": "[2018]."
        },
        "Orientation keypoints for 6D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.04930",
            "ref_texts": "[52] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "52"
            ],
            "1": "For pose estimation, SMPL-based methods either regress the shape and joint angles directly from an image [11], or from various types of intermediate representation, including 2D keypoints and silhouette [52] or semantic segmentation of the body parts [47]."
        },
        "Cromosim: A deep learning-based cross-modality inertial measurement simulator": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2202.10562",
            "ref_texts": ""
        },
        "Texture Generation Using Dual-Domain Feature Flow with Multi-View Hallucinations": {
            "authors": [
                "Seunggyu Chang",
                "Jungchan Cho",
                "Songhwai Oh"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/19895/19654",
            "ref_texts": "2019. Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis. In Int. Conf. Comput. Vis. Liu, Z.; Luo, P.; Qiu, S.; Wang, X.; and Tang, X. 2016. DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations. In IEEE Conf. Comput. Vis. Pattern Recog. Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and Black, M. J. 2015. SMPL: A Skinned Multi-Person Linear Model. ACM Trans. Graph., 34(6): 248:1\u2013248:16. Ma, L.; Jia, X.; Sun, Q.; Schiele, B.; Tuytelaars, T.; and Van Gool, L. 2017. Pose Guided Person Image Generation. InAdv. Neural Inform. Process. Syst. Ma, Q.; Yang, J.; Ranjan, A.; Pujades, S.; Pons-Moll, G.; Tang, S.; and Black, M. J. 2020. Learning to Dress 3D People in Generative Clothing. In IEEE Conf. Comput. Vis. Pattern Recog. Natsume, R.; Saito, S.; Huang, Z.; Chen, W.; Ma, C.; Li, H.; and Morishima, S. 2019. SiCloPe: Silhouette-Based Clothed People. In IEEE Conf. Comput. Vis. Pattern Recog. Neverova, N.; Alp Guler, R.; and Kokkinos, I. 2018. Dense Pose Transfer. In Eur. Conf. Comput. Vis. Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to Estimate 3D Human Pose and Shape From a Single Color Image. In IEEE Conf. Comput. Vis. Pattern Recog. Ren, Y .; Yu, X.; Chen, J.; Li, T. H.; and Li, G. 2020. Deep Image Spatial Transformation for Person Image Generation. InIEEE Conf. Comput. Vis. Pattern Recog. Saito, S.; Huang, Z.; Natsume, R.; Morishima, S.; Kanazawa, A.; and Li, H. 2019. PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human Digitization. In Int. Conf. Comput. Vis. Saito, S.; Simon, T.; Saragih, J.; and Joo, H. 2020. PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization. In IEEE Conf. Comput. Vis. Pattern Recog. Siarohin, A.; Sangineto, E.; Lathuili `ere, S.; and Sebe, N.",
            "ref_ids": [
                "2019"
            ]
        },
        "Vision-based Neural Scene Representations for Spacecraft": {
            "authors": [
                "Anne Mergy",
                "Gurvan Lecuyer",
                "Dawa Derksen",
                "Dario Izzo"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/papers/Mergy_Vision-Based_Neural_Scene_Representations_for_Spacecraft_CVPRW_2021_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 2",
            "ref_ids": [
                "36"
            ],
            "1": "Recent progress has been made using differentiable rendering for learning-based novel view synthesis [49,19] and pose estimation [36]."
        },
        "XFormer: Fast and Accurate Monocular 3D Body Capture": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.11101",
            "ref_texts": "[Pavlakos et al. , 2018b ]Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. InCVPR , 2018.",
            "ref_ids": [
                "Pavlakos et al\\. , 2018b "
            ]
        },
        "PanoMan: Sparse Localized Components\u2013based Model for Full Human Motions": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3447244",
            "ref_texts": "2012. Afacialrigging survey. In Eurographics(STARs) .183\u2013204. Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A. A. Osman, Dimitrios Tzionas, and Michael J. Black. 2019. Expressive body capture: 3Dhands,face,andbodyfromasingleimage.In ProceedingsoftheIEEEConference on ComputerVisionand PatternRecognition . 10975\u201310985. GeorgiosPavlakos,LuyangZhu,XiaoweiZhou,andKostasDaniilidis.2018.Learning to estimate 3D human pose and shape from a single color image. In Proceedings of theIEEEConference on ComputerVisionand PatternRecognition . 459\u2013468. Leonid Pishchulin, Stefanie Wuhrer, Thomas Helten, Christian Theobalt, and Bernt Schiele. 2017. Building statistical shape spaces for 3D human modeling. Pattern Recog.67 (2017), 276\u2013286. Gerard Pons-Moll, Sergi Pujades, Sonny Hu, and Michael J. Black. 2017. ClothCap: Seamless4Dclothingcaptureandretargeting. ACMTrans.Graph. 36,4(2017),73.Gerard Pons-Moll, Javier Romero, Naureen Mahmood, and Michael J. Black. 2015. Dyna: A model of dynamic human shape in motion. ACM Trans. Graph. 34, 4",
            "ref_ids": [
                "2012"
            ],
            "1": "[2012]andChengetal.",
            "2": "[2012]a d dressed the convergence issue of SCAPE by introducing BlendSCAPE, which views the transformation of triangles as the linear blending of rigid patches."
        },
        "MPT: Mesh Pre-Training with Transformers for Human Pose and Mesh Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2211.13357",
            "ref_texts": "[45] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 1, 2, 5",
            "ref_ids": [
                "45"
            ],
            "1": "To address the challenge, prior works [37, 65, 14, 45, 13] attempted to use 3D mesh data, such as motion capture (MoCap) data [1, 35], for training a 2D-to-3D lifting model that projects the 2D joint coordinates into 3D space.",
            "2": "Parametric approaches [26, 23, 56, 17, 24, 28, 45] typically adopt the SMPL model [34] and regress SMPL parameters to generate human meshes.",
            "3": "standard metrics for evaluation, including Mean Per Joint Position Error (MPJPE) [20], Procrustes Analysis with MPJPE (PA-MPJPE) [66], and Mean Per Vertex Error (MPVE) [45]."
        },
        "PA-Tran: Learning to Estimate 3D Hand Pose with Partial Annotation": {
            "authors": [
                "Tianze Yu",
                "Luke Bidulka",
                "Martin J. Mc",
                "Jane Wang"
            ],
            "url": "https://www.mdpi.com/1424-8220/23/3/1555/pdf",
            "ref_texts": "54. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 459\u2013468.",
            "ref_ids": [
                "54"
            ],
            "1": "Evaluation Metrics To fairly evaluate different methods, we report the HPE results using standard performance metrics: Mean-Per-Joint-Position-Error(MPJPE) [53] and Mean-Per-Vertex-PositionError(MPVPE) [54]."
        },
        "Towards locality similarity preserving to 3D human pose estimation": {
            "authors": [
                "Shihao Zhou",
                "Mengxi Jiang",
                "Qicong Wang",
                "Yunqi Lei"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2020W/MMHAU/papers/Zhou_Towards_Locality_Similarity_Preserving_to_3D_Human_Pose_Estimation_ACCVW_2020_paper.pdf",
            "ref_texts": "42. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning t o estimate 3D human pose and shape from a single color image. In: Proceedings of the I EEE Conference on Computer Vision and Pattern Recognition (CVPR). (2018) 45 9\u2013468",
            "ref_ids": [
                "42"
            ]
        },
        "Smplr: Deep smpl reverse for 3d human pose and shape recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.10766",
            "ref_texts": "[20] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CVPR , 2018. 1, 2, 3, 4, 5, 8, 10",
            "ref_ids": [
                "20"
            ],
            "1": "SMPL [2, 10, 20, 9, 18] generates realistic body meshes based on PCA shape components along with relative axisangle rotations of joints.",
            "2": "This can be done by fitting generative models [22, 8, 5, 2, 10] or training discriminative deep models [20, 9, 18, 31].",
            "3": "Therefore, researchers developed their solutions based on available 2D joints by applying intermediate representations [20, 18] or adversarial training [9] for 3D inference.",
            "4": "Similar to our work, [20, 18, 35] estimate pose and shape parameters from intermediate information, like body segments [18], 2D joint heatmaps and body mask [20] or 3D joints [35].",
            "5": "However, this process is ill-posed and sub-optimal because of the loss of depth information (in the case of [20, 18]) or the ambiguity in joint orientations and shape parameters (in the case of [35]).",
            "6": "Instead, researchers use intermediate representations like 2D joints and body silhouette [20] or body segments [18] to regress SMPL parameters.",
            "7": "L2loss has been commonly applied in recent regression problems [28, 20].",
            "8": "9 Pavlakos [20] 75.",
            "9": "5mm error reported in [20].",
            "10": "2, 8, 9\n[20] G."
        },
        "CameraPose: Weakly-Supervised Monocular 3D Human Pose Estimation by Leveraging In-the-wild 2D Annotations": {
            "authors": [
                "Yen Yang",
                "Jiajia Luo",
                "Lu Xia",
                "Yuyin Sun",
                "Nan Qiao",
                "Ke Zhang",
                "Zhongyu Jiang",
                "Neng Hwang",
                "Hao Kuo"
            ],
            "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Yang_CameraPose_Weakly-Supervised_Monocular_3D_Human_Pose_Estimation_by_Leveraging_In-the-Wild_WACV_2023_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. CoRR , abs/1805.04092, 2018.",
            "ref_ids": [
                "27"
            ],
            "1": "Although deep learning based methods have boosted the performance of 3D HPE [23, 24, 27, 28, 37], the error will typically increase to around two times from Human3."
        },
        "Temporal consistency loss for high resolution textured and clothed 3D human reconstruction from monocular video": {
            "authors": [
                "Akin Caliskan",
                "Armin Mustafa",
                "Adrian Hilton"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021W/DynaVis/papers/Caliskan_Temporal_Consistency_Loss_for_High_Resolution_Textured_and_Clothed_3D_CVPRW_2021_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1,2",
            "ref_ids": [
                "41"
            ],
            "1": "Recent research has learnt to estimate full 3D human shape from a single image with impressive results [41,43,52,20,46,6].",
            "2": "The first group of approach use parametric human model such as SMPL [32,3] to estimate the body pose and shape parameters in an iterative manner using either 2D joints locations [22], 2D joints and silhouettes [5] or 3D joints and mesh coordinates [41]."
        },
        "Generating Multiple Hypotheses for 3D Human Mesh and Pose Using Conditional Generative Adversarial Nets": {
            "authors": [
                "Xu Zheng",
                "Yali Zheng",
                "Shubing Yang"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Zheng_Generating_Multiple_Hypotheses_for_3D_Human_Mesh_and_Pose_using_ACCV_2022_paper.pdf",
            "ref_texts": "35. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2018)",
            "ref_ids": [
                "35"
            ],
            "1": "We compare with SMPLify and its variations [3, 20, 35], HMR [14] and SPIN [18] in terms of the silhouette Intersection over Union (sil-IoU) on LSP test dataset, which measures the matching rate of the projected silhouette of the predicted 3D human mesh and image human segment, and report the results in Table 1.",
            "2": "67 SMPLify+anchor [35] 92."
        },
        "Real-time Monocular Full-body Capture in World Space via Sequential Proxy-to-Motion Learning": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2307.01200",
            "ref_texts": "[41] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "41"
            ],
            "1": "To alleviate this issue, previous approaches have exploited the different proxy representations, including silhouettes [41, 56], 2D/3D landmarks [41, 53, 55, 34, 35, 51, 28, 24], segmentation [19, 38, 47, 19], and IUV [67, 59]."
        },
        "Multi-view human pose and shape estimation using learnable volumetric aggregation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.13427",
            "ref_texts": "[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.",
            "ref_ids": [
                "32"
            ],
            "1": "[32] use a two-stage approach, first estimating 2D keypoints and a silhouette from a convolutional encoder and then separately regressing pose and shape parameters from two intermediate representations, respectively."
        },
        "HybrIK-X: Hybrid Analytical-Neural Inverse Kinematics for Whole-body Mesh Recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2304.05690",
            "ref_texts": "[53] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d inCVPR , 2018. 2, 3, 9",
            "ref_ids": [
                "53"
            ],
            "1": "With the advances in deep learning networks, there are increasing studies that focus on learning-based methods [6], [7], [8], [9], [53], [54], [55], [56], [57], [58], using a deep network to estimate the pose and shape parameters.",
            "2": "XXXX 3 representations to alleviate this problem, such as keypoints and silhouettes [53], semantic part segmentation [54], and 2D heatmap input [59].",
            "3": "[53] 75.",
            "4": "2\n[53] G."
        },
        "HybrIK-Transformer": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2302.04774",
            "ref_texts": "2014. Microsoft COCO:Common Objects in Context. CoRRabs/1405.0312(2014). arXiv:1405.0312 Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksa ndr Sotnychenko, WeipengXu,andChristianTheobalt.2017. Monocular3Dhuma nposeestimation in the wild using improved CNN supervision. In Proc. Fifth Int. Conf. 3D Vision (3DV). GyeongsikMoon,JuYongChang,andKyoungMuLee.2019. Camer aDistance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image. InProc.ICCV . GyeongsikMoon and Kyoung Mu Lee. 2020. I2L-MeshNet:Imageto-lixel prediction network foraccurate3D humanpose and meshestimationfroma single RGB image. InProc.ECCV . GeorgiosPavlakos,LuyangZhu,XiaoweiZhou,andKostasDan iilidis.2018. Learning to estimate3Dhumanpose and shapefromasingle color image. InProc.CVPR . KeSun,BinXiao,Dong Liu,and Jingdong Wang.2019. DeepHigh -ResolutionRepresentation Learningfor HumanPose Estimation. In CVPR. XiaoSun,BinXiao,FangyinWei,ShuangLiang,andYichenWei .2018.Integralhuman pose regression.In Proc.ECCV . Ashish Vaswani, Noam Shazeer, Niki Parmar,Jakob Uszkoreit , Llion Jones, Aidan N Gomez,LukaszKaiser,andIlliaPolosukhin.2017. Attentio nisallyouneed.In Proc. NeurIPS. Timo von Marcard,Roberto Henschel, Michael Black, Bodo Ros enhahn, and Gerard Pons-Moll. 2018. Recovering Accurate 3D Human Pose in The Wi ld Using IMUs and a MovingCamera.In Proc.ECCV .",
            "ref_ids": [
                "2014"
            ]
        },
        "SMPL-A: Modeling Person-Specific Deformable Anatomy": {
            "authors": [
                "Hengtao Guo",
                "Benjamin Planche",
                "Meng Zheng",
                "Srikrishna Karanam",
                "Terrence Chen",
                "Ziyan Wu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Guo_SMPL-A_Modeling_Person-Specific_Deformable_Anatomy_CVPR_2022_paper.pdf",
            "ref_texts": "[28] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "28"
            ],
            "1": "Simple yet highly expressive, this model has been widely adopted by the community [5, 17, 20, 28, 36] and many extensions have been proposed since, e.",
            "2": "2, 3, 5\n[28] G."
        },
        "Human 3D Avatar Modeling with Implicit Neural Representation: A Brief Survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2306.03576",
            "ref_texts": "[36] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "36"
            ],
            "1": "The representation of the reconstructed avatar model can be divided into three categories: voxel [50, 55], mesh [20, 36] and implicit field [31,40,46]."
        },
        "Shape-from-mask: A deep learning based human body shape reconstruction from binary mask images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1806.08485",
            "ref_texts": "(2013). Andrew Nealen, Takeo Igarashi, Olga Sorkine, and Marc Alexa. 2007. FiberMesh: designing freeform surfaces with 3D curves. ACM Trans. Graph 26, 3 (2007). Andrew Nealen, Olga Sorkine, Marc Alexa, and Daniel Cohen-Or. 2005. A SketchBased Interface for Detail-Preserving Mesh Editing. ACM Transactions on Graphics (Proceedings of ACM SIGGRAPH) 24, 3 (2005), 1142\u20131147. Gen Nishida, Ignacio Garcia-Dorado, Daniel G. Aliaga, Bedrich Benes, and Adrien Bousseau. 2016. Interactive Sketching of Urban Procedural Models. ACM Transactions on Graphics (SIGGRAPH Conference Proceedings) (2016). http://www-sop.inria. fr/reves/Basilic/2016/NGGBB16 Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In CVPR . Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele. 2016. DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . http://arxiv.org/abs/1511.06645 Leonid Pishchulin, Stefanie Wuhrer, Thomas Helten, Christian Theobalt, and Bernt Schiele. 2015. Building Statistical Shape Spaces for 3D Human Modeling. CoRR abs/1503.05860 (2015). Elad Richardson, Matan Sela, and Ron Kimmel. 2016. 3D Face Reconstruction by Learning from Synthetic Data. CoRR abs/1609.04387 (2016). Alec Rivers, Fr\u00e9do Durand, and Takeo Igarashi. 2010. 3D modeling with silhouettes. ACM Transactions on Graphics 29, 4 (July 2010), 109:1\u2013109:. K. M. Robinette, H. A. M. Daanen, and E. Paquet. 1999. The CAESAR project: a 3-D surface anthropometry survey. In 3DIM99 . Leonid Sigal, Alexandru Balan, and Michael J. Black. 2008. Combined discriminative and generative articulated pose and non-rigid shape estimation. In Advances in Neural Information Processing Systems 20, NIPS-2007 . MIT Press, 1337\u00e2\u0102\u015e1344. Rupesh Kumar Srivastava, Klaus Greff, and J\u00fcrgen Schmidhuber. 2015. Training Very Deep Networks. In Proceedings of the 28th International Conference on Neural Information Processing Systems Volume 2 (NIPS\u201915) . 2377\u20132385. Jing Tong, Jin Zhou, Ligang Liu, Zhigeng Pan, and Hao Yan. 2012. Scanning 3D Full Human Bodies Using Kinects. IEEE Trans. Vis. Comput. Graph 18, 4 (2012), 643\u2013650. Tong Tong, Gen Li, Xiejie Liu, and Qinquan Gao. 2017. Image Super-Resolution Using Dense Skip Connections. IEEE Computer Society. G\u00fcl Varol, Javier Romero 0002, Xavier Martin, Naureen Mahmood, Michael J. Black, Ivan Laptev, and Cordelia Schmid. 2017. Learning from Synthetic Humans. CoRR abs/1701.01370 (2017). Daniel Vlasic, Pieter Peers, Ilya Baran, Paul E. Debevec, Jovan Popovic, Szymon Rusinkiewicz, and Wojciech Matusik. 2009. Dynamic shape capture using multi-view photometric stereo. ACM Trans. Graph 28, 5 (2009), 174:1\u2013174:11. Yipin Yang, Yao Yu, Yu Zhou, Sidan Du, James Davis, and Ruigang Yang. 2014. Semantic Parametric Reshaping of Human Body Models. In 3DV (Workshops) . IEEE, 41\u201348. http://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=7035242 978-1-47997000-1. Yizhou Yu, Kun Zhou, Dong Xu, Xiaohan Shi, Hujun Bao, Baining Guo, and HeungYeung Shum. 2004. Mesh editing with Poisson-based gradient field manipulation. ACM Transactions on Graphics 23, 3 (Aug. 2004), 644\u2013651."
        },
        "PONet: Robust 3D Human Pose Estimation via Learning Orientations Only": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2112.11153",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "33"
            ],
            "1": "These methods [2], [3], [13], [14], [18], [33], [40], [41] recover the JOURNAL OF L ATEXe CLASS FILES, VOL."
        },
        "Human action transfer based on 3D model reconstruction": {
            "authors": [
                "Shanyan Guan",
                "Shuo Wen",
                "Dexin Yang",
                "Bingbing Ni",
                "Wendong Zhang",
                "Jun Tang",
                "Xiaokang Yang"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/4849/4722",
            "ref_texts": "34(6):248:1\u2013248:16. Paszke, A.; Gross, S.; Chintala, S.; Chanan, G.; Yang, E.; DeVito, Z.; Lin, Z.; Desmaison, A.; Antiga, L.; and Lerer, A. 2017. Automatic differentiation in pytorch. Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 . Popa, A.-I.; Zanfir, M.; and Sminchisescu, C. 2017. Deep multitask architecture for integrated 2d and 3d human sensing. In Conference on Computer Vision and Pattern Recognition , volume 1, 5. Sigal, L.; Balan, A. O.; and Black, M. J. 2009. Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International Journal of Computer Vision 87(1):4. Sigurdsson, G. A.; Russakovsky, O.; and Gupta, A. 2017. What actions are needed for understanding human actions in videos? In IEEE International Conference on Computer Vision , 2156\u20132165. Tak, S., and Ko, H.-S. 2005. A physically-based motion retargeting filter. ACM Trans. Graph. 24(1):98\u2013117. Villegas, R.; Yang, J.; Ceylan, D.; and Lee, H. 2018. Neural kinematic networks for unsupervised motion retargetting. InThe IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Wang, Z.; Bovik, A. C.; Sheikh, H. R.; and Simoncelli, E. P."
        },
        "Learning attention map for 3d human recovery from a single rgb image": {
            "authors": [],
            "url": "https://www.bmvc2021-virtualconference.com/assets/papers/1127.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "23"
            ],
            "1": "Some other works tried to exploit 2D keypoint heatmaps [23], silhouette [30]."
        },
        "Pixel-Aligned Non-parametric Hand Mesh Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.09198",
            "ref_texts": "12 Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 459\u2013468, 2018. Songyou Peng, Michael Niemeyer, Lars Mescheder, Marc Pollefeys, and Andreas Geiger. Convolutional occupancy networks. In European Conference on Computer Vision , pp. 523\u2013540. Springer, 2020. Anurag Ranjan, Timo Bolkart, Soubhik Sanyal, and Michael J Black. Generating 3d faces using convolutional mesh autoencoders. In Proceedings of the European Conference on Computer Vision (ECCV) , pp. 704\u2013720, 2018. Javier Romero, Dimitrios Tzionas, and Michael J Black. Embodied hands: Modeling and capturing hands and bodies together. arXiv preprint arXiv:2201.02610 , 2022. Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, and Hao Li. Pifu: Pixel-aligned implicit function for high-resolution clothed human digitization. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 2304\u20132314, 2019. Shunsuke Saito, Tomas Simon, Jason Saragih, and Hanbyul Joo. Pifuhd: Multi-level pixel-aligned implicit function for high-resolution 3d human digitization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 84\u201393, 2020. Omid Taheri, Vasileios Choutas, Michael J Black, and Dimitrios Tzionas. Goal: Generating 4d whole-body motion for hand-object grasping. arXiv preprint arXiv:2112.11454 , 2021. Jun Kai Vince Tan, Ignas Budvytis, and Roberto Cipolla. Indirect deep structured learning for 3d human body shape and pose prediction. 2017. Xiao Tang, Tianyu Wang, and Chi-Wing Fu. Towards accurate alignment in real-time 3d hand-mesh reconstruction. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp."
        },
        "Permutation-invariant relational network for multi-person 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.04913",
            "ref_texts": "[27] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.",
            "ref_ids": [
                "27"
            ],
            "1": "[27] G."
        },
        "BoPR: Body-aware Part Regressor for Human Shape and Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.11675",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "30"
            ],
            "1": "Regression-based methods [9, 13, 28, 30, 17, 16, 20] that predict human model parameters from image features have made significant progress in recent years and have become the leading paradigm.",
            "2": "We evaluate our method using three common metrics: MJE [10], PAMJE [8], and PVE [30]."
        },
        "Zolly: Zoom Focal Length Correctly for Perspective-Distorted Human Mesh Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.13796",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 459\u2013468, 2018. 3",
            "ref_ids": [
                "40"
            ],
            "1": "Learning-based approaches [22, 40, 57, 27] leverage a deep neural network to regress the human body model parameters or 3D coordinates of the human mesh, which can be further divided into model-based and model-free methods."
        },
        "Error Estimation for Single-Image Human Body Mesh Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.17245",
            "ref_texts": "[20] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "20"
            ],
            "1": "Broadly speaking 3D pose and shape estimation methods are divided into two classes: optimization-based methods that deform a canonical pose to match the image [1, 28, 14] and regressionbased methods that directly estimate the mesh from the image [9, 19, 20]."
        },
        "Single-shot 3d multi-person shape reconstruction from a single rgb image": {
            "authors": [],
            "url": "https://www.mdpi.com/1099-4300/22/8/806/pdf",
            "ref_texts": "3. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018; pp. 459\u2013468.",
            "ref_ids": [
                "3"
            ],
            "1": "[3] predicted SMPL parameters using keypoints and silhouettes as intermediate Entropy 2020 ,22, 806 4 of 16 representations.",
            "2": "Our method is a single-shot method of reconstructing the 3D human shapes of multiple persons, but it outperforms many state-of-the-art methods [3,24,41] that focus on a single person.",
            "3": "[3] 75."
        },
        "D3L: Decomposition of 3D Rotation and Lift from 2D Joint to 3D for Human Mesh Recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2306.06406",
            "ref_texts": "[14] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "14"
            ],
            "1": "Regression is the second paradigm of 3D mesh recovery, which can be further classified into parametric [13,14,15,16,3] and non-parametric [17,18,19].",
            "2": "First, various network architectures have been designed to predict body model parameters with the development of deep learning [13,14]."
        },
        "Instance-level task parameters: A robust multi-task weighting framework": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2106.06129",
            "ref_texts": "[29] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 5",
            "ref_ids": [
                "29"
            ],
            "1": "[29]* 151."
        },
        "On the robustness of human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.06401",
            "ref_texts": "44. Pavlakos G, Zhu L, Zhou X, Daniilidis K (2018) Learning to estimate 3d human pose and shape from a single color image. pp 459\u2013468, DOI 10.1109/CVPR.",
            "ref_ids": [
                "44"
            ],
            "1": "There exist various approaches for single-person 3D-HPE systems [15, 18, 26, 41, 44, 45, 49, 61, 66, 67] , but a thorough analysis of such systems is beyond the scope of this article, therefore, we only analyse the popular system presented in [67] with an aim to depict the generality of our results from 2D-HPE systems."
        },
        "Joint 3d human shape recovery and pose estimation from a single image with bilayer graph": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.08472",
            "ref_texts": "[37] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In IEEE Conf. Comput. Vis. Pattern Recog. , pages 459\u2013468, 2018. 6",
            "ref_ids": [
                "37"
            ],
            "1": "5 Pavlakos [37] 75.",
            "2": "64 SMPLify on [37] 92."
        },
        "A Review of Deep Learning-Powered Mesh Reconstruction Methods": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.02879",
            "ref_texts": "[115] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "115"
            ],
            "1": "1 Human from single image [115] Retrieve and deform template Mesh 2.",
            "2": "1 Deform one template Deforming a single template mesh to create shapes of different poses has been widely used for face [34] and human body [78, 10, 115] shape reconstruction, see Figure 2.",
            "3": "These figures are taken from their corresponding publications (a)[34], (b)[115]."
        },
        "Optical Mouse: 3D mouse pose from single-view video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2106.09251",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "23"
            ],
            "1": "By combining these methods with libraries of human shapes [19] and human poses, 3D human pose estimates can be grounded to real kinematic models and realistic motions [3, 23, 28]."
        },
        "K-Order Graph-oriented Transformer with GraAttention for 3D Pose and Shape Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.11328",
            "ref_texts": "[40] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018.",
            "ref_ids": [
                "40"
            ],
            "1": "For 3D shape estimation, we use the Mean-Per-Vertex-Error (MPVE) [40] in millimeters, which measures the Euclidean distances between the ground truth vertices and the predicted vertices."
        },
        "Deep Portrait Lighting Enhancement with 3D Guidance": {
            "authors": [
                "Fangzhou Han",
                "Can Wang",
                "Hao Du",
                "Jing Liao"
            ],
            "url": "https://arxiv.org/pdf/2108.02121"
        },
        "Adjustable Method Based on Body Parts for Improving the Accuracy of 3D Reconstruction in Visually Important Body Parts from Silhouettes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2211.14822",
            "ref_texts": "[34] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a sing le color image. In CVPR, 2018. 1, ",
            "ref_ids": [
                "34"
            ],
            "1": "[34], 2D pose data using 2D articulated human pose estimation methods \n[38],[39] were extracted and utilized as 2D key points along with mask s to learn a mapping to SMPL [23] model parameter.",
            "2": "In recent years most works that used SMPL computed its parameters using deep neural networks [34].",
            "3": ") [9], or combination of 2D key points (or 2D joints) and silhouettes (or masks) [38],[39],[35], \n[37],[34]."
        },
        "Iterative 3D Deformable Registration from Single-view RGB Images using Differentiable Rendering.": {
            "authors": [],
            "url": "https://www.scitepress.org/Papers/2022/108171/108171.pdf",
            "ref_texts": "(2011). HDR-VDP-2 : A calibrated visual metric for visibility and quality predictions in all luminance conditions. ACM Transactions on graphics (TOG) , 30(4):1\u201314. Merry, B. (2012). Performance tuning for tile-based architectures. OpenGL Insights , page 323. Mescheder, L., Oechsle, M., Niemeyer, M., Nowozin, S., and Geiger, A. (2019). Occupancy networks: Learning 3D reconstruction in function space. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 4460\u20134470. Moreno, P., Williams, C. K., Nash, C., and Kohli, P. (2016). Overcoming occlusion with inverse graphics. In European Conference on Computer Vision (ECCV) , pages 170\u2013185. Myronenko, A. and Song, X. (2010). Point set registration: Coherent point drift. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) , 32(12):2262\u20132275. Pan, J., Han, X., Chen, W., Tang, J., and Jia, K. (2019). Deep mesh reconstruction from single RGB images via topology modification networks. In IEEE International Conference on Computer Vision (ICCV) , pages 9964\u20139973. Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., Desmaison, A., Kopf, A., Yang, E., DeVito, Z., Raison, M., Tejani, A., Chilamkurthy, S.,Steiner, B., Fang, L., Bai, J., and Chintala, S. (2019). PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NeurIPS) , pages 8024\u20138035. Pavlakos, G., Zhu, L., Zhou, X., and Daniilidis, K. (2018). Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013"
        },
        "Learning nonparametric human mesh reconstruction from a single image without ground truth meshes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.00052",
            "ref_texts": "[37] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InCVPR , 2018. 1, 2, 5, 6, 7",
            "ref_ids": [
                "37"
            ],
            "1": "Human mesh reconstruction [30, 54, 11, 16, 25, 37, 11, 24, 51, 23] has recently drawn an increasing attention as it plays an important role for a variety of applications such as augmented reality, human-computer interaction, and activity analysis.",
            "2": "However, many existing approaches [25, 37, 11, 24, 59] require ground truth mesh labels for training.",
            "3": "To address the problem, recent studies [37, 21, 35, 10] propose to use a parametric human model such as skinned multi-person linear model (SMPL) [30] and regress the shape and pose coefficients.",
            "4": "The regression can be done with the help of various 2D human body features such as human skeletons [25, 37], silhouettes [37], and body part segmentations [35].",
            "5": "To have a fair performance comparison, we follow the previous studies [25, 35, 24, 42, 21, 37] and use the same topology as the SMPL model [30] in the experiments.",
            "6": "[37] 100:5 GraphCMR [24] 100:2 Ours 81:5 Ours + GT Inputs 73.",
            "7": "We evaluate the performance of mesh reconstruction by using the metric mean Per-Vertex-Error (mPVE) [37], where the unit is millimeter (mm).",
            "8": "[37] 3 75:9 HMR unpaired [21] 3 66:5 NBF [35] 3 59:9 HMR [21] 3 56:8 GraphCMR+SMPL [24] 3 50:1 GraphCMR [24] 7 69:0 Ours 7 58:5 Table 3: Evaluation of 3D pose estimation on Human3.",
            "9": "Method Accuracy F1 Accuracy F1 SMPLify [3] 91:89 0:88 87:71 0:64 SMPLify on [37] 92:17 0:88 88:24 0:64 BodyNet [49] 92:75 0:84\u0000 \u0000 HMR [21] 91:67 0:87 87:12 0:60 GraphCMR [24] 91:46 0:87 88:69 0:66 Ours 91:23 0:86 88:86 0:66 Table 4: Performance comparison of segmentation on LSP test set.",
            "10": "1\n[37] G."
        },
        "The rapid construction method of human body model for virtual try-on on mobile terminal based on MDD-Net": {
            "authors": [],
            "url": "https://www.researchsquare.com/article/rs-420606/latest.pdf"
        },
        "3D Human Pose and Shape Estimation via HybrIK-Transformer": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=GhL5WawHVfy",
            "ref_texts": "2014. Microsoft COCO:Common Objects in Context. CoRRabs/1405.0312(2014). arXiv:1405.0312 Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksa ndr Sotnychenko, WeipengXu,andChristianTheobalt.2017. Monocular3Dhuma nposeestimation in the wild using improved CNN supervision. In Proc. Fifth Int. Conf. 3D Vision (3DV). GyeongsikMoon,JuYongChang,andKyoungMuLee.2019. Camer aDistance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image. InProc.ICCV . GyeongsikMoon and Kyoung Mu Lee. 2020. I2L-MeshNet:Imageto-lixel prediction network foraccurate3D humanpose and meshestimationfroma single RGB image. InProc.ECCV . GeorgiosPavlakos,LuyangZhu,XiaoweiZhou,andKostasDan iilidis.2018. Learning to estimate3Dhumanpose and shapefromasingle color image. InProc.CVPR . KeSun,BinXiao,Dong Liu,and Jingdong Wang.2019. DeepHigh -ResolutionRepresentation Learningfor HumanPose Estimation. In CVPR. XiaoSun,BinXiao,FangyinWei,ShuangLiang,andYichenWei .2018.Integralhuman pose regression.In Proc.ECCV . Ashish Vaswani, Noam Shazeer, Niki Parmar,Jakob Uszkoreit , Llion Jones, Aidan N Gomez,LukaszKaiser,andIlliaPolosukhin.2017. Attentio nisallyouneed.In Proc. NeurIPS. Timo von Marcard,Roberto Henschel, Michael Black, Bodo Ros enhahn, and Gerard Pons-Moll. 2018. Recovering Accurate 3D Human Pose in The Wi ld Using IMUs and a MovingCamera.In Proc.ECCV .",
            "ref_ids": [
                "2014"
            ]
        },
        "Volnet: estimating human body part volumes from a single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.02259",
            "ref_texts": "[31] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , June 2018.",
            "ref_ids": [
                "31"
            ],
            "1": "Introduction Reconstruction of 3D poses and shapes from a single 2D image has received increasing attention from the deep learning community [9, 46, 31, 21, 25, 40, 11]."
        },
        "Explicit Residual Descent for 3D Human Pose Estimation from 2D Joint Locations.": {
            "authors": [],
            "url": "https://www.bmvc2020-conference.com/assets/papers/0151.pdf",
            "ref_texts": "[24] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. Y. KANG ET AL.: EXPLICIT RESIDUAL DESCENT FOR 3D HUMAN POSE ESTIMATION 13",
            "ref_ids": [
                "24"
            ],
            "1": "Several improved variants of this framework have been proposed in [14, 24]."
        },
        "A novel joint points and silhouette-based method to estimate 3D human pose and shape": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2012.06109",
            "ref_texts": "20. Pavlakos, G., Zhu, L.Y., Zhou, X.W., Daniilidis, K.: Learning to estimate 3D human pose and shape from a single color image. CVPR pp. 459{468 (2018)",
            "ref_ids": [
                "20"
            ],
            "1": "In [20], the pose and shape parameters were separately trained in two pipelines to make the result better."
        },
        "Skeleton-based Approaches based on Machine Vision: A Survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2012.12447",
            "ref_texts": "[21] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "21"
            ],
            "1": "These parameters are meshed together into a 3D body with 2D annotations [21].",
            "2": "CLS FOR JOURNALS 7\n[21] G."
        },
        "Application of 3D human pose estimation for motion capture and character animation": {
            "authors": [],
            "url": "https://oulurepo.oulu.fi/bitstream/handle/10024/14190/nbnfioulu-201906262670.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[42] Pavlakos G., Zhu L., Zhou X. & Daniilidis K. (2018) Learning to estimate 3d human pose and shape from a single color image. CoRR abs/1805.04092. URL: http://arxiv.org/abs/1805.04092 .",
            "ref_ids": [
                "42"
            ],
            "1": "[42] pursue the same target as SMPLify.",
            "2": "[42] whose architecture is shown in Figure 12 use the CNN named Human2D at the early stage of their framework to produce two types of data from a single input image silhouette and a set of heatmaps for each joint.",
            "3": "[42].",
            "4": "This dataset is a great tool for training and validation of different NNs, and thus it is very popular among the researchers [16, 32, 33, 34, 35, 36, 42, 44, 45].",
            "5": "[42] Pavlakos G."
        },
        "Analytical derivatives for differentiable renderer: 3D pose estimation by silhouette consistency": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1906.07870",
            "ref_texts": "28. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K.: Learning to estimate 3d human pose and shape from a single color image. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2018) 459{468",
            "ref_ids": [
                "28"
            ],
            "1": "[28] presented an end-to-end framework to predict the parameters of the statistical body shape model by training CNNs with single image and 3D ground truth.",
            "2": "Evaluation metric For quantitative evaluation, per-vertex error from [28] is used as metric for evaluating the accuracy of 3D pose when comparing with other methods.",
            "3": "[28].",
            "4": "Though our method performs 3D pose estimation without any 2D joint error term, the results are comparable with the learning-based method [28] whose model is trained with 3D ground truth.",
            "5": "From left to right, we show the input images, ground truth, the results obtained by our method, the results obtained by N3MR [3] and results of L2EPS [28].",
            "6": "The result of our method is worse than that of L2EPS [28] since the method in [28] leverages 3D ground truth but our method only leverages 2D silhouettes and predict 3D pose in an unsupervised manner.",
            "7": "Quantitative results compared with other state-of-the-art methods Method Per-vertex error (mm) L2EPS [28] (supervised) 117."
        },
        "Body shape privacy in images: understanding privacy and preventing automatic shape extraction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.11503",
            "ref_texts": "44. G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 3 Body Shape Privacy in Images 17",
            "ref_ids": [
                "44"
            ],
            "1": "Recent model based approaches are using deep learning based 2D detections [10] { by either fftting a model to them at test time [2,50,7,3,21] or by using them to supervise bottom-up 3D shape predictors [40,44,28,60,58,2]."
        },
        "NeuralReshaper: Single-image Human-body Retouching with Deep Neural Networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.10496",
            "ref_texts": "(b) Figure B5 Comparisons with the direct warping method and Zhou et al. [24]. For each case, from left to right are the original image and the reshaping results generated by direct warping, Zhou et al. [24], and our method respectively. The sliders below each case indicate the attributes and their degrees that have been edited. We also highlight the distorted areas with red bounding boxes. Appendix B.4 Comparisons In this section, we compare our approach to the direct warping method, the warping-based human reshaping method [24], the state-of-the-art human image editing method [14] using deep learning and the state-of-the-art human reshaping method [19]. Visual comparisons with the direct warping method and the warping-based human reshaping method are shown in Fig. B3, Fig. B5 and Fig. B4. As one can see, both directly warping-based methods introduce distortions in the foreground and background, leading to unrealistic and implausible results. The larger deformations conducted, the severe distortions induced. This is mainly because that directly warping-based methods first conduct delaunay triangulation on the full image and deform these triangles according to the 3d human model. Thus, the deformations of human model are propagated to the whole image, introducing unfavorable changes on background. Despite the background distortions, warping-based methods also induce distortions on unfitted body areas such as hair (see Fig. B5 (a)). This is mainly because that the unfitted body areas are treated as background. As suggested in [24], one possible strategy to alleviate such distortion artifacts is to manually adjust the saliency map. Nevertheless, this involves lots of human intervention. In contrast, our method is fully automatic in fitting, and preserves regular patterns occluded by humans (e.g., wire fence in Fig. B4 (a)) rather than distorting them. This is because that our method decomposes the generation of foreground and background parts and the generator learns to inpaint the missing areas. The human image editing method [14] trains their network with paired images sampled from videos in a fully supervised manner and applies it to specific tasks like pose-guided human image transfer. For our body reshaping task, since we lack paired data, it is impossible to reproduce their method on outdoor in-the-wild datasets like COCO [13]. We compare our method with [14] on their dataset, COCO dataset and online images, respectively. Fig. B6 (a) shows that our self-supervised method even gets better results than their supervised training method on the reshaping task. One can see that our method can preserve original appearances well and our results look more realistic. As shown in Fig. B6 (b), their method leads to seriously degraded results when facing non-seen cases. We also do quantitative comparison with [14] in Table. B1. We show the Frechet Inception Distance (FID) between randomly sampled generated images and original images. The superiority proves that our method can generate more realistic images again. We also compare our method with the state-of-the-art reshaping method [19]. Ren et al. [19] exploit neural networks to generate deformation flow for image warping. A single scalar is used to control the deformation extent. To train their network, they require a dataset of reshaped ground truth produced by artists. However, their method can only amend the weight and is unable to modify the height. Visual comparisons on COCO dataset are shown in Fig. B7. The results show that our method generates comparable results with B7 (see results in columns 2 and 3) while our method can also change the height (see results in column 4). Moreover, the deformation field generated by their method can introduce artifacts to the image. As highlighted in the red bounding boxes in Fig .B7 (c), undesirable deformations and distortions exist, while our method generates more realistic results. For a fairer comparison, we also present results on their released dataset BR-5K in Fig. B8. We again observe that Ren et al. [19] sometimes Beijia Chen , et al. Sci China Inf Sci September 2023 Vol. 66 199101:9 Figure B6 Comparison with Liu et al. [14]. For each case, from left to right are the original image, the reshaping result by the method in [14], and the reshaping result by our method. generate unnatural reshaping effects, as highlighted in the red bounding box, while our method produces more global consistent results. Moreover, their methodis unable to produce height change, while our method generates realistic height-changing effects. Weight ",
            "ref_ids": [
                "24",
                "24",
                "24",
                "14",
                "19",
                "24",
                "14",
                "13",
                "14",
                "14",
                "19",
                "19",
                "19",
                "14",
                "14"
            ],
            "1": "66 199101 https://doi.",
            "2": "1007/s11432-022-3675-1 .",
            "3": "Sci China Inf Sci, 2023, 66(9): 199101, https://doi.",
            "4": "1007/s11432-022-3675-1 Semantic retouching of human bodies in images, such as increasing the height and slimming the body, has been long desired.",
            "5": "Early attempts [24] have attempted to address this issue by interactively fitting a 3D parametric human model to human bodies in images and allowing the fitted 3D model to delegate the transformation via image warping.",
            "6": "CV] 14 Aug 2023 Beijia Chen , et al.",
            "7": "66 199101:2 Input Image SMPL Model Fitting SMPL Model Resculpting Warping Field Computing Stage 1: SMPL Model Fitting Inpainting area via Eq.",
            "8": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 2019.",
            "9": "66 199101:3 Proceedings of the British Machine Vision Conference.",
            "10": "5244/C.",
            "11": "24.",
            "12": "7122\u20137131\n9 Kato H, Ushiku Y, Harada T.",
            "13": "arXiv preprint arXiv:14126980, 2014\n11 Kolotouros N, Pavlakos G, Black M J, et al.",
            "14": "arXiv preprint arXiv:170502894, 2017\n13 Lin T Y, Maire M, Belongie S, et al.",
            "15": "Springer, 740\u2013755\n14 Liu W, Piao Z, Min J, et al.",
            "16": "5904\u20135913\n15 Liu Z, Luo P, Qiu S, et al.",
            "17": "10975\u201310985\n19 Ren J, Yao Y, Lei B, et al.",
            "18": "5505\u20135514\n23 Yu J, Lin Z, Yang J, et al.",
            "19": "4471\u20134480\n24 Zhou S, Fu H, Liu L, et al.",
            "20": "66 199101:4 Appendix A Method Details Appendix A.",
            "21": "Note here we do not use the parametric model of SCAPE [2], which is used in [24], since the SMPL model is more accurate and compatible with modern rendering pipelines [16].",
            "22": "66 199101:5 The input image Warping field Nerual ReshapingRandom Resculpting Warping fieldDirectly pixel warp OutputWarping field computing Warping field computing Loss computingForeground Background Figure A3 Our self-supervised training strategy.",
            "23": "All the shape variations are controlled to weight/height changes in the range of [0-20] kg/cm, which are consistent with previous work [24] and satisfy most of the real-world reshaping requirements.",
            "24": "66 199101:6 Figure B1 A series of representative reshaping results for outdoor images.",
            "25": "1 Dataset We have conducted extensive experiments on an indoor dataset DeepFashion [15] (512 \u00d7512 resolution) and an outdoor dataset consisting of images from COCO [13], MPII [1], and LSP [7] (256 \u00d7256 resolution).",
            "26": "Specifically, we randomly pick 24 ,806 for training and the rest for testing.",
            "27": "1 Fitting Stage The initial SMPL fitting network [8, 11] cannot handle images of varying input size, we crop and resize all training images into 224\u00d7224.",
            "28": "66 199101:7\n(b) \n Height \n (c) Height Weight \n Weight \n(a) Height Weight \n(d) Height Weight \n(e) Height Weight \n(f) Height Weight Figure B2 Several reshaping results tested on online images.",
            "29": "66 199101:8 Figure B4 Comparison with Zhou et al.",
            "30": "[24].",
            "31": "For each case, from left to right are the original image, the reshaping result by the method in [24], and the reshaping result by our method.",
            "32": "We also highlight the distorted areas in [24] and their corresponding patches in our result with red bounding boxes.",
            "33": "[24].",
            "34": "[24], and our method respectively.",
            "35": "4 Comparisons In this section, we compare our approach to the direct warping method, the warping-based human reshaping method [24], the state-of-the-art human image editing method [14] using deep learning and the state-of-the-art human reshaping method [19].",
            "36": "As suggested in [24], one possible strategy to alleviate such distortion artifacts is to manually adjust the saliency map.",
            "37": "The human image editing method [14] trains their network with paired images sampled from videos in a fully supervised manner and applies it to specific tasks like pose-guided human image transfer.",
            "38": "For our body reshaping task, since we lack paired data, it is impossible to reproduce their method on outdoor in-the-wild datasets like COCO [13].",
            "39": "We compare our method with [14] on their dataset, COCO dataset and online images, respectively.",
            "40": "We also do quantitative comparison with [14] in Table.",
            "41": "We also compare our method with the state-of-the-art reshaping method [19].",
            "42": "[19] exploit neural networks to generate deformation flow for image warping.",
            "43": "[19] sometimes Beijia Chen , et al.",
            "44": "66 199101:9 Figure B6 Comparison with Liu et al.",
            "45": "[14].",
            "46": "For each case, from left to right are the original image, the reshaping result by the method in [14], and the reshaping result by our method.",
            "47": "[19].",
            "48": "For each case, from left to right are the original image, the reshaping result by [19], and two different reshaping results by our method.",
            "49": "66 199101:10 Weight \n (a) \n Weight \n Weight \n Weight \n Height Weight \n (b) Weight \n Weight \n Weight \n Height Figure B8 Comparison with Ren et al.",
            "50": "[19] on BR-5K dataset.",
            "51": "weight-gaining and weight-losing) by [19], and three reshaping results (i.",
            "52": "Method FID \u2193 Liquid Warping [14] 89.",
            "53": "66 199101:11 Figure B9 Ablation study on the SMPL fitting optimization.",
            "54": "66 199101:12 Figure B12 Comparison with an alternative approach by combining direct warping on foreground with background inpainting."
        },
        "Parametric human shape reconstruction via bidirectional silhouette guidance": {
            "authors": [
                "Shuang Sun",
                "Chen Li",
                "Zhenhua Guo",
                "Yuwing Tai"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Sun_Parametric_Human_Shape_Reconstruction_via_Bidirectional_Silhouette_Guidance_ICCVW_2019_paper.pdf",
            "ref_texts": "[29] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProc. of Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "29"
            ],
            "1": "Recent advances, such as [41,37,24,29,14], have demonstrated the possibility of using deep neural network to directly regress the model parameters of human body shape templates, i.",
            "2": "Our method follows the previous frameworks [14,29,24] by aligning the SMPL model [18] to an unconstrained human image.",
            "3": "Noticing the deep feature for 3D pose estimation and 3D shape reconstruction might be at different level [29], we decouple the regression of SMPL parameters into two sub-networks and use more appropriate backbone architecture for each of them to better estimate the corresponding parameters respectively.",
            "4": ", body segmentation [29], 3D joint positions [41,37,24], volumetric geometry representation [42]) followed by regressing the SMPL parameters, our method is in a simple end-to-end framework which is easy to train and the converged results are more stable.",
            "5": "Our method shows substantial improvements over the previous methods [14,29,5,24,42], especially for extreme human body pose and shape.",
            "6": "Besides optimization based approaches, the model parameters can also be regressed using deep neural networks [41,37,24,29,14].",
            "7": "These methods are generally supervised by 2D/3D joints and other image features, for example the body segmentation [29,41,24].",
            "8": "Although previous methods regress reasonable SMPL parameters from a shared generic image feature [24,14,29], the projected body shape does not always overlap with human silhouette.",
            "9": "6M [28,29,14].",
            "10": "[29] 75.",
            "11": "Evaluation with the state-of-the-art methods We compare our results with both the state-of-the-art 3D pose estimation methods [40,19,27,45] and 3D shape reconstruction methods [14,29,15,5,24,42].",
            "12": "2,two state-of-the-art 3D human shape reconstruction methods, NBF [24] and HMR [14] and our method have very competitive results and are significantly better than others [5,15,29]i nProtocol 2 .",
            "13": "28s Modern GPU SMPLify-anchor [29] 0.",
            "14": "Three methods, SMPLify [5], SMPLify-anchor [29] and our approach arrive the upper bound of F1-score while our method is extremely faster than others.",
            "15": "2,5,6\n[29] G."
        },
        "Towards generalization of 3d human pose estimation in the wild": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.09989",
            "ref_texts": "[20] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in CVPR , 2018.",
            "ref_ids": [
                "20"
            ],
            "1": "An alternative proposed with SURREAL [19] and exploited in [20], is to generate realistic ground-truth data synthetically."
        },
        "MonoMR: Synthesizing Pseudo-2.5 D Mixed Reality Content from Monocular Videos": {
            "authors": [
                "Hyun Hwang",
                "Hideki Koike"
            ],
            "url": "https://www.mdpi.com/2076-3417/11/17/7946/pdf",
            "ref_texts": "7. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to Estimate 3D Human Pose and Shape From a Single Color Image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201323 June 2018.",
            "ref_ids": [
                "7"
            ],
            "1": "Some methods try to estimate the parameters using landmarks in images [7].",
            "2": "[7] proposed a system that can determine the silhouette information of the human body in the image and generates a mesh model based on this acquired information.",
            "3": "MonoMR does not use a global motion compensation algorithm and the camera posture estimation method using specific landmarks [7,47] because of high computation and low generalization capacity."
        },
        "2.5 D human pose estimation for shadow puppet animation.": {
            "authors": [],
            "url": "https://itiis.org/digital-library/manuscript/file/22075/TIISVol13No4-17.pdf",
            "ref_texts": ""
        },
        "Learning Transferable Kinematic Dictionary for 3D Human Pose and Shape Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.00953",
            "ref_texts": "2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Ramakrishna, V .; Kanade, T.; and Sheikh, Y . 2012. Reconstructing 3d human pose from 2d image landmarks. In European Conference on Computer Vision . Springer. Rogez, G.; and Schmid, C. 2016. Mocap-guided data augmentation for 3d pose estimation in the wild. In Advances in neural information processing systems . Romero, J.; Tzionas, D.; and Black, M. J. 2017. Embodied Hands: Modeling and Capturing Hands and Bodies Together. ACM Transactions on Graphics, (Proc. SIGGRAPH Asia) 36(6).Saini, N.; Price, E.; Tallamraju, R.; Enficiaud, R.; Ludwig, R.; Martinovic, I.; Ahmad, A.; and Black, M. J. 2019. Markerless Outdoor Human Motion Capture Using Multiple Autonomous Micro Aerial Vehicles. In The IEEE International Conference on Computer Vision . Shoemake, K. 1985. Animating rotation with quaternion curves. In ACM SIGGRAPH computer graphics . ACM. Sun, X.; Shang, J.; Liang, S.; and Wei, Y . 2017. Compositional human pose regression. In Proceedings of the IEEE International Conference on Computer Vision . Sun, X.; Xiao, B.; Wei, F.; Liang, S.; and Wei, Y . 2018. Integral human pose regression. In Proceedings of the European Conference on Computer Vision . Tan, V .; Budvytis, I.; and Cipolla, R. 2018. Indirect deep structured learning for 3d human body shape and pose prediction . Toshev, A.; and Szegedy, C. 2014. Deeppose: Human pose estimation via deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Varol, G.; Ceylan, D.; Russell, B.; Yang, J.; Yumer, E.; Laptev, I.; and Schmid, C. 2018. Bodynet: V olumetric inference of 3d human body shapes. In Proceedings of the European Conference on Computer Vision . Wang, C.; Wang, Y .; Lin, Z.; Yuille, A. L.; and Gao, W.",
            "ref_ids": [
                "2017"
            ]
        },
        "Single-view 3D Body and Cloth Reconstruction under Complex Poses": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.04087",
            "ref_texts": "1296. Natsume, R., Saito, S., Huang, Z., Chen, W., Ma, C., Li, H., and Morishima, S. (2019). Siclope: Silhouette-based clothed people. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Omran, M., Lassner, C., Pons-Moll, G., Gehler, P., and Schiele, B. (2018). Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In 2018 international conference on 3D vision (3DV) , pages 484\u2013494. IEEE. Onizuka, H., Hayirci, Z., Thomas, D., Sugimoto, A., Uchiyama, H., and Taniguchi, R.-i. (2020). Tetratsdf: 3d human reconstruction from a single image with a tetrahedral outer shell. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 6011\u20136020. Park, J. J., Florence, P., Straub, J., Newcombe, R., and Lovegrove, S. (2019). DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. (2017). Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Pavlakos, G., Zhu, L., Zhou, X., and Daniilidis, K. (2018). Learning to Estimate 3d Human Pose and Shape from a Single Color Image. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Pumarola, A., Agudo, A., Porzi, L., Sanfeliu, A., Lepetit, V ., and Moreno-Noguer, F. (2018). Geometry-aware network for non-rigid shape prediction from a single view. In Proceedings of the Conference on Computer Vision and Pattern Recognition (IEEE Conference on Computer Vision and Pattern Recognition (CVPR)) . Pumarola, A., Popov, S., Moreno-Noguer, F., and Ferrari, V .",
            "ref_ids": [
                "1296"
            ]
        },
        "Diffimpact: Differentiable rendering and identification of impact sounds": {
            "authors": [],
            "url": "https://proceedings.mlr.press/v164/clarke22a/clarke22a.pdf",
            "ref_texts": "[12] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "12"
            ],
            "1": "However, whereas differentiable image renderers have empowered new approaches in visual perception [11, 12, 13, 14], differentiable audio renderers have been introduced only recently.",
            "2": "[12] G."
        },
        "Camera Motion Agnostic 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2112.00343",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2, 3, 4",
            "ref_ids": [
                "31",
                "32"
            ],
            "1": "Introduction 3D human pose estimation [7,11,13,16\u201319,26,28,31,33] is an important topic in computer vision that can be applied to many applications, such as virtual/augmented reality, human action recognition, and human behavior understanding.",
            "2": "The global pose is generally defined on the basis of the camera coordinate system in existing methods [13, 16, 18, 24, 32]; thus, the estimated 3D human pose is coupled to the camera motion.",
            "3": "[13, 18, 29, 32] belong to the model-based approach.",
            "4": "[32] used keypoints and silhouettes as an intermediate representation for predicting SMPL parameters.",
            "5": "Unlike existing methods [13,16,18,24,32], the proposed method generates a global human mesh defined in the world coordinate system by adding the translation to the 3D human mesh Mas follows: Mg(\u0012;ff;T ) =M(\u0012;ff) +T; (1) whereT2R3denotes the global translation, which is one of the outputs of the proposed method."
        },
        "PointHuman: Reconstructing Clothed Human from Point Cloud of Parametric Model": {
            "authors": [],
            "url": "https://www.cai.sk/ojs/index.php/cai/article/download/2023_2_457/1225",
            "ref_texts": "[14]Pavlakos, G.\u2014Zhu, L.\u2014Zhou, X.\u2014Daniilidis, K. : Learning to Estimate 3D Human Pose and Shape from a Single Color Image. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 459\u2013468, doi: 10.1109/CVPR.2018.00055.",
            "ref_ids": [
                "14"
            ],
            "1": "[14] regress SMPL parameters by relying on a smaller number of key points and body contours, further adopt a similar method, then use a segmentation map of human body parts as an intermediate representation.",
            "2": "[14]Pavlakos, G."
        },
        "Building digital twins of articulated objects and scenes through interactive perception": {
            "authors": [],
            "url": "https://repositories.lib.utexas.edu/bitstream/handle/2152/119137/HSU-THESIS-2023.pdf?sequence=1",
            "ref_texts": "[89] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "89"
            ],
            "1": "Developing vision-based methods to automate the estimation [37, 1] and reconstruction [77] of articulated objects has been an active line of research, accelerated by new tools developed from the 3D vision community, including geometric deep learning [48, 85, 89] and implicit neural representations [18, 84]."
        },
        "MeshLifter: Weakly Supervised Approach for 3D Human Mesh Reconstruction from a Single 2D Pose Based on Loop Structure": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/20/15/4257/pdf",
            "ref_texts": "22. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, USA, 18\u201322 June 2018; pp. 459\u2013468.",
            "ref_ids": [
                "22"
            ],
            "1": "[22] 75."
        },
        "Concise and Effective Network for 3D Human Modeling From Orthogonal Silhouettes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.11616",
            "ref_texts": "[17] G. Pavlakos, L. Zhu, X. Zhou, K. Daniilidis, Learning to estimate 3d human pose and shape from a single color image, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp.",
            "ref_ids": [
                "17"
            ],
            "1": "2 Related Work Estimation 3D human shape from images is a popular research topic that has been widely studied for many years [3, 8, 15, 16, 17].",
            "2": "[17] G."
        },
        "Synthetic training for monocular human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2010.14036",
            "ref_texts": "[6] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in IEEE CVPR , 2018.",
            "ref_ids": [
                "6"
            ],
            "1": "Recently, more works try to directly recover the 3D human body mesh from a single image [3], [4], [5], [6], [7] to facilitate application.",
            "2": "Recently, plenty of ConvNet-based parameters recovery methods [4], [6], [35], [36], [37] are proposed.",
            "3": "The angular pose is converted from axis-angle representation to rotation matrices via the Rodrigues formula for more stable training [4], [6].",
            "4": "[6] G."
        },
        "FoGMesh: 3D Human Mesh Recovery in Videos with Focal Transformer and GRU": {
            "authors": [],
            "url": "https://bmvc2022.mpi-inf.mpg.de/0618.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "33"
            ],
            "1": "The well-known Skinned Multi-Person Linear model (SMPL) [28] has been widely used by existing approaches [19, 20, 32, 33].",
            "2": "Since then, several studies have been proposed to directly regress the SMPL model parameters using deep neural networks [13, 17, 32, 33].",
            "3": "Moreover, due to the lack of 3D annotations, many existing approaches use a weakly supervised method by re-projecting the losses obtained by 2D key points [17], such as using a self-supervised method by enforcing consistency of the feature representations across different resolutions [44], or recording body and part segmentation as an intermediate representation [32, 33].",
            "4": "Mean-Per-Vertex-Error (MPVE) [33] measures the Euclidean distances between the ground truth vertices and the predicted vertices."
        },
        "3D Spatial Perception with Real-Time Dense Metric-Semantic SLAM": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/150288/RosinolVidal-arosinol-PhD-AeroAstro-2023-thesis.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[206] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pages 459\u2013468, 2018.",
            "ref_ids": [
                "206"
            ],
            "1": "While we refer the reader to [129, 132\u2013134] for a broader review, it is worth mentioning that related work includes optimization-based approaches, which fit a 3D mesh to 2D image keypoints [27,132, 145,297,307], and learning-based methods, which infer the mesh directly from pixel information [119, 132,134,200,206,264]."
        },
        "Leveraging the Learnable Vertex-Vertex Relationship to Generalize Human Pose and Mesh Reconstruction for In-the-Wild Scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2202.07228"
        },
        "Learning Joint Twist Rotation for 3D Human Pose Estimation from a Single Image.": {
            "authors": [],
            "url": "https://pdfs.semanticscholar.org/35ce/a4e3abbdf2bcdc4fa9468117acde8a6d7b53.pdf",
            "ref_texts": "39(4), 82:1\u201382:17. Mehta, D., Sridhar, S., Sot nychenko, O., Rhodin, H., Shafiei, M., Seidel, H.-P., Xu, W., Casas, D., & Theobalt, C. (2017). VNect: real -time 3D human pose estimation with a single RGB camera. TOG, 36(4), 1\u201314. Murthy, P., Butt, H. T., Hiremath, S., Khoshhal, A., & Stricker, D. (2019). Learning 3D joint constraints from vision-based motion capture datasets. IPSJ Transactions on Computer V ision and Applications, 11(1), 5. O m r a n , M . , L a s s n e r , C . , P o n s M o l l , G . , G e h l e r , P . , & Schiele, B. (2018). Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation. 3DV, 484\u2013494. Pavlakos, G., Choutas , V., Ghorbani, N., Bolkart, T., Osman, A. A., Tzionas, D., & Black, M. J. (2019). Expressive Body Capture: 3D Hands, Face, and Body From a Single Image. CVPR, 10967 \u201310977. Pavlakos, G., Zhu, L., Zhou, X., & Daniilidis, K. (2018). Learning to estimate 3D human pose and shape from a single color image. CVPR, 459\u2013468. Rong, Y., Liu, Z., Li, C., Cao, K., & Loy, C. C. (2019). Delving deep into hybrid annotations for 3d human recovery in the wild. ICCV, 5340\u20135348. Simonyan, K., & Zisserman, A. (2015). Very Deep Convolutional Networks for Large-Scale Image Recognition. ICLR. Varol, G., Ceylan, D., Russell, B., Yang, J., Yumer, E., Laptev, I., & Schmid, C. (2018). Bodynet: Volumetric inference of 3d human body shapes. ECCV, 20\u201336. Xiang, D., Joo, H., & Sheikh, Y. (2019). Monocular total c a p t u r e : P o s i n g f a c e , b o d y , a n d h a n d s i n t h e w i l d . CVPR, 10965\u201310974. Xu, J., Yu, Z., Ni, B., Yang, J., Yang, X., & Zhang, W. "
        },
        "Self-supervised Learning and Domain Adaptation for Visual Analysis": {
            "authors": [],
            "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/45771/Lin_washington_0250E_21446.pdf?sequence=1",
            "ref_texts": "[141] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proc. CVPR , pages 459{468, 2018.",
            "ref_ids": [
                "141"
            ],
            "1": "Human mesh construction [118, 203, 67, 78, 101, 141, 67, 95, 194, 91] has recently drawn an increasing attention as it plays an important role for a variety of applications 89 Input frame Our result Input frame Our result Figure 5.",
            "2": "However, many existing approaches [101, 141, 67, 95, 220] require 3D ground truth mesh labels for training.",
            "3": "To address the problem, recent studies [141, 89, 135, 66] propose to use a parametric human model such as skinned multiperson linear model (SMPL) [118] and regress the shape and pose coeflcients of the model.",
            "4": "The regression can be done with the help of various 2D human body features such as human skeletons [101, 141], silhouettes [141], and body part segmentations [135].",
            "5": "To have a fair performance comparison, we follow the previous studies [101, 135, 95, 160, 89, 141] and use the same human mesh topology as the SMPL model [118] in the experiments.",
            "6": "[141] 100 :5 GraphCMR [95] 100 :2 Ours 81 :5 Ours + GT Inputs 73.",
            "7": "We evaluate the performance of mesh construction by using the metric mean Per-Vertex-Error (mPVE) [141], where the unit is millimeter (mm).",
            "8": "[141] 3 75:9 HMR unpaired [89] 3 66:5 NBF [135] 3 59:9 HMR [89] 3 56:8 GraphCMR+SMPL [95] 3 50:1 GraphCMR [95] 7 69:0 Ours 7 58:5 Table 5.",
            "9": "Method Accuracy F1 Accuracy F1 SMPLify [17] 91 :89 0:88 87:71 0:64 SMPLify on [141] 92 :17 0:88 88:24 0:64 BodyNet [190] 92 :75 0:84\u0000 \u0000 HMR [89] 91 :67 0:87 87:12 0:60 GraphCMR [95] 91 :46 0:87 88:69 0:66 Ours 91 :23 0:86 88:86 0:66\n106 Input w/o Laplacian w/ Laplacian Figure 5."
        },
        "Deep Structured Layers for Instance-Level Optimization in 2D and 3D Vision": {
            "authors": [],
            "url": "https://discovery.ucl.ac.uk/id/eprint/10164015/1/Kokkinos_Main.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "30"
            ],
            "1": "SMPL is also a linear statistical model where the coefficients can be easily estimated using optimization [28, 29, 30] or regressed using deep neural networks [31, 32].",
            "2": "On the other end of the spectrum, many methods [34, 30, 35] rely exclusively on regression to address the problem of human 3D reconstruction."
        },
        "A novel self-intersection penalty term for statistical body shape models and its applications in 3d pose estimation": {
            "authors": [],
            "url": "https://www.mdpi.com/2076-3417/9/3/400/pdf",
            "ref_texts": "14. Pavlakos, G.; Zhu, L.; Zhou, X.; Daniilidis, K. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. arXiv 2018 , arXiv:1805.04092.",
            "ref_ids": [
                "14"
            ],
            "1": "[14] used a variant of Hourglass [15] to predict 2D joints and 2D masks simultaneously, then the 2D joints and 2D masks were used to regress pose parameters and shape parameters of SMPL separately in a direct prediction way."
        },
        "Human Motion Analysis Using 3D Skeleton Representation in The Context of Real-World Applications: From Home-Based Rehabilitation to Sensing In The Wild": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/45950/1/RenatoBaptista_PhD_thesis.pdf",
            "ref_texts": "[97] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in CVPR , 2018.",
            "ref_ids": [
                "97"
            ],
            "1": "[97] further trained the network with addition ordinal depth information of human joints as constraints.",
            "2": "An alternative proposed with SURREAL [195] and exploited in [97], is to generate realistic ground-truth data synthetically.",
            "3": "149\n[97] G."
        },
        "A distributed model for computing 3D mesh local descriptors based on k-rings": {
            "authors": [],
            "url": "https://revistas.ulima.edu.pe/index.php/Interfases/article/download/5886/5714",
            "ref_texts": "(Ed.), Proceedings of the Alvey Vision Conference (pp. 23.1-23.6). http://dx.doi. org/10.5244/C.2.23 Herath, U., Tavadze, P., He, X., Bousquet, E., Singh, S., Mu\u00f1oz, F., & Romero, A. H. (2020). PyProcar: A Python library for electronic structure pre/post-processing. Computer Physics Communications, 251 , 107080. https://doi.org/10.1016/j. cpc.2019.107080 Lee, C. H., Varshney, A., & Jacobs, D. W. (2005). Mesh saliency. ACM Transactions on Graphics , 24(3), 659-666. https://doi.org/10.1145/1186822.1073244 Franci Suni-Lopez, Jan Hurtado, Alejandra M\u00e1rquez, Leonardo Guzm\u00e1n INTER FASES n.\u00b0 15 // julio 2022 // ISSN 1993-4912 54Le Tien, M., Tan, K. N., & Raffin, R. (2021, 15-16 December). Analysis of geometrical features of 3D model based on the surface curvature of a set of point cloud. In The 5th International Conference on Future Networks & Distributed Systems (pp. 17-23). The Association of Computing Machinery. https://doi.org/10.1145/3508072.3508076 Levoy, M., Pulli, K., Curless, B., Rusinkiewicz, S., Koller, D., Pereira, L., Ginzton, M., Anderson, S., Davis, J., Ginsberg, J., Shade, J., & Fulk, D. (2000). The digital Michelangelo project: 3D scanning of large statues. In Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques (pp. 131-144). SIFFGRAPH. https://doi.org/10.1145/344779.344849 Li, B., Lu, Y., Li, C., Godil, A., Schreck, T., Aono, M., Burtscher, M., Chen, Q., Chowdhury, N. K., Fang, B., Fu, H., Furuya, T., Li, H., Liu, J., Johan, H., Kosaka, R., Koyanagi, H., Ohbuchi, R., Tatsuma, A., Wan, Y, Zhang, C., & Zou, C. (2015). A comparison of 3D shape retrieval methods based on a large-scale benchmark supporting multimodal queries. Computer Vision and Image Understanding , 131, 1-27. https:// doi.org/10.1016/j.cviu.2014.10.006 Luffel, M., Gurung, T., Lindstrom, P., & Rossignac, J. (2014). Grouper: A Compact, Streamable Triangle Mesh Data Structure. IEEE Transactions on Visualization and Computer Graphics , 20(1), 84-98. https://doi.org/10.1109/TVCG.2013.81 Maquart, T., Elguedj, T., Gravouil, A., & Rochette, M. (2021). 3D B-Rep meshing for real-time data-based geometric parametric analysis. Advanced Modeling and Simulation in Engineering Sciences, 8 , 8. https://doi.org/10.1186/s40323-021-00194-5 Mitra, N. J., Pauly, M., Wand, M., & Ceylan, D. (2013). Symmetry in 3D geometry: Extraction and applications. Computer Graphics Forum, 32 (6), 1-23. https://doi.org/10.1111/ cgf.12010 O\u2019 Sullivan, E., Van de Lande, L. S., Papaioannou, A., Breakey, R. W. F., Jeelani, N. O., Ponniah, A., Duncan, C., Schievano, S., Khonsari, R. H., Zafeiriou, S., & Dunaway, D. J. (2022). Convolutional mesh autoencoders for the 3-dimensional identification of FGFR-related craniosynostosis. Scientific Reports, 12 , 2230. https://doi. org/10.1038/s41598-021-02411-y Pavlakos, G., Zhu, L., Zhou, X., & Daniilidis, K. (2018). Learning to estimate 3D human pose and shape from a single color image . In L. O\u2019Conner (Ed.), Proceedings of the 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. "
        },
        "Animal 3D reconstruction from videos": {
            "authors": [],
            "url": "https://era.library.ualberta.ca/items/40f35ca5-6f26-44ce-ac76-278cf967b9d5/download/76ec0180-9e7a-464f-92dc-c4a493e6459c",
            "ref_texts": "[22] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d CoRR , vol. abs/1805.04092, 2018. arXiv: 1805.04092. [Online]. Available: http://arxiv.org/abs/1805.04092.",
            "ref_ids": [
                "22",
                "Online"
            ],
            "1": "[Online].",
            "2": "[Online].",
            "3": "[Online].",
            "4": "[Online].",
            "5": "[Online].",
            "6": "[Online].",
            "7": "[Online].",
            "8": "[Online].",
            "9": "[Online].",
            "10": "[Online].",
            "11": "[Online].",
            "12": "[Online].",
            "13": "[Online].",
            "14": "[Online].",
            "15": "[22] G.",
            "16": "[Online].",
            "17": "[Online].",
            "18": "[Online].",
            "19": "[Online].",
            "20": "[Online].",
            "21": "[Online].",
            "22": "[Online].",
            "23": "[Online].",
            "24": "[Online].",
            "25": "[Online].",
            "26": "[Online].",
            "27": "[Online].",
            "28": "[Online].",
            "29": "[Online].",
            "30": "[Online].",
            "31": "[Online].",
            "32": "[Online].",
            "33": "[Online].",
            "34": "[Online].",
            "35": "[Online].",
            "36": "[Online].",
            "37": "[Online].",
            "38": "[Online].",
            "39": "[Online].",
            "40": "[Online].",
            "41": "[Online].",
            "42": "[Online].",
            "43": "[Online]."
        },
        "Monocular Human Shape and Pose with Dense Mesh-borne Local Image Features": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.05319",
            "ref_texts": "[28] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "28"
            ],
            "1": "To deal with occlusions and noisy situations which make image-based methods more susceptible to failure, some approaches use alternative inputs such as 2D joint heatmaps [32], silhouettes [28], [33] and semantic segmentation maps [26].",
            "2": "[28] G."
        },
        "Overcoming Data Scarcity in IMU-based Human Motion Analysis": {
            "authors": [],
            "url": "https://macsphere.mcmaster.ca/bitstream/11375/27943/2/Hao_Yujiao_202209_phd.pdf",
            "ref_texts": "[129] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 459\u2013468.",
            "ref_ids": [
                "129"
            ],
            "1": "SMPL has been widely used in HPE tasks [128, 39, 129, 130], which is capable of modelling muscle and soft tissue artifacts.",
            "2": "[129] G."
        },
        "Inferring Dense Human Representation from Sparse or Incomplete Point Clouds": {
            "authors": [],
            "url": "https://inria.hal.science/tel-03880124/file/ZHOU_2022_archivage.pdf",
            "ref_texts": "106 BIBLIOGRAPHY. Sandro Lombardi, Bangbang Yang, Tianxing Fan, Hujun Bao, Guofeng Zhang, Marc Pollefeys, and Zhaopeng Cui. Latenthuman: Shape-and-pose disentangled latent representation for human bodies. In 2021 International Conference on 3D Vision (3DV) , pages 278\u2013288. IEEE, 2021. Matthew Loper, Naureen Mahmood, and Michael J Black. Mosh: Motion and shape capture from sparse markers. ACM Transactions on Graphics (TOG) , 33(6):220, 2014. Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, and Gerard Pons-Moll. Combining implicit function learning and parametric models for 3d human reconstruction. In Proceedings of the European Conference on Computer Vision . Springer, August 2020a. Thiemo Alldieck, Marcus Magnor, Bharat Lal Bhatnagar, Christian Theobalt, and Gerard Pons-Moll. Learning to reconstruct people in clothing from a single rgb camera. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019b. Verica Lazova, Eldar Insafutdinov, and Gerard Pons-Moll. 360-degree textures of people in clothing from a single image. In International Conference on 3D Vision (3DV) , sep 2019. Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, and Gerard Pons-Moll. Loopreg: Self-supervised learning of implicit surface correspondences, pose and shape for 3d human mesh registration. In Advances in Neural Information Processing Systems (NeurIPS) , December 2020b. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 459\u2013468, 2018. Mohamed Omran, Christoph Lassner, Gerard Pons-Moll, Peter Gehler, and Bernt Schiele. Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In 2018 international conference on 3D vision (3DV) , pages 484\u2013494. IEEE, 2018. Wen Jiang, Nikos Kolotouros, Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. Coherent reconstruction of multiple humans from a single image. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5579\u20135588, 2020a. BIBLIOGRAPHY. 107 Muhammed Kocabas, Nikos Athanasiou, and Michael J Black. Vibe: Video inference for human body pose and shape estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5253\u20135263, 2020. Zhengyi Luo, S Alireza Golestaneh, and Kris M Kitani. 3d human motion estimation via motion compression and refinement. In Proceedings of the Asian Conference on Computer Vision , 2020. Jathushan Rajasegaran, Georgios Pavlakos, Angjoo Kanazawa, and Jitendra Malik. Tracking people with 3d representations. arXiv preprint arXiv:2111.07868 , 2021. Angela Dai, Charles Ruizhongtai Qi, and Matthias Nie\u00dfner. Shape completion using 3d-encoder-predictor cnns and shape synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5868\u2013"
        },
        "TriPose: A Weakly-Supervised 3D Human Pose Estimation via Triangulation from Video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.06599",
            "ref_texts": "[29] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "29"
            ],
            "1": "It is however an ill-posed problem and most of the proposed solutions rely on supervised training that requires 3D annotations [22, 29, 11, 34, 5, 19, 27, 28]."
        },
        "Deep deformable models for 3D human body": {
            "authors": [],
            "url": "https://spiral.imperial.ac.uk/bitstream/10044/1/99150/1/Wang-H-2022-PhD-Thesis.pdf",
            "ref_texts": "[87] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 48, 65, 66",
            "ref_ids": [
                "87"
            ],
            "1": "However the axis-angle joint rotations used by the SMPL model is difficult to regress, as such, many methods have been proposed to improve the results either by using an iterative error feedback regressor [10] or intermediate representation of the image such as joint heatmaps and part segmentation maps [87][88].",
            "2": "[88] and Pavlakos [87]), this suggests that the mesh convolutional decoder is a more suitable structure compared to linear blend skinning based models in deep neural networks in the task of mesh recovery from images.",
            "3": "[87] 117.",
            "4": "[87] 75."
        },
        "Predictive personalized three-dimensional body models": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/f3/ff/f3/58aae4279e6ffa/US11069131.pdf",
            "ref_texts": " Conference on Computer Vision (ICCV ) , 2011 , 8 pages . Devries , T. and Taylor , G. W. , Learning Confidence for Out of Distribution Detection in Neural Networks , arXiv preprint arXiv : 1802 . 04865 , 2018 , 12 pages . Dibra , E. , Jain , H \u00d6ztireli , C. , Ziegler , R. and Gross , M. , \u201c HSNets : Estimating Human Body Shape from Silhouettes with Convolu tional Neural Networks , \u201d In International Conference on 3D Vision (3DV ) , 2016 , 10 pages . Dibra , E. , Jain , H. , \u00d6ztireli , C. , Ziegler , R. and Gross , M. , \u201c Human Shape from Silhouettes Using Generative HKS Descriptors and Cross Modal Neural Networks , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2017 , 11 pages . Dibra E. , Jain , H. , \u00d6ztireli , C. , Ziegler , R. and Gross , M. , \u201c Shape from Selfies : Human Body Shape Estimation Using CCA Regres sion Forests , \u201d In European Converence on Computer Vision (ECCV ) , 2016 , 17 pages . Gilbert , A. , Volino , M. , Collomosse , J. and Hilton , A. , \u201c Volumetric Performance Capture from Minimal Camera View Points , \u201d In Euro pean Conference on Computer Vision , 2018 , 16 pages . Gong , K. , Liang , X. , Zhang , D. , Shen , X. and Lin , L. , \u201c Look into Person : Self Supervised Structure Sensitive Learning and a New Benchmark for Human Parsing , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2017 , 9 pages . Ngiam , J. , Khosla , A. , Kim , M. , Nam , J. , Lee , H.and Ng , A. Y , \u201c Multimodal Deep Learning , \u201d In International Conference on Machine Learning (ICML ) , pp . 689-696 , 2011 , 8 pages . Omran , M. , Lassner , C. , Pons Moll , G. , Gehler , P. V. and Schiele , B. , \u201c Neural Body Fitting : Unifying Deep Learning and Model Based Human Pose and Shape Estimation , \" In International Con ference on 3D Vision (3DV ) , 2018 , 13 pages . Pavlakos , G. , Zhu , L. , Zhou , X. and Daniilidis , K. , \u201c Learning to Estimate 3D Human Pose and Shape from a Single Color Image , \" In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2018 , 10 pages . Popa , A.-I. , Zanfir , M. and C. Sminchisescu , C. , \u201c Deep Multitask Architecture for Integrated 2D and 3D Human Sensing , \" In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2017 , 10 pages . Rhodin , H. , Robertini , N. , Casas , D. , Richardt , C. , Seidel , H.-P. and Theobalt , C. , \u201c General Automatic Human Shape and Motion Cap ture Using Volumetric Contour Cues , \u201d In European Conference on Computer Vision , 2016 , 18 pages . Robinette , K. M. , Blackwell , S. , Daanen , H. , Boehmer , M. , Flem ing , S. , Brill , T. , Hoeferlin , D. and Burnsides , D. , \u201c Civilian Ameri can and European Surface Anthropometry Resource (CAESAR ) Final Report , \u201d Tech . Rep . AFRL HEWP TR 2002-0169 , US Air Force Research Laboratory , 2002 , 70 pages . Sigal , L. , B?lan , A. O. and Black , M. J. , \u201c Combined Discriminative and Generative Articulated Pose and Non Rigid Shape Estimation , \u201d In Neural Information Processing Systems (NIPS ) , 2007 , 8 pages . Sun , J. , Ovsjanikov , M. and Guibas , L. , \" A Concise and Provably Informative Multi Scale Signature Based on Heat Diffusion , \u201d In Symposium on Geometry Processing , 2009 , 10 pages . US 11,069,131 B2 "
        },
        "Learning 3D Global Human Motion Estimation from Unpaired, Disjoint Datasets.": {
            "authors": [],
            "url": "https://www.bmvc2020-conference.com/assets/papers/0481.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "23"
            ],
            "1": "[23] completes the same task in a similar manner."
        },
        "Neural mesh reconstruction": {
            "authors": [],
            "url": "https://summit.sfu.ca/_flysystem/fedora/2023-06/etd22528.pdf",
            "ref_texts": "[190] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "190"
            ],
            "1": "1 Deformation-based Deforming a single template mesh to create shapes of different poses has been widely used for face [58] and human body [124, 18, 190] shape reconstruction."
        },
        "Development of 3D body shape creation methodology for obesity information and body shape management for tracking body condition check: body type in their 20s \u2026": {
            "authors": [],
            "url": "https://www.researchsquare.com/article/rs-1837661/latest.pdf",
            "ref_texts": "23. Su, H., Jampani, V., Sun, D., Maji, S., Kalogerakis, E., Yang, M. H., & Kautz, J., Splatnet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2530\u20132539 (2018) Page 14/1624. Pavlakos, G., Zhu, L., Zhou, X., & Daniilidis, K., Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 459\u2013468 (2018).",
            "ref_ids": [
                "23"
            ]
        },
        "Personalized pattern recommendation system of men's shirts based on precise body measurement": {
            "authors": [],
            "url": "https://www.theses.fr/2022CLIL0003.pdf",
            "ref_texts": "[104] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in Proceedings of the IEEE Conferen ce on Computer Vision and Pattern Recognition , 2018, pp. 459 \u2013468. ",
            "ref_ids": [
                "104"
            ],
            "1": "[104] G."
        },
        "AI-enabled wearable sensing system to perform conformity test in healthcare": {
            "authors": [
                "R Zhengxuan"
            ],
            "url": "https://scholar.archive.org/work/dgu6yx7k4rd6hpyz7r3znspbge/access/wayback/https://s3-ap-southeast-2.amazonaws.com/pstorage-mq-9738860830/38057688/01whole.pdf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA3OGA3B5WIXFT74VL/20221107/ap-southeast-2/s3/aws4_request&X-Amz-Date=20221107T194421Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=f042d00b82276627c71536063398e49301d2ec806447a085a769a6e690733c74"
        },
        "Syst\u00e8me de recommandation de patrons personnalis\u00e9s de chemises pour hommes bas\u00e9 sur des mesures corporelles pr\u00e9cises": {
            "authors": [],
            "url": "https://theses.hal.science/tel-04029797/document",
            "ref_texts": "[104] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3D human pose and shape from a single color image,\u201d in Proceedings of the IEEE Conferen ce on Computer Vision and Pattern Recognition , 2018, pp. 459 \u2013468. ",
            "ref_ids": [
                "104"
            ],
            "1": "[104] G."
        },
        "Development of a non-invasive motion capture system for swimming biomechanics": {
            "authors": [],
            "url": "https://e-space.mmu.ac.uk/628369/1/GA%20PhD%20thesis%20MMU.pdf",
            "ref_texts": "[21] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \\Learning to estimate 3d human pose and shape from a single color image,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 459{468, 2018.",
            "ref_ids": [
                "21"
            ],
            "1": "For land-based applications, such systems (which can be broadly categorised as `image-based markerless motion capture systems') have been shown to be accurate enough for biomechanics research [21, 22], but none of them have been successfully applied to swimming6.",
            "2": "In the context of 3D markerless motion capture, shape refers to the dimensions of the object being reconstructed and to its outer surface [21].",
            "3": "Pose, on the other hand, refers to the position in space of the centres of rotation of the person's joints [21].",
            "4": "The simplest way [21] is to project the 3D model back onto the image plane and then measure the overlap between its projection and the original silhouette and/or 2D pose21.",
            "5": "Indeed, the Stacked Hourglass algorithm is the de facto baseline model for 2D pose detection: it is often used as an intermediary step in complex pipelines that require automatic 2D pose detection (such as 2D-to-3D algorithms [21,54,57]), and many newer algorithms for 2D pose detection are essentially modiffed Stacked Hourglass networks [6{8, 185, 186].",
            "6": "[21] G."
        },
        "Learning Body Shape and Pose from Dense Correspondences": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.11955"
        },
        "Full-body performance capture of sports from multi-view video": {
            "authors": [],
            "url": "http://kahlan.eps.surrey.ac.uk/projects/4d/performance_capture_sports/2019_cvmp_bridgeman.pdf",
            "ref_texts": "[6] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "6"
            ],
            "1": "A recent trend has seen the use of CNNs to estimate the model parameters directly from images, as in [6]."
        },
        "\u4ece\u4f20\u7edf\u6e32\u67d3\u5230\u53ef\u5fae\u6e32\u67d3: \u57fa\u672c\u539f\u7406, \u65b9\u6cd5\u548c\u5e94\u7528": {
            "authors": [],
            "url": "http://scis.scichina.com/cn/2021/SSI-2020-0272.pdf",
            "ref_texts": "25Pavlakos G, Zhu L, Zhou X, et al. Learning to estimate 3D human pose and shape from a single color image. In: Proceedings of 2018 IEEE Conference on Computer Vision and Pattern Recognition, Salt Lake City, 2018. 459\u2013"
        },
        "\u57fa\u4e8e\u6df1\u5ea6\u6d4b\u91cf\u7684\u884c\u4eba\u4f53\u6001\u7279\u5f81\u63d0\u53d6\u4e0e\u518d\u8bc6\u522b\u65b9\u6cd5": {
            "authors": [],
            "url": "http://emt.cnjournals.com/yqyb/article/pdf/20230120"
        },
        "\u0420\u0435\u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u044f \u0442\u0440\u0435\u0445\u043c\u0435\u0440\u043d\u043e\u0439 \u043c\u043e\u0434\u0435\u043b\u0438 \u0447\u0435\u043b\u043e\u0432\u0435\u043a\u0430 \u043f\u043e \u0435\u0434\u0438\u043d\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u043c\u0443 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044e": {
            "authors": [],
            "url": "https://rdl-journal.ru/article/download/690/769",
            "ref_texts": "8. Pavlakos G., Zhu L., Zhou X. Learning to estimate 3D human pose and shape from a single color image // Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. P . 459 \u2013468. ",
            "ref_ids": [
                "8"
            ],
            "1": "\u0412\u0441\u0451 \u0447\u0430\u0449\u0435 \u043d\u0430\u0447\u0438\u043d\u0430\u044e\u0442 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u0432\u044b\u0441\u043e\u043a\u043e\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0433\u043b\u0443\u0431\u043e\u043a\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0438 \u0431\u043e\u043b \u044c\u0448\u0438\u0435 \u043f\u0435\u0440\u0441\u043f\u0435\u043a\u0442\u0438\u0432\u044b \u0432 \u0440\u0435\u043a\u043e\u043d\u0441\u0442\u0440\u0443\u043a\u0446\u0438\u0438, \u0434\u0430\u0436\u0435 \u0438\u043c\u0435\u044f \u043d\u0430 \u0432\u0445\u043e\u0434\u0435 \u0432\u0441\u0435\u0433\u043e \u043e\u0434\u043d\u043e \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0435 [8]."
        },
        "Articulated object reconstruction from interaction videos": {
            "authors": [],
            "url": "https://summit.sfu.ca/_flysystem/fedora/2022-08/input_data/22179/etd21501.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "29"
            ],
            "1": "Onthe other hand, regression-based methods [12, 27, 29] rely on deep neural networks andlarge amounts of training data [9, 23] to directly predict the 3D pose of the human."
        },
        "Automated Ergonomics Assessment Through Computer Vision and Machine Learning": {
            "authors": [
                "Carlos Pompeyo"
            ],
            "url": "https://repository.lib.ncsu.edu/bitstream/handle/1840.20/38648/etd.pdf?sequence=1&isAllowed=y"
        },
        "Understanding Tradeoffs Among Algorithm Complexity and Performance": {
            "authors": [],
            "url": "https://escholarship.org/content/qt32f214p3/qt32f214p3.pdf",
            "ref_texts": "[13] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "13"
            ],
            "1": "0 [13] to extract features from input images."
        },
        "Understanding Tradeoffs Between Algorithm Complexity and Performance": {
            "authors": [],
            "url": "https://escholarship.org/content/qt32f214p3/qt32f214p3_noSplash_c8c04204875fea8e5066238ee0f36ccf.pdf",
            "ref_texts": "[13] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "13"
            ],
            "1": "0 [13] to extract features from input images."
        },
        "Learning-based online monitoring for robust robotic perception": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127404/1192555157-MIT.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[29] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to estimate 3d human pose and shape from a single color image,\u201d IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) , pp. 459\u2013468, 2018.",
            "ref_ids": [
                "29"
            ],
            "1": "While we refer the reader to [9, 22] for a broader review, it is worth mentioning that related work includes optimization-based approaches, which fit a 3D mesh to 2D image keypoints [23, 24, 25, 22], and learning-based methods, which infer the mesh directly from pixel information [26, 27, 28, 29, 9, 22].",
            "2": "[29] G."
        },
        "Three-dimensional body composition from two-dimensional images": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/e4/5e/6c/489ceb96ca3c3a/US11423630.pdf",
            "ref_texts": " Based Human Pose and Shape Estimation , \u201d In International Con ference on 3D Vision (3DV ) , 2018 , 13 pages . Pavlakos , G. , Zhu , L. , Zhou , X. and Daniilidis , K. , \u201c Learning to Estimate 3D Human Pose and Shape from a Single Color Image , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2018 , 10 pages . Popa , A.-I. , Zanfir , M. and C. Sminchisescu , C. , \u201c Deep Multitask Architecture for Integrated 2D and 3D Human Sensing , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2017 , 10 pages . US 11,423,630 B1 "
        },
        "Expressive Whole-Body 3D Multi-Person Pose and Shape Estimation from a Single Image": {
            "authors": [],
            "url": "https://s-space.snu.ac.kr/bitstream/10371/175282/1/000000165777.pdf",
            "ref_texts": "[24] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \\Learning to estimate 3D human pose and shape from a single color image,\" in CVPR , 2018.",
            "ref_ids": [
                "24"
            ],
            "1": "[24] used 2D joint heatmaps and silhouette as cues for predicting accurate SMPL parameters.",
            "2": "9 Pavlakos [24] 75.",
            "3": "[24] G."
        },
        "A study on 3D reconstruction of animals in the wild": {
            "authors": [],
            "url": "https://researchportal.murdoch.edu.au/esploro/fulltext/graduate/A-study-on-3D-reconstruction-of/991005540264607891?repId=12135094710007891&mId=13137018920007891&institution=61MUN_INST",
            "ref_texts": "[10] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \"Learning to estimate 3D human p ose and shape from a single color image,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018, pp. 459 -468. ",
            "ref_ids": [
                "10"
            ],
            "1": "Specialised techniques have also been developed for some classes of shapes such as human bod y shapes and faces [9, 10] .",
            "2": "Most existing techniques and methods for 3D reconstruction of human shapes fail to solve the problem in animals [8, 10, 15].",
            "3": "[10] Y Y N Y N Y Y N Mesh CNN -> 3D ground truth \n-> Mesh Lassner et al.",
            "4": "[10] uses the same pipeline in Figure 1 for 2D keypoints and based on the 2D keypoints the mesh representation of human body poses, and deformation is represented.",
            "5": "[10] uses same dataset, and uses same level of sup ervision for their research method, but Pavlakos et al .",
            "6": "[10] uses single RGB image and mask as an input and follows a slight variation in the pipeline for achieving the results .",
            "7": "[10] method achieves higher accuracy than Omran et al.",
            "8": "[10] G."
        },
        "Human Mesh Recovery Using Radio Signals": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/139037/Liu-liuyc-SM-EECS-2021-thesis.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[24]DiederikKingmaandJimmyBa.Adam:Amethodforstochasticoptimization.InProceedingsofthe3rdInternationalConferenceonLearningRepresentations,ICLR,2014.[25]CarnegieMellonGraphicsLab.CMUGraphicsLabMotionCaptureDatabase.[26]ChristophLassner,JavierRomero,MartinKiefel,FedericaBogo,MichaelJBlack,andPeterVGehler.Unitethepeople:Closingtheloopbetween3dand2dhumanrepresentations.InIEEEConf.onComputerVisionandPatternRecognition(CVPR),volume2,page3,2017.[27]JohnPLewis,MattCordner,andNicksonFong.Posespacedeformation:aunifiedapproachtoshapeinterpolationandskeleton-drivendeformation.InProceedingsofthe27thannualconferenceonComputergraphicsandinteractivetechniques,pages165\u2013172.ACMPress/Addison-WesleyPublishingCo.,2000.[28]Tsung-YiLin,PiotrDoll\u00e1r,RossGirshick,KaimingHe,BharathHariharan,andSergeBelongie.Featurepyramidnetworksforobjectdetection.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,pages2117\u20132125,2017.[29]ZhouhanLin,MinweiFeng,CiceroNogueiradosSantos,MoYu,BingXiang,BowenZhou,andYoshuaBengio.Astructuredself-attentivesentenceembedding.ICLR,2017.[30]MatthewLoper,NaureenMahmood,andMichaelJBlack.Mosh:Motionandshapecapturefromsparsemarkers.ACMTransactionsonGraphics(TOG),33(6):220,2014.[31]MatthewLoper,NaureenMahmood,JavierRomero,GerardPons-Moll,andMichaelJ.Black.SMPL:Askinnedmulti-personlinearmodel.ACMTrans.Graphics(Proc.SIGGRAPHAsia),34(6):248:1\u2013248:16,October2015.[32]LarsMescheder,AndreasGeiger,andSebastianNowozin.Whichtrainingmethodsforgansdoactuallyconverge?arXivpreprintarXiv:1801.04406,2018.[33]PavloMolchanov,ShaliniGupta,KihwanKim,andKariPulli.Short-rangefmcwmonopulseradarforhand-gesturesensing.In2015IEEERadarConference(Radar-Con),pages1491\u20131496.IEEE,2015.[34]GeorgiosPavlakos,LuyangZhu,XiaoweiZhou,andKostasDaniilidis.Learningtoestimate3dhumanposeandshapefromasinglecolorimage.InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,pages459\u2013468,2018.[35]JohnPeabodyJr,GregoryLCharvat,JustinGoodwin,andMartinTobias.Through-wallimagingradar.Technicalreport,MassachusettsInstituteofTechnology-LincolnLaboratoryLexingtonUnitedStates,2012.47",
            "ref_ids": [
                "24",
                "25",
                "26",
                "27",
                "28",
                "29",
                "30",
                "31",
                "32",
                "33",
                "34",
                "35"
            ],
            "1": "213RadioFrequencySignalsPrimer233.",
            "2": "244Method254.",
            "3": "264.",
            "4": "274.",
            "5": "274.",
            "6": "274.",
            "7": "274.",
            "8": "284.",
            "9": "284.",
            "10": "284.",
            "11": "304.",
            "12": "304.",
            "13": "319\n4.",
            "14": "315Experiments335.",
            "15": "335.",
            "16": "335.",
            "17": "335.",
            "18": "345.",
            "19": "345.",
            "20": "345.",
            "21": "265-1HumanmeshpredictionfromRF-Avatar.",
            "22": "26cmandmeanvertex-to-vertexdistanceof1.",
            "23": "1ShapeRepresentationCompactandaccuraterepresentationsforhumanbodymesheshavebeenstudiedincom-putergraphics,withmanymodelsproposedinpriorworksuchaslinearblendskinning(LBS),theposespacedeformationmodel(PSD)[27],SCAPE[9],andothers[7].",
            "24": "Morerecently,theSkinnedMulti-PersonLinear(SMPL)modelwasproposedby[31].",
            "25": "[26]developedonthisapproach,incorporatingasemi-automaticannotationschemetoimprovescalability.",
            "26": "Morerecentwork[22,34]demonstratedcapturing3Dmeshesfrom2Dimages,incorporatinganadversariallosstermtoenforcerealism,andKanazawaet.",
            "27": "[26]usedoptimizationmethodstofitSMPLparametersandthusencodehumanshape;however,priorsonhumanmotionwerenotencodedwhentrainingtheirsystems.",
            "28": "4WirelessSensingtoCaptureShapeRadarsystemscanuseRFreflectionstodetectandtrackhumans[4,35].",
            "29": "21\n22 Chapter3RadioFrequencySignalsPrimerMuchoftheworkonsensingpeopleusingradiosignalsusesatechnologycalledFrequencyModulatedContinuousWave(FMCW)[38,33].",
            "30": "25 ttraj 1traj 2 AttentionTPNTCNNPDD RoIAlign\u27131\u27132.",
            "31": "1HumanMeshRepresentationWeusetheSkinnedMulti-PersonLinear(SMPL)model[31]toencodethe3Dmeshofahumanbody.",
            "32": "26\n4.",
            "33": "Proposingregionsin3Dspaceremovesscale-variationofregionsduetoperspectiveprojectiontoimagespace[28].",
            "34": "27\n4.",
            "35": "Weutilizemulti-headedself-attention[29],allowingtheneuralnetworktoattendtodifferentaspectsoftheshapefeaturesdifferently.",
            "36": "Withoutsuchaprior,andespeciallygiventheweaksupervisionforthe3Djointangles(seeSection28\n4.",
            "37": "WeuseMoSh-eddatafromtheCMUMoCapdataset[25]asrealdynamicsdata.",
            "38": "29\n4.",
            "39": "Unfor-tunately,strongsupervisionthatcapturesfullinformationabout3Dmeshesisdifficulttoobtain,asitrequireshighlyconstrainedsettingsfordatacollectioninvolvingasophisti-catedmulti-viewcamerasetup,andminimallyclothedsubjects[30,21];suchsetupsarenotscalable.",
            "40": "30\n4.",
            "41": "WhentrainingTCNNtogetherwiththePDD,wefollowstandardadversarialtrainingschemes[17,32]andusethefollowinglosstermforTCNN:Lprior=\u2212E\u0398\u223cpElog(D(\u0398)),(4.",
            "42": "3)\n31\n32 Chapter5ExperimentsWedescribeourdataset,implementationdetails,quantitativeandqualitativeresultsonshapeandposeestimation,andanalyzewhatislearnedbytheattentionmodule.",
            "43": "Ourself-attentionmoduleusestwofully33 connectedlayerswithtanh(\u00b7)activationinthemiddle.",
            "44": "Duringtraining,ourmodeltakesin300RFframes(10seconds)asinputwithabatchsizeof1.",
            "45": "OurmodelistrainedwiththeAdam[24]optimizerfor40000iterations.",
            "46": "34\n5.",
            "47": "8cm[34].",
            "48": "432.",
            "49": "261.",
            "50": "ACMTransactionsonGraphics,34(6):219,November2015.",
            "51": "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,pages7297\u20137306,2018.",
            "52": "InEuropeanConferenceonComputerVision,pages300\u2013313.",
            "53": "InAdvancesinneuralinformationprocessingsystems,pages2672\u20132680,2014.",
            "54": "InComputerVisionandPatternRecognition(CVPR),2010IEEECon-ferenceon,pages1823\u20131830.",
            "55": "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,pages7122\u20137131,2018.",
            "56": "46\n[24]DiederikKingmaandJimmyBa.",
            "57": "[25]CarnegieMellonGraphicsLab.",
            "58": "[26]ChristophLassner,JavierRomero,MartinKiefel,FedericaBogo,MichaelJBlack,andPeterVGehler.",
            "59": "[27]JohnPLewis,MattCordner,andNicksonFong.",
            "60": "InProceedingsofthe27thannualconferenceonComputergraphicsandinteractivetechniques,pages165\u2013172.",
            "61": "[28]Tsung-YiLin,PiotrDoll\u00e1r,RossGirshick,KaimingHe,BharathHariharan,andSergeBelongie.",
            "62": "InProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition,pages2117\u20132125,2017.",
            "63": "[29]ZhouhanLin,MinweiFeng,CiceroNogueiradosSantos,MoYu,BingXiang,BowenZhou,andYoshuaBengio.",
            "64": "[30]MatthewLoper,NaureenMahmood,andMichaelJBlack.",
            "65": "ACMTransactionsonGraphics(TOG),33(6):220,2014.",
            "66": "[31]MatthewLoper,NaureenMahmood,JavierRomero,GerardPons-Moll,andMichaelJ.",
            "67": "SIGGRAPHAsia),34(6):248:1\u2013248:16,October2015.",
            "68": "[32]LarsMescheder,AndreasGeiger,andSebastianNowozin.",
            "69": "[33]PavloMolchanov,ShaliniGupta,KihwanKim,andKariPulli.",
            "70": "[34]GeorgiosPavlakos,LuyangZhu,XiaoweiZhou,andKostasDaniilidis.",
            "71": "[35]JohnPeabodyJr,GregoryLCharvat,JustinGoodwin,andMartinTobias.",
            "72": "NaturePhotonics,4(7):429,2010.",
            "73": "InIEEProceedingsF(RadarandSignalProcessing),volume139,pages343\u2013350.",
            "74": "InAdvancesinNeuralInformationPro-cessingSystems,pages1278\u20131288,2017.",
            "75": "InProceedingsofthe2018ConferenceoftheACMSpecialInterestGrouponDataCommunication,pages267\u2013281."
        },
        "3D Object Detection and Depth Completion for Scene Perception": {
            "authors": [],
            "url": "https://dam-oclc.bac-lac.gc.ca/download?is_thesis=1&oclc_number=1335043843&id=9d2b8e5e-0393-4180-a238-fc304a67b0e8&fileName=Ku_Jason_%20_202003_MAS_thesis.pdf",
            "ref_texts": "[74] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459{468, 2018.",
            "ref_ids": [
                "74"
            ],
            "1": "More recent works have explored the task of estimating 3D pose keypoints in images [75, 74]."
        },
        "Computer Vision Methods for Sign Language and Cognitive Evaluation through Physical Tasks": {
            "authors": [],
            "url": "https://rc.library.uta.edu/uta-ir/bitstream/handle/10106/29375/DILLHOFF-DISSERTATION-2020.pdf?sequence=1&isAllowed=y"
        },
        "Supplementary Material: Skeleton2Mesh: Kinematics Prior Injected Unsupervised Human Mesh Recovery": {
            "authors": [],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/supplemental/Yu_Skeleton2Mesh_Kinematics_Prior_ICCV_2021_supplemental.pdf",
            "ref_texts": "[6] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , pages 459\u2013468, 2018. 4",
            "ref_ids": [
                "6"
            ],
            "1": "[6] report 50ms per image), but our performance surpasses theirs by significant margins."
        },
        "Structured Prediction with Output Regularization: Improving Statistical and Computational Efficiency": {
            "authors": [],
            "url": "https://www.theses.fr/2023IPPAT015.pdf",
            "ref_texts": "(1):1\u201314, 2017. Anton Osokin, Francis Bach, and Simon Lacoste-Julien. On structured prediction theory with calibrated convex surrogate losses. Advances in Neural Information Processing Systems , 30, 2017. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. Advances in Neural Information Processing Systems , 32:8026\u20138037, 2019. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 459\u2013468, 2018. Bibliography. 146 Gabriel Peyr\u00e9 and Marco Cuturi. Computational optimal transport: With applications to data science. Foundations and Trends\u00ae in Machine Learning , 11(5-6):355\u2013607, 2019. Gabriel Peyr\u00e9, Marco Cuturi, and Justin Solomon. Gromov-Wasserstein averaging of kernel and distance matrices. In International Conference on Machine Learning , pages 2664\u20132672. PMLR, 2016. Venkata K Pillutla, Vincent Roulet, Sham M Kakade, and Zaid Harchaoui. A smoother way to train structured prediction models. Advances in Neural Information Processing Systems 31 , 2018. Boris T Polyak. Some methods of speeding up the convergence of iteration methods. Ussr Computational Mathematics and Mathematical Physics , 4(5):1\u201317, 1964. Ryan Prenger, Rafael Valle, and Bryan Catanzaro. Waveglow: A flow-based generative network for speech synthesis. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) , pages 3617\u20133621. IEEE, 2019. Guillaume Rabusseau and Hachem Kadri. Low-rank regression with tensor responses. Advances in Neural Information Processing Systems , 29:1867\u20131875, 2016. Liva Ralaivola, Sanjay Joshua Swamidass, Hiroto Saigo, and Pierre Baldi. Graph kernels for chemical informatics. Neural Networks , 18(8):1093\u20131110, 2005. Marc\u2019Aurelio Ranzato, Fu Jie Huang, Y-Lan Boureau, and Yann LeCun. Unsupervised learning of invariant feature hierarchies with applications to object recognition. In 2007 IEEE Conference on Computer Vision and Pattern Recognition , pages 1\u20138. IEEE, 2007. Bernardino Romera-Paredes, Hane Aung, Nadia Bianchi-Berthouze, and Massimiliano Pontil. Multilinear multitask learning. In International Conference on Machine Learning , pages 1444\u20131452. PMLR, 2013. Lorenzo Rosasco, Ernesto De Vito, and Alessandro Verri. Spectral methods for regularization in learning theory. DISI, Universita degli Studi di Genova, Italy, Technical Report DISI-TR-05-18 , 2005. Alessandro Rudi and Lorenzo Rosasco. Generalization properties of learning with random features. In NIPS , pages 3215\u20133225, 2017. Alessandro Rudi, Guillermo D. Ca\u00f1as, and Lorenzo Rosasco. On the sample complexity of subspace learning. In Advances in Neural Information Processing Systems , pages 2067\u20132075, 2013. Alessandro Rudi, Ra ffaello Camoriano, and Lorenzo Rosasco. Less is more: Nystr\u00f6m computational regularization. In NIPS , pages 1657\u20131665, 2015. Alessandro Rudi, Carlo Ciliberto, GianMaria Marconi, and Lorenzo Rosasco. Manifold structured prediction. Advances in Neural Information Processing Systems , 31, 2018. David E Rumelhart, Richard Durbin, Richard Golden, and Yves Chauvin. Backpropagation: The basic theory. Backpropagation: Theory, Architectures and Applications , pages 1\u201334, 1995. Bibliography. 147 Hasim Sak, Andrew W Senior, and Fran\u00e7oise Beaufays. Long short-term memory recurrent neural network architectures for large scale acoustic modeling. INTERSPEECH 2014, 15th Annual Conference of the International Speech Communication Association , 2014. Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and control. In International Conference on Machine Learning , pages 4470\u20134479. PMLR, 2018. Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural Networks , 20(1):61\u201380, 2008. Bernhard Sch\u00f6lkopf, Ralf Herbrich, and Alex J. Smola. A generalized representer theorem. In International Conference on Computational Learning Theory , pages 416\u2013"
        },
        "Computer Vision-based Marker-less Real Time Motion Analysis for Rehabilitation\u2013An Interdisciplinary Research Project": {
            "authors": [],
            "url": "https://www.theseus.fi/bitstream/handle/10024/452905/AWP-1-2021_Hellsten_Karlsson_Pulkkis.pdf?sequence=1",
            "ref_texts": "\"Quantitative measurements of forward head posture in a clinical settings: a technical feasibility study\", European journal of physiotherapy, vol. 19, no. 3, pp. 119123. Mishima, N. & Berg, M. 2020, M\u00e4tning av vinkeln i kn\u00e4leden vid ett aktivt kn\u00e4b\u00f6j med ett mark\u00f6rl\u00f6st datorseendeprogram , Arcada UAS. Mohsin, F., McGarry, A. & Bowers, R. 2018, \"The Reliability of a Video Analysis System (PnO Clinical Movement Data) and the Universal Goniometer in the Measurement of Hip, Knee, and Ankle Sagittal Plane Motion among Healthy Subjects\", Journal of prosthetics and orthotics, vol. 30, no. 3, pp. 1. Pavlakos, G., Zhou, X., Derpanis, K.G. & Daniilidis, K. 2017, \"Harvesting multiple views for marker-less 3d human pose annotations\", Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 6988. Pavlakos, G., Zhu, L., Zhou, X. & Daniilidis, K. 2018, \"Learning to estimate 3D human pose and shape from a single color image\", Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 459. Reissner, L., Fischer, G., List, R., Taylor, W.R., Giovanoli, P. & Calcagni, M. 2019, "
        },
        "EAS Journal of Nursing and Midwifery": {
            "authors": [],
            "url": "https://www.easpublisher.com/media/features_articles/EASJNM_31_12-18c_c5cRIG7.pdf",
            "ref_texts": ""
        },
        "Inf\u00e9rer une repr\u00e9sentation dense de l'humain avec un nuage de points \u00e9pars ou incomplet": {
            "authors": [],
            "url": "https://www.theses.fr/2022GRALM033.pdf",
            "ref_texts": "106 BIBLIOGRAPHY. Sandro Lombardi, Bangbang Yang, Tianxing Fan, Hujun Bao, Guofeng Zhang, Marc Pollefeys, and Zhaopeng Cui. Latenthuman: Shape-and-pose disentangled latent representation for human bodies. In 2021 International Conference on 3D Vision (3DV) , pages 278\u2013288. IEEE, 2021. Matthew Loper, Naureen Mahmood, and Michael J Black. Mosh: Motion and shape capture from sparse markers. ACM Transactions on Graphics (TOG) , 33(6):220, 2014. Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, and Gerard Pons-Moll. Combining implicit function learning and parametric models for 3d human reconstruction. In Proceedings of the European Conference on Computer Vision . Springer, August 2020a. Thiemo Alldieck, Marcus Magnor, Bharat Lal Bhatnagar, Christian Theobalt, and Gerard Pons-Moll. Learning to reconstruct people in clothing from a single rgb camera. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , June 2019b. Verica Lazova, Eldar Insafutdinov, and Gerard Pons-Moll. 360-degree textures of people in clothing from a single image. In International Conference on 3D Vision (3DV) , sep 2019. Bharat Lal Bhatnagar, Cristian Sminchisescu, Christian Theobalt, and Gerard Pons-Moll. Loopreg: Self-supervised learning of implicit surface correspondences, pose and shape for 3d human mesh registration. In Advances in Neural Information Processing Systems (NeurIPS) , December 2020b. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 459\u2013468, 2018. Mohamed Omran, Christoph Lassner, Gerard Pons-Moll, Peter Gehler, and Bernt Schiele. Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In 2018 international conference on 3D vision (3DV) , pages 484\u2013494. IEEE, 2018. Wen Jiang, Nikos Kolotouros, Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. Coherent reconstruction of multiple humans from a single image. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5579\u20135588, 2020a. BIBLIOGRAPHY. 107 Muhammed Kocabas, Nikos Athanasiou, and Michael J Black. Vibe: Video inference for human body pose and shape estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 5253\u20135263, 2020. Zhengyi Luo, S Alireza Golestaneh, and Kris M Kitani. 3d human motion estimation via motion compression and refinement. In Proceedings of the Asian Conference on Computer Vision , 2020. Jathushan Rajasegaran, Georgios Pavlakos, Angjoo Kanazawa, and Jitendra Malik. Tracking people with 3d representations. arXiv preprint arXiv:2111.07868 , 2021. Angela Dai, Charles Ruizhongtai Qi, and Matthias Nie\u00dfner. Shape completion using 3d-encoder-predictor cnns and shape synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5868\u2013"
        },
        "Pushing the envelope for estimating poses and actions via full 3D reconstruction": {
            "authors": [],
            "url": "https://spiral.imperial.ac.uk/bitstream/10044/1/96473/1/Baek-S-2020-PhD-Thesis.pdf",
            "ref_texts": "[139] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 66, 68, 69",
            "ref_ids": [
                "139"
            ],
            "1": "Since RGB/mesh pairs are not sufficient, the network is learned to fit the 3D model using 2D segmentation masks and skeletons as supervision, similar to recent work on human body pose estimation [77, 139, 209], via neural renderer.",
            "2": "Inspired by the success of existing human body reconstruction work [77,139,209], we take an indirect approach by learning a DHPE which combines the HME and a new projection operator .",
            "3": "Adopting recent human body pose estimation approaches [139, 209], we 68 further stratify learning of fDHPE:XC!Yby decomposing fHME:XC!YPinto a 2D evidence estimator fE2D:XC!Z and a 3D mesh estimator fE3D:Z! YP.",
            "4": "1 2D evidence estimator fE2D= (F,fJ2D) Silhouettes (or foreground masks) and 2D skeletons have been widely used as the mid-level cues for estimating 3D body meshes [78, 139, 209].",
            "5": "15\n[139] G."
        },
        "Measuring, modelling, simulating, and predicting human tissue properties": {
            "authors": [
                "Austin Caulfield"
            ],
            "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0387124/4",
            "ref_texts": "[44] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In Conference on Computer Vision and Pattern Recognition , 2018.!page 7",
            "ref_ids": [
                "44"
            ],
            "1": "Finally, there has been a significant amount of work on learning body shape from images [7, 11, 14, 22, 44].",
            "2": "!pages v, 12, 15, 23, 24\n[44] G."
        },
        "Markerloses 3D-Tracking von Menschen und Bauteil zur Ansteuerung eines Spatial Augmented Reality Assistenzsystems": {
            "authors": [
                "David Kostolani"
            ],
            "url": "https://scholar.archive.org/work/tksgjv3hpnbz7msb35r5nq7spq/access/wayback/https://repositum.tuwien.at/bitstream/20.500.12708/16710/1/Markerloses%20D-Tracking%20von%20Menschen%20und%20Bauteil%20zur%20Ansteuerung%20eines%20Spatial%20Augmented%20Reality%20Assistenzsystems.pdf",
            "ref_texts": ""
        },
        "FISHnet: Learning to Segment the Silhouettes of Swimmers": {
            "authors": [],
            "url": "https://core.ac.uk/download/pdf/334952605.pdf",
            "ref_texts": "[7] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, ``Learning to estimate 3D human pose and shape from a single color image,'' in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., Jun. 2018, pp. 459\u0015468.",
            "ref_ids": [
                "7"
            ],
            "1": "The silhouette and/or the 2D joints are then used as inputs for either an optimisation algorithm (typically Iterative Closest Point [5], [6]) or a neural network (typically a deep convolutional neural network [7]\u0015[9], more recently a generative adversarial The associate editor coordinating the review of this manuscript and approving it for publication was Kang Li .",
            "2": "The literature seems to agree on what the best options are to extract the 2D locations of the joints (which are collectively referred to as 2D pose): they can be either digitised manually [4], or extracted automatically by a deep neural network, such as the Stacked Hourglass network [7], [12] or OpenPose [13].",
            "3": "More recently, off-the-shelf convolutional neural networks (CNNs) have replaced background subtraction in 2D-to-3D pipelines [7], [9] and in 2D real-time segmentation of sports videos [17], leading to better and more generalisable results.",
            "4": "[7] developed a CNN for silhouette extraction.",
            "5": "[7] G."
        },
        "Extraction de comportements reproductibles en avatar virtuel": {
            "authors": [
                "Kodjine Dare"
            ],
            "url": "https://papyrus.bib.umontreal.ca/xmlui/bitstream/handle/1866/26525/Dare_Kodjine_2021_Memoire.pdf?sequence=4",
            "ref_texts": "86 Z. Cao, T. Simon, S. Wei, Y. Sheikh: Realtime multi -person 2d pose estimation using part affinity fields. In: Proceedings of the IEEE Conference on CVPR, pp. 7291 -7299. Hawaii (2017). A. Agarwal, B. Triggs: Recovering 3d huma n pose from monocular images. TPAMI 28(1), 44 \u201358(2006). S. Zhou, H. Fu, L. Liu, D. Cohen -Or, X. Han: Parametric reshaping of human bodies in images. In: SIGGRAPH \u201910, pp. 1 -10. Association for Computing Machinery, USA (2010). M. Loper, N. Mahmood, J. Romero, G. Pons -Moll, M. J. Black: SMPL: A skinned multi -person linear model. ACM Trans. Graphics 34(6), 1 -16 (2015). A. Kanazawa, M. J. Black, D. W. Jacobs, J. Malik: End -to-end recovery of human shape and pose. In: Proceedings of the IEEE Conference on C VPR, pp. 7122 -7131. IEEE Computer Society, Salt Lake City -USA (2018). H.-Y. Tung, H. -W. Tung, E. Yumer, K. Fragkiadaki: Self -supervised learning of motion capture. In: Proceedings of the 31st International Conference on NIPS, pp. 5242 \u20135252. Curran Associat es Inc, Long Beach -USA (2017). G. Pavlakos, L. Zhu, X. Zhou, K. Daniilidis: Learning to estimate 3D human pose and shape from a single -color image. In: Proceedings of the IEEE Conference on CVPR, pp. 459 -468. IEEE Computer Society, Salt Lake City -USA (2018 ). M. Omran, C. Lassner, G. Pons -Moll, P. Gehler, B. Schiele: Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In: International Conference on 3DV, pp. 484 -494. IEEE Computer Society, Verona -Italy (2018). T. Alld ieck, M. Magnor, W. Xu, C. Theobalt, G. Pons -Moll: Video based reconstruction of 3d people model. In: Proceedings of the IEEE Conference on CVPR, pp. 8387 -8397. IEEE Computer Society, Salt Lake City -USA (2018). G. Papandreou, T. Zhu, Tyler, L -C. Chen, S. G idaris, J. Tompson, K. Murphy: PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom -Up, Part -Based, Geometric Embedding Model. In: Ferrari V., Hebert M., Sminchisescu C., Weiss Y. (eds) ECCV 2018, LNCS, vol 11218. Springer, Cham (2018) . "
        },
        "IMAGE GENERATION WITH CONVOLUTIONAL NEURAL NETWORKS": {
            "authors": [
                "Dmitry Ulyanov"
            ],
            "url": "https://www.skoltech.ru/app/data/uploads/2019/11/thesis24.pdf",
            "ref_texts": "(Jan):19{60, 2010. Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian J. Goodfellow. Adversarial autoencoders. Proc. ICLR , 2016. Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, and Zhen Wang. Multi-class generative adversarial networks with the L2 loss function. CoRR , abs/1611.04076, 2016. Antonio Marquina. Nonlinear inverse scale space methods for total variation blind deconvolution. SIAM J. Imaging Sciences , 2(1):64{83, 2009. Ricardo Martin-Brualla, Rohit Pandey, Shuoran Yang, Pavel Pidlypenskyi, Jonathan Taylor, Julien P. C. Valentin, Sameh Khamis, Philip L. Davidson, Anastasia Tkach, Peter Lincoln, Adarsh Kowdle, Christoph Rhemann, Dan B. Goldman, Cem Keskin, Steven M. Seitz, Shahram Izadi, and Sean Ryan Fanello. LookinGood : enhancing performance capture with real-time neural re-rendering. ACM Trans. Graph. , 37(6): 255:1{255:14, 2018. Youssef Marzouk, Tarek Moselhy, Matthew Parno, and Alessio Spantini. An introduction to sampling via measure transport. arXiv preprint arXiv:1602.05023 , 2016. Masahiro Mori. The uncanny valley. Energy , 7(4):33{35, 1970. Franziska Mueller, Florian Bernard, Oleksandr Sotnychenko, Dushyant Mehta, Srinath Sridhar, Dan Casas, and Christian Theobalt. GANerated hands for real-time 3d hand tracking from monocular RGB. In Proc. CVPR , June 2018. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading digits in natural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011 , 2011. URL http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf . Natalia Neverova, Riza Alp G\u007f uler, and Iasonas Kokkinos. Dense pose transfer. In Proc. ECCV , September 2018. Mohamed Omran, Christoph Lassner, Gerard Pons-Moll, Peter V. Gehler, and Bernt Schiele. Neural body fftting: Unifying deep learning and model-based human pose and shape estimation. Verona, Italy, 2018. Bibliography. 119 G. Owen. Game Theory . Academic Press, 1982. ISBN 9780125311502. URL https: //books.google.ru/books?id=pusfAQAAIAAJ . Vardan Papyan, Yaniv Romano, and Michael Elad. Convolutional neural networks analyzed via convolutional sparse coding. Journal of Machine Learning Research , 18(83): 1{52, 2017a. Vardan Papyan, Yaniv Romano, Jeremias Sulam, and Michael Elad. Convolutional dictionary learning via local processing. In Proc. ICCV , 2017b. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proc. CVPR , June 2018. Georg Petschnigg, Richard Szeliski, Maneesh Agrawala, Michael F. Cohen, Hugues Hoppe, and Kentaro Toyama. Digital photography with ash and no-ash image pairs. ACM Trans. Graph. , 23(3):664{672, 2004. Gerard Pons-Moll, Javier Romero, Naureen Mahmood, and Michael J Black. Dyna: A model of dynamic human shape in motion. ACM Transactions on Graphics (TOG) , 34(4):120, 2015. J. Portilla and E. P. Simoncelli. A parametric texture model based on joint statistics of complex wavelet coeflcients. IJCV , 40(1):49{70, 2000. Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. Proc. ICLR , 2016. Alex Rav-Acha, Pushmeet Kohli, Carsten Rother, and Andrew W. Fitzgibbon. Unwrap mosaics: a new representation for video editing. ACM Trans. Graph. , 27(3):17:1{"
        },
        "Supplementary Material for \u201cCoherent Reconstruction of Multiple Humans from a Single Image\u201d": {
            "authors": [],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/supplemental/Jiang_Coherent_Reconstruction_of_CVPR_2020_supplemental.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 3",
            "ref_ids": [
                "23"
            ],
            "1": ", [10, 21, 23] do not directly compare with skeleton-based approaches, e."
        },
        "3D Human Mesh Regression with Dense Correspondence** Supplementary Material": {
            "authors": [],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/supplemental/Zeng_3D_Human_Mesh_CVPR_2020_supplemental.pdf",
            "ref_texts": "[16] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018.",
            "ref_ids": [
                "16"
            ],
            "1": "[16] uses no training data from Human3.",
            "2": "[16] NBF[15] HMR [7] SPIN [9] DenseRac [20] CMR [10] Ours Human3."
        },
        "Supplemental Material: Hierarchical Kinematic Human Mesh Recovery": {
            "authors": [],
            "url": "https://cs.gmu.edu/~ggeorgak/eccv2020/supp.pdf",
            "ref_texts": "5. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018.",
            "ref_ids": [
                "5"
            ],
            "1": "[5] 75."
        },
        "Wearable device battery conservation": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/da/24/22/c483196f425fa2/US11477736.pdf",
            "ref_texts": " Omran , M. , Lassner , C. , Pons Moll , G. , Gehler , P. V. and Schiele , B. , \u201c Neural Body Fitting : Unifying Deep Learning and Model Based Human Pose and Shape Estimation , \u201d In International Con ference on 3D Vision (3DV ) , 2018 , 13 pages . Pavlakos , G. , Zhu , L. , Zhou , X. and Daniilidis , K. , \u201c Learning to Estimate 3D Human Pose and Shape from a Single Color Image , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2018 , 10 pages . Popa , A.-I. , Zanfir , M. and C. Sminchisescu , C. , \u201c Deep Multitask Architecture for Integrated 2D and 3D Human Sensing , \u201d In IEEE Conference on Computer Vision and Pattern Recognition (CVPR ) , 2017 , 10 pages . Rhodin , H. , Robertini , N. , Casas , D. , Richardt , C. , Seidel , H.-P. and Theobalt , C. , \u201c General Automatic Human Shape and Motion Cap ture Using Volumetric Contour Cues , \u201d In European Conference on Computer Vision , 2016 , 18 pages . Robinette , K. M. , Blackwell , S. , Daanen , H. , Boehmer , M. , Flem ing , S. , Brill , T. , Hoeferlin , D. and Burnsides , D. , \u201c Civilian Ameri can and European Surface Anthropometry Resource (CAESAR ) Final Report , \u201d Tech . Rep . AFRL HEWP TR 2002-0169 , US Air Force Research Laboratory , 2002 , 70 pages . Sigal , L. , B?lan , A. O. and Black , M. J. , \u201c Combined Discriminative and Generative Articulated Pose and Non Rigid Shape Estimation , \u201d In Neural Information Processing Systems (NIPS ) , 2007 , 8 pages . Sun , J. , Ovsjanikov , M. and Guibas , L. , \u201c A Concise and Provably Informative Multi Scale Signature Based on Heat Diffusion , \u201d In Symposium on Geometry Processing , 2009 , 10 pages . Tan , J. K. V. , Budvytis , I. and Cipolla , R. , \u201c Indirect Deep Structured Learning for 3D Human Body Shape and Pose Prediction , \u201d In British Machine Vision Conference , 2017 , 11 pages . TC2 Labs LLC , \u201c SizeUSA \u201d , 3 pages , http://scan2fit.com/sizeusa/ about.php Varol , G. , Ceylan , D. , Russell , B. , Yang , J. , Yumer , E. , Laptev , I. and Schmid , C. , \u201c BodyNet : Volumetric Inference of 3D Human Body Shapes , \u201d In European Conference on Computer Vision (ECCV ) , 2018 , 17 pages . > > "
        },
        "Motion retargeting with kinematic constraints": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/2d/c4/0f/07347c4b44b868/US20220020199A1.pdf"
        },
        "Method and apparatus with human body estimation": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/a0/64/8c/c3e58df0ff5486/US20220189123A1.pdf"
        },
        "Learning to Reconstruct 3D Human Pose and Shape via Model-fitting in the Loop** Supplementary Material": {
            "authors": [],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Kolotouros_Learning_to_Reconstruct_ICCV_2019_supplemental.pdf",
            "ref_texts": "[10] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. In CVPR , 2018. 1",
            "ref_ids": [
                "10"
            ],
            "1": ", [3, 10, 11]3DPW LSP (masks) MPI-INF static fits (from mean pose init) 66."
        },
        "End-to-end Hand Mesh Recovery from a Monocular RGB Image Supplementary Material": {
            "authors": [],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/supplemental/Zhang_End-to-End_Hand_Mesh_ICCV_2019_supplemental.pdf",
            "ref_texts": "[4] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 459\u2013468, 2018. 1",
            "ref_ids": [
                "4"
            ],
            "1": "al [4] 0."
        },
        "3D human body mesh generation from 2D images using body silhouette, bone orientation, and joints triangulation": {
            "authors": [],
            "url": "https://espace.etsmtl.ca/id/eprint/2769/1/AJANOHOUN_Jordy.pdf",
            "ref_texts": "10 19. Loper, M., Mahmood, N., Romero, J., Pons-Moll, G. & Black, M. J. (2015). SMPL: A Skinned Multi-Person Linear Model. ACM Transactions on Graphics , 34(6), 248:1\u2013248:16. Loper, M. M. & Black, M. J. (2014). OpenDR: An Approximate Differentiable Renderer. European Conference on Computer Vision (ECCV) , 8695, 154\u2013169. Madadi, M., Bertiche, H. & Escalera, S. (2020). SMPLR: Deep learning based SMPL reverse for 3D human pose and shape recovery. Pattern Recognition , 106, 107472. Newell, A., Yang, K. & Deng, J. (2016). Stacked Hourglass Networks for Human Pose Estimation. European Conference on Computer Vision (ECCV) , pp. 483\u2013499. Nocedal, J. & Wright, S. J. (2006). Numerical optimization (ed. 2). Springer. Omran, M., Lassner, C., Pons-Moll, G., Gehler, P. V. & Schiele, B. (2018). Neural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation. International Conference on 3D Vision (3DV) , pp. 484\u2013494. Pavlakos, G., Zhou, X., Derpanis, K. G. & Daniilidis, K. (2017a). Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1263-1272. Pavlakos, G., Zhou, X., Derpanis, K. G. & Daniilidis, K. (2017b, July). Harvesting Multiple Views for Marker-Less 3D Human Pose Annotations. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1253-1262. Pavlakos, G., Zhu, L., Zhou, X. & Daniilidis, K. (2018). Learning to Estimate 3D Human Pose and Shape from a Single Color Image. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 459\u2013468. Pishchulin, L., Insafutdinov, E., Tang, S., Andres, B., Andriluka, M., Gehler, P. & Schiele, B."
        },
        "\u5f71\u5b50\u8f85\u52a9\u7684\u4e09\u7ef4\u4eba\u4f53\u91cd\u5efa": {
            "authors": [],
            "url": "https://www.jcad.cn/cn/article/pdf/preview/d7b354ea-fad5-46d4-b755-4d349a8f8b64.pdf",
            "ref_texts": "[14]Pavlakos G, Zhu L, Zhou X, et al. Learning to estimate 3D hu man pose and shape from a single color image[C] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 459-468.",
            "ref_ids": [
                "14",
                "C"
            ],
            "1": "Pavlakos \u7b49[14]\u548c\u66fe\u5fd7\u8d85\u7b49[15]\n\u68c0\u6d4b\u56fe\u50cf\u4e2d\u7684\u4eba\u4f53\u8f6e\u5ed3 , \u5e76\u6839\u636e\u8f6e\u5ed3\u4f30\u8ba1\u4f53\u578b.",
            "2": "End-to-end recovery of human shape and pose[C] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "3": "Learning to reconstruct 3D human pose and shape via model-fitting in the loop[C] //Proceedings of the IEEE/CVF International Confer ence on Computer Vision.",
            "4": "Vibe: Video inference for human body pose and shape estimation[C] //Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition.",
            "5": "End-to-end human pose and mesh re construction with transformers[C] //Proceedings of the IEEE/ CVF Conference on Computer Vision and Pattern Recognition.",
            "6": "Thundr: Transformerbased 3d human reconstruction with markers[C] //Proceedings of the IEEE/CVF International Conference on Computer Vi sion.",
            "7": "Monocular 3d pose estimation and tracking by detection[C] //2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition.",
            "8": "Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image[C] //European Conference on Computer Vision.",
            "9": "I2l-meshnet: Image-to-lixel prediction net work for accurate 3d human pose and mesh estimation from a single rgb image[C] //European Conference on Computer Vi sion.",
            "10": "[14]Pavlakos G, Zhu L, Zhou X, et al.",
            "11": "Learning to estimate 3D hu man pose and shape from a single color image[C] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "12": "Video based reconstruction of 3d people models[C] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "13": "Neural body fitting: Unifying deep learning and model based human pose and shape estimation[C] //International Conference on 3D Vision (3DV).",
            "14": "Bodynet: V olumetric inference of 3d human body shapes[C] //Proceedings of the Euro pean Conference on Computer Vision (ECCV).",
            "15": "Towards 3d human pose esti mation in the wild: a weakly-supervised approach[C] //Pro ceedings of the IEEE International Conference on Computer Vision.",
            "16": "Ordinal depth supervision for 3d human pose estimation[C] //Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "17": "Learning monocular 3d human pose estimation from multi-view images[C] //Proceed ings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "18": "Weakly-supervised 3d human pose learning via multi-view images in the wild[C] //Proceed ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.",
            "19": "Cross-view tracking for multi-hu man 3d pose estimation at over 100 fps[C] //Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog nition.",
            "20": "Motion capture from internet videos[C] //European Conference on Computer Vision.",
            "21": "Reconstructing 3d human pose by watching humans in the mirror[C] //Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog nition.",
            "22": "A multi-task mean teacher for semi-supervised shadow detection[C] //Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recog nition.",
            "23": "Stacked hourglass networks for hu man pose estimation[C] //European Conference on Computer Vision.",
            "24": "Explicit Residual Descent for 3D Human Pose Estimation from 2D Joint Locations[C] //The British Machine Vision Conference.",
            "25": "Learning 3d human dynamics from video[C] //Proceedings of the IEEE/CVF Confer ence on Computer Vision and Pattern Recognition.",
            "26": "Convolutional mesh regression for single-image human shape reconstruction[C] // Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.",
            "27": "Camera distance-aware topdown approach for 3d multi-person pose estimation from a sin -gle RGB image[C] //Proceedings of the IEEE/CVF Interna tional Conference on Computer Vision."
        },
        "\uc601\uc0c1\uacfc \ube44\ub514\uc624\ub85c\ubd80\ud130\uc758 3 \ucc28\uc6d0 \ud734\uba3c \uc790\uc138 \ubc0f \ud615\uc0c1 \ubcf5\uc6d0 \uae30\uc220": {
            "authors": [],
            "url": "http://www.kibme.org/resources/journal/20220617111149246.pdf",
            "ref_texts": "[8] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis, Learning to Estimate {3D} Human Pose and Shape From a Single Color Image, Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018), pp. 459-468.",
            "ref_ids": [
                "8"
            ],
            "1": "\ud559\uc2b5 \uae30\ubc18 \uc811\uadfc\ubc95\ub4e4\uc740 \ucd94\uac00\uc801\uc73c\ub85c \ubaa8\ub378 \uae30\ubc18(model-based) \uc811\uadfc\ubc95[1, 2, 3, 6, 7, 8, 12, 14, 18, 21, 26, 30]\uacfc \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294(model-free) \uc811\uadfc\ubc95[10, 15, 22]\uc73c\ub85c \ub098\ub220\uc9c8 \uc218 \uc788\ub2e4.",
            "2": "\ud559\uc2b5 \uae30\ubc18 \uc811\uadfc\ubc95\ub4e4\uc740 \ucd94\uac00\uc801\uc73c\ub85c \ubaa8\n\ub378 \uae30\ubc18(model -based) \uc811\uadfc\ubc95 [1, 2, 3, 6, 7, 8, 12, 14, 18, 21, 26, 30 ]\uacfc \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294(model free) \uc811\uadfc\ubc95 [10, 15, 22 ]\uc73c\ub85c \ub098\ub220\uc9c8 \uc218 \uc788\ub2e4.",
            "3": "\ud559\uc2b5 \uae30\ubc18 \uc811\uadfc\ubc95\ub4e4\uc740 \ucd94\uac00\uc801\uc73c\ub85c \ubaa8\n\ub378 \uae30\ubc18(model -based) \uc811\uadfc\ubc95 [1, 2, 3, 6, 7, 8, 12, 14, 18, 21, 26, 30 ]\uacfc \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\ub294(model free) \uc811\uadfc\ubc95 [10, 15, 22 ]\uc73c\ub85c \ub098\ub220\uc9c8 \uc218 \uc788\ub2e4.",
            "4": "\ucd5c\uadfc \ub2e4\uc218\uc758 \uc5f0\uad6c\ub4e4[1, 2, 3, 6, 7, 8, 12, 14, 18, 21, 26, 30]\uc5d0\uc11c \ubaa8\ub378 \uae30\ubc18 \uc811\uadfc\ubc95\uc774 \uc0ac\uc6a9\ub418\uc5c8\uc73c\uba70, \uc8fc\ubaa9\ud560 \ub9cc\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc5c8\ub2e4.",
            "5": "\uadf8 \ud6c4 Pavlakos \ub4f1\uc740 \ub2e8\uc77c \uc601\uc0c1\uc5d0\uc11c SMPL \ub9e4\uac1c\ubcc0\uc218\n\ub97c \ucd94\uc815\ud558\ub294 CNN \uae30\ubc18 \ubc29\ubc95[8]\uc744 \uc81c\uc548\ud588\ub2e4.",
            "6": "\ucd5c\n\uadfc \ub2e4\uc218\uc758 \uc5f0\uad6c\ub4e4[1, 2, 3, 6, 7, 8, 12, 14, 18, 21, 26, 30 ]\uc5d0\uc11c \ubaa8\ub378 \uae30\ubc18 \uc811\uadfc\ubc95\uc774 \uc0ac\uc6a9\ub418\uc5c8 \uc73c\uba70, \uc8fc\n\ubaa9\ud560 \ub9cc\ud55c \uacb0\uacfc\ub97c \ubcf4\uc5ec\uc8fc\uc5c8\ub2e4 .",
            "7": "\uadf8 \ud6c4 Pavlakos \ub4f1\uc740 \ub2e8\uc77c \uc601\uc0c1\uc5d0\uc11c SMPL \ub9e4\uac1c\ubcc0\uc218\ub97c \ucd94\uc815\ud558\ub294 CNN \uae30\ubc18 \ubc29\ubc95[8]\uc744 \uc81c\uc548\ud588\n\ub2e4.",
            "8": "[8]\uc740 \ud734\uba3c \uba54\uc26c\ub97c \uc601\uc0c1 \uacf5\uac04\uc5d0\uc11c\uc758 \ud734\uba3c \ub9c8\uc2a4\ud06c\ub85c \ub098\n\ud0c0\ub0b8 \ud6c4 \uc774\ub97c \ud65c\uc6a9\ud558\ub294 \uc2e4\ub8e8\uc5e3 \uc190\uc2e4 \ud568\uc218(LSil)\ub97c \uc81c\uc548\ud588\n\uace0, \uc774 \uc190\uc2e4 \ud568\uc218\ub294 \ud734\uba3c \ubcf5\uc6d0 \uacb0\uacfc\ub97c \ucd94\uac00\uc801\uc73c\ub85c \ud5a5\uc0c1\uc2dc\ud0ac \uc218 \uc788\ub294 \uac83\uc73c\ub85c \uc54c\ub824\uc838 \uc788\ub2e4."
        },
        "Derin \u00f6\u011frenme kullan\u0131larak g\u00f6r\u00fcnt\u00fclerden insan duru\u015f tespiti": {
            "authors": [],
            "url": "https://acikerisim.sakarya.edu.tr/bitstream/handle/20.500.12619/97194/T09577.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[5] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u201cLearning to Estimate 3D Human Pose a nd Shape from a Single Color Image,\u201d Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit. , pp. 459 \u2013468, 2018, doi: ",
            "ref_ids": [
                "5"
            ],
            "1": "Pavlokos ve ark [5], yapm\u0131\u015f oldu\u011fu \u00e7al\u0131\u015f mada, tek renkli g\u00f6r\u00fcnt\u00fcden t\u00fcm g\u00f6vde 3B insan poz ve \u015feklini tahmin etme sorunu ele al\u0131nm\u0131\u015ft\u0131r.",
            "2": "6M 3600000 %98,4 Pavlokos ve ark [5] SMPLify H3.",
            "3": "[5] G."
        },
        "\u0391\u03bd\u03b8\u03c1\u03c9\u03c0\u03bf\u03ba\u03b5\u03bd\u03c4\u03c1\u03b9\u03ba\u03ae \u03bc\u03bf\u03bd\u03c4\u03b5\u03bb\u03bf\u03c0\u03bf\u03af\u03b7\u03c3\u03b7 \u03bc\u03b5 \u03b5\u03c6\u03b1\u03c1\u03bc\u03bf\u03b3\u03ae \u03c3\u03c4\u03b7 \u03c1\u03bf\u03bc\u03c0\u03bf\u03c4\u03b9\u03ba\u03ae \u03c5\u03c0\u03bf\u03b2\u03bf\u03ae\u03b8\u03b7\u03c3\u03b7\u03c2: \u03c3\u03c4\u03bf\u03c7\u03b1\u03c3\u03c4\u03b9\u03ba\u03ae \u03b5\u03ba\u03c4\u03af\u03bc\u03b7\u03c3\u03b7 \u03ba\u03b1\u03b9 \u03c1\u03bf\u03bc\u03c0\u03bf\u03c4\u03b9\u03ba\u03ae \u03bc\u03ac\u03b8\u03b7\u03c3\u03b7 \u03c3\u03c4\u03b7 \u03bb\u03ae\u03c8\u03b7 \u03b1\u03c0\u03bf\u03c6\u03ac\u03c3\u03b5\u03c9\u03bd": {
            "authors": [],
            "url": "https://dspace.lib.ntua.gr/xmlui/bitstream/handle/123456789/50877/PhD_Thesis_v2.pdf?sequence=1",
            "ref_texts": "[129] G. Pavlakos, L. Zhu, X. Zhou, and K. Daniilidis, \u2018\u2018Learning to estimate 3D human pose and shape from a single color image,\u2019\u2019 in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018.",
            "ref_ids": [
                "129"
            ],
            "1": "\u03a0\u03c1\u03cc\u03c3\u03c6\u03b1\u03c4\u03b5\u03c2\n\u03ad\u03c1\u03b5\u03c5\u03bd\u03b5\u03c2 \u03c3\u03c4\u03bf\u03c7\u03b5\u03cd\u03bf\u03c5\u03bd \u03bd\u03b1 \u03b5\u03c0\u03b9\u03bb\u03cd\u03c3\u03bf\u03c5\u03bd \u03c4\u03b7\u03bd \u03b1\u03b2\u03b5\u03b2\u03b1\u03b9\u03cc\u03c4\u03b7\u03c4\u03b1 \u03c3\u03c4\u03b9\u03c2 2\u2206-\u03c3\u03b5-3\u2206 \u03b1\u03bd\u03c4\u03b9\u03c3\u03c4\u03bf\u03b9\u03c7\u03af\u03b5\u03c2 \u00b5\u03b1\u03b8\u03b1\u03af\u03bd\u03bf\u03bd\u03c4\u03b1\u03c2 3\u2206 \u03c0\u03cc\u03b6\u03b5\u03c2 \u03b1\u03c0\u03cc \u03b5\u03b9\u03ba\u03cc\u03bd\u03b5\u03c2 [129,130].",
            "2": "[129] G."
        },
        "Unapre\u0111enje performansi procesa u LEAN industrijskim sistemima primenom tehnolo\u0161kih pilara Industrije 4.0": {
            "authors": [
                "Milos Radovic"
            ],
            "url": "https://nardus.mpn.gov.rs/bitstream/handle/123456789/18676/Doctoral_thesis_11560.pdf?sequence=1",
            "ref_texts": "86. Pavlako s G., Zhu L., Zhou X., Daniilidis K. (2018) Learning to estimate 3D human pose and shape from a single color image. In IEEE Conference on Computer Vision and Pattern Recognition . ",
            "ref_ids": [
                "86"
            ]
        }
    }
}