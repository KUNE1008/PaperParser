{
    "title": "Coarse-to-fine volumetric prediction for single-image 3D human pose",
    "id": 0,
    "valid_pdf_number": "515/621",
    "matched_pdf_number": "407/515",
    "matched_rate": 0.7902912621359224,
    "citations": {
        "Recent advances in deep learning for object detection": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.03673",
            "ref_texts": "[56] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarse-to-fine volumetric prediction for single-image 3d human pose, in: CVPR, 2017.",
            "ref_ids": [
                "56"
            ],
            "1": "FPN achieved significant progress in detecting multi-scale objects and has been widely used in many other domains such as video detection [53, 54] and human pose recognition [55, 56].",
            "2": "[56] G."
        },
        "End-to-end recovery of human shape and pose": {
            "authors": [
                "Angjoo Kanazawa",
                "Michael J. Black",
                "David W. Jacobs",
                "Jitendra Malik"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Kanazawa_End-to-End_Recovery_of_CVPR_2018_paper.pdf",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR , 2017. 3,6,7,8",
            "ref_ids": [
                "33"
            ],
            "1": "Our approach is similar to 3D interpreter networks [33, 50] in the use of reprojection loss and the more recent adversarial inverse graphics networks [47] for the use of the adversarial prior.",
            "2": "[45], many recent methods estimate 3D joints directly from images in a deep learning framework [33,43,44,51,52].",
            "3": "Many methods do not solve for the camera, but estimate the depth relative to root and use a predefined global scale based the average length of bones [33,51,52].",
            "4": "Following previous work [33,36], we downsample all videos from 50fps to 10fps to 2https://akanazawa.",
            "5": "[33] 51.",
            "6": "[33] 71.",
            "7": "Even methods that are based on a reprojection loss [33,47,50] require paired 2D-to-3D training data.",
            "8": "3\n[33] G."
        },
        "3d human pose estimation in video with temporal convolutions and semi-supervised training": {
            "authors": [
                "Dario Pavllo",
                "Christoph Feichtenhofer",
                "David Grangier",
                "Michael Auli"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Pavllo_3D_Human_Pose_Estimation_in_Video_With_Temporal_Convolutions_and_CVPR_2019_paper.pdf",
            "ref_texts": "[41] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1,2,4,5,6,7",
            "ref_ids": [
                "41"
            ],
            "1": "We build on the approach of state-of-the-art methods which formulate the problem as 2D keypoint detection followed by 3D pose estimation [41,52,34,50,10,40,58,33].",
            "2": "The first neural methods with convolutional neural networks (CNN) focused on end-to-end reconstruction [28,53,51,41] by directly estimating 3D poses from RGB images without intermediate supervision.",
            "3": "A new family of 3D pose estimators builds on top of 2D pose estimators by first predicting 2D joint positions in image space (keypoints ) which are subsequently lifted to 3D [21,34,41,52,4,16].",
            "4": "Some approaches leverage both image features and 2D ground-truth poses [39,41,52,54].",
            "5": "Compared to [41,40], we do not use heatmaps and instead describe poses with detected keypoint coordinates.",
            "6": "Following previous work [41,52,34,50,10, 40,58,33], we adopt a 17-joint skeleton, train on five subjects (S1, S5, S6, S7, S8), and test on two subjects (S9 and S11).",
            "7": "We also report results when training one model for all actions (multi action \u2013 MA), as in [41,27].",
            "8": "In our experiments, we consider three evaluation protocols: Protocol 1 is the mean per-joint position error (MPJPE) in millimeters which is the mean Euclidean distance between predicted joint positions and ground-truth joint positions and follows [29,53,61,34,41].",
            "9": "Implementation details for 3D pose estimation For consistency with other work [34,29,53,61,34,41], we train and evaluate on 3D poses in camera space by rotating and translating the ground-truth poses according to the camera transformation, and not using the global trajectory (except for the semi-supervised setting, \u00a74).",
            "10": "[41] CVPR\u201917 (\u2217) 67.",
            "11": "[41] (MA) 22.",
            "12": "1, 2,4,6,7\n[41] G."
        },
        "A simple yet effective baseline for 3d human pose estimation": {
            "authors": [
                "Julieta Martinez",
                "Rayat Hossain",
                "Javier Romero",
                "James J. Little"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Martinez_A_Simple_yet_ICCV_2017_paper.pdf",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 1,2,3,4,5,6,8",
            "ref_ids": [
                "33"
            ],
            "1": "Recently, some systems have explored the possibility of directly inferring 3d poses from images with end-to-end deep architectures [33,45], and other systems argue that 3d reasoning from colour images can be achieved by training on synthetic data [38,48].",
            "2": "[33] introduced a deep convolutional neural network based on the stacked hourglass architecture [30] that, instead of regressing 2d joint probability heatmaps, maps to probability distributions in 3d space.",
            "3": "[33] present a baseline where a direct 3d joint representation (such as ours) is used instead (Table 1 in [33]), with much less accurate results than using volumetric regression1Our work contradicts the idea that regressing 3d keypoints from 2d joint detections directly should 1This approach, however, is slightly different from ours, as the input is still image pixels, and the intermediate 2d body representation is a series of joint heatmaps \u2013 not joint 2d locations.",
            "4": "2d/3d positions Our first design choice is to use 2d and 3d points as inputs and outputs, in contrast to recent work that has used raw images [11,13,24,32,33,45,46,54,56] or 2d probability distributions [33,56] as inputs, and 3d probabilities [33], 3d motion parameters [54] or basis pose coefficients and camera parameter estimation [2,7,36,55,56] as outputs.",
            "5": "2642\n Linear-RELU layers Most deep learning approaches to 3d human pose estimation are based on convolutional neural networks, which learn translation-invariant filters that can be applied to entire images [13,24,32,33,45], or 2dimensional joint-location heatmaps [33,56].",
            "6": "A natural choice of global coordinate frame is the camera frame [11,24,33,46,54,56] since this makes the 2d to 3d problem similar across different cameras, implicitly enabling more training data per camera and preventing overfitting to a particular global coordinate frame.",
            "7": "[33] (MA) 67.",
            "8": "[33], which is the best result on Human3.",
            "9": "[33] (MA) 17j \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "10": "[33] 22.",
            "11": "[33], which uses a stacked-hourglass architecture, is trained end-to-end on Human3.",
            "12": "For example, the volumetric regression approach of [33]et al.",
            "13": "is based on the hypothesis that directly regressing 3d points is inherently difficult, and regression in a volumetric space would provide easier gradients for the network (see Table 1 in [33]).",
            "14": "3,4,5\n[33] G."
        },
        "I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.03713",
            "ref_texts": "39. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR (2017)",
            "ref_ids": [
                "39"
            ],
            "1": "[39] and Moon et al."
        },
        "Vnect: Real-time 3d human pose estimation with a single rgb camera": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1705.01583.pdf%C3%AF%C2%BC%E2%80%B0%C3%A6%CB%86%E2%80%93[%C3%A8%C2%BF%E2%84%A2%C3%A4%C2%B8%E2%82%AC%C3%A4%C2%B8%C2%AA]%C3%AF%C2%BC%CB%86https://arxiv.org/",
            "ref_texts": ""
        },
        "Monocular human pose estimation: A survey of deep learning-based methods": {
            "authors": [
                "Yucheng Chen",
                "Yingli Tian",
                "Mingyi He"
            ],
            "url": "https://arxiv.org/pdf/2006.01423",
            "ref_texts": "484\u2013494. Ouyang, W., Chu, X., Wang, X., 2014. Multi-source deep learning for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 2329\u20132336. Papandreou, G., Zhu, T., Chen, L.C., Gidaris, S., Tompson, J., Murphy, K., 2018. Personlab: Person pose estimation and instance segmentation with a bottom-up, part-based, geometric embedding model. arXiv preprint arXiv:1803.08225 . Papandreou, G., Zhu, T., Kanazawa, N., Toshev, A., Tompson, J., Bregler, C., Murphy, K., 2017. Towards accurate multi-person pose estimation in the wild, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4903\u20134911. Pavlakos, G., Zhou, X., Daniilidis, K., 2018a. Ordinal depth supervision for 3d human pose estimation. arXiv preprint arXiv:1805.04095 . Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1263\u20131272. Pavlakos, G., Zhu, L., Zhou, X., Daniilidis, K., 2018b. Learning to estimate 3d human pose and shape from a single color image. arXiv preprint arXiv:1805.04092 . Peng, X., Tang, Z., Yang, F., Feris, R.S., Metaxas, D., 2018. Jointly optimize data augmentation and network training: Adversarial data augmentation in human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 2226\u20132234. Perez-Sala, X., Escalera, S., Angulo, C., Gonzalez, J., 2014. A survey on model based approaches for 2d and 3d visual human pose recovery. Sensors 14, 4189\u20134210. Pfister, T., Charles, J., Zisserman, A., 2015. Flowing convnets for human pose estimation in videos, in: Proc. IEEE International Conference on Computer Vision, pp. 1913\u20131921. Pfister, T., Simonyan, K., Charles, J., Zisserman, A., 2014. Deep convolutional neural networks for e flcient pose estimation in gesture videos, in: Proc. Asian Conference on Computer Vision, Springer. pp. 538\u2013552.Pishchulin, L., Insafutdinov, E., Tang, S., Andres, B., Andriluka, M., Gehler, P.V ., Schiele, B., 2016. Deepcut: Joint subset partition and labeling for multi person pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4929\u20134937. Pons-Moll, G., Romero, J., Mahmood, N., Black, M.J., 2015. Dyna: A model of dynamic human shape in motion. ACM Transactions on Graphics 34, 120. Popa, A.I., Zanfir, M., Sminchisescu, C., 2017. Deep multitask architecture for integrated 2d and 3d human sensing, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 4714\u20134723. Poppe, R., 2007. Vision-based human motion analysis: An overview. Computer Vision and Image Understanding 108, 4\u201318. Qammaz, A., Argyros, A., 2019. Mocapnet: Ensemble of snn encoders for 3d human pose estimation in rgb images, in: Proc. British Machine VIsion Conference. Rafi, U., Leibe, B., Gall, J., Kostrikov, I., 2016. An e flcient convolutional network for human pose estimation, in: Proc. British Machine Vision Conference, p. 2. Ramakrishna, V ., Munoz, D., Hebert, M., Bagnell, J.A., Sheikh, Y ., 2014. Pose machines: Articulated pose estimation via inference machines, in: Proc. European Conference on Computer Vision, Springer. pp. 33\u201347. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks, in: Advances in neural information processing systems, pp. 91\u201399. Rhodin, H., Salzmann, M., Fua, P., 2018a. Unsupervised geometry-aware representation for 3d human pose estimation. arXiv:1804.01110 . Rhodin, H., Sp \u00a8orri, J., Katircioglu, I., Constantin, V ., Meyer, F., M \u00a8uller, E., Salzmann, M., Fua, P., 2018b. Learning monocular 3d human pose estimation from multi-view images, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 8437\u20138446. Rogez, G., Weinzaepfel, P., Schmid, C., 2017. Lcr-net: Localizationclassification-regression for human pose, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 3433\u20133441. Rohrbach, M., Amin, S., Andriluka, M., Schiele, B., 2012. A database for fine grained activity detection of cooking activities, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1194\u20131201. Sapp, B., Taskar, B., 2013. Modec: Multimodal decomposable models for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 3674\u20133681. Sapp, B., Weiss, D., Taskar, B., 2011. Parsing human motion with stretchable models, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1281\u20131288. Sarafianos, N., Boteanu, B., Ionescu, B., Kakadiaris, I.A., 2016. 3d human pose estimation: A review of the literature and analysis of covariates. Computer Vision and Image Understanding 152, 1\u201320. Shahroudy, A., Liu, J., Ng, T.T., Wang, G., 2016. Ntu rgb +d: A large scale dataset for 3d human activity analysis, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition, pp. 1010\u20131019. Shotton, J., Girshick, R., Fitzgibbon, A., Sharp, T., Cook, M., Finocchio, M., Moore, R., Kohli, P., Criminisi, A., Kipman, A., et al., 2012. E flcient human pose estimation from single depth images. IEEE transactions on pattern analysis and machine intelligence 35, 2821\u20132840. Sidenbladh, H., De la Torre, F., Black, M.J., 2000. A framework for modeling the appearance of 3d articulated figures, in: Proc. IEEE Conference on Automatic Face and Gesture Recognition, IEEE. pp. 368\u2013375. Sigal, L., Balan, A.O., Black, M.J., 2010. Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International journal of computer vision 87, 4. Sminchisescu, C., 2008. 3d human motion analysis in monocular video: techniques and challenges, in: Human Motion. Springer, pp. 185\u2013211. Sun, K., Xiao, B., Liu, D., Wang, J., 2019. Deep high-resolution representation learning for human pose estimation, in: Proc. IEEE Conference on Computer Vision and Pattern Recognition. Sun, X., Shang, J., Liang, S., Wei, Y ., 2017. Compositional human pose regression, in: Proc. IEEE International Conference on Computer Vision, p. 7. Sun, X., Xiao, B., Wei, F., Liang, S., Wei, Y ., 2018. Integral human pose regression, in: Proc. European Conference on Computer Vision, pp. 529\u2013"
        },
        "Soft rasterizer: A differentiable renderer for image-based 3d reasoning": {
            "authors": [
                "Shichen Liu",
                "Tianye Li",
                "Weikai Chen",
                "Hao Li"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Soft_Rasterizer_A_Differentiable_Renderer_for_Image-Based_3D_Reasoning_ICCV_2019_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017. 1,5",
            "ref_ids": [
                "36"
            ],
            "1": "key points/contours [3,36,27,33] or shape/appearance priors [1,29,6,24,50].",
            "2": "2D joints [3] or feature points [36], to obtain supervision signals for optimization."
        },
        "Pose2mesh: Graph convolutional network for 3d human pose and mesh recovery from a 2d human pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.09047",
            "ref_texts": "51. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
            "ref_ids": [
                "51"
            ],
            "1": "Following [27, 51], all methods are trained on 5 subjects (S1, S5, S6, S7, S8) and tested on 2 subjects (S9, S11)."
        },
        "Integral human pose regression": {
            "authors": [
                "Xiao Sun",
                "Bin Xiao",
                "Fangyin Wei",
                "Shuang Liang",
                "Yichen Wei"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Xiao_Sun_Integral_Human_Pose_ECCV_2018_paper.pdf",
            "ref_texts": "37. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1 611.07828 (2016)",
            "ref_ids": [
                "37"
            ],
            "1": "The he at maps are also extended for 3D pose estimation and shown promising [37].",
            "2": "For evaluation, many previous works [8,46,32,54,25,31,37,51,41,4,53, 44,56] use the mean per joint position error (MPJPE).",
            "3": "Effect of backbone network [37] is the only previous work using 3D heat map representation.",
            "4": "8, we follow exactly the same practice as in [37] for a fair comparis on Integral Human Pose Regression 13 Table 7.",
            "5": "Comparison with Coarse-to-Fine Volumetric Prediction [37] trai ned only on Human3.",
            "6": "[37] Ours H1 Ours I1 One Stage (d= 64) 85.",
            "7": "First, our baseline implementation H1 i s strong enough that is already better than [37] at both stages.",
            "8": "Ours is the best Method Zhou[53] Tekin[44] Xingyi[56] Sun [42] Pavlakos[37] Ours MPJPE 113."
        },
        "Mhformer: Multi-hypothesis transformer for 3d human pose estimation": {
            "authors": [
                "Wenhao Li",
                "Hong Liu",
                "Hao Tang",
                "Pichao Wang",
                "Luc Van"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Li_MHFormer_Multi-Hypothesis_Transformer_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034, 2017. 3",
            "ref_ids": [
                "33"
            ],
            "1": "One-stage approaches directly infer 3D poses from input images without intermediate 2D pose representations [18, 28, 33, 36], while two-stage ones first obtain 2D keypoints from pretrained 2D pose detections and then feed them into a 2D-to3D lifting network to estimate 3D poses."
        },
        "Exploiting spatial-temporal relationships for 3d pose estimation via graph convolutional networks": {
            "authors": [
                "Yujun Cai",
                "Liuhao Ge",
                "Jun Liu",
                "Jianfei Cai",
                "Jen Cham",
                "Junsong Yuan",
                "Nadia Magnenat"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Cai_Exploiting_Spatial-Temporal_Relationships_for_3D_Pose_Estimation_via_Graph_Convolutional_ICCV_2019_paper.pdf",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "38"
            ],
            "1": "Despite the tremendous success achieved in recent years [8, 27, 28, 38, 44, 5, 16, 49, 25, 13], it remains a challenging problem due to the frequent selfocclusions and substantial depth ambiguity in 2D representations.",
            "2": "[38] introduced a deep convolutional neural network based on the stacked hourglass architecture, with a fine discretization of the 3D space to predict per voxel likelihoods for each joint.",
            "3": "9 Pavlakos, CVPR17 [38] (T= 1)67."
        },
        "Convolutional mesh regression for single-image human shape reconstruction": {
            "authors": [
                "Nikos Kolotouros",
                "Georgios Pavlakos",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Kolotouros_Convolutional_Mesh_Regression_for_Single-Image_Human_Shape_Reconstruction_CVPR_2019_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 3",
            "ref_ids": [
                "30"
            ],
            "1": ", [3,19,22,24, 25,29,30,34,35,38,40,41,42,50,51]."
        },
        "Monocular 3d human pose estimation in the wild using improved cnn supervision": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1611.09813.pdf?source=post_page---------------------------",
            "ref_texts": "[44] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR 2017-IEEE Conference on Computer Vision & Pattern Recognition , 2017. 1, 2, 7, 8",
            "ref_ids": [
                "44"
            ],
            "1": "Recent advances in direct CNNbased 3D regression show promise, utilizing different prediction space formulations [65, 35, 81, 44, 40] and incorporating additional constraints [81, 67, 83, 78].",
            "2": "Deep CNNs achieve state-of-the-art results [81, 66, 44].",
            "3": "30 V olumetric Coarse-Fine[44]J17,B,S*71.",
            "4": "Note that the V olumetric coarse to fine approach [44] requires estimates of the bone lengths to convert their predictions from pixels to 3D space.",
            "5": "3\n[44] G."
        },
        "Hybrik: A hybrid analytical-neural inverse kinematics solution for 3d human pose and shape estimation": {
            "authors": [
                "Jiefeng Li",
                "Chao Xu",
                "Zhicun Chen",
                "Siyuan Bian",
                "Lixin Yang",
                "Cewu Lu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Li_HybrIK_A_Hybrid_Analytical-Neural_Inverse_Kinematics_Solution_for_3D_Human_CVPR_2021_paper.pdf",
            "ref_texts": "[48] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 1",
            "ref_ids": [
                "48"
            ],
            "1": "Instead of the direct regression, previous methods [48,60] adopt volumetric heatmap as the target representation to learn 3D joint locations and have achieved 3383\n impressive performance."
        },
        "Pymaf: 3d human pose and shape regression with pyramidal mesh alignment feedback loop": {
            "authors": [
                "Hongwen Zhang",
                "Yating Tian",
                "Xinchi Zhou",
                "Wanli Ouyang",
                "Yebin Liu",
                "Limin Wang",
                "Zhenan Sun"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_PyMAF_3D_Human_Pose_and_Shape_Regression_With_Pyramidal_Mesh_ICCV_2021_paper.pdf",
            "ref_texts": ""
        },
        "Semantic graph convolutional networks for 3d human pose regression": {
            "authors": [
                "Long Zhao",
                "Xi Peng",
                "Yu Tian",
                "Mubbasir Kapadia",
                "Dimitris N. Metaxas"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_Semantic_Graph_Convolutional_Networks_for_3D_Human_Pose_Regression_CVPR_2019_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In CVPR , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "41"
            ],
            "1": "A couple of algorithms directly predicted 3D pose from the image [75], while others combined 2D heatmaps with volumetric representation [41], pairwise distance matrix estimation [36] or image cues [56] for 3D human pose regression.",
            "2": "Therefore, we choose to predict 3D pose in the camera coordinate system [11, 32, 41, 57], which makes the 2D to 3D regression problem similar across different cameras.",
            "3": "we require that the sum of length of all 3D bones is equal to that of a canonical skeleton as shown in [41, 75, 78].",
            "4": "[41] CVPR\u201917 67."
        },
        "Learning to estimate 3D human pose and shape from a single color image": {
            "authors": [
                "Georgios Pavlakos",
                "Luyang Zhu",
                "Xiaowei Zhou",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Pavlakos_Learning_to_Estimate_CVPR_2018_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2,8",
            "ref_ids": [
                "31"
            ],
            "1": "Many recent works follow the end-to-end paradigm [48, 40,42,46,55], using images as input to predict 3D joint locations [23,45,34,28], regress 3D heatmaps [31], or classify the image in a particular pose class [39,40].",
            "2": ", [27,31]), but they do so only by leveraging the training data of this dataset for training.",
            "3": "4\n[31] G."
        },
        "Human pose regression with residual log-likelihood estimation": {
            "authors": [
                "Jiefeng Li",
                "Siyuan Bian",
                "Ailing Zeng",
                "Can Wang",
                "Bo Pang",
                "Wentao Liu",
                "Cewu Lu"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Li_Human_Pose_Regression_With_Residual_Log-Likelihood_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[46] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose, 2017.",
            "ref_ids": [
                "46"
            ],
            "1": "Existing methods can be divided into two categories: heatmap-based [57, 56, 62, 4, 64, 54, 46, 52] and regression-based [58, 5, 53, 70, 42, 61].",
            "2": "These methods generate a likelihood heatmap for each joint and locate the joint as the point with the argmax [56, 64, 46] or soft-argmax [40, 31, 54] operations.",
            "3": "[46] first extend the heatmap to 3D space."
        },
        "Learning to estimate 3d hand pose from single rgb images": {
            "authors": [
                "Christian Zimmermann",
                "Thomas Brox"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Zimmermann_Learning_to_Estimate_ICCV_2017_paper.pdf",
            "ref_texts": "[15] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3d Human Pose. arXiv preprint arXiv:1611.07828 , 2016.",
            "ref_ids": [
                "15"
            ],
            "1": "[15] proposed a volumetric approach that treats pose estimation as per voxel prediction of scores in a coarse-to-fine manner, which gives a natural representation to the data, but is computationally expensive and limited by the GPU memory to fit the voxel grid.",
            "2": "[15] G."
        },
        "Camera distance-aware top-down approach for 3d multi-person pose estimation from a single rgb image": {
            "authors": [
                "Gyeongsik Moon",
                "Ju Yong",
                "Kyoung Mu"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Moon_Camera_Distance-Aware_Top-Down_Approach_for_3D_Multi-Person_Pose_Estimation_From_ICCV_2019_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "32"
            ],
            "1": "Recently, many methods [21, 32, 37, 38, 43, 46] utilize deep convolutional neural networks (CNNs) and have achieved noticeable performance improvement on large-scale publicly available datasets [14, 23].",
            "2": "Most of the previous 3D human pose estimation methods [21, 32, 37, 38, 43, 46] are designed for single-person case.",
            "3": "To handle this issue, many methods [21, 32, 37, 38, 43, 46] estimate the relative 3D pose to a reference point in the body, e.",
            "4": "Prior information on the bone length [32] or the groundtruth [38] has been commonly used for the localization of the root.",
            "5": "[18, 32, 37\u201339] are based on the single-stage approach.",
            "6": "[32] extended the U-net shaped network to estimate a 3D heatmap for each joint.",
            "7": "For example, many works [32,38,43,46] estimatethe 2D image coordinates and root-relative depth values of keypoints.",
            "8": "Many works have been presented for this topic [21,23,32,37,38,43,46].",
            "9": "6M dataset, we used additional MPII 2D human pose estimation dataset [1] following [32, 37, 38, 46]."
        },
        "Graph stacked hourglass networks for 3d human pose estimation": {
            "authors": [
                "Tianhan Xu",
                "Wataru Takano"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Graph_Stacked_Hourglass_Networks_for_3D_Human_Pose_Estimation_CVPR_2021_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
            "ref_ids": [
                "34"
            ],
            "1": "In recent years, with the development of deep learning, there has been an increase in using deep neural networks for image-to-3D human pose estimation [43,44,34,41,47,8].",
            "2": "[34] exploit voxel to discretize representations of the space around the human body and use 3D heatmaps to estimate 3D human pose."
        },
        "Neural body fitting: Unifying deep learning and model based human pose and shape estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.05942",
            "ref_texts": "[36] G. Pavlakos, X. Zhou, and K. Daniilidis. Ordinal depth supervision for 3d human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2018. 3[37] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3D human pose. In CVPR 2017-IEEE Conference on Computer Vision & Pattern Recognition , 2017.",
            "ref_ids": [
                "36",
                "37"
            ],
            "1": "Consequently, it is not clear \u2013 despite excellent performance on standard benchmarks \u2013 how methods [59, 25, 37, 26] generalize to in-the-wild images.",
            "2": "[36] take another approach by relying on weak 3D supervision in form of a relative 3D ordering of joints, similar to the previously proposed PoseBits [40].",
            "3": "3\n[36] G.",
            "4": "3[37] G."
        },
        "Probabilistic modeling for human mesh recovery": {
            "authors": [
                "Nikos Kolotouros",
                "Georgios Pavlakos",
                "Dinesh Jayaraman",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Kolotouros_Probabilistic_Modeling_for_Human_Mesh_Recovery_ICCV_2021_paper.pdf",
            "ref_texts": ""
        },
        "2d/3d pose estimation and action recognition using multitask deep learning": {
            "authors": [
                "Diogo C. Luvizon",
                "David Picard",
                "Hedi Tabia"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Luvizon_2D3D_Pose_Estimation_CVPR_2018_paper.pdf",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "35"
            ],
            "1": "3D pose estimation tasks thanks to the rise of new architectures and the availability of large amounts of data [33, 35].",
            "2": "[35] proposed the volumetric stacked hourglass architecture.",
            "3": "In our approach, we also propose an intermediate volumetric representation for 3D poses, but we use a much lower resolution than in [35] and still are able to increase significantly the state-of-the-art results, since our method is based on a continuous regression function.",
            "4": "[35] 67.",
            "5": "[35] 96.",
            "6": "We followed the common evaluation protocol [47, 35, 31, 11] by taking five subjects for training (S1, S5, S6, S7, S8) and evaluating on two subjects (S9, S11) on one every 64 frames.",
            "7": "[35] G."
        },
        "Towards 3d human pose estimation in the wild: a weakly-supervised approach": {
            "authors": [
                "Xingyi Zhou",
                "Qixing Huang",
                "Xiao Sun",
                "Xiangyang Xue",
                "Yichen Wei"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhou_Towards_3D_Human_ICCV_2017_paper.pdf",
            "ref_texts": "[19] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016. 2,5,6, 7",
            "ref_ids": [
                "19"
            ],
            "1": "In contrast these works, Pavlakos et al introduce a 3D approach, which regresses a volumetric representation of 3D skeleton [19].",
            "2": "Regarding 3D pose estimation from 2D joint locations, [34] use an EM algorithm to compute a 3D skeleton by combining a sparse dictionary induced from the 2D heat-maps; [30,19] use 3D pose data and its 2D projection to train a heatmap-to-3D pose network without the original image; Bogo et al.",
            "3": "During testing, such calibration is not needed, by requiring that the sum of all 3D bones lengths is equal to that of a pre-defined canonical skeleton, as is done in [19,35].",
            "4": "[19] 58.",
            "5": "[19] 76.",
            "6": "90mm, which is superior to all previous work [15,19].",
            "7": "[19] provided an alternative decoupled version which can also be applied in the wild, but its MPJPE increased to 78.",
            "8": "3\n[19] G."
        },
        "Bodynet: Volumetric inference of 3d human body shapes": {
            "authors": [
                "Gul Varol",
                "Duygu Ceylan",
                "Bryan Russell",
                "Jimei Yang",
                "Ersin Yumer",
                "Ivan Laptev",
                "Cordelia Schmid"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Gul_Varol_BodyNet_Volumetric_Inference_ECCV_2018_paper.pdf",
            "ref_texts": "6. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coars e-to-fine volumetric prediction for single-image 3D human pose. In: CVPR. (2017)",
            "ref_ids": [
                "6"
            ],
            "1": "Extending the notion of 2D heatmaps to 3D, we represent 3D joint locations with 3D Gaussians defined on a voxel grid as in [6]."
        },
        "V2v-posenet: Voxel-to-voxel prediction network for accurate 3d hand and human pose estimation from a single depth map": {
            "authors": [
                "Gyeongsik Moon",
                "Ju Yong",
                "Kyoung Mu"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Moon_V2V-PoseNet_Voxel-to-Voxel_Prediction_CVPR_2018_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d hu5087",
            "ref_ids": [
                "31"
            ],
            "1": "[31] estimated the per-voxel likelihood for each body keypoint via 2D CNN as in the Figure 2(b).",
            "2": "[31] G."
        },
        "3d human pose estimation in the wild by adversarial learning": {
            "authors": [
                "Wei Yang",
                "Wanli Ouyang",
                "Xiaolong Wang",
                "Jimmy Ren",
                "Hongsheng Li",
                "Xiaogang Wang"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_3D_Human_Pose_CVPR_2018_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CVPR , 2017. 2,6",
            "ref_ids": [
                "31"
            ],
            "1": "[31] proposed a voxel representation for each joint as the regression target, and designed a coarse-to-fine learning strategy.",
            "2": "CVPR\u201917 [31] 67.",
            "3": "CVPR\u201917 [31] \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "4": "2\n[31] G."
        },
        "Mixste: Seq2seq mixed spatio-temporal encoder for 3d human pose estimation in video": {
            "authors": [
                "Jinlu Zhang",
                "Zhigang Tu",
                "Jianyu Yang",
                "Yujin Chen",
                "Junsong Yuan"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_MixSTE_Seq2seq_Mixed_Spatio-Temporal_Encoder_for_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 2, 5",
            "ref_ids": [
                "36"
            ],
            "1": "Some methods [36, 42, 44] followed this manner but required a high computation cost due to regressing directly from the image space."
        },
        "Large pose 3D face reconstruction from a single image via direct volumetric CNN regression": {
            "authors": [
                "Aaron S. Jackson",
                "Adrian Bulat",
                "Vasileios Argyriou",
                "Georgios Tzimiropoulos"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Jackson_Large_Pose_3D_ICCV_2017_paper.pdf",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016.",
            "ref_ids": [
                "16"
            ],
            "1": "The method of [16] extends classical work on heatmap regression [24, 18] by proposing a 4D representation for regressing the location of sparse 3D landmarks for human pose estimation.",
            "2": "Different from [16], we demonstrate that a 3D volumetric representation is particular effective for learning dense 3D facial geometry.",
            "3": "[16] G."
        },
        "Self-supervised learning of 3d human pose using multi-view geometry": {
            "authors": [
                "Muhammed Kocabas",
                "Salih Karagoz",
                "Emre Akbas"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition , 2017. 2,6,7",
            "ref_ids": [
                "29"
            ],
            "1": "[29] were the first to consider 3D human pose estimation as a 3D keypoint localization problem in a voxel space.",
            "2": "Our self supervised (SS) model performs quite well compared to the recent fully 3D supervised methods [29,32,33, 40] which require abundant labeled data to learn.",
            "3": "[29] (CVPR\u201917) 71."
        },
        "Monocular total capture: Posing face, body, and hands in the wild": {
            "authors": [
                "Donglai Xiang",
                "Hanbyul Joo",
                "Yaser Sheikh"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Xiang_Monocular_Total_Capture_Posing_Face_Body_and_Hands_in_the_CVPR_2019_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "42"
            ],
            "1": "Direct estimation methods predict 3D human pose directly from images, in the form of direct coordinate regression [46,55,56], voxel [42,32,66] or depth map [73].",
            "2": "We follow the standard training-testing protocol as in [42].",
            "3": "For evaluation, we follow [42] to rescale our output to match the size of an average skeleton computed from the training set.",
            "4": "The Mean Per Joint Position Error (MPJPE) after aligning the root joint is reported as in [42].",
            "5": "As an example, our result with 10970\n Method Pavlakos [42]Zhou [73]Luo [31]Martinez [33]Fang [20]Yang [70]Pavlakos [41]Dabral [18]Sun [56]*Kanazawa [27]*Mehta [35]*Mehta [34]*Ours *Ours+ MPJPE 71."
        },
        "Modulated graph convolutional network for 3D human pose estimation": {
            "authors": [
                "Zhiming Zou",
                "Wei Tang"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Zou_Modulated_Graph_Convolutional_Network_for_3D_Human_Pose_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "37"
            ],
            "1": "Some approaches [61, 35, 44, 37, 43, 54, 23, 4] regress 3D joint coordinates or heat maps directly from a monocular image via a convolutional neural network (CNN) [21, 19].",
            "2": "The first category is to train deep convolutional neural networks (CNNs) to directly regress 3D human poses from input images in an end-to-end fashion [44, 4, 37, 33, 61, 35, 23, 45, 60].",
            "3": "[37] introduce a fine discretization of the 3D space around the subject and train a CNN to predict per voxel likelihoods for each joint."
        },
        "Exemplar fine-tuning for 3d human model fitting towards in-the-wild 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.03686",
            "ref_texts": "[49] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2, 3",
            "ref_ids": [
                "49"
            ],
            "1": "Related Work Deep learning has significantly advanced 2D pose recognition [10,9,63,44,66,57], facilitating the more challenging task of 3D reconstruction [59,60,40,49,48,45,50,27, 35, 65, 11, 58, 56, 13, 43, 12], which is our focus.",
            "2": "Later approaches use instead deep neural networks, and differ mainly in the nature of their inputs and outputs [59,60,40,49,48,45,50,27,35,65,11,67,33,43].",
            "3": "Methods also differ in their output, with some predicting 3D keypoints directly [40], some predicting the parameters of a 3D human body model [27,65], and others volumetric heatmaps for the body joints [49] or meshes [35,12]."
        },
        "Ordinal depth supervision for 3d human pose estimation": {
            "authors": [
                "Georgios Pavlakos",
                "Xiaowei Zhou",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Pavlakos_Ordinal_Depth_Supervision_CVPR_2018_paper.pdf",
            "ref_texts": "[32] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2,3,4,6,7,8",
            "ref_ids": [
                "32"
            ],
            "1": "We develop on the idea of ordinal relations demonstrating their flexibility and effectiveness in a variety of settings: 1) we use them to predict directly the depths of joints, 2) we combine them with 2D keypoint annotations to predict 3D poses, 3) we demonstrate how they can be incorporated within a volumetric representation of 3D pose [32].",
            "2": "Prior work uses ConvNets to regress the coordinates of the 3D joints [22, 47,48,51,44,26], to regress 3D heatmaps [32], or to classify each image in the appropriate pose class [39,40].",
            "3": "3we explore the incorporation of ordinal relations within a volumetric representation for 3D human pose [32].",
            "4": "Volumetric prediction for 3D pose Apart from direct regression of the 3D pose coordinates, recent work has investigated the use of a volumetric representation for 3D human pose [32].",
            "5": "This allows most of the stateof-the-art discriminative ConvNets [64,44,48,32] to be used as-is, and be complemented with the proposed ordinal depth supervision when 3D ground truth is not available.",
            "6": "08 regression fully supervised [32] 112.",
            "7": "93 volumehourglass fully supervised [32] 85.",
            "8": "03 hourglasses fully supervised [32] 69.",
            "9": "[32] (CVPR\u201917) 67.",
            "10": "[32] (CVPR\u201917) 47.",
            "11": "Improving 3D pose detectors : After the sanity check that ordinal supervision is competitive to training with the full 3D ground truth, we explore using ordinal depth annotations provided by humans, to boost the performance of a standard ConvNet for 3D human pose [32].",
            "12": "[32] 22.",
            "13": "1,6\n[32] G."
        },
        "Cross view fusion for 3d human pose estimation": {
            "authors": [
                "Haibo Qiu",
                "Chunyu Wang",
                "Jingdong Wang",
                "Naiyan Wang",
                "Wenjun Zeng"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Qiu_Cross_View_Fusion_for_3D_Human_Pose_Estimation_ICCV_2019_paper.pdf",
            "ref_texts": "[17] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric pre-diction for single-image 3D human pose. In CVPR , pages 1263\u20131272, 2017. 1",
            "ref_ids": [
                "17"
            ],
            "1": "Most efforts [16,13,33,17,23,19,29,28,6] have been devoted to estimating relative3D poses from monocular images."
        },
        "Single-shot multi-person 3d pose estimation from monocular rgb": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1712.03453",
            "ref_texts": "[40] G. Papandreou, T. Zhu, N. Kanazawa, A. Toshev, J. Tompson, C. Bregler, and K. Murphy. Towards accurate multi-person pose estimation in the wild. arXiv preprint arXiv:1701.01779 , 2017.[41] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-ffne volumetric prediction for singleimage 3D human pose. In CVPR 2017-IEEE Conference on Computer Vision & Pattern Recognition , 2017.",
            "ref_ids": [
                "40",
                "41"
            ],
            "1": "We call our method single shot since it reasons about all people in a scene jointly in a single forward pass, and does not require explicit bounding box proposals by a separate algorithm as a preprocessing step [49, 40].",
            "2": "Multi-Person 2D Pose Estimation : A common approach for multi-person 2D pose estimation is to ffrst detect single persons and then 2D pose [44, 13, 55, 19, 40].",
            "3": "Single-Person 3D Pose Estimation : Existing monocular single-person 3D pose methods show good performance on standard datasets [18, 51, 59, 41, 28, 27].",
            "4": "[41] (67.",
            "5": "Pavlakos et al [41] 60.",
            "6": "Pavlakos et al [41] 92.",
            "7": "[40] G.",
            "8": "[41] G."
        },
        "Occlusion-aware networks for 3d human pose estimation in video": {
            "authors": [
                "Yu Cheng",
                "Bo Yang",
                "Bo Wang",
                "Wending Yan",
                "Robby T. Tan"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Cheng_Occlusion-Aware_Networks_for_3D_Human_Pose_Estimation_in_Video_ICCV_2019_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "28"
            ],
            "1": "Recent top-down pose estimation methods have achieved promising results [29, 13, 27, 6, 21, 28, 36].",
            "2": "[28] CVPR\u201917 67.",
            "3": "[28] CVPR\u201917 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "4": "[28] CVPR\u201917 22."
        },
        "Exploiting temporal information for 3d human pose estimation": {
            "authors": [
                "Mir Rayat",
                "Imtiaz Hossain",
                "Jim Little"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Mir_Rayat_Imtiaz_Hossain_Exploiting_temporal_information_ECCV_2018_paper.pdf",
            "ref_texts": "7. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coars e-to-fine volumetric prediction for single-image 3D human pose. In: IEEE Conference o n Computer Vision and Pattern Recognition (CVPR). (2017)",
            "ref_ids": [
                "7"
            ],
            "1": "Deep network based methods With the success of deep networks, many have designed networks that can be trained end-to-end to predict 3D poses f rom images directly [7,8,6,14,9,15,10,38\u201340].",
            "2": "[7] extend ed the stacked-hourglass network [18] originally designed to predict 2D heat maps of each joint to make it predict 3D volumetric heatmaps.",
            "3": "7 Pavlakos et al [7] (MA) 67.",
            "4": "1 Pavlakos et al [7] (MA) 17j \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "5": "[7] 22."
        },
        "Deep kinematics analysis for monocular 3d human pose estimation": {
            "authors": [
                "Jingwei Xu",
                "Zhenbo Yu",
                "Bingbing Ni",
                "Jiancheng Yang",
                "Xiaokang Yang",
                "Wenjun Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Deep_Kinematics_Analysis_for_Monocular_3D_Human_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "31"
            ],
            "1": "With the excellent feature extraction capacity of deep neural networks, many approaches [19, 31, 44, 42, 26, 32, 27, 10, 54, 6] utilize Deep Convolutional Neural Networks to estimate 3D poses from the images or other sources (e.",
            "2": "[31] 22.",
            "3": "[31] Ours Figure 8: Analysis on decomposed 3D estimation."
        },
        "Learning convolutional networks for content-weighted image compression": {
            "authors": [
                "Mu Li",
                "Wangmeng Zuo",
                "Shuhang Gu",
                "Debin Zhao",
                "David Zhang"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Learning_Convolutional_Networks_CVPR_2018_paper.pdf",
            "ref_texts": ""
        },
        "Cascaded deep monocular 3d human pose estimation with evolutionary training data": {
            "authors": [
                "Shichao Li",
                "Lei Ke",
                "Kevin Pratama",
                "Wing Tai",
                "Keung Tang",
                "Ting Cheng"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Cascaded_Deep_Monocular_3D_Human_Pose_Estimation_With_Evolutionary_Training_CVPR_2020_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "43"
            ],
            "1": "Thanks to their representation learning power, deep models have achieved unprecedented high accuracy [43, 41, 28, 34, 32, 60].",
            "2": "Pertinent and recent deep neural networks (DNNs) employ two mainstream architectures: one-stage methods [66, 69, 32, 43, 41, 28, 60, 16]andtwo-stage methods [39, 34, 47, 68]."
        },
        "XNect: Real-time multi-person 3D motion capture with a single RGB camera": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3386569.3392410",
            "ref_texts": "2018. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation. In 3DV. George Papandreou, Tyler Zhu, Nori Kanazawa, Alexander Toshev, Jonathan Tompson, Chris Bregler, and Kevin Murphy. 2017. Towards Accurate Multi-person Pose Estimation in the Wild. In CVPR . Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani, Timo Bolkart, Ahmed A. A. Osman, Dimitrios Tzionas, and Michael J. Black. 2019. Expressive Body Capture: 3D Hands, Face, and Body from a Single Image. (2019). Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. 2018a. Ordinal Depth Supervision for 3D Human Pose Estimation. In CVPR . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In CVPR . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018b. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In CVPR . Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele. 2016. DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation. In CVPR . Leonid Pishchulin, Arjun Jain, Mykhaylo Andriluka, Thorsten Thorm\u00e4hlen, and Bernt Schiele. 2012. Articulated people detection and pose estimation: Reshaping the future. In CVPR . IEEE, 3178\u20133185. Gerard Pons-Moll, David J Fleet, and Bodo Rosenhahn. 2014. Posebits for monocular human pose estimation. In CVPR . 2337\u20132344. Alin-Ionut Popa, Mihai Zanfir, and Cristian Sminchisescu. 2017. Deep Multitask Architecture for Integrated 2D and 3D Human Sensing. In CVPR . Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh. 2012. Reconstructing 3d human pose from 2d image landmarks. In ECCV . Springer, 573\u2013586. Mir Rayat Imtiaz Hossain and James J Little. 2018. Exploiting temporal information for 3d human pose estimation. In Proceedings of the European Conference on Computer Vision (ECCV) . 68\u201384. Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. 2019. Regularized evolution for image classifier architecture search. 33 (2019), 4780\u20134789. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015. Faster R-CNN: Towards real-time object detection with region proposal networks. In NeurIPS . 91\u201399. Helge Rhodin, Christian Richardt, Dan Casas, Eldar Insafutdinov, Mohammad Shafiei, Hans-Peter Seidel, Bernt Schiele, and Christian Theobalt. 2016a. EgoCap: Egocentric Marker-less Motion Capture with Two Fisheye Cameras. TOG (Proc. SIGGRAPH Asia) (2016). Helge Rhodin, Nadia Robertini, Dan Casas, Christian Richardt, Hans-Peter Seidel, and Christian Theobalt. 2016b. General Automatic Human Shape and Motion Capture Using Volumetric Contour Cues. In ECCV . 509\u2013526. https://doi.org/10.1007/978-3-319-46454-1_31 Gregory Rogez, Philippe Weinzaepfel, and Cordelia Schmid. 2017. LCR-Net: Localization-Classification-Regression for Human Pose. In CVPR . Gr\u00e9gory Rogez, Philippe Weinzaepfel, and Cordelia Schmid. 2019. LCR-Net++: Multi-person 2D and 3D Pose Detection in Natural Images. PAMI (2019). Eduardo Romera, Jos\u00e9 M Alvarez, Luis M Bergasa, and Roberto Arroyo. 2018. Erfnet: Efficient residual factorized convnet for real-time semantic segmentation. IEEE Transactions on Intelligent Transportation Systems 19, 1 (2018), 263\u2013272. Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. In CVPR . IEEE, 4510\u20134520. Nikolaos Sarafianos, Bogdan Boteanu, Bogdan Ionescu, and Ioannis A Kakadiaris. 2016.",
            "ref_ids": [
                "2018"
            ],
            "1": "[2018]; Huang et al .",
            "2": "[2018]; Mehta et al .",
            "3": "[2018]; Pavlakos et al .",
            "4": "[2018] compute dense correspondences from pixels to the surface of SMPL [2015], but they do not estimate 3D pose.",
            "5": "9 Hossain & Little [2018] 58."
        },
        "Recent advances of monocular 2d and 3d human pose estimation: A deep learning perspective": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.11536",
            "ref_texts": "[19] G. Pavlakos, X.-W. Zhou, K.-G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "To achieve this, the body structural models [45]\u2013[47], multiscale feature fusion [14], [18], multistage pipelines [41], [48], refinement in a coarse-to-fine manner [19], [49], multi-task learning [23], [26], [27], etc, have been explored and designed.",
            "2": "Following this pipeline, Coarse-to-Fine (C2F) [19] network is proposed to stack the hourglass networks [14], and progressively extend the volumetric direction of the predicted heatmap for fine-gained results.",
            "3": "Model Type Input/Output Type Main Idea Methods Skeleton-basedSingle personHeatmap-based\u000fCoarse-to-fine [19];\n\u000fVNect [149];\n\u000fIntergral heatmap regression IHP [21].",
            "4": "com/DenisTome/Lifting-from-the-Deep-release C2F [19] CVPR\u201917 71.",
            "5": "[19] G."
        },
        "Optimizing network structure for 3d human pose estimation": {
            "authors": [
                "Hai Ci",
                "Chunyu Wang",
                "Xiaoxuan Ma",
                "Yizhou Wang"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Ci_Optimizing_Network_Structure_for_3D_Human_Pose_Estimation_ICCV_2019_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": ", [12,22,23,24,29,31, 33,38,39]) treat3D pose estimation as a supervised regression problem.",
            "2": "[23] 67.",
            "3": "[23] 51."
        },
        "Learning the depths of moving people by watching frozen people": {
            "authors": [
                "Zhengqi Li",
                "Tali Dekel",
                "Forrester Cole",
                "Richard Tucker",
                "Noah Snavely",
                "Ce Liu",
                "William T. Freeman"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Learning_the_Depths_of_Moving_People_by_Watching_Frozen_People_CVPR_2019_paper.pdf"
        },
        "Denserac: Joint 3d pose and shape estimation by dense render-and-compare": {
            "authors": [
                "Yuanlu Xu",
                "Chun Zhu",
                "Tony Tung"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Xu_DenseRaC_Joint_3D_Pose_and_Shape_Estimation_by_Dense_Render-and-Compare_ICCV_2019_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition , 2017. 2",
            "ref_ids": [
                "41"
            ],
            "1": "Several methods predict 3D pose directly given monocular data [52,41,50,38,32,16,19,47]."
        },
        "Self-supervised learning of motion capture": {
            "authors": [
                "Yu Tung",
                "Wei Tung",
                "Ersin Yumer",
                "Katerina Fragkiadaki"
            ],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2017/file/ab452534c5ce28c4fbb0e102d4a4fb2e-Paper.pdf",
            "ref_texts": "[27] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR , abs/1611.07828, 2016.",
            "ref_ids": [
                "27"
            ],
            "1": "Many recent works learn to regress to 3D human pose directly given an RGB image [27] using deep neural networks and large supervised training sets [22].",
            "2": "[27] G."
        },
        "Lcr-net++: Multi-person 2d and 3d pose detection in natural images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1803.00455",
            "ref_texts": "[43] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis., \u201c Coarse-tofine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017. 3, 9, 10 TO APPEAR IN IEEE TRANSACTIONS ON PATTERN ANAL YSIS AND MACHINE INTELLIGENCE, 2019 15",
            "ref_ids": [
                "43"
            ],
            "1": "Recently, this has been naturally extended to end-to-end mappings using CNN architectures, either in monocular images [7], [8], [12], [41], [42], [43] or in videos [11], [44].",
            "2": "[43] propose a volumetric representation for 3D human pose and employ a ConvNet to predict per-voxel likelihoods for each joint.",
            "3": "[43] (17 jts) 71.",
            "4": "On this protocol, we establish a new state-of-the-art performance both with 13 (65:4mm obtained with LCR-Net++) and 17 joints (61:2mm obtained with LCR-Net+) and outperform all previously published methods, including very recent work, despite the fact that (a) we also perform localization, in contrastto most methods such as [8], [43], [51] that assume a bounding box annotation of the human and (b) we propose an end-to-end architecture trained with Human3.",
            "5": "[43] (17 jts) 67.",
            "6": "3\n[43] G."
        },
        "Hand pose estimation via latent 2.5 d heatmap regression": {
            "authors": [
                "Umar Iqbal",
                "Pavlo Molchanov",
                "Thomas Breuel",
                "Jurgen Gall",
                "Kautz Jan"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Umar_Iqbal_Hand_Pose_Estimation_ECCV_2018_paper.pdf",
            "ref_texts": "30. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3D human pose. In: CVPR. (2017) 2,3,7",
            "ref_ids": [
                "30"
            ],
            "1": "Creating volumetric heatmaps for 3D pose estimation [30], however, results in very high computational overhead.",
            "2": "Other approaches for mulate the problem in a multi-task setup to jointly estimate both 2D keypoin t locations and 3D pose [29,30,55\u201358].",
            "3": "The closest work to ours are the approaches of [29,30,56,58] in that they also perform 2.",
            "4": "In order to deal with this, the approach in [30] performs dense volumetric regression.",
            "5": "Theexistingapproacheseithermakeverystrongassumptionssuchast hegroundtruthlocationoftheroot[29]andtheglobalscaleofthehandin3Disknown[56], or resort to an approximate solution [30].",
            "6": "However, they are scarcely used for 3D pose estimation since a 3D volumet ric heatmap representation [30] results in a high computational and storage cost."
        },
        "Exploiting temporal contexts with strided transformer for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2103.14304",
            "ref_texts": "[37] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "37"
            ],
            "1": "R ELATED WORK At the early stage of applying deep neural networks on 3D pose estimation task, many methods [37]\u2013[40] learned the direct mapping from RGB images to 3D poses (i.",
            "2": "Full-to-Single Prediction The iterative refinement scheme, aimed at producing predictions in multiple processing stages, is effective for 3D pose estimation [24], [37].",
            "3": "[37] 22.",
            "4": "[37] G."
        },
        "Exploiting temporal context for 3D human pose estimation in the wild": {
            "authors": [
                "Anurag Arnab",
                "Carl Doersch",
                "Andrew Zisserman"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Arnab_Exploiting_Temporal_Context_for_3D_Human_Pose_Estimation_in_the_CVPR_2019_paper.pdf",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , pages 1263\u20131272, 2017. 2,6",
            "ref_ids": [
                "35"
            ],
            "1": "6M [35,41,34].",
            "2": "Following previous work [35,40, 20], we downsample the videos from 50fps to 10fps and evaluate on the validation set.",
            "3": "2\n[35] G."
        },
        "Learning pose grammar to encode human body configuration for 3d pose estimation": {
            "authors": [
                "Shu Fang",
                "Yuanlu Xu",
                "Wenguan Wang",
                "Xiaobai Liu",
                "Chun Zhu"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/12270/12129",
            "ref_texts": "12.Martinez, J.; Hossain, R.; Romero, J.; and Little, J. J. 2017. A simple yet effective baseline for 3d human pose estimation. In IEEE International Conference on Computer Vision . Moreno-Noguer, F. 2017. 3d human pose estimation from a single image via distance matrix regression. IEEE Conference on Computer Vision and Pattern Recognition . Newell, A.; Yang, K.; and Deng, J. 2016. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision . Nie, B. X.; Wei, P.; and Zhu, S.-C. 2017. Monocular 3d human pose estimation by predicting depth on joints. In IEEE International Conference on Computer Vision . Park, S.; Nie, X.; and Zhu, S.-C. 2015. Attributed and-or grammar for joint parsing of human pose, parts and attributes. IEEE International Conference on Computer Vision . Paul, G. S.; Viola, P.; and Darrell, T. 2003. Fast pose estimation with parameter-sensitive hashing. In IEEE International Conference on Computer Vision . Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE International Conference on Computer Vision . Rogez, G., and Schmid, C. 2016. Mocap-guided data augmentation for 3d pose estimation in the wild. In Annual Conference on Neural Information Processing Systems . Sanzari, M.; Ntouskos, V .; and Pirri, F. 2016. Bayesian image based 3d pose estimation. In European Conference on Computer Vision . Sigal, L.; Balan, A. O.; and Black, M. J. 2010. Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International Journal of Computer Vision 87(1):4\u201327. Simo-Serra, E.; Quattoni, A.; Torras, C.; and Moreno-Noguer, F.",
            "ref_ids": [
                "12"
            ]
        },
        "Physcap: Physically plausible monocular 3d motion capture in real time": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3414685.3417877",
            "ref_texts": ""
        },
        "Attention mechanism exploits temporal contexts: Real-time 3d human pose reconstruction": {
            "authors": [
                "Ruixu Liu",
                "Ju Shen",
                "He Wang",
                "Chen Chen",
                "Vijayan Asari"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Attention_Mechanism_Exploits_Temporal_Contexts_Real-Time_3D_Human_Pose_Reconstruction_CVPR_2020_paper.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , page 1263\u20131272, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "While vast and powerful deep models on 3D pose prediction are emerging (from convolutional neural network (CNN) [34,40,22] to generative adversarial networks (GAN) [43,10]), many of these approaches focus on a single image inference, which is inclined to jittery motion or inexact body configuration.",
            "2": "The former explores the possibility of jointly extracting both 2D and 3D poses in a holistic manner [34,42]; while the latter decouples the estimation into two steps: 2D body part detection and 3D correspondence inference [8,5,50].",
            "3": "With the rise of convolutional neural networks (CNNs) [34,38], automated feature learning disentangles the dependencies among output variables and surpasses the performance of tailor-made solvers.",
            "4": "pelvis ) between the predicted and ground-truth poses, referred as MPJPE [14,21,34,25].",
            "5": "CVPR\u201918 [34]48.",
            "6": "CVPR\u201918 [34]34.",
            "7": "[34] 22.",
            "8": "[34] G."
        },
        "Holopose: Holistic 3d human reconstruction in-the-wild": {
            "authors": [
                "Riza Alp",
                "Iasonas Kokkinos"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Guler_HoloPose_Holistic_3D_Human_Reconstruction_In-The-Wild_CVPR_2019_paper.pdf",
            "ref_texts": "[32] Martin R. Oswald, Eno T \u00a8oppe, and Daniel Cremers. Fast and globally optimal single view reconstruction of curved objects. In 2012 IEEE Conference on Computer Vision and Pattern Recognition, Providence, RI, USA, June 16-21, 2012 , pages 534\u2013541, 2012. 1[33] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. InComputer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 2,6",
            "ref_ids": [
                "32",
                "33"
            ],
            "1": "Prior information about geom-etry can leverage on multiple cues such as object contours [32,57,4], surface-to-image correspondences [30,38,29] or shading [15,12], but, maybe the largest contribution to monocular 3D reconstruction comes from semantics: the constrained variability of known object categories can easily resolve the ambiguities in the 3D reconstruction, for instance if the object\u2019s shape is bound to lie in a lowdimensional space [7,21,49].",
            "2": "In parallel with these works, 3D human joint estimation has seen a steady rise in accuracy [47,63,33,35], most recently based on directly localizing 3D joints in a volumetric output space through hybrids of classification and regression [46,27,22].",
            "3": "[33] 51.",
            "4": "1,2,4,6\n[32] Martin R."
        },
        "Category-level articulated object pose estimation": {
            "authors": [
                "Xiaolong Li",
                "He Wang",
                "Li Yi",
                "Leonidas J. Guibas",
                "Lynn Abbott",
                "Shuran Song"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Category-Level_Articulated_Object_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[19] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 3",
            "ref_ids": [
                "19"
            ],
            "1": "For human pose estimation, approaches have been developed using end-to-end networks to predict 3D joint locations directly [17,23,19], using dense correspondence maps between 2D images and 3D surface models [3], orestimating full 3D shape through 2D supervision [15, 20]."
        },
        "Unsupervised geometry-aware representation for 3d human pose estimation": {
            "authors": [
                "Helge Rhodin",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Helge_Rhodin_Unsupervised_Geometry-Aware_Representation_ECCV_2018_paper.pdf",
            "ref_texts": "24. Pavlakos, G., Zhou, X., Derpanis, K., Konstantinos, G., Dan iilidis, K.: Coarse-ToFine Volumetric Prediction for Single-Image 3D Human Pose. In: Conference on Computer Vision and Pattern Recognition (2017)",
            "ref_ids": [
                "24"
            ],
            "1": "While most current human pose estimation methods [25,54,24,42,27,20,22,33,38] are fully supervised, relying on large training sets annotated with ground-truth 3D positions comi ng from multi-view motion capture systems [21,12], several methods have recently been proposed to limit the requirement for labeled data.",
            "2": "Note that even higher accuracies on H36M than those of RhodinCVPR and Resnet have been reported in the literature [24,20,54,38,27] but they depend both on more complex architectures and using additional information such as labeled 2D poses [22,54,38,20] or semantic segmentation [27], which is not our point here."
        },
        "Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints": {
            "authors": [
                "Andrei Zanfir",
                "Elisabeta Marinoiu",
                "Cristian Sminchisescu"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Zanfir_Monocular_3D_Pose_CVPR_2018_paper.pdf",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "Related Work Our work relates to recently developed deep architectures for 2d human pose estimation [4,9,21,35,36], 3d human pose estimation based on fitting volumetric models [2,15], feedforward deep models for 3d prediction [18,22,40], as well as integrated deep models for 2d and 3d reasoning [23,27,34,19].",
            "2": "[22] G."
        },
        "Pymaf-x: Towards well-aligned full-body model regression from monocular images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.06400",
            "ref_texts": "[64] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d inCVPR , 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "64"
            ],
            "1": "Such strategies can benefit from synthetic data [29], [63] and the progress in the estimation of proxy representations [27], [64], [65], [66], [67].",
            "2": "[64] G.",
            "3": "Following the common protocols [1], [19], [64], our experiments use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation."
        },
        "Sfv: Reinforcement learning of physical skills from videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1810.03599",
            "ref_texts": ""
        },
        "Sim2real transfer learning for 3d human pose estimation: motion to the rescue": {
            "authors": [
                "Carl Doersch",
                "Andrew Zisserman"
            ],
            "url": "https://proceedings.neurips.cc/paper/2019/file/d4a93297083a23cc099f7bd6a8621131-Paper.pdf",
            "ref_texts": "[56] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "56"
            ],
            "1": "Other works regress poses directly from pixels [46,55,56,68,71,77,78,96], which generally relies on having a good match between training and testing.",
            "2": "[56] G."
        },
        "Graformer: Graph-oriented transformer for 3d pose estimation": {
            "authors": [
                "Weixi Zhao",
                "Weiqiang Wang",
                "Yunjie Tian"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Zhao_GraFormer_Graph-Oriented_Transformer_for_3D_Pose_Estimation_CVPR_2022_paper.pdf"
        },
        "Detailed 2d-3d joint representation for human-object interaction": {
            "authors": [
                "Lu Li",
                "Xinpeng Liu",
                "Han Lu",
                "Shiyi Wang",
                "Junqi Liu",
                "Jiefeng Li",
                "Cewu Lu"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Detailed_2D-3D_Joint_Representation_for_Human-Object_Interaction_CVPR_2020_paper.pdf",
            "ref_texts": "[46] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "46"
            ],
            "1": "Recent deep learning based 3D pose estimation methods [26,14,46] have achieved substantial progresses."
        },
        "Learning monocular 3d human pose estimation from multi-view images": {
            "authors": [
                "Helge Rhodin",
                "Jorg Sporri",
                "Isinsu Katircioglu",
                "Victor Constantin",
                "Frederic Meyer",
                "Erich Muller",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Rhodin_Learning_Monocular_3D_CVPR_2018_paper.pdf",
            "ref_texts": "[18] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis. Coarse-To-Fine V olumetric Prediction for Single-Image 3D Human Pose. In Conference on Computer Vision and Pattern Recognition , 2017. 1,2,5,6",
            "ref_ids": [
                "18"
            ],
            "1": "Walking and upright poses are prime examples of this, and state-of-the-art algorithms [18,27,20,15,17] now deliver impressive real-time results in uncontrolled environments.",
            "2": "Related work Algorithms for 3D human pose estimation from single images [18,27,20,15,17,23,19,31,26,25] have now matured to the point where they can operate in real-time and in the wild.",
            "3": "[18] 71.",
            "4": "In the top portion of Table 1, we report the MPJPE and NMPJPE values of fully-supervised methods on H36M using the same protocol as in [13,31,16,26,18, 19]: Five subjects (S1, S5, S6, S7, S8) are used for training and the remaining two (S9, S11) for testing.",
            "5": "[18] even takes 67 ms.",
            "6": "1,2\n[18] G."
        },
        "Voxelpose: Towards multi-camera 3d human pose estimation in wild environment": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.06239",
            "ref_texts": "28. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR, IEEE (2017) 1263{1272",
            "ref_ids": [
                "28"
            ],
            "1": "Some recent works [6,28,19,29,26] also propose to regress a volumetric 3D pose representation from images."
        },
        "Motion guided 3d pose estimation from videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.13985",
            "ref_texts": "26. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7025{7034 (2017) Motion 17",
            "ref_ids": [
                "26"
            ],
            "1": "Keywords: 3D Pose Estimation, Motion Loss, Graph Convolution 1 Introduction 3D human pose estimation aims at reconstructing 3D body keypoints from thier 2D projections, such as images [36,14,33,26], videos [4,35], 2D pose [17,27,15], or their combination [24,34].",
            "2": "In the ffrst type, estimators predict 3D poses from 2D images directly [14,35,26,33].",
            "3": "[26] predicts per voxel likelihoods for each joint 1The demo video is in https://www.",
            "4": "9 Pavlakos [26] 67."
        },
        "Canonpose: Self-supervised monocular 3d human pose estimation in the wild": {
            "authors": [
                "Bastian Wandt",
                "Marco Rudolph",
                "Petrissa Zell",
                "Helge Rhodin",
                "Bodo Rosenhahn"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wandt_CanonPose_Self-Supervised_Monocular_3D_Human_Pose_Estimation_in_the_Wild_CVPR_2021_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u2013",
            "ref_ids": [
                "32"
            ],
            "1": "Several others followed this end-to-end approach [44,30,5,26,32,38,45,42,22, 43,52,19,50,13]."
        },
        "Propagating lstm: 3d pose estimation based on joint interdependency": {
            "authors": [
                "Kyoungoh Lee",
                "Inwoong Lee",
                "Sanghoon Lee"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Kyoungoh_Lee_Propagating_LSTM_3D_ECCV_2018_paper.pdf",
            "ref_texts": "19. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3D human pose. In: Computer Visio n and Pattern Recognition (CVPR). (2017) 1,3,9,10",
            "ref_ids": [
                "19"
            ],
            "1": "[19] extended the existing 2D pose estimation method [2] to 3D.",
            "2": "Previous works [5,18,19,22\u201324,26\u201329,31,43,44] performed the evaluation according to several different protocols.",
            "3": "This protocol was used in [5,18,19,22,24,26\u201329,31,44].",
            "4": "3 Pavlakos, CVPR\u201917 [19] 67."
        },
        "Unsupervised 3d pose estimation with geometric self-supervision": {
            "authors": [
                "Hang Chen",
                "Ambrish Tyagi",
                "Amit Agrawal",
                "Dylan Drover",
                "Rohith M",
                "Stefan Stojanov",
                "James M. Rehg"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Unsupervised_3D_Pose_Estimation_With_Geometric_Self-Supervision_CVPR_2019_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. InCVPR , July 2017. 2",
            "ref_ids": [
                "34"
            ]
        },
        "Generating multiple hypotheses for 3d human pose estimation with mixture density network": {
            "authors": [
                "Chen Li",
                "Gim Hee"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Generating_Multiple_Hypotheses_for_3D_Human_Pose_Estimation_With_Mixture_CVPR_2019_paper.pdf",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and Pattern Recognition , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "The first category is to train deep convolutional neural networks (CNNs) end-to-end to estimate 3D human poses directly from the input images [20,16,28,19,27,14,23].",
            "2": "[20] use volumetric representation to represent 3D poses and adopt the stacked hourglass network [18], which is originally designed for 2D pose estimation, to predict 3D volumetric heatmaps.",
            "3": "[20] 67.",
            "4": "[20] G."
        },
        "Weakly-supervised 3d human pose learning via multi-view images in the wild": {
            "authors": [
                "Umar Iqbal",
                "Pavlo Molchanov",
                "Jan Kautz"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Iqbal_Weakly-Supervised_3D_Human_Pose_Learning_via_Multi-View_Images_in_the_CVPR_2020_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 1, 2",
            "ref_ids": [
                "28"
            ],
            "1": "The state-of-the-art methods [6,16,17,28,32,39\u201341,52,53] in this area use images annotated with 3D poses and train deep neural networks to directly regress 3D pose from images.",
            "2": ", 2D pose annotations [6,28,32,39,40,52], boolean geometric relationship between body parts [27,31,37], action labels [20], and temporal consistency [2]."
        },
        "Anatomy-aware 3d human pose estimation with bone-based pose decomposition": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2002.10322",
            "ref_texts": "[7] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "7"
            ],
            "1": "[7] integrated the volumetric representation with a coarse-to-fine supervision scheme to figure out the 3D joint locations by the predicted 3D volumetric heat maps.",
            "2": "Based on the ConvNet pose estimator and the volumetric heap map representation proposed by [7], recent approaches mainly made progress from two aspects.",
            "3": "[7] G."
        },
        "Weakly supervised 3d human pose and shape reconstruction with normalizing flows": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.10350",
            "ref_texts": "32. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR (2017)",
            "ref_ids": [
                "32"
            ],
            "1": "More recently, there has been signiffcant interest in 3D human pose and shape estimation [38,6,13,20,1,44], with some in the form of a reduced parametric model [32] decoded by 2D predictions, volumetric variants [41] or direct vertex prediction combined with 3D model fftting [10,46]."
        },
        "Unified pose sequence modeling": {
            "authors": [
                "Lin Geng",
                "Tianjiao Li",
                "Hossein Rahmani",
                "Qiuhong Ke",
                "Jun Liu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Foo_Unified_Pose_Sequence_Modeling_CVPR_2023_paper.pdf",
            "ref_texts": "[53] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "53"
            ],
            "1": "In 3D Pose Estimation [24, 41, 45, 84, 95, 96], we predict the 3D coordinates of a human\u2019s joints, with the input being either RGB images [53, 70] or 2D poses [24, 41, 45, 84, 95, 96]."
        },
        "Point-to-point regression pointnet for 3d hand pose estimation": {
            "authors": [
                "Liuhao Ge",
                "Zhou Ren",
                "Junsong Yuan"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Liuhao_Ge_Point-to-Point_Regression_PointNet_ECCV_2018_paper.pdf",
            "ref_texts": "24. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: CVPR (2017)",
            "ref_ids": [
                "24"
            ],
            "1": "However, it is non-trivial to lift 2D heat-maps to 3D joint locations [24,30, 41]."
        },
        "Learning to fuse 2d and 3d image cues for monocular body pose estimation": {
            "authors": [
                "Bugra Tekin",
                "Pablo Marquez",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2017/papers/Tekin_Learning_to_Fuse_ICCV_2017_paper.pdf",
            "ref_texts": "[46] G. Pavlakos, X. Zhou, K. Derpanis, and K. Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In arXiv preprint, arXiv:1611.07828 , 2016. 1, 2,5,6,7",
            "ref_ids": [
                "46"
            ],
            "1": "Over the years, two main classes of approaches have been proposed: Discriminative ones that directly regress 3D pose from image data [1,8,34,46,56,68] and generative ones that search the pose space for a plausible body configuration that aligns with the image data [21,60,69].",
            "2": "Discriminative methods aim at predicting 3D pose directly from the input data, may it be single images [28,29, 37,38,39,46,52,55,64,74], depth images [23,50,59], or short image sequences [65].",
            "3": "More recently, [46] and [66] also used 2D joint location confidence maps as an intermediate representation and combined them with the image features at certain layers of the network to guide the pose estimation process in a discriminative regression scheme.",
            "4": "6m, we used the same data partition and evaluation protocol as in earlier work [17,38,39,40,45, 46,53,65,64,66,77,76] for a fair comparison.",
            "5": "On the KTH Multiview Football II dataset, we evaluate our method on the sequence containing Player 2, as in [7,10,46,65].",
            "6": "Following [7,10,46,65], the first half of the sequence from camera 1 is used for training and the second half for testing.",
            "7": "To compare our results to those of [7,10,46,65], we report accuracy using the percentage of correctly estimated parts (PCP) score.",
            "8": "In Table 1, we compare the results of our trainable fusion approach with those of the following stateof-the-art single image-based methods: KDE regression from HOG features to 3D poses [30], jointly training a 2D body part detector and a 3D pose regressor [38,45], the maximum-margin structured learning framework of [39, 40], the deep structured prediction approach of [64], pose regression with kinematic constraints [76], pose estimation with mocap guided data augmentation [53], volumetric pose prediction approach of [46] and lifting 2D heatmap predictions to 3D human pose [66].",
            "9": "By leveraging reliable 2D joint location estimates, [46] also yields accurate 3D pose estimates, however our approach outperforms it on average across the entire 3945\n Input Method Directions Discussion Eating Greeting Phone Talk Posing Buying Sitting Sitting Down Single-ImageIonescu et al.",
            "10": "[46] 67.",
            "11": "[46] 71.",
            "12": "While [46,66,76] train single models, the rest carry out action-specific training.",
            "13": "In Table 4, we compare our approach to [7,10,46,65] on the KTH Multiview Football II dataset.",
            "14": "Method: [10] [10] [7] [65] [46] Ours-NoPretraining Ours-Pretraining Input: Image Image Image Video Image Image Image Num.",
            "15": "2 Table 4: On KTH Multiview Football II, we compare our method that uses a single image to those of [10,46,65] that use either one or two images, the one of [7] that uses two, and the one of [65] that operates on a sequence.",
            "16": "As in [7, 10,46,65], we measure performance as the percentage of correctly estimated parts (PCP) score.",
            "17": "2,5,6\n[46] G."
        },
        "A comprehensive study of weight sharing in graph networks for 3d human pose estimation": {
            "authors": [],
            "url": "https://www.evl.uic.edu/documents/eccv20_wtang.pdf",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7025{7034 (2017)",
            "ref_ids": [
                "25"
            ],
            "1": "The ffrst one is to regress the 3D human pose directly from the input image [25, 35].",
            "2": "Recent approaches [25, 44, 31, 32, 39] exploit convolutional neural networks (CNNs) to learn powerful visual ?The ffrst two authors contributed equally to this work."
        },
        "Learning 3d human pose from structure and motion": {
            "authors": [
                "Rishabh Dabral",
                "Anurag Mundhada",
                "Abhishek Sharma"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Rishabh_Dabral_Learning_3D_Human_ECCV_2018_paper.pdf",
            "ref_texts": "27. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 3,11",
            "ref_ids": [
                "27"
            ],
            "1": "Some approaches make use of volumetric-heatmaps [27], some define a pose using bones instead of joints [34], while the approach in [23] directly regresses for 3D location maps.",
            "2": "Recent ConvNet based approaches [23,30,41,34,43,27] have reported substantial improvements in real-world setting by pre-training or joint training of their 2D prediction modules, but it still remains an open problem.",
            "3": "0 Pavlakos [27] 58.",
            "4": "9 Pavlakos [27] 103."
        },
        "Monoperfcap: Human performance capture from monocular video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1708.02136",
            "ref_texts": ""
        },
        "Alignsdf: Pose-aligned signed distance fields for hand-object reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.12909",
            "ref_texts": "[46] Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3D human pose. In: CVPR (2017)",
            "ref_ids": [
                "46"
            ],
            "1": "To estimate the relative 3D translation (\u20d7to), we employ volumetric heatmaps [38, 46] to predict per voxel likelihood for the object centroid and use a soft-argmax operator [60] to extract the 3D coordinate from heatmaps.",
            "2": "In: CVPR\n(2019)\n[46] Pavlakos, G."
        },
        "DeepFly3D, a deep learning-based approach for 3D limb and appendage tracking in tethered, adult Drosophila": {
            "authors": [],
            "url": "https://elifesciences.org/articles/48571.pdf",
            "ref_texts": "10.1016/j.cub.2018.12.019 ,PMID: 30661796 Mehta D , Sridhar S, Sotnychenko O, Rhodin H, Shafiei M, Seidel H, Xu W, Casas D, Theobalt C. 2017. Vnect: Real-Time3D Human Pose Estimation with a Single RGB Camera. SIGGRAPH. Mendes CS , Bartos I, Akay T, Ma \u00b4rka S, Mann RS. 2013. Quantification of gait parameters in freely walking wild type and sensory deprived Drosophila Melanogaster. eLife 2:e00231. DOI: https://doi.org/10.7554/eLife.00231 , PMID: 23326642 Moeslund TB , Granum E. 2000. Multiple cues used in model-based human motion capture.. Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580) 362\u2013367. DOI: https://doi.org/10.1109/AFGR.2000.840660 Moreno-noguer F . 2017. 3d human pose estimation from a single image via distance matrix regression. CVPR. Murphy KP , Weiss Y, Jordan MI. 1999. Loopy belief propagation for approximate inference: an empirical study. Onference on Uncertainty in Artificial Intelligence p. 467\u2013475. Nath T , Mathis A, Chen AC, Patel A, Bethge M, Mathis MW. 2019. Using DeepLabCut for 3D markerless pose estimation across species and behaviors. Nature Protocols 14:2152\u20132176. DOI: https://doi.org/10.1038/ s41596-019-0176-0 ,PMID: 31227823 Newell A , Yang K, Deng J. 2016. European Conference on Computer Vision. In: Stacked Hourglass Networks for Human Pose Estimation . Springer. p. 483\u2013499. Gu\u00a8nelet al. eLife 2019;8:e48571. DOI: https://doi.org/10.7554/eLife.48571 22 of 23Tools and resources Neuroscience Pavlakos G , Zhou X, Derpanis K, Konstantinos G, Daniilidis K. 2017a. Coarse-To-Fine volumetric prediction for Single-Image 3D human pose. CVPR. Pavlakos G , Zhou X, Konstantinos KDG, Kostas D. 2017b. Harvesting multiple views for Marker-Less 3D human pose annotations. In: CVPR. Pereira TD , Aldarondo DE, Willmore L, Kislin M, Wang SS, Murthy M, Shaevitz JW. 2019. Fast animal pose estimation using deep neural networks. Nature Methods 16:117\u2013125. DOI: https://doi.org/10.1038/s41592018-0234-5 ,PMID: 30573820 Popa AI , Zanfir M, Sminchisescu C. 2017. Deep multitask architecture for integrated 2D and 3D human sensing. In: CVPR. Puwein J , Ballan L, Ziegler R, Pollefeys M. 2014. Accelerated Kmeans Clustering Using Binary Random Projection. In: Joint Camera Pose Estimation and 3D Human Pose Estimation in a Multi-Camera Setup . springer. p. 473\u2013487. Rhodin H , Robertini N, Casas D, Richardt C, Seidel HP, Theobalt C. 2016. General automatic human shape and motion capture using volumetric contour cues. ECCV. Rogez G , Weinzaepfel P, Schmid C. 2017. Lcr-Net: localization-classification-regression for human pose. In: CVPR. Seeds AM , Ravbar P, Chung P, Hampel S, Midgley FM, Mensh BD, Simpson JH. 2014. A suppression hierarchy among competing motor programs drives sequential grooming in Drosophila. eLife 3:e02951. DOI: https://doi. org/10.7554/eLife.02951 ,PMID: 25139955 Seelig JD , Chiappe ME, Lott GK, Dutta A, Osborne JE, Reiser MB, Jayaraman V. 2010. Two-photon calcium imaging from head-fixed Drosophila during optomotor walking behavior. Nature Methods 7:535\u2013540. DOI: https://doi.org/10.1038/nmeth.1468 ,PMID: 20526346 Simon T , Joo H, Matthews I, Sheikh Y. 2017. Hand keypoint detection in single images using multiview bootstrapping. In: CVPR. Sun X , Shang J, Liang S, Wei Y. 2017. Compositional human pose regression. ICCV. Takahashi K , Mikami D, Isogawa M, Kimata H. 2018. Human pose as calibration pattern; 3D human pose estimation with multiple unsynchronized and uncalibrated cameras. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops. Tekin B , Marquez-neila P, Salzmann M, Fua P. 2017. Learning to fuse 2D and 3D image cues for monocular body pose estimation. ICCV. Todd JG , Kain JS, de Bivort BL. 2017. Systematic exploration of unsupervised methods for mapping behavior. Physical Biology 14:015002. DOI: https://doi.org/10.1088/1478-3975/14/1/015002 ,PMID: 28166059 Tome D , Russell C, Agapito L. 2017. Lifting from the deep: convolutional 3D pose estimation from a single image. arXiv .https://arxiv.org/abs/1701.00295 . Triggs B , Mclauchlan P, Hartley R, Fitzgibbon A. 2000. Vision Algorithms: Theory and Practice . Springer. Uhlmann V , Ramdya P, Delgado-Gonzalo R, Benton R, Unser M. 2017. FlyLimbTracker: an active contour based approach for leg segment tracking in unmarked, freely behaving Drosophila. PLOS ONE 12:e0173433. DOI: https://doi.org/10.1371/journal.pone.0173433 ,PMID: 28453566 Zhou X , Huang Q, Sun X, Xue X, Wei Y. 2017. Weakly-supervised transfer for 3d human pose estimation in the wild. IEEE International Conference on Computer Vision. Gu\u00a8nelet al. eLife 2019;8:e48571. DOI: https://doi.org/10.7554/eLife.48571 23 of 23Tools and resources Neuroscience "
        },
        "Multi-task deep learning for real-time 3D human pose estimation and action recognition": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.08077",
            "ref_texts": "[42] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 3, 6, 8, 10, 12",
            "ref_ids": [
                "42"
            ],
            "1": "[42] proposed the volumetric stacked hourglass architecture, but the method suffers from significant increase in the number of parameters and from the required memory to store all the gradients.",
            "2": "4 Pose Re-injection As systematically noted in recent works [7, 20, 40, 42], predictions re-injection is a very efficient way to improve precision on estimated poses.",
            "3": "We follow the most common evaluation protocol [65, 54, 37, 38, 42] by taking five subjects for training (S1, S5, S6, S7, S8) and evaluating on two subjects (S9, S11) on one every 64 frames.",
            "4": "[42] 67.",
            "5": "[42] 96.",
            "6": "[42] 71.",
            "7": "2\n[42] G."
        },
        "Diffpose: Toward more reliable 3d pose estimation": {
            "authors": [
                "Jia Gong",
                "Lin Geng",
                "Zhipeng Fan",
                "Qiuhong Ke",
                "Hossein Rahmani",
                "Jun Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Gong_DiffPose_Toward_More_Reliable_3D_Pose_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE CVPR , pages 7025\u20137034, 2017. 2, 7",
            "ref_ids": [
                "31"
            ],
            "1": "Some works [7\u20139,30,31,42] use Convolutional Neural Networks (CNNs) to output a human pose from the RGB image, while many works [26, 46, 51, 52] first detect the 2D pose and then use it to regress the 3D pose.",
            "2": "MPJPE(CPN) Dir Disc Eat Greet Phone Photo Pose Pur Sit SitD Smoke Wait WalkD Walk WalkT Avg Pavlakos [31] 67."
        },
        "Camera-space hand mesh recovery via semantic aggregation and adaptive 2d-1d registration": {
            "authors": [
                "Xingyu Chen",
                "Yufeng Liu",
                "Chongyang Ma",
                "Jianlong Chang",
                "Huayan Wang",
                "Tian Chen",
                "Xiaoyan Guo",
                "Pengfei Wan",
                "Wen Zheng"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Camera-Space_Hand_Mesh_Recovery_via_Semantic_Aggregation_and_Adaptive_2D-1D_CVPR_2021_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1,2,5",
            "ref_ids": [
                "32"
            ],
            "1": "reconstruction, including [16,17,20,21,23,27,30,31,32, 33,36,39], to name a few.",
            "2": ",RGB\u2192MANO/SMPL [16,40,42,44],RGB\u2192Voxel [15,27, 32,39], and RGB\u2192Coord (coordinate) [8,9,21,22].",
            "3": "We follow existing methods [6,16,27,32] to use subjects S1, S5, S6, S7, S8 for training and subjects S9, S11 for testing."
        },
        "In the wild human pose estimation using explicit 2d features and intermediate 3d representations": {
            "authors": [
                "Ikhsanul Habibie",
                "Weipeng Xu",
                "Dushyant Mehta",
                "Gerard Pons",
                "Christian Theobalt"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Habibie_In_the_Wild_Human_Pose_Estimation_Using_Explicit_2D_Features_CVPR_2019_paper.pdf",
            "ref_texts": "[26] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 2,7",
            "ref_ids": [
                "26"
            ],
            "1": "[26] proposed using a volumetric representation as an extension of the 2D joint heatmaps in the 3D space.",
            "2": "6 Pavlakos [26] 67.",
            "3": "5 Pavlakos [26] 96.",
            "4": "3,4\n[26] G."
        },
        "Diverse trajectory forecasting with determinantal point processes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.04967",
            "ref_texts": "10 Published as a conference paper at ICLR 2020 C. Ionescu, D. Papava, V . Olaru, and C. Sminchisescu. Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE transactions on pattern analysis and machine intelligence , 36(7):1325\u20131339, 2013. A. Jain, A. Singh, H. S. Koppula, S. Soh, and A. Saxena. Recurrent neural networks for driver activity anticipation via sensory-fusion architecture. In Robotics and Automation (ICRA), 2016 IEEE International Conference on , pages 3118\u20133125. IEEE, 2016a. A. Jain, A. R. Zamir, S. Savarese, and A. Saxena. Structural-rnn: Deep learning on spatio-temporal graphs. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 5308\u20135317, 2016b. M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul. An introduction to variational methods for graphical models. Machine learning , 37(2):183\u2013233, 1999. A. Kanazawa, J. Zhang, P. Felsen, and J. Malik. Learning 3d human dynamics from video. arXiv preprint arXiv:1812.01601 , 2018. D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 , 2014. K. M. Kitani, B. D. Ziebart, J. A. Bagnell, and M. Hebert. Activity forecasting. In European Conference on Computer Vision , pages 201\u2013214. Springer, 2012. A. Kulesza and B. Taskar. k-dpps: Fixed-size determinantal point processes. In Proceedings of the 28th International Conference on Machine Learning (ICML-11) , pages 1193\u20131200, 2011. A. Kulesza, B. Taskar, et al. Determinantal point processes for machine learning. Foundations and Trends R in Machine Learning , 5(2\u20133):123\u2013286, 2012. N. Lee, W. Choi, P. Vernaza, C. B. Choy, P. H. Torr, and M. Chandraker. Desire: Distant future prediction in dynamic scenes with interacting agents. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 336\u2013345, 2017. S. Lee, S. P. S. Prakash, M. Cogswell, V . Ranjan, D. Crandall, and D. Batra. Stochastic multiple choice learning for training diverse deep ensembles. In Advances in Neural Information Processing Systems , pages 2119\u20132127, 2016. Z. Li, Y . Zhou, S. Xiao, C. He, Z. Huang, and H. Li. Auto-conditioned recurrent networks for extended complex human motion synthesis. arXiv preprint arXiv:1707.05363 , 2017. W.-C. Ma, D.-A. Huang, N. Lee, and K. M. Kitani. Forecasting interactive dynamics of pedestrians with fictitious play. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 774\u2013782, 2017. O. Macchi. The coincidence approach to stochastic point processes. Advances in Applied Probability , 7(1): 83\u2013122, 1975. J. Martinez, R. Hossain, J. Romero, and J. J. Little. A simple yet effective baseline for 3d human pose estimation. In Proceedings of the IEEE International Conference on Computer Vision , pages 2640\u20132649, 2017. G. L. Nemhauser, L. A. Wolsey, and M. L. Fisher. An analysis of approximations for maximizing submodular set functionsi. Mathematical programming , 14(1):265\u2013294, 1978. D. Nilsson. An efficient algorithm for finding the m most probable configurationsin probabilistic expert systems. Statistics and computing , 8(2):159\u2013173, 1998. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. D. Pavllo, C. Feichtenhofer, D. Grangier, and M. Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7753\u20137762, 2019. N. Rhinehart, K. M. Kitani, and P. Vernaza. R2p2: A reparameterized pushforward policy for diverse, precise generative path forecasting. In Proceedings of the European Conference on Computer Vision (ECCV) , pages 772\u2013788, 2018. N. Rhinehart, R. McAllister, K. Kitani, and S. Levine. Precog: Prediction conditioned on goals in visual multi-agent settings. arXiv preprint arXiv:1905.01296 , 2019. A. Robicquet, A. Sadeghian, A. Alahi, and S. Savarese. Learning social etiquette: Human trajectory understanding in crowded scenes. In European conference on computer vision , pages 549\u2013565. Springer, 2016. B. Seroussi and J.-L. Golmard. An algorithm directly finding the k most probable configurations in bayesian networks. International Journal of Approximate Reasoning , 11(3):205\u2013233, 1994. H. Soo Park, J.-J. Hwang, Y . Niu, and J. Shi. Egocentric future localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4697\u20134705, 2016. J. Walker, C. Doersch, A. Gupta, and M. Hebert. An uncertain future: Forecasting from static images using variational autoencoders. In European Conference on Computer Vision , pages 835\u2013851. Springer, 2016. D. Xie, S. Todorovic, and S.-C. Zhu. Inferring \u201ddark matter\u201d and \u201ddark energy\u201d from videos. 2013 IEEE International Conference on Computer Vision , pages 2224\u20132231, 2013. T. Yagi, K. Mangalam, R. Yonetani, and Y . Sato. Future person localization in first-person videos. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018."
        },
        "Neural monocular 3d human motion capture with physical awareness": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3450626.3459825",
            "ref_texts": "2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Computer Vision and Pattern Recognition (CVPR) . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018. Learning to estimate 3D human pose and shape from a single color image. In Computer Vision and Pattern Recognition (CVPR) . Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 2019. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Computer Vision and Pattern Recognition (CVPR) . Xue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel van de Panne. 2018a. Deepmimic: Example-guided deep reinforcement learning of physics-based character skills. ACM Transactions on Graphics (TOG) 37, 4 (2018). Xue Bin Peng, Angjoo Kanazawa, Jitendra Malik, Pieter Abbeel, and Sergey Levine.",
            "ref_ids": [
                "2017"
            ],
            "1": "[2017] estimate 3D human poses along with the inner and exterior forces from images for object lifting and walking."
        },
        "Dense 3d regression for hand pose estimation": {
            "authors": [
                "Chengde Wan",
                "Thomas Probst",
                "Luc Van",
                "Angela Yao"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Wan_Dense_3D_Regression_CVPR_2018_paper.pdf",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "30"
            ],
            "1": "This becomes very parameter-heavy and as a result, severely limits the working resolution[12, 30,22].",
            "2": "3,4, 6\n[30] G."
        },
        "Frankmocap: Fast monocular 3d hand and body motion capture by regression and integration": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.08324",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "38"
            ],
            "1": "Many monocular 3D body pose estimation approaches consider to predict 3D body keypoint locations from single images [41, 50, 52, 29, 38]."
        },
        "Smap: Single-shot multi-person absolute 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.11469",
            "ref_texts": "29. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR (2017)",
            "ref_ids": [
                "29"
            ],
            "1": "Most of them are learning-based [1,36,28,29,35,40,8,21]."
        },
        "Harvesting multiple views for marker-less 3d human pose annotations": {
            "authors": [
                "Georgios Pavlakos",
                "Xiaowei Zhou",
                "Konstantinos G. Derpanis",
                "Kostas Daniilidis"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Pavlakos_Harvesting_Multiple_Views_CVPR_2017_paper.pdf",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. CVPR , 2017. 3,5",
            "ref_ids": [
                "29"
            ],
            "1": "[29] instead propose the regression of 3D heatmaps instead of 3D coordinates.",
            "2": ", the volumetric representation for 3D pose [29].",
            "3": "7\n[29] G."
        },
        "Monocular 3d human pose estimation by generation and ordinal ranking": {
            "authors": [
                "Saurabh Sharma",
                "Pavan Teja",
                "Prashast Bindal",
                "Abhishek Sharma",
                "Arjun Jain"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Sharma_Monocular_3D_Human_Pose_Estimation_by_Generation_and_Ordinal_Ranking_ICCV_2019_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 6, 8",
            "ref_ids": [
                "25"
            ],
            "1": "[25] 67.",
            "2": "[25] 47.",
            "3": "[25] 22."
        },
        "Game Plan: What AI can do for Football, and What Football can do for AI": {
            "authors": [],
            "url": "https://www.jair.org/index.php/jair/article/download/12505/26683",
            "ref_texts": "84 Game Plan: What AI can do for Football, and What Football can do for AI Panait, L., & Luke, S. (2005). Cooperative multi-agent learning: The state of the art. Auton. Agents Multi Agent Syst. ,11(3), 387{434. Papandreou, G., Zhu, T., Chen, L.-C., Gidaris, S., Tompson, J., & Murphy, K. (2018). Personlab: Person pose estimation and instance segmentation with a bottom-up, partbased, geometric embedding model. In Proceedings of the european conference on computer vision (ECCV) (pp. 269{286). Papandreou, G., Zhu, T., Kanazawa, N., Toshev, A., Tompson, J., Bregler, C., & Murphy, K. (2017). Towards accurate multi-person pose estimation in the wild. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4903{4911). Pavlakos, G., Choutas, V., Ghorbani, N., Bolkart, T., Osman, A. A., Tzionas, D., & Black, M. J. (2019). Expressive body capture: 3d hands, face, and body from a single image. InProceedings of the IEEE conference on computer vision and pattern recognition (pp. 10975{10985). Pavlakos, G., Zhou, X., Derpanis, K. G., & Daniilidis, K. (2017). Coarse-to-ffne volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7025{7034). Pavllo, D., Feichtenhofer, C., Grangier, D., & Auli, M. (2019). 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7753{7762). Pishchulin, L., Insafutdinov, E., Tang, S., Andres, B., Andriluka, M., Gehler, P. V., & Schiele, B. (2016). Deepcut: Joint subset partition and labeling for multi person pose estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4929{4937). Puerzer, R. (2002, 01). From scientiffc baseball to sabermetrics: Professional baseball as a reection of engineering and management in society. Nine: A Journal of Baseball History and Culture ,11, 34-48. Quiroga, J., Carrillo, H., Maldonado, E., Ruiz, J., & Zapata, L. M. (2020, June). As seen on tv: Automatic basketball video production using gaussian-based actionness and game states recognition. In Proceedings of the ieee/cvf conference on computer vision and pattern recognition (CVPR) workshops. Ramos, G., Vaz, J., Mendonca, G., Pezarat-Correia, P., Rodrigues, J., Alfaras, M., & Gamboa, H. (2020, 01). Fatigue evaluation through machine learning and a global fatigue descriptor. Journal of Healthcare Engineering ,2020 , 1-18. Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster R-CNN: Towards realtime object detection with region proposal networks. In Advances in neural information processing systems 28 (pp. 91{99). Curran Associates, Inc. Retrieved from http://papers.nips.cc/paper/5638-faster-r-cnn-towards-real -time-object-detection-with-region-proposal-networks.pdf RoboCup project. (2020). Retrieved 2020-09-09, from https://www.robocup.org 85 Tuyls, Omidshafiei, Muller et al. Rossi, A., Pappalardo, L., Cintia, P., Iaia, F., Fern\u0013 andez, J., & Medina, D. (2018, 06). Machine learning approach to injury prediction. Schmidhuber, J. (2015). Deep learning in neural networks: An overview. Neural Networks , 61, 85-117. (Published online 2014; based on TR arXiv:1404.7828 [cs.NE]) doi: 10.1016/j.neunet.2014.09.003 Shih, H.-C. (2017). A survey of content-aware video analysis for sports. IEEE Transactions on Circuits and Systems for Video Technology ,28(5), 1212{1231. Shoham, Y., Powers, R., & Grenager, T. (2007). If multi-agent learning is the answer, what is the question? Artif. Intell. ,171(7), 365{377. Sindik, J., & Vidak, N. (2008, 06). Application of game theory in describing eflcacy of decision making in sportsman's tactical performance in team sports. Interdisciplinary Description of Complex Systems scientiffc journal ,6, 53-66. Skinner, B. (2010). The price of anarchy in basketball. Journal of Quantitative Analysis in Sports ,6(1). Song, A., Severini, T., & Allada, R. (2017). How jet lag impairs major league baseball performance. Proceedings of the National Academy of Sciences ,114(6), 1407{1412. Spearman, W. (2016, 02). Quantifying pitch control. doi: 10.13140/RG.2.2.22551.93603 Spearman, W. (2018). Beyond expected goals. In Proceedings of the 12th mit sloan sports analytics conference (pp. 1{17). Statsbomb. (2020). Retrieved 2020-09-09, from https://statsbomb.com/ Stats perform. (2020). Retrieved 2020-09-17, from https://www.statsperform.com/ resource/stats-playing-styles-introduction/ Stone, P., Sutton, R. S., & Kuhlmann, G. (2005). Reinforcement learning for RoboCupsoccer keepaway. Adaptive Behavior ,13(3), 165{188. StriVR Immersive Sports Analytics. (2020). Retrieved 2020-09-09, from https://www .strivr.com/use-cases/sports/ Su, S.-Y., Hajimirsadeghi, H., & Mori, G. (2019). Graph generation with variational recurrent neural network. arXiv preprint arXiv:1910.01743 . Sun, C., Karlsson, P., Wu, J., Tenenbaum, J. B., & Murphy, K. (2019). Stochastic prediction of multi-agent interactions from partial observations. arXiv preprint arXiv:1902.09641 . Sun, J., Xie, J., Hu, J.-F., Lin, Z., Lai, J., Zeng, W., & Zheng, W.-s. (2019). Predicting future instance segmentation with contextual pyramid convlstms. In Proceedings of the 27th acm international conference on multimedia (pp. 2043{2051). Sun, K., Xiao, B., Liu, D., & Wang, J. (2019). Deep high-resolution representation learning for human pose estimation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 5693{5703). Sun, X., Davis, J., Schulte, O., & Liu, G. (2020). Cracking the black box: Distilling deep sports analytics. In Proceedings of the 26th acm sigkdd international confer86 Game Plan: What AI can do for Football, and What Football can do for AI ence on knowledge discovery & data mining (p. 3154{3162). New York, NY, USA: Association for Computing Machinery. Retrieved from https://doi.org/10.1145/"
        },
        "Recovering 3d human mesh from monocular images: A survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.01923",
            "ref_texts": "[9] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d inCVPR , 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "9"
            ],
            "1": "With these advances, researchers further seek to estimate human pose in 3D space [6], [7], [8], [9], [10], [11], [12].",
            "2": "[9] G."
        },
        "Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation": {
            "authors": [
                "Kun Zhou",
                "Xiaoguang Han",
                "Nianjuan Jiang",
                "Kui Jia",
                "Jiangbo Lu"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Zhou_HEMlets_Pose_Learning_Part-Centric_Heatmap_Triplets_for_Accurate_3D_Human_ICCV_2019_paper.pdf",
            "ref_texts": "[20] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "A straightforward strategy is to use volumetric heatmaps to represent the likelihood map of each 3D joint location [20].",
            "2": "3D\u00adaware intermediate states To further bridge the gap between the 2D image and the target 3D human pose under estimation, some recent works [20, 25, 19, 28] proposed to involve 3D-aware states for intermediate supervisions.",
            "3": "A volumetric representation for 3D joint-heatmaps is proposed in [20], with which the 3D pose is regressed in a coarse-to-fine manner.",
            "4": "We follow the standard protocol as in [13, 20], and use 5 subjects (S1, S5, S6, S7, S8) for training and the rest 2 subjects (S9, S11) for evaluation (referred to as Protocol #1)."
        },
        "Neural rendering and reenactment of human actor videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1809.03658",
            "ref_texts": ""
        },
        "Compressed volumetric heatmaps for multi-person 3d pose estimation": {
            "authors": [
                "Matteo Fabbri",
                "Fabio Lanzi",
                "Simone Calderara",
                "Stefano Alletto",
                "Rita Cucchiara"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Fabbri_Compressed_Volumetric_Heatmaps_for_Multi-Person_3D_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1,2,3,4",
            "ref_ids": [
                "29"
            ],
            "1": "Heatmaps have also been extended for 3D HPE, showing promising results in single person contexts [38,29,41].",
            "2": "Finally, recent works estimate 3D pose information directly [38,29,41,18,25,34,35].",
            "3": "[29] were the first to propose a fine discretization of the 3D space around the target by learning a coarse-to-fine prediction scheme in an end to end fashion.",
            "4": "[29], overcoming all the limitations that arise when facing a multi-person context.",
            "5": "Volumetric Heatmaps By considering a voxelization of the RGB-D volumetric space [7,29], we refer as a volumetric heatmap, h, the 3D confidence map with size D\u00d7H\u00d7W, whereDrepresents the depth dimension (appropriately quantized), while HandWrepresent the height and width of the image plane respectively.",
            "6": "In fact, joint predictions do not estimate a unique location but rather a per voxel confidence, which makes it easier for a network to learn the target function [29].",
            "7": "Some of those compromises consist in utilizing low resolution heatmaps that introduce quantization errors or complex training strategies that involve coarse-to-fine predictions through iterative refining of network output [29]."
        },
        "Benchmarking and error diagnosis in multi-instance pose estimation": {
            "authors": [
                "Matteo Ruggero",
                "Pietro Perona"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2017/papers/Ronchi_Benchmarking_and_Error_ICCV_2017_paper.pdf",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016. 8",
            "ref_ids": [
                "30"
            ],
            "1": "Two promising directions for improvement are possible: (i) collecting 3D annotations [7] for the humans in COCO and learning to directly regress 3D pose end-to-end [30]; (ii) modeling the manifold of human poses [3,6,35] and learning how to jointly predict the 3D pose of a person along with its 2D skeleton [41].",
            "2": "1,3,4,5,6,8\n[30] G."
        },
        "Hierarchical kinematic human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.04232",
            "ref_texts": "23. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-ffne volumetric prediction for single-image 3d human pose. In CVPR . IEEE, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": "A common paradigm has been the direct CNNbased regression of the body model parameters with focus on capturing multiscale information [22,23] or encoding spatial relationships between keypoints 4 G."
        },
        "D &D: Learning Human Dynamics from Dynamic Camera": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.08790",
            "ref_texts": "40. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: CVPR (2017) 3",
            "ref_ids": [
                "40"
            ],
            "1": "Numerous prior works estimate 3D human poses by locating the 3D joint positions [2, 38, 57, 37, 8, 30, 49, 40, 44, 31, 66, 33, 50, 35, 54, 64, 20]."
        },
        "Rignet: Neural rigging for articulated characters": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2005.00559",
            "ref_texts": ""
        },
        "Learning to regress bodies from images using differentiable semantic rendering": {
            "authors": [
                "Sai Kumar",
                "Nikos Athanasiou",
                "Muhammed Kocabas",
                "Michael J. Black"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Dwivedi_Learning_To_Regress_Bodies_From_Images_Using_Differentiable_Semantic_Rendering_ICCV_2021_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, K. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 3",
            "ref_ids": [
                "33"
            ],
            "1": "Image cues and 2D/3D joints Towards estimating 3D human pose and shape, initial attempts focus on estimating the coordinates of 3D joints or heatmaps [12, 21, 33, 39\u201341, 43] from images using geometric assumptions for the human body and 3D training data."
        },
        "Weakly-supervised discovery of geometry-aware representation for 3d human pose estimation": {
            "authors": [
                "Xipeng Chen",
                "Yee Lin",
                "Wentao Liu",
                "Chen Qian",
                "Liang Lin"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Chen_Weakly-Supervised_Discovery_of_Geometry-Aware_Representation_for_3D_Human_Pose_Estimation_CVPR_2019_paper.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "Following previous methods [38, 7, 22, 17], we adopt this dataset for evaluating the cross-domain generalization qualitatively.",
            "2": "(CVPR\u201917) [22] 79."
        },
        "Single image 3D object reconstruction based on deep learning: A review": {
            "authors": [
                "Kui Fu"
            ],
            "url": "https://bibbase.org/service/mendeley/bfbbf840-4c42-3914-a463-19024f50b30c/file/50ce3995-76fc-91ef-3ac9-84c5c9cff6e6/s11042_020_09722_8.pdf.pdf",
            "ref_texts": "80. Pavlakos G, Zhou X, Derpanis KG, Daniilidis K (2017) Coarse-to-fine volumetric prediction for singleimage 3D human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 7025 \u20137034",
            "ref_ids": [
                "80"
            ],
            "1": "At present, some studies have used voxel-based and mesh-based methods to study the 3D human pose estimation of a single image [80,81]."
        },
        "A-nerf: Articulated neural radiance fields for learning human shape, appearance, and pose": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/65fc9fb4897a89789352e211ca2d398f-Paper.pdf",
            "ref_texts": "[44] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "44"
            ],
            "1": "While feed-forward estimation of the 3D joint positions [26,32,34,35,43,44,52,59,64,69,72] or joint angles and bone lengths [53,73] of the skeleton is highly accurate, such discriminative estimates are prone to misalignment when overlayed onto the input image due to the generalization gap.",
            "2": "[44] G."
        },
        "Motionet: 3d human motion reconstruction from monocular video with skeleton consistency": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2006.12075",
            "ref_texts": ""
        },
        "3dpeople: Modeling the geometry of dressed humans": {
            "authors": [
                "Albert Pumarola",
                "Jordi Sanchez",
                "Gary P. T",
                "Alberto Sanfeliu",
                "Francesc Moreno"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Pumarola_3DPeople_Modeling_the_Geometry_of_Dressed_Humans_ICCV_2019_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "36"
            ],
            "1": "The combination of Convolutional Neural Networks with large Mo2242\n Cap datasets [44,21], resulted in a substantial number of works that robustly predict the 3D position of the body joints [29,30,32,36,40,49,52,56,64].",
            "2": "While the problem of localizing the 3D position of the joints from a single image has been extensively studied [29,30,32,36,40,45,49, 52,56,64,67], the estimation of the 3D body shape has received relatively little attention."
        },
        "Deep network for the integrated 3d sensing of multiple people in natural images": {
            "authors": [
                "Andrei Zanfir",
                "Elisabeta Marinoiu",
                "Mihai Zanfir",
                "Ionut Popa",
                "Cristian Sminchisescu"
            ],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2018/file/6a6610feab86a1f294dbbf5855c74af9-Paper.pdf",
            "ref_texts": "[9]G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "9"
            ],
            "1": "[9] use a discretized 3d space around the person, from which they read 3d joint activations.",
            "2": "[9]G."
        },
        "Feature boosting network for 3D pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1901.04877",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3D human pose. In Proc. IEEE Conf. Comput. Vis. Pattern Recognit. , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "25"
            ],
            "1": "In this paper, we address the problem of 3D pose estimation from a single RGB image that is much easier to be captured in uncontrolled environments [23, 25, 32, 44].",
            "2": "Recently, they have also been successfully applied to 3D pose estimation [19, 25, 30, 32, 39, 42, 44].",
            "3": "[25] 67.",
            "4": "[25] G."
        },
        "Can 3d pose be learned from 2d projections alone?": {
            "authors": [
                "Dylan Drover",
                "Rohith M",
                "Hang Chen",
                "Amit Agrawal",
                "Ambrish Tyagi",
                "Cong Phuoc"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Drover_Can_3D_Pose_be_Learned_from_2D_Projections_Alone_ECCVW_2018_paper.pdf",
            "ref_texts": "34. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: CVPR (July 201 7)",
            "ref_ids": [
                "34"
            ],
            "1": "3D Pose Estimation: Several approaches try to directly estimate 3D joint locations from images [34,33,37,49,28] in an end-to-end learning framework."
        },
        "Conditional directed graph convolution for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.07797",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) .",
            "ref_ids": [
                "34"
            ],
            "1": "Some works explored to directly infer 3D human pose from monocular images/videos with end-to-end deep neural networks [34,43].",
            "2": "Following previous works [7,28, 34,35,42,44,49], we adopted the 17-joint pose, trained a single model on five subjects (S1, S5, S6, S7, S8) for all kinds of actions, and tested it on the remaining two subjects (S9 and S11)."
        },
        "Single-stage is enough: Multi-person absolute 3D pose estimation": {
            "authors": [
                "Lei Jin",
                "Chenyang Xu",
                "Xiaojuan Wang",
                "Yabo Xiao",
                "Yandong Guo",
                "Xuecheng Nie",
                "Jian Zhao"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Jin_Single-Stage_Is_Enough_Multi-Person_Absolute_3D_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "24"
            ],
            "1": "Related Work Single-Person 3D Pose Estimation There are two lines to solve the problem of single-person 3D pose estimation with monocular RGB images: single-stage [10,24,27,28] and two-stage [16,21,33] approaches.",
            "2": "[24] propose a coarse-tofine approach to estimate a 3D heatmap for pose estimation."
        },
        "Concurrent segmentation and localization for tracking of surgical instruments": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1703.10701",
            "ref_texts": "21. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR. (2017)",
            "ref_ids": [
                "21"
            ],
            "1": "Therefore, in the proposed model (CSL), we address this problem by regressing a heatmap for each tracked landmark instead of its exact coordinates, as recently used in the ffeld of human pose estimation [21, 22]."
        },
        "xr-egopose: Egocentric 3d human pose from an hmd camera": {
            "authors": [
                "Denis Tome",
                "Patrick Peluse",
                "Lourdes Agapito",
                "Hernan Badino"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Tome_xR-EgoPose_Egocentric_3D_Human_Pose_From_an_HMD_Camera_ICCV_2019_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 2",
            "ref_ids": [
                "32"
            ],
            "1": "Two main trends have emerged: (i)fully supervised regression of 3D joint locations directly from images [22,31,47,58,32,27] and (ii)pipeline approaches that decouple the problem into the tasks of 2D joint detection followed by 3D lifting [26,29,35,1,59,60,4,43]."
        },
        "Improving robustness and accuracy via relative information encoding in 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.13994",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) . 7025\u20137034.",
            "ref_ids": [
                "31"
            ],
            "1": "With the help of 3D large-scale motion capture datasets [16,34], learning-based methods [10,31,35], which utilize neural networks to regress the 3D coordinates of human joints, have achieved promising results.",
            "2": "Most of the early works [19,31,33,36], which directly regress 3D human joints from original images or videos, are known as onestep methods.",
            "3": "In the same manner as [25,31], we conduct the training and evaluating process by subject on two actions: Walk and Jog.",
            "4": "[31] CVPR\u201917 48.",
            "5": "[31] CVPR\u201917 34.",
            "6": "[31] 22."
        },
        "Context-aware human motion prediction": {
            "authors": [
                "Enric Corona",
                "Albert Pumarola",
                "Guillem Alenya",
                "Francesc Moreno"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Corona_Context-Aware_Human_Motion_Prediction_CVPR_2020_paper.pdf",
            "ref_texts": "[49] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "49"
            ],
            "1": "Since the release of large-scale MoCap datasets [52,24,29], there has been a growing interest in the problem of estimating 3D human pose from single images [5,52,49,60,56,55,44,57]."
        },
        "Metrabs: metric-scale truncation-robust heatmaps for absolute 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.07227",
            "ref_texts": "[13] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "13"
            ],
            "1": "5D volumetric representation [13], [14], [15], [16].",
            "2": "bone length priors [13] or a skeleton length prior [17], computed by averaging over the training poses.",
            "3": "5D heatmap learning using bone-length-based scale recovery [13], under otherwise equal training conditions.",
            "4": "[13] propose extending 2D heatmaps with a root-relative metric depth axis.",
            "5": "[13] Given 2D pixel positions and root relative depth estimates from volumetric heatmaps, they optimize the absolute person distance such that the backprojected skeleton\u2019s bone lengths match the average over the training set in a least squares sense, assuming a full perspective model.",
            "6": "Up to this point the process is similar to other volumetric heatmap approaches [13], [14].",
            "7": "When testing on single-person datasets, we apply the trained network with an effective stride of 4, to obtain heatmaps with spatial size 64, which is the typical size used in prior work [13], [14].",
            "8": "\u2019s work [13], which introduced volumetric heatmaps for 3D human pose estimation.",
            "9": "To reiterate, as in [13], the absolute pose is not supervised during the baseline\u2019s training and the convex optimization of Z0is not backpropagated through, for simplicity.",
            "10": "[13] 67.",
            "11": "Nie [68] Pavlakos [13] Sun [59] Martinez [8] Sun [14] Nibali [12] Habibie [69] Xu [65] Chen [29] 2.",
            "12": "[13] G."
        },
        "DART: Articulated hand model with diverse accessories and rich textures": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/f06d5ebd4ff40b40dd97e30cee632123-Paper-Datasets_and_Benchmarks.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "Existing I2P methods can be divided into two paradigms: heatmap-based [45,34,55] and regression-based [44,39,20]."
        },
        "Eventcap: Monocular 3d capture of high-speed human motions using an event camera": {
            "authors": [
                "Lan Xu",
                "Weipeng Xu",
                "Vladislav Golyanik",
                "Marc Habermann",
                "Lu Fang",
                "Christian Theobalt"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_EventCap_Monocular_3D_Capture_of_High-Speed_Human_Motions_Using_an_CVPR_2020_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
            "ref_ids": [
                "40"
            ],
            "1": "These methods either regress the root-relative 3D positions of body joints from single images [31,55,73,34,56,40,35], or lift 2D detection to 3D [4,74,10,70,24]."
        },
        "Shape-aware human pose and shape reconstruction using multi-view images": {
            "authors": [
                "Junbang Liang",
                "Ming C. Lin"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Liang_Shape-Aware_Human_Pose_and_Shape_Reconstruction_Using_Multi-View_Images_ICCV_2019_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 2,13",
            "ref_ids": [
                "31"
            ],
            "1": "Inferring 2D or 3D poses in images of one or more people is a popular topic in Computer Vision and has been extensively studied [31,42,43,54,55]."
        },
        "Towards accurate marker-less human shape and pose estimation over time": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1707.07548",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "33"
            ],
            "1": "[33] directly regress 3D pose from RGB image via CNNs in a coarse-to-fine manner.",
            "2": "[33] G."
        },
        "3D human pose machines with self-supervised learning": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1901.03798",
            "ref_texts": "[19] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "The first type [19], [20], [21] focuses on K.",
            "2": "[19] presented a coarse-to-fine prediction scheme to cast 3D human pose estimation as a 3D keypoint localization problem in a voxel space in an end-to-end manner.",
            "3": "10 Pavlakos CVPR\u201917 [19] 67.",
            "4": "8 Pavlakos CVPR\u201917 [19] 22.",
            "5": "[19] Zhou et al.",
            "6": "[19], Lin et al.",
            "7": "[19] et al.",
            "8": "Following [14], [15], [19], [21], [23], [37], we employ the popular 3D pose error metric [55], which calculates the Euclidean errors on all joints and all frames up to translation.",
            "9": "[19], Zhou et al.",
            "10": ", [14], [19], [20], [21], [23], [50]), we directly use their official implementations for comparisons.",
            "11": ", [4], [14], [15], [19], [20], [21], [23], [36], [37], also employ deep learning techniques.",
            "12": ", [23] and [19] proposed using Stacked Hourglass [18], while [21] and [20] employed CPM [10]) to obtain satisfactory accuracies.",
            "13": "Comparison on HumanEva-I: We compare our model against competing methods, including discriminative regressions [57], [58], 2D pose detector-based methods [22], [31], [55], [56], CNN-based approaches [15], [19], [22], [38], [50] and our preliminary version Lin [21], on the HumanEva-I dataset.",
            "14": "In terms of time efficiency, compared with [14] (880 ms per image), [19] (170 ms per image), [23] (311 ms per image), and [20] (444 ms per image), our model model only requires 51 ms per image.",
            "15": "Our model performs approximately 3 times faster than [19], which is the fastest of the compared methods.",
            "16": "[19] G."
        },
        "3d human body reconstruction from a single image via volumetric regression": {
            "authors": [
                "Aaron S. Jackson",
                "Chris Manafas",
                "Georgios Tzimiropoulos"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Jackson_3D_Human_Body_Reconstruction_from_a_Single_Image_via_Volumetric_ECCVW_2018_paper.pdf",
            "ref_texts": "12. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: Computer Visio n and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE (2017) 1263 \u20131272",
            "ref_ids": [
                "12"
            ],
            "1": "In [12] they regress a 3D heatmap, which is a similar idea to our own work."
        },
        "Trajectory space factorization for deep video-based 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.08289",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Conference on Computer Vision and Pattern Recognition , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "28"
            ],
            "1": "[28] extend the idea of regressing heat-map from 2d to 3d and use a coarse-to-fine approach to estimate the 3d heat-map for joint estimation.",
            "2": "Several works [4, 10, 12, 14, 18, 21, 24, 27, 28, 29, 32, 42] also report the error after aligning further with respect to the ground truth pose via Procrustes Analysis.",
            "3": "[28] 67.",
            "4": "[28] 51."
        },
        "Ego-pose estimation and forecasting as real-time pd control": {
            "authors": [
                "Ye Yuan",
                "Kris Kitani"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Yuan_Ego-Pose_Estimation_and_Forecasting_As_Real-Time_PD_Control_ICCV_2019_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017. 3",
            "ref_ids": [
                "35"
            ],
            "1": "Deep learning based approaches [70,35,32, 57] have also succeeded in directly regressing images to 3D joint locations with the help of large-scale MoCap datasets [15]."
        },
        "3d human pose estimation with 2d marginal heatmaps": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1806.01484",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. CVPR . IEEE, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "[20] partially mitigate the impact on memory consumption by gradually building up the depth resolution of the activations throughout the network in a coarse-to-fine fashion.",
            "2": "Marginal heatmaps with soft-argmax In this section we will derive marginal heatmaps for use in 3D pose estimation from the volumetric heatmaps used by existing work [14, 20].",
            "3": "This drawback is identified and partially mitigated within existing work by reducing the resolution of the volumetric heatmaps in some way [14, 20].",
            "4": "[20] 71.",
            "5": "[20] G."
        },
        "MobileHumanPose: Toward real-time 3D human pose estimation in mobile devices": {
            "authors": [
                "Sangbum Choi",
                "Seokeon Choi",
                "Changick Kim"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021W/MAI/papers/Choi_MobileHumanPose_Toward_Real-Time_3D_Human_Pose_Estimation_in_Mobile_Devices_CVPRW_2021_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "35"
            ],
            "1": "In contrast, the one-stage approach [3,41,35,50,27,39,31] is based on a volumetric heatmap to extract 3D joints."
        },
        "Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1803.05959",
            "ref_texts": "[36] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "36"
            ],
            "1": "The most recent improvements are due to hierarchical processing [38, 60] and combining 2D and 3D tasks [33, 36, 72].",
            "2": "[36] G."
        },
        "Multi-person 3d human pose estimation from monocular images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1909.10854",
            "ref_texts": "[24] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1, 3",
            "ref_ids": [
                "24"
            ],
            "1": "Although, there is a vast literature on single-person 3D pose estimation [31, 13, 40, 41, 24, 21, 5, 36, 3, 16, 1, 39, 6, 12], the space of multi-person 3D pose estimation is mostly unexplored with only a handful of prior work [27, 20, 37, 28, 38].",
            "2": "Furthermore, many pipelined approaches [21, 27, 39, 31, 41, 24] have reported significant improvements in in-the-wild performances by using the more diverse 2D pose datasets to pre-train or jointly train their 2D prediction modules.",
            "3": "1, 2, 3, 4\n[24] G."
        },
        "Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation": {
            "authors": [
                "Bastian Wandt",
                "Bodo Rosenhahn"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.pdf",
            "ref_texts": "[28] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017. 1,2, 6",
            "ref_ids": [
                "28"
            ],
            "1": "Recent approaches are able to infer 3D human poses from monocular images in good quality [27,8,21,23,28,32,24,20,19,31].",
            "2": "[27,8,21,23,28,32,24,19].",
            "3": "Several works try to build an endto-end system which extracts the 3D pose from the image data [27,8,21,23,28,32,19,17,26,29,36,45].",
            "4": "[28] 67.",
            "5": "1,2,6\n[28] G."
        },
        "gSDF: Geometry-Driven Signed Distance Functions for 3D Hand-Object Reconstruction": {
            "authors": [
                "Zerui Chen",
                "Shizhe Chen",
                "Cordelia Schmid",
                "Ivan Laptev"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_gSDF_Geometry-Driven_Signed_Distance_Functions_for_3D_Hand-Object_Reconstruction_CVPR_2023_paper.pdf",
            "ref_texts": "[44] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 4",
            "ref_ids": [
                "44"
            ],
            "1": "Therefore, we first train a 3D hand joint prediction model which produces volumetric heatmaps [38, 44] for 21 hand joints."
        },
        "Xnect: Real-time multi-person 3d human pose estimation with a single rgb camera": {
            "authors": [],
            "url": "https://pure.mpg.de/rest/items/item_3093760/component/file_3093762/content",
            "ref_texts": "2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In CVPR . Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. 2018b. Learning to Estimate 3D Human Pose and Shape from a Single Color Image. In CVPR . Leonid Pishchulin, Eldar Insafutdinov, Siyu Tang, Bjoern Andres, Mykhaylo Andriluka, Peter Gehler, and Bernt Schiele. 2016. DeepCut: Joint Subset Partition and Labeling for Multi Person Pose Estimation. In CVPR . Leonid Pishchulin, Arjun Jain, Mykhaylo Andriluka, Thorsten Thorm\u00e4hlen, and Bernt Schiele. 2012. Articulated people detection and pose estimation: Reshaping the future. In CVPR . IEEE, 3178\u20133185. Gerard Pons-Moll, David J Fleet, and Bodo Rosenhahn. 2014. Posebits for monocular human pose estimation. In CVPR . 2337\u20132344. Alin-Ionut Popa, Mihai Zanfir, and Cristian Sminchisescu. 2017. Deep Multitask Architecture for Integrated 2D and 3D Human Sensing. In CVPR . Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh. 2012. Reconstructing 3d human pose from 2d image landmarks. In ECCV . Springer, 573\u2013586. Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. 2018. Regularized evolution for image classifier architecture search. arXiv preprint arXiv:1802.01548",
            "ref_ids": [
                "2017"
            ],
            "1": "[2017] use a detection-based approach and first find representative poses of discrete pose clusters that are subsequently refined.",
            "2": "DenseNet [2017] uses full dense concatenation-skip connectivity, which results in a parameter efficient network but is slow due to the associated cost of the enormous number of concatenation operations.",
            "3": "4ms Xception [2017] 81 36."
        },
        "Neural human video rendering by learning dynamic textures and rendering-to-video translation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2001.04947",
            "ref_texts": "[57] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d in Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "57"
            ],
            "1": "Recent dense tracking approaches build on top of joint detections, either in 2D [53], [54], in 3D [55], [56], [57], or a combination thereof [58], [59], [60].",
            "2": "[57] G."
        },
        "Pandanet: Anchor-based single-shot multi-person 3d pose estimation": {
            "authors": [
                "Abdallah Benzine",
                "Florian Chabot",
                "Bertrand Luvison",
                "Quoc Cuong",
                "Catherine Achard"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Benzine_PandaNet_Anchor-Based_Single-Shot_Multi-Person_3D_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 3",
            "ref_ids": [
                "34"
            ],
            "1": "The models in [20,34,42,43,44,50,47] are direct approaches."
        },
        "Orinet: A fully convolutional network for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1811.04989",
            "ref_texts": "[20] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CVPR , 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "Another way is to use 2D pixel coordinates and depth to represent each joint [20, 26] and assuming known intrinsic parameter to recover the final 3D pose .",
            "2": "[20] introduces 3D heatmap to predict per-voxel likelihood by discretizing depth values."
        },
        "Ego-Body Pose Estimation via Ego-Head Pose Estimation": {
            "authors": [
                "Jiaman Li",
                "Karen Liu",
                "Jiajun Wu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Ego-Body_Pose_Estimation_via_Ego-Head_Pose_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "28"
            ],
            "1": "One is to regress joint positions directly from images and videos [25, 28, 36, 52]."
        },
        "Soccer on your tabletop": {
            "authors": [
                "Konstantinos Rematas",
                "Ira Kemelmacher",
                "Brian Curless",
                "Steve Seitz"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Rematas_Soccer_on_Your_CVPR_2018_paper.pdf",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "35"
            ],
            "1": "In the case of a single camera, motion capture can be obtained using 3D pose estimators [35,36,30].",
            "2": "3\n[35] G."
        },
        "Graph-based 3d multi-person pose estimation using multi-view images": {
            "authors": [
                "Size Wu",
                "Sheng Jin",
                "Wentao Liu",
                "Lei Bai",
                "Chen Qian",
                "Dong Liu",
                "Wanli Ouyang"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Graph-Based_3D_Multi-Person_Pose_Estimation_Using_Multi-View_Images_ICCV_2021_paper.pdf",
            "ref_texts": ""
        },
        "A deep coarse-to-fine network for head pose estimation from synthetic data": {
            "authors": [
                "Yujia Wang"
            ],
            "url": "https://liangwei-bit.github.io/web/project/headpose/PR-headpose-2019.pdf",
            "ref_texts": "[25] G. Pavlakos , X. Zhou , K.G. Derpanis , K. Daniilidis , Coarse-to-fine volumetric prediction for single-image 3d human pose, in: Proceedings of the CVPR, 2017, pp. 1263\u20131272 . ",
            "ref_ids": [
                "25"
            ],
            "1": "[25] employed a step-wise approach to predict human pose, which consists of a convolutional network for 2D joint localization and a subsequent optimization step to recover 3D pose.",
            "2": "[25] G."
        },
        "Neural descent for visual 3d human pose and shape": {
            "authors": [
                "Andrei Zanfir",
                "Eduard Gabriel",
                "Mihai Zanfir",
                "William T. Freeman",
                "Rahul Sukthankar",
                "Cristian Sminchisescu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zanfir_Neural_Descent_for_Visual_3D_Human_Pose_and_Shape_CVPR_2021_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1",
            "ref_ids": [
                "29"
            ],
            "1": ", body joints, kinematic pose and shape [30,48,16,19, 36,8,17,20,2,44,18,40,15,29,45,49,33,37,27,26,14] rely, ab initio , at their learning core, on complete supervision."
        },
        "Multiview-consistent semi-supervised learning for 3d human pose estimation": {
            "authors": [
                "Rahul Mitra",
                "Nitesh B. Gundavarapu",
                "Abhishek Sharma",
                "Arjun Jain"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Mitra_Multiview-Consistent_Semi-Supervised_Learning_for_3D_Human_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 1263\u20131272, 2017. 1,4",
            "ref_ids": [
                "35"
            ],
            "1": "Introduction Over the years, the performance of monocular 3D human pose estimation has improved significantly due to increasingly sophisticated CNN models [55,35,46,45,30,49].",
            "2": "Pose Regression Most 3D-pose estimation approaches focus on regressing for pose in the local camera coordinate system [55,35, 49,28,46,52,40]."
        },
        "Monoclothcap: Towards temporally coherent clothing capture from monocular rgb video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.10711",
            "ref_texts": "[38] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "38"
            ],
            "1": "Most previous work in human pose estimation focuses on the position of body keypoints in 2D [50, 11, 10] and 3D\n[60, 38, 46].",
            "2": "1, 2\n[38] G."
        },
        "Skeleton-aware 3d human shape reconstruction from point clouds": {
            "authors": [
                "Haiyong Jiang",
                "Jianfei Cai",
                "Jianmin Zheng"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Jiang_Skeleton-Aware_3D_Human_Shape_Reconstruction_From_Point_Clouds_ICCV_2019_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR",
            "ref_ids": [
                "29"
            ],
            "1": "Another category of related works is about human pose estimation [37, 38, 9, 29, 30], which focuses on predicting 2D or 3D joint positions.",
            "2": "Convolutions on Graph Structures The previous works on human joint or pose estimation [37, 38, 29] mainly use a multi-layer perceptron to estimate poses."
        },
        "A graph attention spatio-temporal convolutional network for 3D human pose estimation in video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.14179",
            "ref_texts": ""
        },
        "Uncertainty-aware adaptation for self-supervised 3d human pose estimation": {
            "authors": [
                "Jogendra Nath",
                "Siddharth Seth",
                "Pradyumna Y",
                "Varun Jampani",
                "Anirban Chakraborty",
                "Venkatesh Babu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Kundu_Uncertainty-Aware_Adaptation_for_Self-Supervised_3D_Human_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[66] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 3",
            "ref_ids": [
                "66"
            ],
            "1": "The former setup is further categorized into one-stage [62, 65, 66, 80, 91, 100] and two-stage methods [27, 53, 59, 99].",
            "2": "3\n[66] G."
        },
        "Rethinking pose in 3d: Multi-stage refinement and recovery for markerless motion capture": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.01525",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 3, 7",
            "ref_ids": [
                "20"
            ],
            "1": "Following the trend in 2D human pose estimation to predict heatmaps rather than regressing 2D landmarks, Pavlakos [20] predicted per-voxel likelihoods, or 3D heatmaps, for each joint using a coarse-to-fine approach.",
            "2": "[20] 67.",
            "3": "[20] 17j 51.",
            "4": "2\n[20] G."
        },
        "3d human sensing, action and emotion recognition in robot assisted therapy of children with autism": {
            "authors": [
                "Elisabeta Marinoiu",
                "Mihai Zanfir",
                "Vlad Olaru",
                "Cristian Sminchisescu"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Marinoiu_3D_Human_Sensing_CVPR_2018_paper.pdf",
            "ref_texts": "[26] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "26"
            ],
            "1": "Recent advances in 2d and 3d pose estimation [7,28,21,6,22,26,38] can potentially offer an alternative to depth sensors by providing reliable pose es-timates from only RGB data.",
            "2": "[26] G."
        },
        "Distribution-aware single-stage models for multi-person 3D pose estimation": {
            "authors": [
                "Zitian Wang",
                "Xuecheng Nie",
                "Xiaochao Qu",
                "Yunpeng Chen",
                "Si Liu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Distribution-Aware_Single-Stage_Models_for_Multi-Person_3D_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "24"
            ],
            "1": "The top-down methods require additional human detector to provide human position prior for downstream single person pose estimator to generate individual 3D poses [24, 34, 35, 41]."
        },
        "Learning 3d human shape and pose from dense body parts": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.13344",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "33"
            ],
            "1": "For the recovery of 3D human pose or human model, 2D joint positions [24], [25], [26], [27], silhouette [6], [28], [29], segmentation [7], depth maps [30], [31], joint heatmaps [4], [6], [32], volumetric representation [33], [34], [35], [36], and 3D orientation fields [37], [38] are adopted in literature as intermediate representations to facilitate the learning task.",
            "2": "Following the common protocols [5], [6], [33], we use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation.",
            "3": "[33] 47.",
            "4": "[33] G."
        },
        "Dope: Distillation of part experts for whole-body 3d pose estimation in the wild": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.09457",
            "ref_texts": "52. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR (2017)",
            "ref_ids": [
                "52"
            ],
            "1": "Two basic categories of work can be found in the recent literature: (a) approaches that directly estimate the 3D body keypoints from an input image [46,48,52,54,55] and (b) methods that leverage 2D human pose estimation [6,13,38,45]."
        },
        "Bodies at rest: 3d human pose and shape estimation from a pressure image using synthetic data": {
            "authors": [
                "Henry M. Clever",
                "Zackory Erickson",
                "Ariel Kapusta",
                "Greg Turk",
                "Karen Liu",
                "Charles C. Kemp"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Clever_Bodies_at_Rest_3D_Human_Pose_and_Shape_Estimation_From_CVPR_2020_paper.pdf",
            "ref_texts": "[40] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR . IEEE, 2017.",
            "ref_ids": [
                "40"
            ],
            "1": "The field has been moving rapidly with the estimation of 3D skeleton models [40,53], and human pose and shape estimation as a 3D mesh [4,27,39] using human body models such as SCAPE [3] and SMPL [32]."
        },
        "Multi-person 3d pose estimation in crowded scenes based on multi-view geometry": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.10986",
            "ref_texts": "37. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: Proc. CVPR (2017)",
            "ref_ids": [
                "37"
            ],
            "1": "State-of-the-art methods can be divided into two categories, direct regression methods [10,21,36] and indirect regression methods based on heat maps [20,27,37].",
            "2": "In [37], a coarseto-ffne prediction scheme was developed by analyzing 3D human pose in a volumetric representation."
        },
        "Jgr-p2o: Joint graph reasoning based pixel-to-offset prediction network for 3d hand pose estimation from a single depth image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.04646",
            "ref_texts": "29. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7025{7034 (2017) 2",
            "ref_ids": [
                "29"
            ],
            "1": "Contrary to their regression-based counterparts that directly map the depth images to 3D hand pose parameters and severely sufier from the problem of highly non-linear mapping, the detection-based methods can learn better feature representations by pose reparameterization and have proven to be more efiective for both human pose estimation [29,4] and hand pose estimation [10,22,43]."
        },
        "DeepFuse: An IMU-aware network for real-time 3D human pose estimation from multi-view image": {
            "authors": [
                "Fuyang Huang",
                "Ailing Zeng",
                "Minhao Liu",
                "Qiuxia Lai",
                "Qiang Xu"
            ],
            "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Huang_DeepFuse_An_IMU-Aware_Network_for_Real-Time_3D_Human_Pose_Estimation_WACV_2020_paper.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. IEEE Conference on Computer Vision and Pattern Recognition , abs/1611.07828, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "Generally speaking, heatmap-based methods [23, 28, 40, 39, 30, 34, 46] show superior performance to that of direct regression work [21, 27, 42, 47].",
            "2": "Heatmap-based methods [23, 34, 39, 40] regress volumetric heatmaps from 2D image.",
            "3": "[34] G."
        },
        "Unified end-to-end YOLOv5-HR-TCM framework for automatic 2D/3D human pose estimation for real-time applications": {
            "authors": [
                "Cuong Nguyen",
                "Hao Nguyen",
                "Rafal Scherer",
                "Hung Le"
            ],
            "url": "https://www.mdpi.com/1424-8220/22/14/5419/pdf",
            "ref_texts": "42. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the CVPR 2017: 30th IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2016; pp. 1263\u20131272. [CrossRef]",
            "ref_ids": [
                "42"
            ],
            "1": "[42] DL Protocol #1: 51.",
            "2": "[42] proposed a CNN for the end-to-end learning paradigm, including two works: a convolutional network (ConvNet) to predict the 2D joint location and a subsequent optimization step to recover the 3D coordinate joints of the 3D human pose."
        },
        "Predicting camera viewpoint improves cross-dataset generalization for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.03143",
            "ref_texts": "23.Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR (2017)",
            "ref_ids": [
                "23"
            ],
            "1": "Recent methods are typically based on deep neural network architectures [17, 21, 23, 24, 30, 50] trained on one of a few large scale, publicly available datasets.",
            "2": "Among these are [17, 23, 30] evaluated on H36M, [19, 50] work on both H36M [8] and 3DHP [19], [15, 34] work on TOTALCAPTURE [34] and 3DPW[15], [43] work on the GPA dataset [43].",
            "3": "3D Human Pose Estimation With the recent development of deep neural networks (CNNs), there are signiffcant improvements on 3D human pose estimation [5, 17, 23, 44]."
        },
        "Virtualpose: Learning generalizable 3d human pose models from virtual data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.09949",
            "ref_texts": "25.Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: CVPR. pp. 7025\u20137034 (2017) 1",
            "ref_ids": [
                "25"
            ],
            "1": "Most works [4,5,17,19,24,25,32,38,39] focus on a simpler sub-task of relative 3D pose estimation where only relative joint positions are estimated."
        },
        "How robust is 3D human pose estimation to occlusion?": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.09316",
            "ref_texts": "[18] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.[19] U. Rafi, J. Gall, and B. Leibe. A semantic occlusion model for human pose estimation from a single depth image. In CVPR Workshops , 2015.",
            "ref_ids": [
                "18",
                "19"
            ],
            "1": ", [15]), heatmaps have recently been also adopted in 3D methods, including volumetric [18][23] and marginal heatmaps [16].",
            "2": "Occlusion effects have also been studied in 3D pose estimation from depth input [19], where exploiting semantic information from the occluder itself was found to improve predictions.",
            "3": "As in [18], the xandycoordinates are interpreted as image space coordinates, while zis the depth of the particular joint relative to the root (pelvis) joint depth, with the 16 voxels covering 2 meters.",
            "4": "1 Pavlakos [18] 67.",
            "5": "9 Pavlakos [18] (known root depth) 59.",
            "6": "[18] (see Table 1).",
            "7": "[18] G.",
            "8": "[19] U."
        },
        "Mocapdeform: Monocular 3d human motion capture in deformable scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.08439",
            "ref_texts": "[39] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "39"
            ],
            "1": "Several other approaches learn feature representations for 2D poses (without explicit 2D joint outputs) and perform lifting [30, 39, 18]."
        },
        "A unified deep framework for joint 3d pose estimation and action recognition from a single rgb camera": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/20/7/1825/pdf",
            "ref_texts": "27. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine Volumetric Prediction for Single-image 3D Human Pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 22\u201325 July 2017; pp. 7025\u20137034.",
            "ref_ids": [
                "27"
            ],
            "1": "[27] used multiple fully convolutional networks to construct a volumetric stacked hourglass architecture, which can recover 3D poses from RGB images.",
            "2": "To the best of our knowledge, several studies [27,29,30] stated that regressing the 3D pose from 2D joint locations is difficult and not too accurate.",
            "3": "6M dataset [18,27,29,34].",
            "4": "[27] 67."
        },
        "The best of both worlds: Combining model-based and nonparametric approaches for 3d human body estimation": {
            "authors": [
                "Zhe Wang",
                "Jimei Yang",
                "Charless Fowlkes"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022W/ABAW/papers/Wang_The_Best_of_Both_Worlds_Combining_Model-Based_and_Nonparametric_Approaches_CVPRW_2022_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 1, 2",
            "ref_ids": [
                "32"
            ],
            "1": "(Best viewed in Color) Nonparametric methods use non-compressed representations like voxels [32], heatmaps [29] and joint location [19, 21, 36] as the target for modern deep learning.",
            "2": "3D human pose estimation from monocular images Deep learning approaches have shown success in regressing 3D pose from a single image [24,26,28,32,35,40,41,43,49, 52].",
            "3": "The first is to directly estimate 3D pose from images, based on volumetric representation [28, 32]."
        },
        "On boosting single-frame 3d human pose estimation via monocular videos": {
            "authors": [
                "Zhi Li",
                "Xuan Wang",
                "Fei Wang",
                "Peilin Jiang"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Li_On_Boosting_Single-Frame_3D_Human_Pose_Estimation_via_Monocular_Videos_ICCV_2019_paper.pdf",
            "ref_texts": "[16] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "Related Works Nowadays, 3D human pose estimation [4, 6, 20, 11, 17, 16, 15, 19, 21, 22, 24, 25, 26, 28, 29, 30] has grown to the point where it can yield accurate poses even in realtime.",
            "2": "To get accurate 3D poses directly from monocular images, we refer to the work of [16] which introduces a volumetric version of the stacked hourglass network."
        },
        "Hdnet: Human depth estimation for multi-person camera-space localization": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.08943",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR. pp. 1263{1272. IEEE (2017)",
            "ref_ids": [
                "25"
            ],
            "1": "[25, 29] extend the notion of heatmap to the 3D space, where estimation is performed in a volumetric space.",
            "2": "This demonstrates that more accurate root localization also beneffts the precise 3D pose estimation in volumetric-based approaches [21,25,29]."
        },
        "Starmap for category-agnostic keypoint and viewpoint estimation": {
            "authors": [
                "Xingyi Zhou",
                "Arjun Karpur",
                "Linjie Luo",
                "Qixing Huang"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Xingyi_Zhou_Category-Agnostic_Semantic_Keypoint_ECCV_2018_paper.pdf",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: Computer Vis ion and Pattern Recognition (CVPR), 2017 IEEE Conference on. pp. 1263\u20131272. I EEE (2017) 1,3",
            "ref_ids": [
                "25"
            ],
            "1": "Accurate semantic keypoint detection forms the basis for many visual understandingtasks,includinghumanposeestimation[4,22,25,51],handposeestimation[46,52],viewpointestimation[24,35],featurematching[15],fine-grained image classification [47], and 3D reconstruction [36,39,10,9].",
            "2": "[25] lifted the 2D pixel heatmap to a 3D voxel heatmap, resulting in an end-to-end 3D human pose estimation sys tem."
        },
        "Hulc: 3d human motion capture with pose manifold sampling and dense contact guidance": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.05677",
            "ref_texts": "39. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3D human pose. In: Computer Vision and Pattern Recognition (CVPR) (2017) 1, 3",
            "ref_ids": [
                "39"
            ],
            "1": "1 Introduction 3D human motion capture (MoCap) from a single colour camera received a lot of attention over the past years [33, 32, 16, 17, 21, 41, 6, 55, 31, 44, 5, 30, 56, 34, 40, 36, 39, 62, 68, 9, 1, 61, 24, 50, 54, 22, 23, 25].",
            "2": "2 Related Works Most monocular MoCap approaches estimate 3D poses alone or along with the body shape from an input image or video [9, 16, 17, 21, 6, 55, 31, 44, 5, 14, 30, 56, 34, 40, 36, 39, 62, 68, 9, 1, 61, 24, 50, 54, 22, 25, 67]."
        },
        "Full-body awareness from partial observations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.06046",
            "ref_texts": "41. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR (2017)",
            "ref_ids": [
                "41"
            ],
            "1": "By utilizing annotated people in-the-wild , methods have moved toward understanding realistic, challenging settings, and become more robust to occlusion, setting, challenging pose, and scale variation [3,36,37,40,41,61]."
        },
        "Explicit Occlusion Reasoning for Multi-person 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.00090",
            "ref_texts": "59. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 7025\u20137034 (2017) 4",
            "ref_ids": [
                "59"
            ],
            "1": "In recent years a lot of work focuses on single-person 3D poses [1,9,59,45,69,44,51,86,48,28,79,60]."
        },
        "Dhp19: Dynamic vision sensor 3d human pose dataset": {
            "authors": [
                "Enrico Calabrese",
                "Gemma Taverni",
                "Christopher Awai",
                "Sophie Skriabine",
                "Federico Corradi",
                "Luca Longinotti",
                "Kynan Eng",
                "Tobi Delbruck"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPRW_2019/papers/EventVision/Calabrese_DHP19_Dynamic_Vision_Sensor_3D_Human_Pose_Dataset_CVPRW_2019_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034, 2017. 3",
            "ref_ids": [
                "27"
            ],
            "1": "For 3D HPE, existing approaches reconstruct the 3D pose from single [9,23,24,27,30,33] or multiple [4,11,28] camera views.",
            "2": "Other methods directly predict the 3D pose without separately predicting the 2D pose: [23] simultaneously minimizes the 2D heatmaps and 3D pose, while [27] directly outputs a dense 3D volume with separate voxel likelihoods for each joint."
        },
        "Estimating 3d motion and forces of person-object interactions from monocular video": {
            "authors": [
                "Zongmian Li",
                "Jiri Sedlar",
                "Justin Carpentier",
                "Ivan Laptev",
                "Nicolas Mansard",
                "Josef Sivic"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Estimating_3D_Motion_and_Forces_of_Person-Object_Interactions_From_Monocular_CVPR_2019_paper.pdf",
            "ref_texts": "[53] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "53"
            ],
            "1": "Existing direct approaches either rely on generative models to search the state space for a plausible 3D skeleton that aligns with the image evidence [59,26,25] or, more recently, extract deep features from images and learn a discriminative regressor from the 2D image to the 3D pose [37,49,53,62].",
            "2": "[53] G."
        },
        "Learning dynamical human-joint affinity for 3d pose estimation in videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2109.07353",
            "ref_texts": "[14] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017. 2, 6, 7",
            "ref_ids": [
                "14"
            ],
            "1": "A popular solution in this framework is based on the volumetric representation of human pose [14].",
            "2": "[14] 1 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 \u2014\u2013 51.",
            "3": "[14] 122.",
            "4": "Following the previous methods [1]\u2013[3], [14], [17], [21], [33], [39], we report results on Walking and Jogging in three subjects of HumanEva-I by using protocol 2.",
            "5": "2, 5, 6, 10\n[14] G."
        },
        "Not all parts are created equal: 3d pose estimation by modeling bi-directional dependencies of body parts": {
            "authors": [
                "Jue Wang",
                "Shaoli Huang",
                "Xinchao Wang",
                "Dacheng Tao"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Not_All_Parts_Are_Created_Equal_3D_Pose_Estimation_by_ICCV_2019_paper.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "[22] proposed a volumetric representation for 3D joints and used a coarseto-fine strategy to refine the prediction iteratively.",
            "2": "[22] 67.",
            "3": "[22] 47.",
            "4": "Following [48, 22, 45, 21], we down sampled the original videos from 50fps to 10fps to remove redundancy."
        },
        "Gravity-aware monocular 3d human-object reconstruction": {
            "authors": [
                "Rishabh Dabral",
                "Soshi Shimada",
                "Arjun Jain",
                "Christian Theobalt",
                "Vladislav Golyanik"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Dabral_Gravity-Aware_Monocular_3D_Human-Object_Reconstruction_ICCV_2021_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "31"
            ],
            "1": "Many other approaches combine regression of 2D joint locations or 3D joint depths [29, 24, 31, 14]."
        },
        "A neural network for detailed human depth estimation from a single image": {
            "authors": [
                "Sicong Tang",
                "Feitong Tan",
                "Kelvin Cheng",
                "Zhaoyang Li",
                "Siyu Zhu",
                "Ping Tan"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Tang_A_Neural_Network_for_Detailed_Human_Depth_Estimation_From_a_ICCV_2019_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 1",
            "ref_ids": [
                "28"
            ],
            "1": "Despite the differences in network architectures, many works [25,28,22,33,35] use a like1\n7750\n lihood heatmap to represent the distribution of each joint\u2019s location and show better performance than directly regressing the joint location."
        },
        "Weakly supervised 3d multi-person pose estimation for large-scale scenes based on monocular camera and single lidar": {
            "authors": [
                "Peishan Cong",
                "Yiteng Xu",
                "Yiming Ren",
                "Juze Zhang",
                "Lan Xu",
                "Jingya Wang",
                "Jingyi Yu",
                "Yuexin Ma"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/25120/24892",
            "ref_texts": ""
        },
        "Learning latent representations of 3d human pose with deep neural networks": {
            "authors": [],
            "url": "https://hal.science/hal-02509358/file/ijcv18.pdf"
        },
        "Deep autoencoder for combined human pose estimation and body model upscaling": {
            "authors": [
                "Matthew Trumble",
                "Andrew Gilbert",
                "John Collomosse",
                "Adrian Hilton"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Matthew_Trumble_Deep_Autoencoder_for_ECCV_2018_paper.pdf",
            "ref_texts": "33.Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarseto-fine volumetric prediction for single-image 3D human pose. In: CVPR. (2017)",
            "ref_ids": [
                "33"
            ],
            "1": "Pavlakos [33] used a simple volum etric representation in a 3D convnet for pose estimation."
        },
        "Revitalizing optimization for 3d human pose and shape estimation: A sparse constrained formulation": {
            "authors": [
                "Taosha Fan",
                "Kalyan Vasudev",
                "Donglai Xiang",
                "Weipeng Xu",
                "Todd Murphey",
                "Mustafa Mukadam"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Fan_Revitalizing_Optimization_for_3D_Human_Pose_and_Shape_Estimation_A_ICCV_2021_paper.pdf",
            "ref_texts": "[26] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 2, 5, 6",
            "ref_ids": [
                "26"
            ],
            "1": "Unlike [19, 26, 27, 28, 29] that lift 2D keypoints to 3D keypoints, regression methods for 3D human pose and shape estimation face a challenge in having access to large datasets with ground truth labels of 3D human pose and shape.",
            "2": "Following the standard training-testing protocol established in [26], we use subjects S9 and S11 for evaluation.",
            "3": "[26] \u2013 n/a \u2013 \u2013 71."
        },
        "Bihand: Recovering hand mesh with multi-stage bisected hourglass networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.05079",
            "ref_texts": "[23] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u2013",
            "ref_ids": [
                "23"
            ],
            "1": "Inspired from [23], we adopt a coarse-to-fine 3D heatmaps predictor with the resolution along z-axis Z=32 in the first hourglass and Z=64 in the second."
        },
        "Neural scene decomposition for multi-person motion capture": {
            "authors": [
                "Helge Rhodin",
                "Victor Constantin",
                "Isinsu Katircioglu",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.pdf",
            "ref_texts": "[41] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis. Coarse-To-Fine V olumetric Prediction for Single-Image 3D Human Pose. In Conference on Computer Vision and Pattern Recognition , 2017. 2",
            "ref_ids": [
                "41"
            ],
            "1": "In practice, this data bottleneck starkly limits the applicability of deep learningbased single [41,67,45,38,34,37,51,42,89,63,59] and multi-person [36,52,83] 3D pose estimation methods.",
            "2": "2\n[41] G."
        },
        "A generalizable approach for multi-view 3d human pose regression": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1804.10462",
            "ref_texts": "33. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-ffne volumetric prediction for single-image 3D human pose. InIEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263{1272, 2017.",
            "ref_ids": [
                "33"
            ],
            "1": "[33] use a stack of a fully convolutional network [31] to iteratively compute 3D heatmaps per body parts.",
            "2": "Following the standard evaluation protocol used in the literature, ffve subjects (S1, S5, S6, S7, S8) are used for training and two subjects (S9, S11) for testing [11, 33, 28].",
            "3": "6M is a single-person dataset, note that in [41, 33] the input images are cropped using bounding boxes around the persons and that the 2D pose detector models of [31] and [45] used in [11] and [28] are applied on bounding boxes around the persons obtained from ground truth.",
            "4": "[33] 67."
        },
        "Dh-aug: Dh forward kinematics model driven augmentation for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.09303",
            "ref_texts": "42. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 7025\u20137034 (2017)",
            "ref_ids": [
                "42"
            ],
            "1": "There are two mainstream monocular 3D human pose estimation methods, one is to obtain 3D pose end-to-end [42,53,54], and the other is through the multi-stage method, first obtain 2D pose from the images [49,7,52], and then further obtain 3D pose from 2D pose [36,25,59,6]."
        },
        "Self-supervised human depth estimation from monocular videos": {
            "authors": [
                "Feitong Tan",
                "Hao Zhu",
                "Zhaopeng Cui",
                "Siyu Zhu",
                "Marc Pollefeys",
                "Ping Tan"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Tan_Self-Supervised_Human_Depth_Estimation_From_Monocular_Videos_CVPR_2020_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proc. of Computer Vision and Pattern Recognition , 2017. 1,2",
            "ref_ids": [
                "34"
            ],
            "1": "Many works focus on estimating a 2D or 3D skeleton model [6,29,25,34,26,39].",
            "2": "With the development of deep neural network, the estimation of 2D skeleton joints [6,29] and 3D skeleton joints [25, 34,26,39] has achieved great success with robust performance."
        },
        "BodySLAM: joint camera localisation, mapping, and human motion tracking": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2205.02301",
            "ref_texts": "53. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
            "ref_ids": [
                "53"
            ],
            "1": "6m [12] with ground truth 3D labels generated by motion capture systems, it is possible to directly regress from the input images to 3D joint positions using DNNs [53,52]."
        },
        "High-order Graph Convolutional Networks for 3D Human Pose Estimation.": {
            "authors": [],
            "url": "https://www.bmvc2020-conference.com/assets/papers/0550.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u2013",
            "ref_ids": [
                "34"
            ],
            "1": "Some approaches [34, 41, 42, 48, 54] directly regress the 3D pose via a convolutional neural network [22, 24] from an image and demonstrate superior performance over earlier methods relying on handcrafted features [2, 17, 38].",
            "2": "ZOU, LIU, WANG, TANG: HIGH-ORDER GRAPH CONVOLUTIONAL NETWORKS 3 The first category of approaches mainly exploit convolutional neural networks (CNNs) to obtain the 3D pose directly from the input image [31, 33, 34, 42, 53, 54].",
            "3": "[34] propose a fine discretization of the 3D space around the subject and train a CNN to predict the per voxel likelihood for each body joint.",
            "4": "[34] 47."
        },
        "Scene-aware Egocentric 3D Human Pose Estimation": {
            "authors": [
                "Jian Wang",
                "Diogo Luvizon",
                "Weipeng Xu",
                "Lingjie Liu",
                "Kripasindhu Sarkar",
                "Christian Theobalt"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Scene-Aware_Egocentric_3D_Human_Pose_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , 2017. 2",
            "ref_ids": [
                "25"
            ],
            "1": "[25] proposed a coarse-to-fine approach to lift from 2D\n13032\n Egocentric ImagesBody Pose Features Scene Depth Estimator2D Feature Extractor Depth w/o Human BodyV2V NetworkSec."
        },
        "Adaptive multi-view and temporal fusing transformer for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.05092",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 7025\u20137034. 2",
            "ref_ids": [
                "33"
            ],
            "1": "1 Monocular 3D Human Pose Estimation With the pattern self-organizing and non-linear mapping capacity of deep neural networks, many approaches [8], [32], [33], [34], [35], [36], [37], [38] directly map pixel intensities to 3D poses from a single image.",
            "2": "2\n[33] G."
        },
        "Kama: 3d keypoint aware body mesh articulation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.13502",
            "ref_texts": "[53] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 1, 2",
            "ref_ids": [
                "53"
            ],
            "1": "Instead of learning a direct mapping between input images and 3D coordinates [57, 65, 69, 82], these methods first estimate an intermediate volumetric [41,53,66,68] or heatmap-like [23] representation, and then recover the 3D coordinates from them.",
            "2": "Motivated by this, in this work, we propose to harness the superior localization ability of recent keypoint regressors [23, 41, 53, 66, 68] and reconstruct full human body mesh from the regressed 3D keypoint positions only.",
            "3": "CV] 27 Apr 2021 ods [27, 30], the mesh estimates will be more accurate and align better with visual clues since the 3D keypoints can be localized more accurately from images [23, 41, 53, 66, 68].",
            "4": "3D Keypoint Regression : These methods regress 3D key-point positions from an RGB image [13, 35, 36, 52, 53, 53, 57, 65, 66, 69\u201371, 81, 82] or a 2D pose [8, 19, 21, 43, 48, 60] as input.",
            "5": "More recent methods, however, adopt fully-convolutional networks to produce volumetric [41,53,66,68] or heatmaplike [23, 80] representations."
        },
        "Elepose: Unsupervised 3d human pose estimation by predicting camera elevation and learning normalizing flows on 2d poses": {
            "authors": [
                "Bastian Wandt",
                "James J. Little",
                "Helge Rhodin"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Wandt_ElePose_Unsupervised_3D_Human_Pose_Estimation_by_Predicting_Camera_Elevation_CVPR_2022_paper.pdf",
            "ref_texts": "[39] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u2013",
            "ref_ids": [
                "39"
            ],
            "1": "Others followed this image-to-3D approach [9, 17, 26, 29, 33, 37, 39, 43, 48, 50\u201353, 62, 65]."
        },
        "Through-wall human pose reconstruction via UWB MIMO radar and 3D CNN": {
            "authors": [
                "Yongkun Song",
                "Tian Jin",
                "Yongpeng Dai",
                "Yongping Song",
                "Xiaolong Zhou"
            ],
            "url": "https://www.mdpi.com/2072-4292/13/2/241/pdf",
            "ref_texts": "20. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 1263\u20131272.",
            "ref_ids": [
                "20"
            ],
            "1": "[20] proposed a multistage hourglass architecture to reconstruct human 3D pose from a single image, which improved the spatial resolution of the heatmap through continuous coarse-to-fine operation, and finally obtained a 3D heatmap to reconstruct human pose."
        },
        "Chirality nets for human pose regression": {
            "authors": [
                "Raymond Yeh",
                "Ting Hu",
                "Alexander Schwing"
            ],
            "url": "https://proceedings.neurips.cc/paper/2019/file/1f88c7c5d7d94ae08bd752aa3d82108b-Paper.pdf",
            "ref_texts": "[40] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. CVPR .",
            "ref_ids": [
                "40"
            ],
            "1": "The 2D to 3D estimation is formulated as a regression task via deep nets [40,52,35,51,10,41,59,33,17,29,42].",
            "2": "Following prior work [40,52,35,51,33,42], each human pose is represented by a 17-joint skeleton.",
            "3": "We report the two standard metrics used in prior work: Protocol 1 (MPJPE) which is the mean perjoint position error between the prediction and ground-truth [35,40,42] and Protocol 2 (P-MPJPE) which is the error, after alignment, between the prediction and ground-truth [35, 51, 17, 42].",
            "4": "S1 S2 S3 S1 S2 S3 S1 S2 S3 Pavlakos [40] 22.",
            "5": "[40] G."
        },
        "Animepose: Multi-person 3d pose estimation and animation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2002.02792",
            "ref_texts": ""
        },
        "Learning global pose features in graph convolutional networks for 3d human pose estimation": {
            "authors": [
                "Kenkun Liu",
                "Zhiming Zou",
                "Wei Tang"
            ],
            "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Liu_Learning_Global_Pose_Features_in_Graph_Convolutional_Networks_for_3D_ACCV_2020_paper.pdf",
            "ref_texts": "3. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coars e-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 7025\u2013703 4",
            "ref_ids": [
                "3"
            ],
            "1": "The first stream of methods aim to build an end-to-end system that predicts th e 3D coordinates of body joints directly from the input image [3,13].",
            "2": "[3] CVPR\u201917 (*) 67."
        },
        "Drpose3d: Depth ranking in 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1805.08973",
            "ref_texts": "[Pavlakos et al. , 2017 ]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarseto-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "Pavlakos et al\\. , 2017 "
            ]
        },
        "Geometry-aware network for non-rigid shape prediction from a single view": {
            "authors": [
                "Albert Pumarola",
                "Antonio Agudo",
                "Lorenzo Porzi",
                "Alberto Sanfeliu",
                "Vincent Lepetit",
                "Francesc Moreno"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Pumarola_Geometry-Aware_Network_for_CVPR_2018_paper.pdf",
            "ref_texts": "[39] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. arXiv preprint arXiv:1611.07828 , 2016.",
            "ref_ids": [
                "39"
            ],
            "1": "Following the success of recent deep convolutional networks in related topics such as 3D human pose recovery [29, 34, 39], depth [17, 18, 19, 27, 41, 54] and surface normal reconstruction on rigid objects [7, 8, 17, 50], we introduce a unified formulation for the problem of estimating non-rigid shape from single images, that simul4682\n taneously performs 2D detection and 3D lifting while enforcing geometry consistency.",
            "2": "[39] G."
        },
        "Geometric pose affordance: 3d human pose with scene constraints": {
            "authors": [
                "Zhe Wang",
                "Liyan Chen",
                "Shaurya Rathore",
                "Daeyun Shin",
                "Charless Fowlkes"
            ],
            "url": "https://arxiv.org/pdf/1905.07718",
            "ref_texts": ". Ionescu, C., Papava, D., Olaru, V ., Sminchisescu, C., 2014. Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. PAMI . Joo, H., Simon, T., Sheikh, Y ., 2016. Total capture: A 3d deformation model for tracking faces, hands, and bodies, in: CVPR.Li, X., Liu, S., Kim, K., Wang, X., Yang, M.H., Kautz, J., 2019. Putting humans in a scene: Learning a fiordance in 3d indoor environments, in: CVPR. von Marcard, T., Henschel, R., Black, M.J., Rosenhahn, B., Pons-Moll, G., 2018. Recovering accurate 3d human pose in the wild using imus and a moving camera. ECCV . Martinez, J., Hossain, R., Romero, J., Little, J.J., 2017. A simple yet e fiective baseline for 3d human pose estimation, in: ICCV . Matzen, K., Snavely, N., 2013. Nyc3dcars: A dataset of 3d vehicles in geographic context, in: ICCV . Mehta, D., Rhodin, H., Casas, D., Fua, P., Sotnychenko, O., Xu, W., Theobalt, C., 2017. Monocular 3d human pose estimation in the wild using improved cnn supervision, in: 3DV . Monszpart, A., Guerrero, P., Ceylan, D., Yumer, E., Mitra, N.J., 2018. imapper: Interaction-guided joint scene and human motion mapping from monocular videos, in: arxiv. Moon, G., Chang, J., Lee, K.M., 2019. Camera distance-aware top-down approach for 3d multi-person pose estimation from a single rgb image, in: ICCV . Moon, G., Lee, K.M., 2020. I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image, in: ECCV . Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose, in: CVPR. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. NIPS . Rhodin, H., Salzmann, M., Fua, P., 2018a. Unsupervised geometry-aware representation for 3d human pose estimation, in: ECCV . Rhodin, H., Sp \u00a8orri, J., Katircioglu, I., Constantin, V ., Meyer, F., M \u00a8uller, E., Salzmann, M., Fua, P., 2018b. Learning monocular 3d human pose estimation from multi-view images. Rogez, G., Weinzaepfel, P., Schmid, C., 2019. Lcr-net ++: Multi-person 2d and 3d pose detection in natural images. PAMI . Rother, C., Kolmogorov, V ., Blake, A., 2004. \u201d grabcut\u201d interactive foreground extraction using iterated graph cuts, in: ToG. Shin, D., Ren, Z., Sudderth, E., Fowlkes, C., 2019. 3d scene reconstruction with multi-layer depth and epipolar transformers, in: ICCV . Sigal, L., Balan, A.O., Black, M.J., 2010. Humaneva: Synchronizedvideo and motion capture dataset and baseline algorithm forevaluation of articulated human motion, in: IJCV . Song, S., Yu, F., Zeng, A., Chang, A.X., lis Savva, M., Funkhouser, T., 2017. Semantic scene completion from a single depth image, in: CVPR. Sun, X., Xiao, B., Wei, F., Liang, S., Wei, Y ., 2018. Integral human pose regression, in: ECCV . Taheri, O., Ghorbani, N., Black, M.J., Tzionas, D., 2020. GRAB: A dataset of whole-body human grasping of objects, in: ECCV . Trumble, M., Gilbert, A., Malleson, C., Hilton, A., Collomosse, J., 2017. Total capture: 3d human pose estimation fusing video and inertial sensors, in: BMVC."
        },
        "Lightweight 3d human pose estimation network training using teacher-student learning": {
            "authors": [
                "Hyun Hwang",
                "Suntae Kim",
                "Nicolas Monet",
                "Hideki Koike",
                "Soonmin Bae"
            ],
            "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Hwang_Lightweight_3D_Human_Pose_Estimation_Network_Training_Using_Teacher-Student_Learning_WACV_2020_paper.pdf",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE CVPR 2017 .",
            "ref_ids": [
                "35"
            ],
            "1": "3D pose estimation methods using volumetric heatmap regression were proposed [27, 34, 35].",
            "2": "To address this issue, a method with stepwise depth resolution increase [35] and a soft-argmax based method to find 3D coordinates in low-resolution heatmaps [27] have been proposed.",
            "3": "[35] G."
        },
        "Weakly supervised adversarial learning for 3D human pose estimation from point clouds": {
            "authors": [
                "Zihao Zhang",
                "Lei Hu",
                "Xiaoming Deng",
                "Shihong Xia"
            ],
            "url": "http://www.idengxm.com/paper/tvcg_2020.pdf",
            "ref_texts": "[21] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp.",
            "ref_ids": [
                "21"
            ],
            "1": "[21] use a 3D volumetric representation for 3D human pose, and adopt CNN to predict the likelihood of 3D joints in each voxel.",
            "2": "[21] G."
        },
        "Hit-dvae: Human motion generation via hierarchical transformer dynamical vae": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.01565",
            "ref_texts": "[43] Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR). pp. 7025{7034 (2017)",
            "ref_ids": [
                "43"
            ]
        },
        "Densebody: Directly regressing dense 3d human pose and shape from a single color image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1903.10153",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 1, 6",
            "ref_ids": [
                "29"
            ],
            "1": "In the past several years, various approaches have been proposed to either jointly[43, 44, 14] or partially[13, 29, 35] solve this problem.",
            "2": "[29] 51.",
            "3": "1, 2\n[29] G."
        },
        "Skeleton-based human action evaluation using graph convolutional network for monitoring Alzheimer's progression": {
            "authors": [
                "Bruce X"
            ],
            "url": "https://bruceyo.github.io/publication/pr2021skeleton/pr2021skeleton.pdf",
            "ref_texts": "[22] G. Pavlakos , X. Zhou , K.G. Derpanis , K. Daniilidis , Coarse-to-fine volumetric prediction for single-image 3D human pose, in: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE, 2017, pp. 1263\u20131272 . ",
            "ref_ids": [
                "22"
            ],
            "1": "RGB cameras can retrieve 2D skeleton [20] or 3D skeleton [21,22] data but come with higher computational costs.",
            "2": "[22] G."
        },
        "Predicting animation skeletons for 3d articulated models via volumetric nets": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.08506",
            "ref_texts": "[41] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proc. CVPR , 2017.",
            "ref_ids": [
                "41"
            ],
            "1": ", humans, hands) [56, 37, 20, 41, 19, 70], and in contrast to existing graphics approaches that fit pre-defined skeletal templates to 3D meshes [3], our method learns a generic model of skeleton prediction for 3D models: it can extract plausible skeletons for a large variety of input characters, such as humanoids, quadrupeds, birds, fish, robots, and other fictional characters (Figure 1).",
            "2": "Most recent methods use deep architectures to extract joints for humans [48, 19, 41, 33, 38, 75, 61, 42], hands [15, 37, 20, 63, 15, 64, 14], and more recently some species of animals [43].",
            "3": "[41] G."
        },
        "Posenet3d: Learning temporally consistent 3d human pose via knowledge distillation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.03473",
            "ref_texts": "[51] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , July 2017. 2",
            "ref_ids": [
                "51"
            ],
            "1": "Related Work Several deep learning techniques have been proposed to estimate 3D joints directly from 2D images [7, 8, 19, 25, 37, 43, 48, 49, 51, 57, 58, 62, 68, 69, 59, 75, 76].",
            "2": "2\n[51] G."
        },
        "Danet: Decompose-and-aggregate network for 3d human shape and pose estimation": {
            "authors": [],
            "url": "https://guolusjtu.github.io/guoluhomepage/paper/ACMMM2019.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "36"
            ],
            "1": "One-stage methods in literature adopt volumetric representation [36], joint heat map [47] or 3D orientation fields [29] as intermediate representations to facilitate the learning task.",
            "2": "Following the common protocols [19,36,37], we use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for evaluation."
        },
        "mmBody benchmark: 3D body reconstruction dataset and analysis for millimeter wave radar": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.05070",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. InProceedings of the IEEE conference on computer vision and pattern recognition .",
            "ref_ids": [
                "38"
            ],
            "1": "2D/3D skeletons [11,33,38,50,52], the parameters of SMPL [19\u201321,24,39] is learned."
        },
        "Graformer: Graph convolution transformer for 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2109.08364",
            "ref_texts": "2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In IEEE CVPR , 7025\u20137034. Redmon, J.; and Farhadi, A. 2017. YOLO9000: better, faster, stronger. In IEEE CVPR , 7263\u20137271. Romero, J.; Tzionas, D.; and Black, M. J. 2017. Embodied hands: Modeling and capturing hands and bodies together. ACM Transactions on Graphics , 36(6): 1\u201317. Simon, T.; Joo, H.; Matthews, I.; and Sheikh, Y . 2017. Hand keypoint detection in single images using multiview bootstrapping. In IEEE CVPR , 1145\u20131153. Srivastava, N.; Hinton, G.; Krizhevsky, A.; Sutskever, I.; and Salakhutdinov, R. 2014. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research , 15(1): 1929\u20131958. Sun, X.; Shang, J.; Liang, S.; and Wei, Y . 2017. Compositional human pose regression. In IEEE ICCV , 2602\u20132611. Tekin, B.; Bogo, F.; and Pollefeys, M. 2019. H+ o: Unified egocentric recognition of 3d hand-object poses and interactions. In IEEE CVPR , 4511\u20134520. Tekin, B.; Rozantsev, A.; Lepetit, V .; and Fua, P. 2016. Direct prediction of 3d body poses from motion compensated sequences. In IEEE CVPR , 991\u20131000. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, \u0141.; and Polosukhin, I. 2017. Attention is all you need. In Advances in neural information processing systems , 5998\u20136008. Veli\u02c7ckovi \u00b4c, P.; Cucurull, G.; Casanova, A.; Romero, A.; Lio, P.; and Bengio, Y . 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 . Wang, X.; Girshick, R.; Gupta, A.; and He, K. 2018. Nonlocal neural networks. In IEEE CVPR , 7794\u20137803. Weng, J.; Weng, C.; and Yuan, J. 2017. Spatio-temporal naive-bayes nearest-neighbor (st-nbnn) for skeleton-based action recognition. In IEEE CVPR , 4171\u20134180. Xu, T.; and Takano, W. 2021. Graph Stacked Hourglass Networks for 3D Human Pose Estimation. In IEEE CVPR , 16105\u201316114. Yan, S.; Xiong, Y .; and Lin, D. 2018. Spatial temporal graph convolutional networks for skeleton-based action recognition. In AAAI . Yang, J.; Lu, J.; Lee, S.; Batra, D.; and Parikh, D. 2018. Graph r-cnn for scene graph generation. In ECCV , 670\u2013685. Zhao, L.; Peng, X.; Tian, Y .; Kapadia, M.; and Metaxas, D. N. 2019. Semantic graph convolutional networks for 3d human pose regression. In IEEE CVPR , 3425\u20133435. Zhou, X.; Huang, Q.; Sun, X.; Xue, X.; and Wei, Y . 2017. Towards 3d human pose estimation in the wild: a weaklysupervised approach. In IEEE ICCV , 398\u2013407. Zhou, X.; Sun, X.; Zhang, W.; Liang, S.; and Wei, Y . 2016. Deep kinematic pose regression. In ECCV , 186\u2013201.",
            "ref_ids": [
                "2017"
            ]
        },
        "Towards Single Camera Human 3D-Kinematics": {
            "authors": [
                "Marian Bittner",
                "Tse Yang",
                "Xucong Zhang",
                "Ajay Seth",
                "Frans C. T"
            ],
            "url": "https://www.mdpi.com/1424-8220/23/1/341/pdf",
            "ref_texts": "28. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. arXiv 2017 , arXiv:1611.07828.",
            "ref_ids": [
                "28"
            ]
        },
        "Distill knowledge from nrsfm for weakly supervised 3d pose learning": {
            "authors": [
                "Chaoyang Wang",
                "Chen Kong",
                "Simon Lucey"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Distill_Knowledge_From_NRSfM_for_Weakly_Supervised_3D_Pose_Learning_ICCV_2019_paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "29"
            ],
            "1": "Weakly supervised 3D pose learning Most 3D pose estimation methods [36,30,29,47,45,44,28,8,26,6] are fully supervised."
        },
        "Human body pose estimation for gait identification: A comprehensive survey of datasets and models": {
            "authors": [
                "Power Edit"
            ],
            "url": "https://arxiv.org/pdf/2305.13765",
            "ref_texts": "[142] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. 2017. Coarse -to-fine volumetric predict ion for single image 3D human pose. In Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , 1263 \u20131272. DOI:https://doi.org/10.1109/CVPR.2017.139 ",
            "ref_ids": [
                "142"
            ],
            "1": "3mm \n[142] 2017 HumanEva , Huma n3.",
            "2": "The kinematic model, as employed in [24,100,108,142] , include a set of joint positions and limb orientations to represent the human body structure [31].",
            "3": "While extensive literature is available for the model -free HPE [24,83,117,142,174,223 ], this approach has several limitations such as use of conventional methods (e.",
            "4": "In contrast, v arious existing studies take a direct estimation approach by inferring the 3D pose from 2D images without performing 2D HPE \n[86,87,142] .",
            "5": "[142] propose a volumetric representation."
        },
        "3D Human Pose Estimation With Spatio-Temporal Criss-Cross Attention": {
            "authors": [
                "Zhenhua Tang",
                "Zhaofan Qiu",
                "Yanbin Hao",
                "Richang Hong",
                "Ting Yao"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Tang_3D_Human_Pose_Estimation_With_Spatio-Temporal_Criss-Cross_Attention_CVPR_2023_paper.pdf"
        },
        "Synthetic occlusion augmentation with volumetric heatmaps for the 2018 eccv posetrack challenge on 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1809.04987",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "This includes volumetric heatmaps [20][27][13], marginal heatmaps [17] and location maps [15].",
            "2": "in the interpretation of the volumetric heatmap\u2019s axes [20]: X and Y correspond to image space and the depth axis to camera space, relative to the person center.",
            "3": "4 Pavlakos (2017) [20] 67.",
            "4": "[20] G."
        },
        "Geometry-driven self-supervised method for 3d human pose estimation": {
            "authors": [
                "Yang Li",
                "Kan Li",
                "Shuai Jiang",
                "Ziyue Zhang",
                "Congzhentao Huang",
                "Richard Yi",
                "Da Xu"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/6808/6662",
            "ref_texts": "2018. End-to-end recovery of human shape and pose. InCVPR , 7122\u20137131. Kocabas, M.; Karagoz, S.; and Akbas, E. 2019. Selfsupervised learning of 3d human pose using multi-view ge-ometry. In CVPR , 1077\u20131086. Martinez, J.; Hossain, R.; Romero, J.; and Little, J. J. 2017. A simple yet effective baseline for 3d human pose estima-tion. In ICCV , 2640\u20132649. Mehta, D.; Rhodin, H.; Casas, D.; Fua, P .; Sotnychenko, O.; Xu, W.; and Theobalt, C. 2017. Monocular 3d human poseestimation in the wild using improved cnn supervision. In3DV , 506\u2013516. Newell, A.; Yang, K.; and Deng, J. 2016. Stacked hourglass networks for human pose estimation. In ECCV , 483\u2013499. Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017a. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 7025\u20137034. Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K.",
            "ref_ids": [
                "2018"
            ]
        },
        "Adversarial learning of structure-aware fully convolutional networks for landmark localization": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1711.00253",
            "ref_texts": "[41] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3d human pose,\u201d Proc. IEEE Conf. Comp. Vis. Patt. Recogn. , 2016.",
            "ref_ids": [
                "41"
            ],
            "1": "[41] introduced a deep convolutional neural network based on the stacked hourglass architecture [9], which maps 2D joint probability heatmaps to probability distributions in the 3D space.",
            "2": "(MA) [41] 67.",
            "3": "[41] (SA) 51.",
            "4": "[41] G."
        },
        "Dynamic graph reasoning for multi-person 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.11341",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR . 7025\u20137034.",
            "ref_ids": [
                "33"
            ],
            "1": "The inferring methods [16,25,33,40,41] directly regress 3D pose from learned 3D heatmaps."
        },
        "Generalizing monocular 3d human pose estimation in the wild": {
            "authors": [
                "Luyang Wang",
                "Yan Chen",
                "Zhenhua Guo",
                "Keyuan Qian",
                "Mude Lin",
                "Hongsheng Li",
                "Jimmy S. Ren"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Wang_Generalizing_Monocular_3D_Human_Pose_Estimation_in_the_Wild_ICCVW_2019_paper.pdf",
            "ref_texts": "[28] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and PatternReco gnition , 2017. 2,7",
            "ref_ids": [
                "28"
            ],
            "1": "Recently, several methods have been proposed to estimate the 3D pose on the monocular image [11,16,20,28,36,38,40,49].",
            "2": "[28] 67.",
            "3": "2\n[28] G."
        },
        "A baseline for cross-database 3d human pose estimation": {
            "authors": [
                "Michal Rapczynski",
                "Philipp Werner",
                "Sebastian Handrich",
                "Ayoub Al"
            ],
            "url": "https://www.mdpi.com/1424-8220/21/11/3769/pdf",
            "ref_texts": "68. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Proceedings of the 30th IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
            "ref_ids": [
                "68"
            ],
            "1": "[68] 25.",
            "2": "[68] transferred the idea of the heat map-based 2D pose estimation into the 3D domain and predicted per-joint 3D heat maps using a coarse-to-fine stacked hourglass network, where each voxel contains the probability that the joint is located at this position."
        },
        "GraphMLP: A graph MLP-like architecture for 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2206.06420",
            "ref_texts": "[26] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017, pp. 7025\u20137034. 3",
            "ref_ids": [
                "26"
            ],
            "1": "3\n[26] G."
        },
        "Weakly supervised generative network for multiple 3d human pose hypotheses": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.05770",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and Pattern Recognition , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "24"
            ],
            "1": "Most existing works are fully supervised, which train their models either in an end-toend [17, 21, 24, 28, 35] or a two-stage manner [6, 20, 22, 25, 32].",
            "2": "[24] use a volumetric representation for the 3D space and train a deep network to estimate the probability that a joint is located at each voxel."
        },
        "Reducing footskate in human motion reconstruction with ground contact constraints": {
            "authors": [
                "Yuliang Zou",
                "Jimei Yang",
                "Duygu Ceylan",
                "Jianming Zhang",
                "Federico Perazzi",
                "Bin Huang"
            ],
            "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Zou_Reducing_Footskate_in_Human_Motion_Reconstruction_with_Ground_Contact_Constraints_WACV_2020_paper.pdf",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "31"
            ],
            "1": "Mainstream methods predict 3D pose either from a single RGB image [21,31,40,45] or from intermediate representations such as 2D joint detection [7,25,29]."
        },
        "Skeleton-based action recognition of people handling objects": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1901.06882",
            "ref_texts": "[27] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "27"
            ],
            "1": "algorithms [3, 25, 27, 29] provides an easier way to obtain skeletal information.",
            "2": "[27] G."
        },
        "Semi-Dynamic Hypergraph Neural Network for 3D Pose Estimation.": {
            "authors": [
                "Shengyuan Liu",
                "Pei Lv",
                "Yuzhen Zhang",
                "Jie Fu",
                "Junjin Cheng",
                "Wanqing Li",
                "Bing Zhou",
                "Mingliang Xu"
            ],
            "url": "https://www.ijcai.org/proceedings/2020/0109.pdf",
            "ref_texts": "[Pavlakos et al., 2017 ]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarseto-fine volumetric prediction for single-image 3d human pose. In CVPR, pages 1263\u20131272, 2017.",
            "ref_ids": [
                "Pavlakos et al\\., 2017 "
            ]
        },
        "Deep monocular 3d human pose estimation via cascaded dimension-lifting": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.03520",
            "ref_texts": ""
        },
        "Refining OpenPose with a new sports dataset for robust 2D pose estimation": {
            "authors": [
                "Takumi Kitamura",
                "Hitoshi Teshima",
                "Diego Thomas",
                "Hiroshi Kawasaki"
            ],
            "url": "https://openaccess.thecvf.com/content/WACV2022W/CV4WS/papers/Kitamura_Refining_OpenPose_With_a_New_Sports_Dataset_for_Robust_2D_WACVW_2022_paper.pdf",
            "ref_texts": "[19] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR , abs/1611.07828, 2016.",
            "ref_ids": [
                "19"
            ],
            "1": "In [19], the authors propose to discretize the 3D space around the human body and build a 3D heat map that represent the occupancy probability of each joint in each voxel."
        },
        "MEBOW: Monocular estimation of body orientation in the wild": {
            "authors": [
                "Chenyan Wu",
                "Yukun Chen",
                "Jiajia Luo",
                "Chun Su",
                "Anuja Dawane",
                "Bikramjot Hanzra",
                "Zhuo Deng",
                "Bilan Liu",
                "James Z. Wang"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_MEBOW_Monocular_Estimation_of_Body_Orientation_in_the_Wild_CVPR_2020_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7025\u20137034, 2017. 8",
            "ref_ids": [
                "37"
            ],
            "1": "[37] 58."
        },
        "Everybody is unique: Towards unbiased human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.06239",
            "ref_texts": "[26] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "26"
            ]
        },
        "Body size and depth disambiguation in multi-person reconstruction from single images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.01884",
            "ref_texts": "[42] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 4322",
            "ref_ids": [
                "42"
            ],
            "1": "A lot of important studies have been done on this topic for single-person [29, 53, 7, 34, 67, 37, 42, 51, 59, 66] and multi-person [47, 48, 36, 27, 32].",
            "2": "4321, 4322\n[42] G."
        },
        "PCLs: Geometry-aware neural reconstruction of 3D pose with perspective crop layers": {
            "authors": [
                "Frank Yu",
                "Mathieu Salzmann",
                "Pascal Fua",
                "Helge Rhodin"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Yu_PCLs_Geometry-Aware_Neural_Reconstruction_of_3D_Pose_With_Perspective_Crop_CVPR_2021_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u2013",
            "ref_ids": [
                "32"
            ],
            "1": "pose while discarding other ones [43,30,6,27,32,39,44, 42,20,51,17,47]."
        },
        "Automatic tool landmark detection for stereo vision in robot-assisted retinal surgery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1709.05665",
            "ref_texts": "[21] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-tofine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "21"
            ],
            "1": "Closest to our work are the CNN-based keypoint prediction methods, applied for Human Pose Estimation [19], [21], [27].",
            "2": "[21] G."
        },
        "Unsupervised cross-modal alignment for multi-person 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.01388",
            "ref_texts": "43.Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: CVPR (2017) 4",
            "ref_ids": [
                "43"
            ],
            "1": "MethodsSingle shotw/opaired supervisionCamera centric Rogez [49] 7 7 7 Mehta [36] 4 7 7 Rogez [50] 7 7 7 Dabral [7] 7 7 4 Moon [38] 7 7 4 Ours 4 4 4Many approaches have been proposed for solving the problem of single-person 3D human pose estimation [53,26,25,27,43,57]."
        },
        "3d human pose estimation with relational networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1805.08961",
            "ref_texts": "[26] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpa nis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d h uman pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conferenc e on, pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "26"
            ],
            "1": "[26] proposed a volumetric representation that gradually increases the resolution of the depth from heatmaps of 2D pose .",
            "2": "[26] 67.",
            "3": "[26] 83.",
            "4": "The proposed method is compared to the recently proposed method s that estimates 3D pose from a single image [4,6,19,21,26,34,36,40]."
        },
        "Localization with sampling-argmax": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2021/file/e4a6222cdb5b34375400904f03d8e6a5-Paper.pdf",
            "ref_texts": "[29] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-tofine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "29"
            ],
            "1": "Following previous methods [29,34,26,16], MPJPE and PA-MPJPE [5] are used as the evaluation metrics."
        },
        "Procrustean regression networks: Learning 3d structure of non-rigid objects from 2d annotations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.10961",
            "ref_texts": "30. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7025{7034 (2017)",
            "ref_ids": [
                "30"
            ],
            "1": "Prior knowledge can be obtained by dictionary learning [43,44], but neural networks or convolutional neural networks (CNNs) are the most-used methods to learn the 2D-to-3D or image-to-3D mappings [24,30], recently.",
            "2": "The performance may be improved if recently-proposed networks for 3D human pose estimation [25,30] is applied here."
        },
        "Deep reinforcement learning for active human pose estimation": {
            "authors": [
                "Erik Gartner",
                "Aleksis Pirinen",
                "Cristian Sminchisescu"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/6714/6568",
            "ref_texts": "2018. Embodied question answering. In CVPR , volume 5, 6. Ionescu, C.; Papava, D.; Olaru, V .; and Sminchisescu, C. 2014. Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE Transactions on Pattern Analysis and Machine Intelligence 36(7):1325\u20131339. Jayaraman, D., and Grauman, K. 2018. Learning to look around: Intelligently exploring unseen environments for unknown tasks. In CVPR . Johns, E.; Leutenegger, S.; and Davison, A. J. 2016. Pairwise decomposition of image sequences for active multi-view recognition.InCVPR , 3813\u20133822. Joo, H.; Liu, H.; Tan, L.; Gui, L.; Nabbe, B.; Matthews, I.; Kanade, T.; Nobuhara, S.; and Sheikh, Y . 2015. Panoptic studio: A massively multiview system for social motion capture. In ICCV . Joo, H.; Simon, T.; and Sheikh, Y . 2018. Total capture: A 3d deformation model for tracking faces, hands, and bodies. In CVPR . Kanazawa, A.; Black, M. J.; Jacobs, D. W.; and Malik, J. 2018. End-to-end recovery of human shape and pose. In CVPR . Kingma, D., and Ba, J. 2015. Adam: A method for stochastic optimization. ICLR . Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and Black, M. J. 2015. SMPL: A skinned multi-person linear model. SIGGRAPH 34(6):248:1\u201316.Mehta, D.; Sridhar, S.; Sotnychenko, O.; Rhodin, H.; Shafiei, M.; Seidel, H.-P.; Xu, W.; Casas, D.; and Theobalt, C. 2017. Vnect: Real-time 3d human pose estimation with a single rgb camera.ACM Transactions on Graphics (TOG) 36(4):44. Papandreou, G.; Zhu, T.; Kanazawa, N.; Toshev, A.; Tompson, J.; Bregler, C.; and Murphy, K. 2017. Towards accurate multi-person pose estimation in the wild. In CVPR . Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR . Pavlakos, G.; Zhou, X.; and Daniilidis, K. 2018. Ordinal depth supervision for 3D human pose estimation. In CVPR . Pirinen, A., and Sminchisescu, C. 2018. Deep reinforcement learning of region proposal networks for object detection. CVPR . Pirinen, A.; G \u00a8artner, E.; and Sminchisescu, C. 2019. Domes to drones: Self-supervised active triangulation for 3d human pose re-construction. In NeurIPS , 3907\u20133917. Popa, A.-I.; Zanfir, M.; and Sminchisescu, C. 2017. Deep multitask architecture for integrated 2d and 3d human sensing. In CVPR . Ren, S.; He, K.; Girshick, R.; and Sun, J. 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. InNIPS , 91\u201399. Rhodin, H.; Robertini, N.; Casas, D.; Richardt, C.; Seidel, H.-P.; and Theobalt, C. 2016. General automatic human shape and motion capture using volumetric contour cues. In ECCV . Rogez, G.; Weinzaepfel, P.; and Schmid, C. 2017. Lcr-net: Localization-classification-regression for human pose. In CVPR . Simonyan, K., and Zisserman, A. 2015. Very deep convolutional networks for large-scale image recognition. In ICLR . von Marcard, T.; Henschel, R.; Black, M.; Rosenhahn, B.; and Pons-Moll, G. 2018. Recovering accurate 3d human pose in thewild using imus and a moving camera. In ECCV . Wei, S.-E.; Ramakrishna, V .; Kanade, T.; and Sheikh, Y . 2016. Convolutional pose machines. In CVPR , 4724\u20134732. Williams, R. 1992. Simple statistical gradient-following algorithms for connectionist reinforcement learning. Machine Learning. Xia, F.; Zamir, A. R.; He, Z.; Sax, A.; Malik, J.; and Savarese, S.",
            "ref_ids": [
                "2018"
            ]
        },
        "View invariant 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1901.10841",
            "ref_texts": "[4] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3D human pose.\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp.",
            "ref_ids": [
                "4"
            ],
            "1": "The development of neural networks has advanced the 3D human pose estimation [2], [3], [4], [5], [6], [7].",
            "2": "Generally, previous methods are categorized into two classes: i) training an endto-end network to directly predict 3D pose from an image [2], [3], [4], ii) estimating 2D pose from an image first and then lifting the 2D pose to 3D pose [5], [8], [6], [7].",
            "3": "Despite the general success of the end-to-end learning paradigm, two-step solutions which consist of a convolutional neural network for predicting 2D joint locations from an image and a subsequent optimization step to recover the 3D pose also win excellent performance [4], [6], [7].",
            "4": "[4] train a convolutional neural network to predict per voxel likelihoods for each joint in a fine discretized 3D volumetric representation.",
            "5": "Different from those end-to-end 2D image to 3D pose regression approaches [15], [4], [3], Martinez et al.",
            "6": "Protocol #2: Under the same setting as Protocol #1, the evaluation by PA Joint Error is referred to as Protocol #2 [6], [7], [4].",
            "7": "[4] (CVPR\u201917) 67.",
            "8": "[4] (CVPR\u201917) \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "9": "[4] (CVPR\u201917) 79.",
            "10": "[4] G."
        },
        "Activemocap: Optimized viewpoint selection for active human motion capture": {
            "authors": [
                "Sena Kiciroglu",
                "Helge Rhodin",
                "Sudipta N. Sinha",
                "Mathieu Salzmann",
                "Pascal Fua"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Kiciroglu_ActiveMoCap_Optimized_Viewpoint_Selection_for_Active_Human_Motion_Capture_CVPR_2020_paper.pdf",
            "ref_texts": "[21] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis. Coarse-To-Fine V olumetric Prediction for Single-Image 3D Human Pose. In Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "21"
            ],
            "1": "Related work Most recent approaches to markerless motion capture rely on deep networks that regress 3D pose from monocular images [16, 17, 21, 38, 25, 31, 22, 44, 36, 34, 41, 39, 15].",
            "2": "[21] G."
        },
        "From image to stability: Learning dynamics from human pose": {
            "authors": [],
            "url": "https://www.cse.psu.edu/~rtc12/Papers/eccv2020_SCOTT_etal.pdf",
            "ref_texts": "51. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3D human pose. In: IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). pp. 1263{1272. IEEE (2017) 3",
            "ref_ids": [
                "51"
            ],
            "1": "Success in 2D human pose estimation also has encouraged researchers to detect 3D skeletons by extending existing 2D human pose detectors [6, 14, 44, 46, 48, 62, 75] or by directly using image features [1, 51, 57, 64, 74]."
        },
        "3D Human Pose Estimation Using M\u00f6bius Graph Convolutional Networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.10554",
            "ref_texts": "[42] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine V olumetric Prediction for Single-image 3D Human Pose. In CVPR , 2017. 10",
            "ref_ids": [
                "42"
            ],
            "1": "During the test phase, the scale of the outputs is calibrated by forcing the sum of the length of all 3D bones to be equal to a canonical skeleton [42, 74, 76].",
            "2": "Also, as in previous works [27, 33, 42, 71], our network predicts the normalized locations of 3D joints."
        },
        "It's all relative: Monocular 3d human pose estimation from weakly supervised data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1805.06880",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-tofine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "30"
            ],
            "1": "This is achieved by learning to regress the 3D keypoint locations during training, either as a set of 3D coordinates [17] or as volumetric heat maps [30].",
            "2": "[30] 47."
        },
        "Towards part-aware monocular 3d human pose estimation: An architecture search approach": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480715.pdf",
            "ref_texts": "40. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR (2017)",
            "ref_ids": [
                "40"
            ],
            "1": "Recently, many approaches [48, 40, 62, 39] have followed a popular paradigm in predicting per voxel likelihood for each human joint and achieved competitive performance.",
            "2": "Difierent from them, 3D human poses are commonly estimated in a higher-order volumetric space [48, 40, 52, 11].",
            "3": "[40] extend 2D heat maps to 3D volumetric heat maps and predict per voxel likelihood for each joint."
        },
        "Toward marker-free 3D pose estimation in lifting: A deep multi-view solution": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1802.01741",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "31"
            ],
            "1": "While [28], [29], [30] represents intermediate 2D pose as 2D coordination of the joints, [31], [32], [33] define it by a set of heatmaps that encode the probability of observing a specific joint at the corresponding image location.",
            "2": "[31] trains a DNN with 2D joints heatmaps as an intermediate representation to predict per voxel likelihood for each joint in the 3D space instead of directly regressing the 3D joints coordination.",
            "3": "Hierarchical Skip Connections Inferring a 3D pose from joints heatmap as the only intermediate supervision, which is a widely used strategy in previous studies [31], [32], is inherently ambiguous."
        },
        "Mosculp: Interactive visualization of shape and time": {
            "authors": [
                "First Author",
                "Second Author",
                "Third Author",
                "Fourth Author",
                "Fifth Author",
                "Sixth Author"
            ],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3242587.3242592",
            "ref_texts": "40. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. 2017. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. InIEEE Conference on Computer Vision and Pattern Recognition.",
            "ref_ids": [
                "40"
            ],
            "1": "Various methods have been proposed to estimate 3D pose from a single image [6, 26, 40, 41, 39, 12, 48], or from a video [21, 22, 50, 36, 1]."
        },
        "Neural Voting Field for Camera-Space 3D Hand Pose Estimation": {
            "authors": [
                "Lin Huang",
                "Ching Lin",
                "Kevin Lin",
                "Lin Liang",
                "Lijuan Wang",
                "Junsong Yuan",
                "Zicheng Liu"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Neural_Voting_Field_for_Camera-Space_3D_Hand_Pose_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1",
            "ref_ids": [
                "47"
            ],
            "1": "Specifically, as demonstrated in previous works [14, 16, 25, 29, 34, 42, 43, 47, 49, 54\u201356], dense regression-based methods are more effective than holistic regression-based counterparts for handling highly articulated 3D pose structure, attributed to its ability to maintain the input data spatial structure and fully exploit local evidence; (2) the ability to reason 3D hand global geomeThis CVPR paper is the Open Access version, provided by the Computer Vision Foundation."
        },
        "Global-to-Local Modeling for Video-based 3D Human Pose and Shape Estimation": {
            "authors": [
                "Xiaolong Shen",
                "Zongxin Yang",
                "Xiaohan Wang",
                "Jianxin Ma",
                "Chang Zhou",
                "Yi Yang"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Shen_Global-to-Local_Modeling_for_Video-Based_3D_Human_Pose_and_Shape_Estimation_CVPR_2023_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CVPR , 2016. 3",
            "ref_ids": [
                "35"
            ],
            "1": "Moreover, 3D pose estimation [30, 35] is highly related to this task."
        },
        "PoseGTAC: Graph Transformer Encoder-Decoder with Atrous Convolution for 3D Human Pose Estimation.": {
            "authors": [
                "Yiran Zhu",
                "Xing Xu",
                "Fumin Shen",
                "Yanli Ji",
                "Lianli Gao",
                "Heng Tao"
            ],
            "url": "https://www.ijcai.org/proceedings/2021/0188.pdf",
            "ref_texts": "[Mehta et al., 2017 ]Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksandr Sotnychenko, Weipeng Xu, and Christian Theobalt. Monocular 3d human pose estimation in the wild using improved CNN supervision. In 3DV, pages 506\u2013516, 2017.[Pavlakos et al., 2017 ]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR, pages 1263\u20131272, 2017.",
            "ref_ids": [
                "Mehta et al\\., 2017 ",
                "Pavlakos et al\\., 2017 "
            ]
        },
        "Collaborative regression of expressive bodies using moderation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.05301",
            "ref_texts": "[73] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017. 2",
            "ref_ids": [
                "73"
            ],
            "1": "The alternative is to directly regress 3D skeletons [59, 73, 89, 90, 93], statistical model parameters [18, 25, 45, 47, 48, 51, 53, 91], 3D meshes [54, 61], depth maps [27, 87], 3D voxels [100, 114] or distance fields [82, 83] from the image pixels."
        },
        "VoteHMR: Occlusion-aware voting network for robust 3D human mesh recovery from partial point clouds": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.08729",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. 2017. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR",
            "ref_ids": [
                "30"
            ],
            "1": "1 Human Mesh Recovery from 2D Images Human mesh recovery has been extensively studied from RGB images, either by template-based approaches to fit the 2D annotations of the RGB images [18,21,29\u201331,39,40,42,45,47], such as keypoints [3], silhouettes [31], and dense annotations [11,38], or template-less approaches [30,31,41,58,59] that directly regress the 3D coordinates of vertices of the human meshes.",
            "2": "Recent works also try to process depth data [2,9,15,30,48,50] for human mesh recovery, in which the existing methods can also be divided into template-based [2,52,53] and template-less methods [6,7,14,24], in which the template-less methods create the 3D human meshes without any prior knowledge about the body shape and usually volumetrically fuse all captured depth maps to reconstruct 3D models."
        },
        "A dual-source approach for 3D human pose estimation from single images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1705.02883",
            "ref_texts": ""
        },
        "Exploring severe occlusion: Multi-person 3d pose estimation with gated convolution": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.00184",
            "ref_texts": "[5] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "5"
            ],
            "1": "A fine discretization of the 3D space around the subject is proposed in [5], which employs a coarse-to-fine prediction, given that input is a single RGB image.",
            "2": "Following previous work [5], [11], [13], [18], [28]\u2013[32] on Human3.",
            "3": "[5] G."
        },
        "Egocentric pose estimation from human vision span": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.05167",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, Coarse-to-fine volumetric prediction for single image 3d human pose, CVPR 2017. 2",
            "ref_ids": [
                "22"
            ],
            "1": "Both 2D and 3D human pose estimation techniques have been extensively studied from a third person perspective [17, 18, 19, 20, 21, 22, 23, 24, 25].",
            "2": "2\n[22] G."
        },
        "3D human pose estimation with siamese equivariant embedding": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1809.07217",
            "ref_texts": "[8] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarse-to-ffne volumetric prediction for single-image 3d human pose, in: The IEEE Conference on Computer Vision and Pattern Recognition, IEEE, 2017, pp. 1263{1272.",
            "ref_ids": [
                "8"
            ],
            "1": "For example, in [8], the authors predict a 3D heatmap, gradually reffning it along the depth dimension, increasing the resolution step-by-step.",
            "2": "[8] G."
        },
        "Proactive Multi-Camera Collaboration For 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.03767",
            "ref_texts": "3286\u20133295, 2018. Wenhan Luo, Peng Sun, Fangwei Zhong, Wei Liu, Tong Zhang, and Yizhou Wang. End-to-end active object tracking and its real-world deployment via reinforcement learning. IEEE Transactions on Pattern Analysis and Machine Intelligence , 42(6):1317\u20131332, 2019. Xiaoxuan Ma, Jiajun Su, Chunyu Wang, Hai Ci, and Yizhou Wang. Context modeling in 3d human pose estimation: A unified perspective. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 6238\u20136247, 2021. Julieta Martinez, Rayat Hossain, Javier Romero, and James J Little. A simple yet effective baseline for 3d human pose estimation. In Proceedings of the IEEE International Conference on Computer Vision , pp. 2640\u20132649, 2017. Takashi Matsuyama, Shohei Nobuhara, Takeshi Takai, and Tony Tung. Active camera system for object tracking and multi-view observation. In 3D Video and Its Applications , pp. 45\u201385. Springer, 2012. Dushyant Mehta, Srinath Sridhar, Oleksandr Sotnychenko, Helge Rhodin, Mohammad Shafiei, HansPeter Seidel, Weipeng Xu, Dan Casas, and Christian Theobalt. Vnect: Real-time 3d human pose estimation with a single rgb camera. ACM Transactions on Graphics (TOG) , 36(4):1\u201314, 2017. Tobias N\u00e4geli, Samuel Oberholzer, Silvan Pl\u00fcss, Javier Alonso-Mora, and Otmar Hilliges. Flycon: real-time environment-independent multi-view human pose estimation with aerial vehicles. ACM Transactions on Graphics (TOG) , 37(6):1\u201314, 2018. Xuehai Pan, Mickel Liu, Fangwei Zhong, Yaodong Yang, Song-Chun Zhu, and Yizhou Wang. MATE: Benchmarking multi-agent reinforcement learning in distributed target coverage control. In Thirtysixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track , 2022. URL https://openreview.net/forum?id=SyoUVEyzJbE . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 7025\u20137034, 2017a. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Harvesting multiple views for marker-less 3d human pose annotations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 6988\u20136997, 2017b. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 459\u2013468, 2018. Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7753\u20137762, 2019. Aleksis Pirinen, Erik G\u00e4rtner, and Cristian Sminchisescu. Domes to drones: Self-supervised active triangulation for 3d human pose reconstruction. Advances in Neural Information Processing Systems , 32, 2019. Haibo Qiu, Chunyu Wang, Jingdong Wang, Naiyan Wang, and Wenjun Zeng. Cross view fusion for 3d human pose estimation. In Proceedings of the IEEE/CVF International Conference on Computer Vision , pp. 4342\u20134351, 2019. Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, and Yizhou Wang. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia , pp. 1221\u20131224, 2017."
        },
        "SSP-Net: Scalable sequential pyramid networks for real-Time 3D human pose regression": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.01998",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarse-to-ffne volumetric prediction for single-image 3D human pose, in: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "The main reason is due to the additional third dimension in 3D predictions, which signiffcantly increases the required memory and computations, especially in detection based approaches, were the space is frequently represented by voxels [20].",
            "2": "[20] extended the Staked Hourglass network to volumetric heatmaps prediction, on which the zcoordinate is encoded in the additional heatmap dimension.",
            "3": "However, the method proposed in [20] sufiers from the signiffcant increase in the number of parameters and in the required memory to store all the intermediate values, due to the highly expensive volumetric heatmaps.",
            "4": "Difierently from the stacked hourglass [8, 20] architectures, where only the higher resolution features are supervised, we use intermediate supervision at every level of the pyramids.",
            "5": "We followed the most common evaluation protocol [22, 23, 20, 25, 7] by taking ffve subjects for training (S1, S5, S6, S7, S8) and evaluating on two subjects (S9, S11) on one every 64th frames.",
            "6": "As in many similar approaches [22, 23, 20], we use ground truth person bounding boxes for image cropping and the absolute Z of the root joint to do the inverse projection.",
            "7": "The same is not true for detection based approach, like in [20], since in their method the predictions are quantized by the argmax function.",
            "8": "[20] 67.",
            "9": "[20] 96.",
            "10": "[20] G."
        },
        "Weakly-supervised 3D human pose estimation with cross-view U-shaped graph convolutional network": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.10882",
            "ref_texts": "[13] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "13"
            ],
            "1": "[13] introduced a volumetric representation for 3D human poses, while requiring a sophisticating deep network architecture that is impractical in application.",
            "2": "[13] G."
        },
        "Absolute human pose estimation with depth prediction network": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1904.05947",
            "ref_texts": "[6] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in The IEEE Conference on Computer Vision and Pattern Recognition , pp. 1263\u2013",
            "ref_ids": [
                "6"
            ],
            "1": "Most methods relax the problem and only predict the coordinates of the body skeleton relative to a root joint, typically the hip [4]\u2013[6].",
            "2": "[6] predicts a 3D heatmap instead of single coordinates.",
            "3": "[6] G."
        },
        "Learning 2d to 3d lifting for object detection in 3d for autonomous vehicles": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1904.08494",
            "ref_texts": "[17] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "17"
            ],
            "1": "[17] learn to predict 3D human pose from single image using a fine discretization of the 3D space around the subject and predicting per voxel likelihoods for each joint, and using a coarse-to-fine scheme.",
            "2": "[17] G."
        },
        "Image-based synthesis for deep 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1802.04216",
            "ref_texts": "36.G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarseto-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "36"
            ],
            "1": "Recent approaches employ CNNs for 3D pose estimation in monocular images [8,28,36] or in videos [71].",
            "2": "[36] X 58.",
            "3": "[36] X 65.",
            "4": "Only the most recent methods report a better performance [32,36,44,58].",
            "5": "They use accurate 2D joint detectors [32,58] or rely on much more complex architecture [36,44] while we employ a simple AlexNet architecture and return a coarse pose estimate."
        },
        "Metric-scale truncation-robust heatmaps for 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.02953",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-tofine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "35"
            ],
            "1": "5D volumetric representation [35], [46], [15], [23].",
            "2": "bone length priors [35] or a skeleton length prior [44], computed by averaging over the training poses.",
            "3": "5D heatmap learning using bone-length-based scale recovery [35], under otherwise equal training conditions.",
            "4": "have proposed extending 2D heatmaps with a root-relative metric depth axis [35].",
            "5": "Given 2D pixel positions and root relative depth estimates from volumetric heatmaps, they optimize the absolute person distance such that the back-projected skeleton\u2019s bone lengths match the average over the training set in a least squares sense [35].",
            "6": "Centered Striding for Dense Prediction At test time we apply the trained network with an effective stride of 4, to obtain heatmaps with spatial size 64, which is the same size as in [46] and [35].",
            "7": "[35] 67.",
            "8": "Nie [33] Pavlakos [35] Sun [45] Martinez [25] Sun [46] Nibali [32] Habibie [11] Chen [6] 2.",
            "9": "[35] G."
        },
        "Self-supervised 3d human pose estimation with multiple-view geometry": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2108.07777",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarseto-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "Learning-based approaches for 3D human pose estimation still reach the best results with supervised learning [15], [28], [34], [42].",
            "2": "Single-view 3D human pose estimation showed comparable and often better results than multi-view approaches, using deep neural networks [34], [28], [30].",
            "3": "[34] 22.",
            "4": "[34] G."
        },
        "Iterative greedy matching for 3d human pose tracking from multiple views": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2101.09745",
            "ref_texts": "[33] Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Conference on Computer Vision and Pattern Recognition (2017)",
            "ref_ids": [
                "33"
            ],
            "1": "Most existing approaches [19,21,25,26,27,33,38,28,29] address 3D human pose estimation from single images while multi-view 3D human pose estimation [7,23,3,4,12] remains less explored, as obtaining and maintaining a configuration of calibrated cameras is difficult and costly.",
            "2": "There is extensive research in monocular 3D human pose estimation [19,21,25,27,33,38,28,29].",
            "3": "In: European Conference on Computer Vision (2016)\n[33] Pavlakos, G."
        },
        "Lifting monocular events to 3d human poses": {
            "authors": [
                "Gianluca Scarpellini",
                "Pietro Morerio",
                "Alessio Del"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021W/EventVision/papers/Scarpellini_Lifting_Monocular_Events_to_3D_Human_Poses_CVPRW_2021_paper.pdf",
            "ref_texts": "[44] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , page nil, 7 2017. 2,5,6",
            "ref_ids": [
                "44"
            ],
            "1": "The former regresses skeletal 3D joints from a planar image [38,43,44], while the latter fits a tri-dimensional parametric model of the human body to the subjects in the scene [16,3].",
            "2": "Although we can adapt stacked-hourglass models to predict 3D (volumetric) heatmaps [44], this path is widely open for improvements, especially since V olumetric Heatmaps are computational and memory demanding [33].",
            "3": "6m dataset to evaluate monocular Human Pose Estimation methods [43,38,44].",
            "4": "Similar works [43,33,44] evaluate monocular approaches on every64thframe of the recordings.",
            "5": "Moreover, we compare our methodology to state-of-the-art RGB approaches [22,43,44,33].",
            "6": "[44] RGB 71."
        },
        "Poselifter: Absolute 3d human pose lifting network from a single noisy 2d human pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1910.12029",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proc. IEEE Conf. Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034, 2017. 3, 10 Figure 9: Qualitative results of our method are shown for the in-the-wild images of the COCO dataset.",
            "ref_ids": [
                "30"
            ],
            "1": "These outputs exhibit various forms, such as 3D joint coordinates [18], bonebased representations [36], and volumetric heatmaps [30].",
            "2": "9 Pavlakos CVPR\u201917 [30] 67.",
            "3": "7\n[30] G."
        },
        "3d human pose estimation on a configurable bed from a pressure image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1804.07873",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR . IEEE, 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "Two common ConvNet approaches include direct regression to joint labels [14], [21] and regression to discretized confidence maps [15], [16], [18].",
            "2": "[16], who train a ConvNet end-to-end on a 3D confidence voxel space, and Zhou, Zhu et al.",
            "3": "[16] G."
        },
        "Non-local latent relation distillation for self-adaptive 3D human pose estimation": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/018b59ce1fd616d874afad0f44ba338d-Paper.pdf",
            "ref_texts": "[59] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 3",
            "ref_ids": [
                "59"
            ],
            "1": "These models are further categorized into a) one-stage methods [93,73,59,54,60,86] that directly map input image to the 3D pose, and b) two-stage methods [92,48,53,73] that adopt a mapping from the image to an intermediate 2D pose, followed by lifting of 2D-to-3D.",
            "2": "3\n[59] G."
        },
        "Pc-hmr: Pose calibration for 3d human mesh recovery from 2d images/videos": {
            "authors": [
                "Tianyu Luan",
                "Yali Wang",
                "Junhao Zhang",
                "Zhe Wang",
                "Zhipeng Zhou",
                "Yu Qiao"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/16326/16133",
            "ref_texts": "Bogo, F.; Kanazawa, A.; Lassner, C.; Gehler, P.; Romero, J.; and Black, M. J. 2016. Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image. In ECCV. Cai, Y .; Ge, L.; Liu, J.; Cai, J.; Cham, T.-J.; Yuan, J.; and Thalmann, N. M. 2019. Exploiting Spatial-Temporal Relationships for 3D Pose Estimation via Graph Convolutional Networks. In ICCV. Chen, Y .; Wang, Z.; Peng, Y .; Zhang, Z.; Yu, G.; and Sun, J. 2018. Cascaded Pyramid Network for Multi-Person Pose Estimation. In CVPR. Choi, H.; Moon, G.; and Lee, K. M. 2020. Pose2Mesh: Graph Convolutional Network for 3D Human Pose and Mesh Recovery from a 2D Human Pose. In ECCV. Ci, H.; Wang, C.; Ma, X.; and Wang, Y . 2019. Optimizing Network Structure for 3D Human Pose Estimation. In ICCV. Georgakis, G.; Li, R.; Karanam, S.; Chen, T.; Kosecka, J.; and Wu, Z. 2020. Hierarchical Kinematic Human Mesh Recovery. In ECCV. Guler, R. A.; and Kokkinos, I. 2019. Holopose: Holistic 3d human reconstruction in-the-wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 10884\u201310894. Hong, S.; Jung, W.; Woo, I.; and Kim, S. W. 2018. Cascaded Pyramid Network for 3D Human Pose Estimation Challenge. arXiv:1810.01616 . Huang, Z.; Xu, Y .; Lassner, C.; Li, H.; and Tung, T. 2020. ARCH: Animatable Reconstruction of Clothed Humans. In CVPR. Ionescu, C.; Papava, D.; Olaru, V .; and Sminchisescu, C. 2014. Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments. IEEE T-PAMI . Kanazawa, A.; Black, M. J.; Jacobs, D. W.; and Malik, J. 2018. End-to-end Recovery of Human Shape and Pose. In CVPR. Kanazawa, A.; Zhang, J. Y .; Felsen, P.; and Malik, J. 2019. Learning 3D Human Dynamics from Video. In CVPR. Kocabas, M.; Athanasiou, N.; and Black, M. J. 2020. VIBE: Video Inference for Human Body Pose and Shape Estimation. In CVPR. Koks, D. 2006. Explorations in mathematical physics: the concepts behind an elegant language. Springer Science & Business Media. Kolotouros, N.; Pavlakos, G.; Black, M. J.; and Daniilidis, K. 2019. Learning to Reconstruct 3D Human Pose and Shape via Modelfitting in the Loop. In ICCV. Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and Black, M. J. 2015. SMPL: A Skinned Multi-Person Linear Model. ACM Trans. Graphics . Martinez, J.; Hossain, R.; Romero, J.; and Little, J. J. 2017. A simple yet effective baseline for 3d human pose estimation. In ICCV. Moon, G.; Chang, J.; and Lee, K. M. 2019. Camera Distance-aware Top-down Approach for 3D Multi-person Pose Estimation from a Single RGB Image. In ICCV.Newell, A.; Yang, K.; and Deng, J. 2016. Stacked Hourglass Networks for Human Pose Estimation. Nikos Kolotouros, Georgios Pavlakos, K. D. 2019. Convolutional Mesh Regression for Single-Image Human Shape Reconstruction. CVPR . Pavlakos, G.; Zhou, X.; and Daniilidis, K. 2018. Ordinal Depth Supervision for 3D Human Pose Estimation. In CVPR. Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In CVPR. Pavllo, D.; Feichtenhofer, C.; Grangier, D.; and Auli, M. 2019. 3D human pose estimation in video with temporal convolutions and semi-supervised training. In CVPR. Rong, Y .; Liu, Z.; Li, C.; Cao, K.; and Change Loy, C. 2019. Delving Deep into Hybrid Annotations for 3D Human Recovery in the Wild. In ICCV. Saito, S.; ; Huang, Z.; Natsume, R.; Morishima, S.; Kanazawa, A.; and Li, H. 2019. PIFu: Pixel-Aligned Implicit Function for HighResolution Clothed Human Digitization. ICCV . Sun, K.; Xiao, B.; Liu, D.; and Wang, J. 2019a. Deep HighResolution Representation Learning for Human Pose Estimation. InCVPR. Sun, X.; Xiao, B.; Wei, F.; Liang, S.; and Wei, Y . 2018. Integral Human Pose Regression. In ECCV. Sun, Y .; Ye, Y .; Liu, W.; Gao, W.; Fu, Y .; and Mei, T. 2019b. Human Mesh Recovery from Monocular Images via a Skeletondisentangled Representation. In ICCV. Tung, H.-Y . F.; Tung, H.-W.; Yumer, E.; and Fragkiadaki, K. 2017. Self-supervised Learning of Motion Capture. In NeurIPS. Varol, G.; Ceylan, D.; Russell, B.; Yang, J.; Yumer, E.; Laptev, I.; and Schmid, C. 2018. BodyNet: V olumetric Inference of 3D Human Body Shapes. In ECCV. Varol, G.; Romero, J.; Martin, X.; Mahmood, N.; Black, M. J.; Laptev, I.; and Schmid, C. 2017. Learning from Synthetic Humans. InCVPR. von Marcard, T.; Henschel, R.; Black, M.; Rosenhahn, B.; and Pons-Moll, G. 2018. Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera. In ECCV. Wang, Z.; Chen, L.; Rathore, S.; Shin, D.; and Fowlkes, C. 2019. Geometric Pose Affordance: 3D Human Pose with Scene Constraints. In Arxiv. Wang, Z.; Shin, D.; and Fowlkes, C. 2020. Predicting Camera Viewpoint Improves Cross-dataset Generalization for 3D Human Pose Estimation. In ECCVW. Zeng, W.; Ouyang, W.; Luo, P.; Liu, W.; and Wang, X. 2020. 3D Human Mesh Regression with Dense Correspondence. In CVPR. Zhang, H.; Cao, J.; Lu, G.; Ouyang, W.; and Sun, Z. 2019a. DaNet: Decompose-and-aggregate Network for 3D Human Shape and Pose Estimation. In ACMMM. Zhang, J. Y .; Felsen, P.; Kanazawa, A.; and Malik, J. 2019b. Predicting 3D Human Dynamics from Video. In ICCV. Zhao, L.; Peng, X.; Tian, Y .; Kapadia, M.; and Metaxas, D. N."
        },
        "Flex: Extrinsic parameters-free multi-view 3d human motion reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.01937",
            "ref_texts": "56. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1263\u20131272. CVPR \u201917, IEEE Computer Society, Washington, DC, USA (2017)",
            "ref_ids": [
                "56"
            ],
            "1": "The first infers 3D locations directly from images or videos [40,56,87,73,71,13,24]."
        },
        "Automatic calibration of the fisheye camera for egocentric 3d human pose estimation from a single image": {
            "authors": [
                "Yahui Zhang",
                "Shaodi You",
                "Theo Gevers"
            ],
            "url": "https://openaccess.thecvf.com/content/WACV2021/papers/Zhang_Automatic_Calibration_of_the_Fisheye_Camera_for_Egocentric_3D_Human_WACV_2021_paper.pdf",
            "ref_texts": "[21] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "21"
            ],
            "1": "In general, existing methods are categorised into two types: (i)Direct 3D human pose estimation from images with full supervision [13, 21, 27, 26, 39] and (ii)\n3D pose estimation from intermediate 2D pose predictions [2, 4, 12, 15, 19, 34, 33, 20, 19, 37]."
        },
        "Deep learning methods for 3D human pose estimation under different supervision paradigms: a survey": {
            "authors": [
                "Dejun Zhang",
                "Yiqi Wu",
                "Mingyue Guo",
                "Yilin Chen"
            ],
            "url": "https://www.mdpi.com/2079-9292/10/18/2267/pdf"
        },
        "Jointformer: Single-frame lifting transformer with error prediction and refinement for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.03704",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "3"
            ],
            "1": "Direct estimation techniques aim to estimate 3D human pose directly from images [3].",
            "2": "[3] G."
        },
        "A kinematic chain space for monocular motion capture": {
            "authors": [
                "Bastian Wandt",
                "Hanno Ackermann",
                "Bodo Rosenhahn"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Wandt_A_Kinematic_Chain_Space_for_Monocular_Motion_Capture_ECCVW_2018_paper.pdf",
            "ref_texts": "32. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric predictionforsingle-image3Dhumanpose. In:Proceedingsoft heIEEEConference on Computer Vision and Pattern Recognition. (2017)",
            "ref_ids": [
                "32"
            ]
        },
        "Pi-net: Pose interacting network for multi-person monocular 3d pose estimation": {
            "authors": [
                "Wen Guo",
                "Enric Corona",
                "Francesc Moreno",
                "Xavier Alameda"
            ],
            "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Guo_PI-Net_Pose_Interacting_Network_for_Multi-Person_Monocular_3D_Pose_Estimation_WACV_2021_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "41"
            ],
            "1": "On one hand, there are algorithms that directly learn the mapping from image features to 3D poses [10, 29, 32, 41, 43].",
            "2": "[41] introduce a U-Net architecture to recover joint-wise 3D heatmaps."
        },
        "Implicit 3D Human Mesh Recovery using Consistency with Pose and Shape from Unseen-view": {
            "authors": [
                "Hanbyel Cho",
                "Yooshin Cho",
                "Jaesung Ahn",
                "Junmo Kim"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Implicit_3D_Human_Mesh_Recovery_Using_Consistency_With_Pose_and_CVPR_2023_paper.pdf",
            "ref_texts": "[44] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017. 2",
            "ref_ids": [
                "44"
            ]
        },
        "Robust Monocular 3D Human Motion With Lasso-Based Differential Kinematics": {
            "authors": [
                "Abed Malti"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/DynaVis/papers/Malti_Robust_Monocular_3D_Human_Motion_With_Lasso-Based_Differential_Kinematics_CVPRW_2023_paper.pdf",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 5",
            "ref_ids": [
                "41"
            ],
            "1": "We use Protocol 1 which uses all the point of views and Protocol 2 which uses only the frontal point of view [5, 41, 51]."
        },
        "Activity recognition with combination of deeply learned visual attention and pose estimation": {
            "authors": [
                "Jisu Kim",
                "Deokwoo Lee"
            ],
            "url": "https://www.mdpi.com/2076-3417/11/9/4153/pdf",
            "ref_texts": "39. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017; pp. 7025\u20137034.",
            "ref_ids": [
                "39"
            ],
            "1": "[39] proposed a stacked hourglass architecture.",
            "2": "[39] and uses much less memory by using the continuous regression function."
        },
        "Unsupervised domain adaptation for 3D human pose estimation": {
            "authors": [],
            "url": "http://zju-capg.org/unsupervised_domain_adaptation/main.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR . 7025\u20137034.",
            "ref_ids": [
                "37"
            ],
            "1": "The first set of models takes images as input and estimate the 3D pose by directly regressing 3D joint coordinates [26] or volumetric heatmaps of joint locations [37].",
            "2": "[37] 71."
        },
        "3D shape reconstruction of semi-transparent worms": {
            "authors": [
                "Thomas P. Ilett",
                "Omer Yuval",
                "Thomas Ranner",
                "Netta Cohen",
                "David C. Hogg"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ilett_3D_Shape_Reconstruction_of_Semi-Transparent_Worms_CVPR_2023_paper.pdf",
            "ref_texts": "[42] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 7025\u20137034. IEEE, July 2017. 2",
            "ref_ids": [
                "42"
            ],
            "1": "Recent progress [35] relies on end-to-end architectures [19, 27, 29, 32, 42, 61] or splitting the problem into 2D pose estimation and then constructing the 3D pose [10, 38]."
        },
        "Single view physical distance estimation using human pose": {
            "authors": [
                "Xiaohan Fei",
                "Henry Wang",
                "Lin Lee",
                "Xiangyu Zeng",
                "Meng Wang",
                "Joseph Tighe"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Fei_Single_View_Physical_Distance_Estimation_Using_Human_Pose_ICCV_2021_paper.pdf",
            "ref_texts": "[42]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "42"
            ],
            "1": "Related Work Single Image 3-D Networks predict depth maps [14,16,17], reconstruct 3-D shapes [46,55,51], or localize 3-D human skeletons [42,56,49,38,5] from single images that can be used in physical distance estimation."
        },
        "PointAtrousGraph: Deep hierarchical encoder-decoder with point atrous convolution for unorganized 3D points": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.09798",
            "ref_texts": "[15] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "15"
            ],
            "1": "Deep hierarchical encoder-decoder architectures are widely and successfully used for many image-based tasks, such as human pose estimation [14], [15], semantic segmentation [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], optical flow estimation [26], [27], and object detection [28], [29], [30].",
            "2": "[15] G."
        },
        "On Triangulation as a Form of Self-Supervision for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.15865",
            "ref_texts": "32. Pavlakos, G., Zhou, X., Derpanis, K., Konstantinos, G., Daniilidis, K.: Coarse-To-Fine V olumetric Prediction for Single-Image 3D Human Pose. In: Conference on Computer Vision and Pattern Recognition (2017) 1",
            "ref_ids": [
                "32"
            ],
            "1": "1 Introduction Supervised approaches in capturing human 3D pose are now remarkably effective, provided that enough annotated training data is available [21, 22, 32, 35, 42, 43, 51, 52]."
        },
        "Structure from recurrent motion: From rigidity to recurrency": {
            "authors": [
                "Xiu Li",
                "Hongdong Li",
                "Hanbyul Joo",
                "Yebin Liu",
                "Yaser Sheikh"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_Structure_From_Recurrent_CVPR_2018_paper.pdf",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 8",
            "ref_ids": [
                "30"
            ],
            "1": "Our method can be applied for 3D human pose recovery, therefore it is related to many work in this domain,[13,31,30,28,20,21].",
            "2": "8\n[30] G."
        },
        "3d human pose estimation via explicit compositional depth maps": {
            "authors": [
                "Haiping Wu",
                "Bin Xiao"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/6923/6777",
            "ref_texts": "2017. Coarse-to-fine volumetric prediction for single-image3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 7025\u20137034. Pavlakos, G.; Zhou, X.; and Daniilidis, K. 2018. Ordinal depth supervision for 3d human pose estimation. In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition , 7307\u20137316. Pavllo, D.; Feichtenhofer, C.; Grangier, D.; and Auli, M.",
            "ref_ids": [
                "2017"
            ]
        },
        "Camera Motion Agnostic Method for Estimating 3D Human Poses": {
            "authors": [
                "Seong Hyun",
                "Ju Yong"
            ],
            "url": "https://www.mdpi.com/1424-8220/22/20/7975/pdf",
            "ref_texts": "2. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
            "ref_ids": [
                "2"
            ]
        },
        "Towards Stable Human Pose Estimation via Cross-View Fusion and Foot Stabilization": {
            "authors": [
                "Jian Cao",
                "Qi Wang",
                "Bang Zhang",
                "Liefeng Bo"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2023/papers/Zhuo_Towards_Stable_Human_Pose_Estimation_via_Cross-View_Fusion_and_Foot_CVPR_2023_paper.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "22"
            ],
            "1": "eters from the holistic features due to the highly nonlinear mapping [22]."
        },
        "Higher-order implicit fairing networks for 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.00950",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "24"
            ],
            "1": "Most existing 3D pose estimation methods use an end-to-end pipeline [20] or a two-stage pipeline [24, 30].",
            "2": "[24] 47."
        },
        "DeepMoCap: Deep optical motion capture using multiple depth sensors and retro-reflectors": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/19/2/282/pdf",
            "ref_texts": "23. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the Computer Vision and Pattern Recognition (CVPR), 21\u201326 July 2017; IEEE: Honolulu, HI, USA, 2017; pp. 1263\u20131272. Sensors 2019 ,19, 282 25 of 26",
            "ref_ids": [
                "23"
            ],
            "1": "In [25], a real-time method that estimates temporally consistent global 3D pose for MoCap from one single-view RGB video is presented, extending top performing single-view RGB convolutional neural network (CNN) methods for MoCap [20,23]."
        },
        "Reposing humans by warping 3D features": {
            "authors": [
                "Markus Knoche",
                "Istvan Sarandi",
                "Bastian Leibe"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPRW_2020/papers/w70/Knoche_Reposing_Humans_by_Warping_3D_Features_CVPRW_2020_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "25"
            ],
            "1": "Inspired by recent volumetric approaches for related tasks [25, 24], we propose a novel reposing method, illustrated in Fig.",
            "2": "A line of works in 3D human pose estimation [25, 35, 19, 30] has shown that it is feasible to predict depth-related information from images in a volumetric representation (in that case volumetric body joint heatmaps), by a tensor reshaping operation.",
            "3": "This is similar to how joint heatmaps are estimated in [25], but instead of heatmaps, we produce a latent feature volume."
        },
        "Self-supervised 3D Human Pose Estimation in Static Video via Neural Rendering": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.04514",
            "ref_texts": "22. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) pp. 1263\u20131272 (2017)",
            "ref_ids": [
                "22"
            ],
            "1": "[22], [31] and [24] fuse multiple 2D heatmaps while [26] and[27] utilize multi-view consistency as a form of additional supervision in the objective function."
        },
        "Liftformer: 3d human pose estimation using attention models": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.00348",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose.\u201d In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017), pp. 1263\u20131272.",
            "ref_ids": [
                "31"
            ],
            "1": "They employ two networks: the former predicts the 3D root relative coordinates by obtaining volumetric heatmaps (introduced by [31]) and applying a 3D soft-argmax .",
            "2": "[31] G."
        },
        "Multi-hypothesis 3D human pose estimation metrics favor miscalibrated distributions": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.11179",
            "ref_texts": "625\u2013632, New York, NY , USA, August 2005. Association for Computing Machinery. Tuomas P. Oikarinen, Daniel C. Hannah, and Sohrob Kazerounian. Graphmdn: Leveraging graph structure and deep learning to solve inverse problems. arXiv [cs.LG] , Oct 2020. doi: 10.48550/ ARXIV .2010.13668. URL http://arxiv.org/abs/2010.13668 . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine volumetric prediction for Single-Image 3D human pose. November 2016. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Harvesting multiple views for marker-less 3d human pose annotations. In CVPR , 2017. Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3D human pose and shape from a single color image. May 2018. Michael Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. The Semantic Web , pp."
        },
        "ASPset: An outdoor sports pose video dataset with 3D keypoint annotations": {
            "authors": [],
            "url": "http://homepage.cs.latrobe.edu.au/zhe/files/aspset_paper_preprint_newest.pdf",
            "ref_texts": "[24] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarseto-fine volumetric prediction for single-image 3D human pose, in: Proc. CVPR, IEEE, 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "24"
            ],
            "1": "Learning from RGB image features There are a number of 3D pose estimation models which map single-view RGB pixel data input to 3D jointcoordinate outputs [21, 22, 23, 24, 25, 26].",
            "2": "[24] G."
        },
        "Semi-perspective decoupled heatmaps for 3d robot pose estimation from depth maps": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.02519",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in Proc. IEEE Conf. Comput. Vis. Pattern Recog. , 2017, pp. 7025\u20137034.[23] X. Ji, Q. Fang, J. Dong, Q. Shuai, W. Jiang, and X. Zhou, \u201cA survey on monocular 3d human pose estimation,\u201d Virtual Reality & Intelligent Hardware , vol. 2, no. 6, pp. 471\u2013500, 2020.",
            "ref_ids": [
                "22",
                "23"
            ],
            "1": "Recently, several works also addressed the task of 3D HPE from single monocular intensity images, such as in [22] where a coarse-to-fine prediction scheme based on volumetric predictions is exploited to compute both the 2D and then the 3D pose.",
            "2": "However, these volumetric methods [23] are often characterized by computational inefficiencies, in terms of complexity and memory requirement, even though some recent works [24] attempt to address this issue.",
            "3": "[22] 18:15 42 :24 61 :60 86 :15 10 :35\u00061:07 7:11\u00060:65 SPDH (ours) HRNet-32 [27] 53:75 79 :75 93 :90 98 :12 6 :62\u00061:53 4:41\u00061:09\n* relative joint positions Fig.",
            "4": "In our experimental validation, we adopt the state-of-the-art method proposed in [22], which predicts a volume with size d\u0002w\u0002h\u2013 withd= 64 \u2013 for each joint and uses its maximum value as the 3D joint location.",
            "5": "[22] G.",
            "6": "[23] X."
        },
        "Learning three-dimensional skeleton data from sign language video": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3377552",
            "ref_texts": "[45] GeorgiosPavlakos,XiaoweiZhou,KonstantinosG.Derpanis,andKostasDaniilidis.2017.Coarse-to-finevolumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 7025\u20137034.",
            "ref_ids": [
                "45"
            ],
            "1": "[45] Yes No No Sequencesimilarity Mehtaetal.",
            "2": "[45]combineConvNetswithavolumetricstacked hourglass approachto achieve an enhanced3D stick figure estimate.",
            "3": "[45] GeorgiosPavlakos,XiaoweiZhou,KonstantinosG."
        },
        "3D Human Pose Lifting with Grid Convolution": {
            "authors": [
                "Yangyuxuan Kang",
                "Yuyang Liu",
                "Anbang Yao",
                "Shandong Wang",
                "Enhua Wu"
            ],
            "url": "https://arxiv.org/pdf/2302.08760",
            "ref_texts": ""
        },
        "Monocular 3D Human Pose Estimation for Sports Broadcasts using Partial Sports Field Registration": {
            "authors": [
                "Tobias Baumgartner",
                "Stefanie Klatt"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/CVSports/papers/Baumgartner_Monocular_3D_Human_Pose_Estimation_for_Sports_Broadcasts_Using_Partial_CVPRW_2023_paper.pdf",
            "ref_texts": "[18] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Rama Chellappa, Zhengyou Zhang, and Anthony Hoogs, editors, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 3",
            "ref_ids": [
                "18"
            ],
            "1": "Another category of methods aims to infer the 3D information of human poses by concurrently predicting the depth of the current image [14, 18, 24, 27]."
        },
        "MocapNET: Ensemble of SNN Encoders for 3D Human Pose Estimation in RGB Images.": {
            "authors": [],
            "url": "https://bmvc2019.org/wp-content/uploads/papers/0710-paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u2013",
            "ref_ids": [
                "47"
            ],
            "1": "Other works are focused in acquiring 3D points from 2D images using either a single [47], or more cameras [19, 48].",
            "2": "6M (H36M) [25] dataset which it is the de facto standard [6, 12, 18, 26, 29, 39, 40, 47, 54, 57, 58, 63, 64, QAMMAZ, ARGYROS: MOCAPNET, AN ENSEMBLE OF SNN ENCODERS 9 Comparison of methods tested on H36M Protocol 1 (Method / MPJPE)\n[25] Our* [18] [29] [6] [82] [79] [83] [64] [57] [66] [26] [54] [12] [40] [47] [61]\n162 136 119 118 116 113 108 107 101 93 88 88 88 82 80 72 40 Table 3: Comparison of the proposed method to others (errors in mm)."
        },
        "Joint voxel and coordinate regression for accurate 3d facial landmark localization": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1801.09242",
            "ref_texts": "[11] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . IEEE, 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "11"
            ],
            "1": "In [11], Pavlakos et al.",
            "2": "[11] introduce the volumetric representation for 3D body joints and show that predicting the joints in a discretized 3D space could be more effective for 3D pose estimation.",
            "3": "The volumetric representation proposed in [11] could be viewed as a natural extension of the 2D heatmap, which is highly demanding for memory and computation.",
            "4": "Though regressing such a representation in a coarse-to-fine manner could alleviate this problem [11], it still cannot avoid the curse of dimensionality when the number of target landmarks increases.",
            "5": "Compact Volumetric Representation for 3D Face Shape Previous works [23], [11] have shown that encoding the landmark positions into the heatmap-like or volumetric representation could provide much more discriminative information than naively concatenating the coordinate vectors of 2D or 3D landmarks.",
            "6": "For 3D landmark localization, the volumetric representation proposed in [11] encodes the position of a specific landmark in a volume with a 3D Gaussian centered around the groundtruth position.",
            "7": "Inspired by previous works [7], [11] on 2D and 3D human pose estimation, we also adopt the stacked hourglass networks [7] with intermediate supervision and skip connection.",
            "8": "As pointed out in [11], the prediction along the zdimension is much more challenging than another two dimensions.",
            "9": "[11] G."
        },
        "View-invariant action recognition from rgb data via 3d pose estimation": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/39033/2/ICASSP_Baptista_toappear.pdf",
            "ref_texts": "[13] Dushyant Mehta, Helge Rhodin, Dan Casas, Oleksandr Sotnychenko, Weipeng Xu, and Christian Theobalt, \u201cMonocular 3D Human Pose Estimation Using Transfer Learning and Improved CNN Supervision,\u201d CoRR , vol. abs/1611.09813, 2016.[14] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "13",
                "14"
            ],
            "1": "Our work builds on the recent effective Convolutional Neural Network (CNN) based methods for the estimation of 3D skeletons from a single RGB image [13, 14, 15].",
            "2": "[13] Dushyant Mehta, Helge Rhodin, Dan Casas, Oleksandr Sotnychenko, Weipeng Xu, and Christian Theobalt, \u201cMonocular 3D Human Pose Estimation Using Transfer Learning and Improved CNN Supervision,\u201d CoRR , vol."
        },
        "Neural animation and reenactment of human actor videos": {
            "authors": [],
            "url": "https://pure.mpg.de/rest/items/item_3004790/component/file_3004791/content",
            "ref_texts": ""
        },
        "Overview of 3d human pose estimation": {
            "authors": [],
            "url": "https://cdn.techscience.cn/ueditor/files/cmes/134-3/TSP_CMES_20857/TSP_CMES_20857.pdf",
            "ref_texts": "26. Pavlakos, G., Zhou, X., Derpanis, K., Daniilidis, K. (2017). Coarse-to-fine volumetric prediction for singleimage 3D human pose. CVPR, 2017, 7025\u20137034. DOI 10.1109/CVPR.2017.139.",
            "ref_ids": [
                "26"
            ],
            "1": "[26] 67."
        },
        "Estimating 3D motion and forces of human\u2013Object interactions from internet videos": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.01591",
            "ref_texts": "31(4):43 3 Moreno-Noguer F (2017) 3d human pose estimation from a single image via distance matrix regression. In: CVPR 2 Newell A, Yang K, Deng J (2016) Stacked hourglass networks for human pose estimation. In: ECCV 2 Newell A, Huang Z, Deng J (2017) Associative embedding: End-to-end learning for joint detection and grouping. In: NIPS 2 Oberweger M, Rad M, Lepetit V (2018) Making Deep Heatmaps Robust to Partial Occlusions for 3D Object Pose Estimation. In: ECCV 3 Pavlakos G, Zhou X, Derpanis KG, Daniilidis K (2017) Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR 2 Posa M, Cantu C, Tedrake R (2014) A direct method for trajectory optimization of rigid bodies through contact. The International Journal of Robotics Research 33(1):69{81 3 Prest A, Ferrari V, Schmid C (2013) Explicit modeling of human-object interactions in realistic videos. PAMI 35(4):835{848 2 Estimating 3D Motion and Forces of Human-Object Interactions from Internet Videos 21 Project webpage (2021) https://www.di.ens.fr/ willow/research/motionforcesfromvideo/ 14, 15 Rad M, Lepetit V (2017) Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In: ICCV 3 Rad M, Oberweger M, Lepetit V (2018) Feature Mapping for Learning Fast and Accurate 3D Pose Inference from Synthetic Images. In: CVPR 3 Rempe D, Guibas LJ, Hertzmann A, Russell B, Villegas R, Yang J (2020) Contact and human dynamics from monocular video. In: European Conference on Computer Vision, Springer, pp 71{87 2 Schultz G, Mombaur K (2010) Modeling and optimal control of human-like running. IEEE/ASME Transactions on mechatronics 15(5):783{792 3 Shimada S, Golyanik V, Xu W, Theobalt C (2020) Physcap: Physically plausible monocular 3d motion capture in real time. ACM Transactions on Graphics (TOG) 39(6):1{16 2 Sidenbladh H, Black MJ, Fleet DJ (2000) Stochastic tracking of 3d human ffgures using 2d image motion. In: ECCV 2 Tassa Y, Erez T, Todorov E (2012) Synthesis and stabilization of complex behaviors through online trajectory optimization. In: IEEE International Conference on Intelligent Robots and Systems (IROS), DOI"
        },
        "Progressive Multi-View Human Mesh Recovery with Self-Supervision": {
            "authors": [
                "Xuan Gong",
                "Liangchen Song",
                "Meng Zheng",
                "Benjamin Planche",
                "Terrence Chen",
                "Junsong Yuan",
                "David Doermann",
                "Ziyan Wu"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/25144/24916",
            "ref_texts": ""
        },
        "Unsupervised cross-dataset adaptation via probabilistic amodal 3D human pose completion": {
            "authors": [
                "Jogendra Nath",
                "Rahul M",
                "Jay Patravali",
                "Venkatesh Babu"
            ],
            "url": "https://openaccess.thecvf.com/content_WACV_2020/papers/Kundu_Unsupervised_Cross-Dataset_Adaptation_via_Probabilistic_Amodal_3D_Human_Pose_Completion_WACV_2020_paper.pdf",
            "ref_texts": "[38] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "38"
            ],
            "1": "Hence, neural networks trained on such datasets [42,38,31,6] yield impressive performance within the same dataset but do not generalize to unknown motion and camera positions.",
            "2": "[38] G."
        },
        "Structure from articulated motion: accurate and stable monocular 3D reconstruction without training data": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/19/20/4603/pdf",
            "ref_texts": "67. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Proceedings of the Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017.",
            "ref_ids": [
                "67"
            ],
            "1": "[67] * 51."
        },
        "3D Pose Estimation and Tracking in Handball Actions Using a Monocular Camera": {
            "authors": [],
            "url": "https://www.mdpi.com/2313-433X/8/11/308/pdf",
            "ref_texts": "23. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, 21\u201326 July 2017; IEEE Computer Society: Los Alamitos, CA, USA, 2017; pp. 1263\u20131272.",
            "ref_ids": [
                "23"
            ],
            "1": "[23] formulate 3D pose estimation as a 3D keypoint localization problem in a voxel space using a convolutional network to create keypoints heatmaps.",
            "2": "[23] Image Single Joint Heatmap Martinez et al."
        },
        "Skeleton transformer networks: 3d human pose and skinned mesh from single rgb image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.11328",
            "ref_texts": "18. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-ffne volumetric prediction for single-image 3d human pose. CoRR , abs/1611.07828, 2016.",
            "ref_ids": [
                "18"
            ],
            "1": ", volumetric [18] and 2D heatmaps + depth [28]) leads to accurate 3D joint predictions.",
            "2": "The benefft of this representation is that it is more eflcient than the volumetric heatmaps [18], while accurately predicting 3D joint positions when trained using Mocap-video dataset (Human 3.",
            "3": "[18] uses a volumetric heatmap representation, which can avoid regressing the real values in a highly nonlinear manner.",
            "4": "From the projected 2D joints, 2D Gaussian maps [18] are obtained and, after convolutions, they are summed up with the feature maps from bone rotation regressor to serve as approximate positions of 2D joints for cross heatmap regressor.",
            "5": "We followed the same evaluation protocol used in previous approaches [18,28] for evaluation, where we use 5 subjects (S1, S5, S6, S7, S8) for training and the rest 2 subjects (S9, S11) for testing.",
            "6": "Volumetric heatamaps [18] can achieve MPJPE approx.",
            "7": "Also, compared with [18] with two stacks of hourglass networks, cross heatmap is more compact, which requires 1/32 of memory spaces to store.",
            "8": "[18] 67.",
            "9": "[18] 83."
        },
        "Towards robust RGB-D human mesh recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.07383",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 3",
            "ref_ids": [
                "41"
            ],
            "1": "Pavlakos [41] extended the stacked Hourglass [37] model to a coarse-to-fine volumetric prediction in 3D space."
        },
        "Multi-person absolute 3D human pose estimation with weak depth supervision": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.03989",
            "ref_texts": "23. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR. pp. 1263{1272 (2017)",
            "ref_ids": [
                "23"
            ],
            "1": "2 Related work 3D Pose Estimation Although various approaches were used for 3D pose estimation, such as dictionary based methods [24,39] or conditional random ffelds [2], recently state-of-the-art results are dominated by deep learning based algorithms [16,18,23,26,34,30].",
            "2": "Methods include regressing 3D joints directly [16], using volumetric heatmaps [23] or including soft-argmax layers [30]."
        },
        "Pre-training Contextualized World Models with In-the-wild Videos for Reinforcement Learning": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.18499",
            "ref_texts": "[45] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-tofine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "45"
            ],
            "1": "[45], which includes a total of 840 videos with 210 scenarios and 4 different viewpoints for each scenario."
        },
        "Consensus-based optimization for 3D human pose estimation in camera coordinates": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.09245",
            "ref_texts": "[37] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. 2, 4, 7",
            "ref_ids": [
                "37"
            ],
            "1": "Many recent works have proposed to directly predict relative 3D poses from images [47, 46, 37], which requires the model to learn a complex projection from 2D pixels to millimeters in three dimensions.",
            "2": "Instead, we predict a normalized depth map d2Rwf\u0002hfper body joint, corresponding to an interval of 2 meters, which is a common reference size in other methods [37].",
            "3": "Poses are composed of 23 body joints, from which 17 are used for evaluation as in the previous work [37, 56].",
            "4": "3\n[37] G."
        },
        "Residual pose: A decoupled approach for depth-based 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.05010",
            "ref_texts": "[17] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "17"
            ],
            "1": "Nowadays, Deep Neural Networks (DNN) have become the mainstream approach, which lead to the emergence of a large number of methods to address 3D pose estimation from color [4], [12], [23] and depth images [7], [17], [15], [19], [22]."
        },
        "Decanus to Legatus: Synthetic training for 2D-3D human pose lifting": {
            "authors": [
                "Yue Zhu",
                "David Picard"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Zhu_Decanus_to_Legatus_Synthetic_training_for_2D-3D_human_pose_lifting_ACCV_2022_paper.pdf",
            "ref_texts": "34. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. CVPR (2017) 1, 3",
            "ref_ids": [
                "34"
            ],
            "1": "Current existing discriminative 3D human pose estimation methods, in which the neural network directly outputs the positions, can be put into two categories: One stage methods which directly estimate the 3D poses inside the world or camera space [29,34], or two stage methods which first estimate 2D human poses in the camera space, then lift 2D estimated skeletons to 3D [18].",
            "2": "Discriminative models can also be categorized into one stage models which predict directly 3D poses from images [14, 25, 29, 34] and two stage methods which first learn a 2D pose estimator, then lift the obtained 2D poses to 3D [18, 28, 45, 48, 49, 52]."
        },
        "Weakly-supervised 3d pose estimation from a single image using multi-view consistency": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1909.06119",
            "ref_texts": "[20] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , 2017Janua:1263\u20131272, nov 2017. ISSN 1155-4304. doi: 10.1109/CVPR.2017.139. URL http://arxiv.org/abs/1611.07828 .",
            "ref_ids": [
                "20"
            ],
            "1": "[20] developed a fully convolutional end-to-end architecture, inspired by [18], which discretizes the 3D space and performs a voxel-by-voxel classification."
        },
        "Orientation keypoints for 6D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.04930",
            "ref_texts": "[51] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "51"
            ],
            "1": "Other approaches perform a direct 3D prediction of keypoints from the images [16], [48], [51], [60].",
            "2": "To overcome this, [51] propose a fine discretization of the 3D space around the subject and train a network to predict per voxel likelihoods for each joint.",
            "3": "[51] 67."
        },
        "Self-supervised multi-view person association and its applications": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1805.08717",
            "ref_texts": "[52] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "52"
            ],
            "1": "While markerless motion tracking has been widely demonstrated in laboratory setups [24], [33], [40], [63] and more recently in general settings [23], [48], [52], [54], thanks to advances in CNN-based body pose detectors [13], [49], these methods showcase the results on activity involving 1 or 2 people staying in a constrained area (never have to reassociate people) with minimal interactions (inter-occlusion is not considered).",
            "2": "[52] G."
        },
        "Deep reconstruction of 3D human poses from video": {
            "authors": [],
            "url": "https://research-repository.uwa.edu.au/files/261511101/JIAN_TAI.pdf",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR . IEEE, 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "3"
            ],
            "1": "Until recently, the techniques used for human pose recovery aimed at predicting skeletal joint configurations from images [1], [2], [3], [4], [5].",
            "2": "[3] proposed a volumetric technique to estimate 3D human poses from a single image.",
            "3": "Convolutional Pose Machines [1] Allows long range co-relations for body parts Less geometric consistency between frames Stacked Hourglass [23] Incorporates visual different scale features Lacks in inter-frame geometric consistency Optical Flow Methods [5], [24] Account for temporal information 2D key points recovery only 2D to 3D Regression [25], [26], [3] Explainable and trackable design Accumulate error from 2D to 3D domain Transfer Learning [27], [2], [4] Allows intermediate supervision Temporal jitters in video sequences Parameterized Models [28], [29], [30], [31], [32] Simultaneous pose and shape recovery Require complex networks Learning from Synthesized Data [9], [33], [10] Availability of training data in large scale Hard to improve data quality the 3D skeleton recovery problem as a CNN pose regression task that follows an optimization process, termed kinematic skeleton fitting.",
            "4": "[3] G."
        },
        "What Face and Body Shapes Can Tell Us About Height.": {
            "authors": [
                "Semih Gunel",
                "Helge Rhodin",
                "Pascal Fua"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCVW_2019/papers/WIDER/Gunel_What_Face_and_Body_Shapes_Can_Tell_Us_About_Height_ICCVW_2019_paper.pdf",
            "ref_texts": ""
        },
        "An end-to-end framework for unconstrained monocular 3D hand pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.12501",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-toFine V olumetric Prediction for Single-Image 3D Human Pose,\u201d arXiv e-prints , p. arXiv:1611.07828, Nov 2016.",
            "ref_ids": [
                "29"
            ],
            "1": "[29] proposes a fine discretization of 3D space around the human body using voxels.",
            "2": "[29] G."
        },
        "Learning temporal 3d human pose estimation with pseudo-labels": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2110.07578",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": "In this course, several approaches [23,21,24,26] adopt an off-the-shelf 2D body pose estimator to predict the 2D joint positions in the image space, followed by a 2D-3D lifting.",
            "2": "Supervised Learning There is a vast literature on 3D human pose estimation based on ground-truth labels [2,33, 21,20,23,24,34,4].",
            "3": "While the current state-of-the-art is completely based on deep neural networks [33,23,24], the prior work also includes graphical models with hand-crafted features, such as pictorial structures models [3].",
            "4": "[23] 67.",
            "5": "1, 4\n[23] G."
        },
        "Regular Splitting Graph Network for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.05785",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in Proc. IEEE Conference on Computer Vision and Pattern Recognition , pp. 7025\u20137034, 2017.",
            "ref_ids": [
                "3"
            ],
            "1": "Existing 3D human pose estimation methods can be broadly categorized into two main streams: single-stage [2] and twostage approaches [3], [4].",
            "2": "[3] 47.",
            "3": "[3] G."
        },
        "Self-supervised multi-view synchronization learning for 3d pose estimation": {
            "authors": [
                "Simon Jenni",
                "Paolo Favaro"
            ],
            "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Jenni_Self-Supervised_Multi-View_Synchronization_Learning_for_3D_Pose_Estimation_ACCV_2020_paper.pdf",
            "ref_texts": "30. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 7025\u2013703 4",
            "ref_ids": [
                "30"
            ]
        },
        "3d human pose estimation from deep multi-view 2d pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1902.02841",
            "ref_texts": "[5] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d CoRR , vol. abs/1611.07828, 2016.",
            "ref_ids": [
                "5"
            ],
            "1": "Approaches exist which perform 3D pose estimation on a single actor in a single image [5], but the range of 3D poses is heavily limited by the training dataset and limbs which are occluded must be inferred rather than directly measured.",
            "2": "For example, [5] uses a modified stacked hourglass to progressively produce 3D pose detections with more and more depth.",
            "3": "[5] G."
        },
        "Lifting 2D Human Pose to 3D with Domain Adapted 3D Body Concept": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.11969",
            "ref_texts": "10,142 Springer Nature 2021 L ATEX template Article Title 15 Newell A, Yang K, Deng J (2016) Stacked hourglass networks for human pose estimation. In: European conference on computer vision, Springer, pp 483{499 Nie Q, Liu Z, Liu Y (2020) Unsupervised 3d human pose representation with viewpoint and pose disentanglement. In: European Conference on Computer Vision, Springer, pp 102{118 Pavlakos G, Zhou X, Derpanis KG, et al (2017) Coarse-to-ffne volumetric prediction for singleimage 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 7025{7034 Pavllo D, Feichtenhofer C, Grangier D, et al (2019)"
        },
        "XFormer: Fast and Accurate Monocular 3D Body Capture": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.11101",
            "ref_texts": "[Pavlakos et al. , 2017 ]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarseto-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "Pavlakos et al\\. , 2017 "
            ]
        },
        "Smplr: Deep smpl reverse for 3d human pose and shape recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.10766",
            "ref_texts": "[19] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 1263\u20131272. IEEE, 2017. 2, 8, 9",
            "ref_ids": [
                "19"
            ],
            "1": "[19] extend SHN to output 3D volumetric data by a coarseto-fine architecture where at each stack the third dimension is linearly increased with 2D heatmaps.",
            "2": "7 Pavlakos [19] 71.",
            "3": "Compared to [19], a fixed small depth resolution of 16 bins in the volumetric heatmap works better than a coarse-to-fine setup.",
            "4": "1, 2, 3, 4, 8\n[19] G."
        },
        "Cross-View Self-fusion for Self-supervised 3D Human Pose Estimation in the Wild": {
            "authors": [
                "Woo Kim",
                "Hee Lee",
                "Seok Oh",
                "Whan Lee"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Kim_Cross-View_Self-Fusion_for_Self-Supervised_3D_Human_Pose_Estimation_in_the_ACCV_2022_paper.pdf",
            "ref_texts": "19. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 7025\u20137034",
            "ref_ids": [
                "19"
            ]
        },
        "Prediction of 3D body parts from face shape and anthropometric measurements": {
            "authors": [
                "Alessio Gallucci",
                "Dmitry Znamenskiy",
                "Milan Petkovic"
            ],
            "url": "https://pure.tue.nl/ws/files/193208437/20200807030233433.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse to-fine volumetric prediction for single -image 3D human pose,\u201d in Proc . the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025 -7034. ",
            "ref_ids": [
                "34"
            ],
            "1": "[34] G."
        },
        "Learning basis representation to refine 3d human pose estimations": {
            "authors": [
                "Chunyu Wang",
                "Haibo Qiu",
                "Alan L. Yuille",
                "Wenjun Zen"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/4920/4793",
            "ref_texts": ""
        },
        "Learning 3-D Human Pose Estimation from Catadioptric Videos.": {
            "authors": [
                "Chenchen Liu",
                "Yongzhi Li",
                "Kangqi Ma",
                "Duo Zhang",
                "Peijun Bao",
                "Yadong Mu"
            ],
            "url": "https://www.ijcai.org/proceedings/2021/0118.pdf",
            "ref_texts": "[Pavlakos et al., 2017 ]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR, 2017.[Pavllo et al., 2019 ]Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In CVPR, 2019.",
            "ref_ids": [
                "Pavlakos et al\\., 2017 ",
                "Pavllo et al\\., 2019 "
            ]
        },
        "Generating Multiple Hypotheses for 3D Human Mesh and Pose Using Conditional Generative Adversarial Nets": {
            "authors": [
                "Xu Zheng",
                "Yali Zheng",
                "Shubing Yang"
            ],
            "url": "https://openaccess.thecvf.com/content/ACCV2022/papers/Zheng_Generating_Multiple_Hypotheses_for_3D_Human_Mesh_and_Pose_using_ACCV_2022_paper.pdf",
            "ref_texts": "34. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017)",
            "ref_ids": [
                "34"
            ],
            "1": "[34] applied the stack hourglass network to estimate every voxel likelihood for each joint."
        },
        "Two-stage rgb-based action detection using augmented 3d poses": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/39789/1/Springer_Lecture_Notes_in_Computer_Science_CAIP.pdf",
            "ref_texts": "20. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. pp. 1263{1272. IEEE (2017)",
            "ref_ids": [
                "20"
            ],
            "1": "This is achieved thanks to the tremendous advances in Convolutional Neural Network (CNN)-based approaches, which have made the estimation of relatively accurate 3D skeletons from a monocular video [17,20,28] possible.",
            "2": "For that purpose, we exploit the recent advances in deep learning which have enabled the development of a wide range of 3D pose estimators from monocular cameras [17,16,20]."
        },
        "Motion capture from pan-tilt cameras with unknown orientation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.11676",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis. Coarse-To-Fine V olumetric Prediction for Single-Image 3D Human Pose. 2017. 1",
            "ref_ids": [
                "29"
            ],
            "1": "Recent deep-learning-based monocular human pose estimation methods are able to reconstruct articulated 3D pose from moving cameras [23, 24, 29, 42, 31, 27, 36, 30, 44, 41, 39, 43], however, only relative to the camera pose and without accurate scale and depth information [14].",
            "2": "1\n[29] G."
        },
        "Deep 3D human pose estimation under partial body presence": {
            "authors": [],
            "url": "https://spectrum.library.concordia.ca/id/eprint/984661/1/cuthesis.pdf",
            "ref_texts": "[55] G. Pavlakos, X. Zhou, K.G. Derpanis, and K. Daniilidis, \\Coarse-to-ffne volumetric prediction for single-image 3d human pose,\" in Proc. IEEE Conf. Computer Vision Pattern Recognition, 2017, pp. 1263{1272.",
            "ref_ids": [
                "55"
            ],
            "1": "3D pose estimation methods directly from 2D images can be categorized to those using a single view for the estimations [55] and those leveraging multi-view imagery[37, 56, 57].",
            "2": "[15, 55]) as opposed to the ones performing on a sequence of images (video) [11, 14].",
            "3": "[15, 55, 60, 61]).",
            "4": "Numerous papers have utilized deep learning concepts to address the problem of 3D human pose estimation[1, 2, 11, 15, 16, 55, 58].",
            "5": "[55] handle the estimation by discretization of the 3D space and regressing per-voxel likelihood for the joints in the discrete 3D space.",
            "6": "[55] G."
        },
        "Depth-aware action recognition: Pose-motion encoding through temporal heatmaps": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.13399",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 2, 3, 8",
            "ref_ids": [
                "30"
            ],
            "1": "[30], on the other hand, approach the task with a unified architecture, derived from the \u2018stacked hourglass network\u2019 [28], that produces a volumetric output featuring per-voxel likelihood for each joint.",
            "2": "[54], as we found it to generalize much better to in-the-wild images, if compared to other tested approaches [30, 55].",
            "3": "Despite our framework could easily be applied to multiple subjects simultaneously, current state-of-the-art 3D human pose predictors process only one subject at a time [54, 30, 32, 39].",
            "4": "2\n[30] G."
        },
        "A view-invariant framework for fast skeleton-based action recognition using a single rgb camera": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/39038/1/AS7135649983488001547138561080_content_1.pdf",
            "ref_texts": "1811. IEEE. Parameswaran, V . and Chellappa, R. (2006). View invariance for human action recognition. International Journal of Computer Vision , 66(1):83\u2013101. Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. (2017). Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 1263\u20131272. IEEE. Poppe, R. (2010). A survey on vision-based human action recognition. Image and vision computing , 28(6):976\u2013",
            "ref_ids": [
                "1811"
            ]
        },
        "A review of 3D human pose estimation from 2D images": {
            "authors": [],
            "url": "http://www.3dbodyscanning.org/cap/papers/2020/2029bartol.pdf",
            "ref_texts": ""
        },
        "Single-shot 3D multi-person pose estimation in complex images": {
            "authors": [
                "Abdallah Benzine",
                "Bertrand Luvison",
                "Quoc Cuong",
                "Catherine Achard"
            ],
            "url": "https://arxiv.org/pdf/1911.03391",
            "ref_texts": "[35] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarse-to-ffne volumetric prediction for single-image 3d human pose, CVPR (2017).",
            "ref_ids": [
                "35"
            ],
            "1": "Recent methods make this prediction directly from monocular images [35, 36, 37, 38, 39, 40, 41] or from sequences of images [42, 43] using Convolutional Neural Networks.",
            "2": "11 Direction Discussion Eating Greet Phone Photo Pose Purchase [35] 67.",
            "3": "1 Sitting SittingD Smoke Wait WalkD Walk WalkT AVG\n[35] 83.",
            "4": "[35] G."
        },
        "Patch-based 3D Human Pose Refinement.": {
            "authors": [
                "Qingfu Wan",
                "Weichao Qiu",
                "Alan L. Yuille"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPRW_2019/papers/Augmented%20Human%20Human-centric%20Understanding%20and%202D-3D%20Synthesis/Wan_Patch-based_3D_Human_Pose_Refinement_CVPRW_2019_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR . IEEE, 2017. 1,2,3,4,5,7",
            "ref_ids": [
                "31"
            ],
            "1": "Introduction The problem of 3D human pose estimation, defined as localizing 3D semantic keypoints of the human body, has enjoyed substantial progress in recent years [35][34][48][31][22][32].",
            "2": "Later [31] showcase a FCN network with volumetric representation.",
            "3": "Specifically we deploy existing algorithms [31][30][35][21][18], which take the entire RGB image that encompasses global context as input, to estimate initial 3D prediction \u02c6X(0)from a monocular RGB image.",
            "4": "We measure pose accuracy in terms of MPJPE\n(mean per joint position error), which has been widely used before [31] [22] [21][48][35].",
            "5": "We experiment with five methods [31][30][35][21][18].",
            "6": "SitDown on [31][21] and Siton [31][30].",
            "7": "When occlusion happens, the additional segmentation cue makes it 69\n Method Direction Discuss Eat Greet Phone Pose Purchase Sit Pavlakos [31] 59.",
            "8": "6 Method SitDown Smoke Photo Wait Walk WalkDog WalkPair Avg Pavlakos [31] 134.",
            "9": "Ablation Study We use the method in Pavlakos [31] to generate initial pose estimate for ablation study.",
            "10": "The result of refinement with cropped RGB patches and with original RGB image input on [31].",
            "11": "Method Direction Discuss Eat Greet Phone Pose Purchase Sit Pavlakos [31] 59.",
            "12": "4 Method SitDown Smoke Photo Wait Walk WalkDog WalkPair Avg Pavlakos [31] 134.",
            "13": "3,4,5\n[31] G."
        },
        "On the exact recovery conditions of 3D human motion from 2D landmark motion with sparse articulated motion": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.03967",
            "ref_texts": "[41] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3d Human Pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "41"
            ],
            "1": "Many authors [34, 43, 41] and [65] propose to directly regress 3D human pose joint location from an image.",
            "2": "As was reported in previous works [52, 41, 10], we use Protocol 1 which uses all the cameras."
        },
        "From kinematics to dynamics: Estimating center of pressure and base of support from video frames of human motion": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2001.00657",
            "ref_texts": "[36] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "36"
            ],
            "1": "Success in 2D human pose estimation also has encouraged researchers to detect 3D skeletons by extending existing 2D human pose detectors [6, 10, 28, 30, 33, 43, 53] or by directly using image features [1, 36, 40, 44, 54].",
            "2": "[36] G."
        },
        "Deductive learning for weakly-supervised 3D human pose estimation via uncalibrated cameras": {
            "authors": [
                "Xipeng Chen",
                "Pengxu Wei",
                "Liang Lin"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/16194/16001",
            "ref_texts": ""
        },
        "Chained representation cycling: Learning to estimate 3D human pose and shape by cycling between representations": {
            "authors": [
                "Nadine Ruegg",
                "Christoph Lassner",
                "Michael Black",
                "Konrad Schindler"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/6008/5864",
            "ref_texts": "5568 Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. CVPR . Pavlakos, G.; Zhou, X.; and Daniilidis, K. 2018. Ordinal depth supervision for 3D human pose estimation. In Proc. CVPR . Popa, A.; Zanfir, M.; and Sminchisescu, C. 2017. Deep Multitask Architecture for Integrated 2D and 3D Human Sensing. In Proc. CVPR . Ramakrishna, V .; Kanade, T.; and Sheikh, Y . 2012. Reconstructing 3d Human Pose from 2d Image Landmarks. Proc. ECCV . Rhodin, H.; Salzmann, M.; and Fua, P . 2018. Unsupervised geometry-aware representation for 3d human pose estimation. arXiv preprint arXiv:1804.01110 . Robinette, K. M.; Daanen, H.; and Paquet, E. 1999. The caesar project: a 3-d surface anthropometry survey. In 2nd 3DIM . Sun, X.; Shang, J.; Liang, S.; and Wei, Y . 2017. Compositional human pose regression. In Proc. ICCV . Tome, D.; Russell, C.; and Agapito, L. 2017. Lifting from the deep: Convolutional 3d pose estimation from a single image. Proc. CVPR . Tulsiani, S.; Efros, A. A.; and Malik, J. 2018. Multi-view consistency as supervisory signal for learning shape and pose prediction. InProc. CVPR . Tung, H.-Y .; Tung, H.-W.; Y umer, E.; and Fragkiadaki, K. 2017. Self-supervised learning of motion capture. In Adv. NeurIPS . V arol, G.; Romero, J.; Martin, X.; Mahmood, N.; Black, M. J.; Laptev, I.; and Schmid, C. 2017. Learning from synthetic humans. InProc. CVPR . V arol, G.; Ceylan, D.; Russell, B.; Yang, J.; Y umer, E.; Laptev, I.; and Schmid, C. 2018. BodyNet: V olumetric inference of 3D human body shapes. In Proc. ECCV . Zanfir, M.; Popa, A.-I.; Zanfir, A.; and Sminchisescu, C. 2018. Human appearance transfer. In Proc. CVPR . Zhang, W.; Zhu, M.; and Derpanis, K. G. 2013. From actemes to action: A strongly-supervised representation for detailed action understanding. In Proc. CVPR . Zhu, J.-Y .; Park, T.; Isola, P .; and Efros, A. A. 2017a. Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proc. ICCV . Zhu, J.-Y .; Zhang, R.; Pathak, D.; Darrell, T.; Efros, A. A.; Wang, O.; and Shechtman, E. 2017b. Toward multimodal image-to-image translation. In Adv. NeurIPS . Zuffi, S.; Kanazawa, A.; Jacobs, D. W.; and Black, M. J. 2017. 3d menagerie: Modeling the 3d shape and pose of animals. In Proc. CVPR ."
        },
        "An integral pose regression system for the ECCV2018 PoseTrack Challenge": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1809.06079",
            "ref_texts": "5. : MPII Leader Board. http://human-pose.mpi-inf.mpg.de 6. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 (2016)",
            "ref_ids": [
                "5"
            ],
            "1": "The best performing methods on 2D pose estimation are all detection-based [5]."
        },
        "Delving Deep into Pixel Alignment Feature for Accurate Multi-view Human Mesh Recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2301.06020",
            "ref_texts": "4362. Lin, K.; Wang, L.; and Liu, Z. 2021. Mesh graphormer. In Proceedings of the IEEE/CVF International Conference on Computer Vision , 12939\u201312948. Lin, T.-Y .; Maire, M.; Belongie, S.; Hays, J.; Perona, P.; Ramanan, D.; Doll \u00b4ar, P.; and Zitnick, C. L. 2014. Microsoft coco: Common objects in context. In European conference on computer vision , 740\u2013755. Springer. Liu, Y .; Stoll, C.; Gall, J.; Seidel, H.-P.; and Theobalt, C. 2011. Markerless motion capture of interacting characters using multiview image segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 1249\u20131256. IEEE. Loper, M.; Mahmood, N.; Romero, J.; Pons-Moll, G.; and Black, M. J. 2015. SMPL: A skinned multi-person linear model. ACM transactions on graphics (TOG) , 34(6): 1\u201316. Mehta, D.; Rhodin, H.; Casas, D.; Fua, P.; Sotnychenko, O.; Xu, W.; and Theobalt, C. 2017. Monocular 3d human pose estimation in the wild using improved cnn supervision. In 2017 international conference on 3D vision (3DV) , 506\u2013516. IEEE. Moon, G.; and Lee, K. M. 2020. I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image. In European Conference on Computer Vision , 752\u2013768. Springer. Omran, M.; Lassner, C.; Pons-Moll, G.; Gehler, P.; and Schiele, B. 2018. Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In 2018 international conference on 3D vision (3DV) , 484\u2013494. IEEE. Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , 7025\u20137034. Petrovich, M.; Black, M. J.; and Varol, G. 2022. TEMOS: Generating diverse human motions from textual descriptions. arXiv:2204.14109. Rong, Y .; Liu, Z.; Li, C.; Cao, K.; and Loy, C. C. 2019. Delving deep into hybrid annotations for 3d human recovery in the wild. In Proceedings of the IEEE/CVF International Conference on Computer Vision , 5340\u20135348. Rong, Y .; Shiratori, T.; and Joo, H. 2021. Frankmocap: A monocular 3d whole-body pose estimation system via regression and integration. In Proceedings of the IEEE International Conference on Computer Vision Workshops . Sengupta, A.; Budvytis, I.; and Cipolla, R. 2021. Probabilistic 3D human shape and pose estimation from multiple unconstrained images in the wild. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , 16094\u201316104. Shin, S.; and Halilaj, E. 2020. Multi-view human pose and shape estimation using learnable volumetric aggregation. arXiv:2011.13427. Shuai, H.; Wu, L.; and Liu, Q. 2022. Adaptive Multi-view and Temporal Fusing Transformer for 3D Human Pose Estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence . Song, J.; Chen, X.; and Hilliges, O. 2020. Human body model fitting by learned gradient descent. In European Conference on Computer Vision , 744\u2013760. Springer. Sun, Y .; Bao, Q.; Liu, W.; Fu, Y .; Black, M. J.; and Mei, T. 2021. Monocular, one-stage, regression of multiple 3d people. In Proceedings of the IEEE/CVF International Conference on Computer Vision , 11179\u201311188. Tian, Y .; Zhang, H.; Liu, Y .; and Wang, L. 2022. Recovering 3d human mesh from monocular images: A survey. arXiv:2203.01923. Tu, H.; Wang, C.; and Zeng, W. 2020. V oxelpose: Towards multicamera 3d human pose estimation in wild environment. In European Conference on Computer Vision , 197\u2013212. Springer. Varol, G.; Ceylan, D.; Russell, B.; Yang, J.; Yumer, E.; Laptev, I.; and Schmid, C. 2018. Bodynet: V olumetric inference of 3d human body shapes. In Proceedings of the European Conference on Computer Vision (ECCV) , 20\u201336. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, \u0141.; and Polosukhin, I. 2017. Attention is all you need. Advances in neural information processing systems , 30. Wu, S.; Jin, S.; Liu, W.; Bai, L.; Qian, C.; Liu, D.; and Ouyang, W.",
            "ref_ids": [
                "4362"
            ]
        },
        "Heuristic weakly supervised 3d human pose estimation in novel contexts without any 3d pose ground truth": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.10996",
            "ref_texts": "(2018) Neural body fitting: Unifying deep learning and model based human pose and shape estimation. In: 2018 international conference on 3D vision (3DV), IEEE, pp 484\u2013494 7 Park S, Hwang J, Kwak N (2016) 3d human pose estimation using convolutional neural networks with 2d pose information. In: European Conference on Computer Vision, Springer, pp 156\u2013169 2 Pavlakos G, Zhou X, Derpanis KG, Daniilidis K (2017) Coarse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp 7025\u20137034"
        },
        "Anatomy and geometry constrained one-stage framework for 3d human pose estimation": {
            "authors": [
                "Xin Cao",
                "Xu Zhao"
            ],
            "url": "http://openaccess.thecvf.com/content/ACCV2020/papers/Cao_Anatomy_and_Geometry_Constrained_One-Stage_Framework_for_3D_Human_Pose_ACCV_2020_paper.pdf",
            "ref_texts": "17. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coa rse-to-fine volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. (2017) 7025\u2013703 4",
            "ref_ids": [
                "17"
            ],
            "1": "[17] proposed a fine discretization of the 3D space around the human body subject and trained a convNet to predict per voxel likelihoods for each joint.",
            "2": "[17] 67.",
            "3": "[17] 83 96."
        },
        "Accurate Human Pose Estimation using RF Signals": {
            "authors": [],
            "url": "http://staff.ustc.edu.cn/~dongheng/dhfiles/2022MMSP-1.pdf",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE conference on computer vision and pattern recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "3"
            ],
            "1": "[3] proposed a volumetric representation for 3D human pose and predicted 3D pose from coarse to fine.",
            "2": "[3] G."
        },
        "3D Keypoint Estimation Using Implicit Representation Learning": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2306.11529"
        },
        "HybrIK-X: Hybrid Analytical-Neural Inverse Kinematics for Whole-body Mesh Recovery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2304.05690",
            "ref_texts": "[11] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d inCVPR , 2017. 1",
            "ref_ids": [
                "11"
            ],
            "1": "Previous 3D keypoint estimation approaches [11], [12], [13] adopt volumetric heatmap as the target representation to learn 3D joint positions in the Cartesian coordinate system.",
            "2": "1, 2, 8, 10, 12\n[11] G."
        },
        "Shape and Pose Estimation for Closely Interacting Persons Using Multi\u2010view Images": {
            "authors": [
                "Kun Li"
            ],
            "url": "https://www.yangangwang.com/papers/LI-SPE-2018-08.pdf"
        },
        "A Hybrid ANN-SNN Architecture for Low-Power and Low-Latency Visual Perception": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.14176",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conf. Comput. Vis. Pattern Recog. (CVPR) , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "38"
            ],
            "1": "Current techniques for 3D HPE involve reconstructing the 3D pose from either single [6, 33, 38, 46, 52, 7] or multiple [22, 15, 8, 41] camera views."
        },
        "Holistic planimetric prediction to local volumetric prediction for 3d human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1706.04758",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016.",
            "ref_ids": [
                "20"
            ],
            "1": "[20], where J is the number of joints, and Dis the discretized size of the depth axis, which becomes 36 as in the proposed method.",
            "2": "[20] G."
        },
        "PoseKernelLifter: Metric Lifting of 3D Human Pose using Sound": {
            "authors": [
                "Zhijian Yang",
                "Xiaoran Fan",
                "Volkan Isler",
                "Hyun Soo"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Yang_PoseKernelLifter_Metric_Lifting_of_3D_Human_Pose_Using_Sound_CVPR_2022_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1, 2",
            "ref_ids": [
                "43"
            ],
            "1": "To address this limitation, human pose priors have been used in existing lifting approaches [6,20,31,34,43,60,75] to reconstruct the plausible 3D pose given the 2D detected pose by predicting relative depths.",
            "2": "Various representations have been proposed to effectively encode the spatial relationship such as volumetric representation [43], graph structure [4,11,72,77], transformer architecture [31,34,75], compact designs for realtime reconstruction [37,38], and inverse kinematics [30]."
        },
        "Monocular human pose and shape reconstruction using part differentiable rendering": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.10873"
        },
        "Deformer: Dynamic Fusion Transformer for Robust Hand Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.04991",
            "ref_texts": "[42] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "42"
            ],
            "1": "Model-free methods [62, 57, 32, 31, 41, 42, 30, 49] directly regress the 3D coordinates or occupancy of hand joints and mesh vertices.",
            "2": "[42] discretizes the 3D space into a voxel grid, and proposed a CNN in the stacked hourglass [39] style to estimate per joint occupancy."
        },
        "Deep learning-based estimation of whole-body kinematics from multi-view images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2307.05896",
            "ref_texts": "11 on Computer Vision (ICCV) , 2659\u20132668. Mehrizi, R., Peng, X., Xu, X., Zhang, S., Li, K., 2019. A deep neural networkbased method for estimation of 3d lifting motions. Journal of biomechanics 84, 87\u201393. Mehrizi, R., Xu, X., Zhang, S., Pavlovic, V ., Metaxas, D.N., Li, K., 2017. Using a marker-less method for estimating l5 /s1 moments during symmetrical lifting. Applied ergonomics 65, 541\u2013550. Mihradi, S., Ferryanto, Dirgantara, T., Mahyuddin, A.I., 2011. Development of an optical motion-capture system for 3d gait analysis. 2011 2nd International Conference on Instrumentation, Communications, Information Technology, and Biomedical Engineering , 391\u2013394. Moon, G., Chang, J.Y ., Lee, K.M., 2018. V2v-posenet: V oxel-to-voxel prediction network for accurate 3d hand and human pose estimation from a single depth map. 2018 IEEE /CVF Conference on Computer Vision and Pattern Recognition , 5079\u20135088. Newell, A., Yang, K., Deng, J., 2016. Stacked hourglass networks for human pose estimation, in: ECCV . Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 1263\u20131272. Pavllo, D., Grangier, D., Auli, M., 2018. Quaternet: A quaternion-based recurrent model for human motion. ArXiv abs /1805.06485. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M.S., Berg, A.C., Fei-Fei, L., 2015. Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115, 211\u2013252. Sun, K., Xiao, B., Liu, D., Wang, J., 2019. Deep high-resolution representation learning for human pose estimation. 2019 IEEE /CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 5686\u20135696. Toshev, A., Szegedy, C., 2014. Deeppose: Human pose estimation via deep neural networks. 2014 IEEE Conference on Computer Vision and Pattern Recognition , 1653\u20131660. Zhou, X., Sun, X., Zhang, W., Liang, S., Wei, Y ., 2016. Deep kinematic pose regression, in: ECCV Workshops. Zhou, Y ., Barnes, C., Lu, J., Yang, J., Li, H., 2019. On the continuity of rotation representations in neural networks. 2019 IEEE /CVF Conference on Computer Vision and Pattern Recognition (CVPR) , 5738\u20135746."
        },
        "Lifting 2d human pose to 3d: A weakly supervised approach": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.01047",
            "ref_texts": "[4] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on . IEEE, 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "4"
            ],
            "1": "Hence, 3d supervised learning methods [4], [7], [9], [19] do not generalize well to datasets in the wild where 3d ground-truth is not present.",
            "2": "Almost all the recent methods for monocular 3d pose estimation fall under one of these three approaches (i) Estimating 3d pose from images directly using full 3d supervision [3], [4], Fig."
        },
        "Evaluating an accelerometer-based system for spine shape monitoring": {
            "authors": [],
            "url": "https://cg.cs.uni-bonn.de/backend/v1/files/publications/2018_ICCSA_PostureSensei_Preprint.pdf",
            "ref_texts": "23. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, IEEE (2017) 1263{1272",
            "ref_ids": [
                "23"
            ],
            "1": "To overcome the disadvantages of complex hardware settings (number of cameras, 42 and more markers need to be attached for full body capturing), the computer vision community is developing many approaches to compute 3D reconstructions of human poses without markers from single images of video sequences [23,24]."
        },
        "Overview of Methods for 3D Reconstruction of Human Models with Applications in Fashion E-Commerce": {
            "authors": [],
            "url": "http://e-university.tu-sofia.bg/e-publ/files/10385_ICEST_2021_paper_40.pdf",
            "ref_texts": "[9] G.Pavlakos, X.Zhou, K.G.Derpanis and K.Daniilidis, \u201dCoarseto-fine volumetric prediction for single-image 3d human pose\u201d, IEEE Conference onComputer Vision and Pattern Recognition, ",
            "ref_ids": [
                "9"
            ],
            "1": "[9] suggested a voxel relaxation technique that replaces joint coordinates with voxel representation, as well as a coarse-to-fine learning strategy, to reduce the regression computation time.",
            "2": "Fua, \n\u201cStructured prediction of 3d human pose with deep neural networks\u201d, arXiv preprint, 2016; \n[9] G."
        },
        "Structured output prediction and learning for deep monocular 3d human pose estimation": {
            "authors": [],
            "url": "https://inria.hal.science/hal-01672592/document",
            "ref_texts": "13.Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 (2016)",
            "ref_ids": [
                "13"
            ],
            "1": "Inherently 3D approaches [13,14] discretize the depth ?Kinauer, S.",
            "2": "This was recently shown in [13] to deliver results that are largely superior over previous 2-stage approaches.",
            "3": "[13]353."
        },
        "FuRPE: Learning Full-body Reconstruction from Part Experts": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2212.00731",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "33"
            ],
            "1": "Direct prediction methods [28, 29, 33, 36] directly predict the 3D keypoints from the input image, which is very straight forward."
        },
        "Explicit spatiotemporal joint relation learning for tracking human pose": {
            "authors": [
                "Xiao Sun",
                "Chuankang Li",
                "Stephen Lin"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/HANDS/Sun_Explicit_Spatiotemporal_Joint_Relation_Learning_for_Tracking_Human_Pose_ICCVW_2019_paper.pdf",
            "ref_texts": "[47] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016. 6,8",
            "ref_ids": [
                "47"
            ],
            "1": "For this benchmark, we employ the most widely used evaluation protocol in the literature [6,59,40,76,30, 37,47,70,50,2,75,58,73,56,51].",
            "2": "Method Zhou [75]Tekin [58]Xingyi [73]Sun [54]Pavlakos [47]Sun [56]Lin [33]\u2217Coskun [10]\u2217Ours\u2217 MPJPE 113.",
            "3": "1,2\n[47] G."
        },
        "HopFIR: Hop-wise GraphFormer with Intragroup Joint Refinement for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2302.14581",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "24"
            ],
            "1": "The first category of networks regresses 3D human joints directly from the image [24, 46].",
            "2": "[24] adopted a CNN to predict the voxel-wise likelihoods for each joint, and Zhou et al."
        },
        "A Distributed Real-time 3D Pose Estimation Framework based on Asynchronous Multiviews": {
            "authors": [],
            "url": "https://itiis.org/journals/tiis/digital-library/manuscript/file/38401/TIIS%20Vol%2017,%20No%202-15.pdf",
            "ref_texts": "[5] G. Pavlakos, X. Zhou, K. G. Derpanis and K. Daniilidis, \u201cCoarse -to-Fine Volumetric Prediction for Single -Image 3D Human Pose,\u201d in Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, Hawaii, USA, pp. 1 -10, 2017. Article (CrossRef Link) ",
            "ref_ids": [
                "5"
            ],
            "1": "introduced deep CNNs based on the stacked hourglass architecture, instead of 2D pose regression , to infer 3D pose [5].",
            "2": "Article (CrossRef Link) \n[5] G."
        },
        "Bootstrapping Human Optical Flow and Pose": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.15121",
            "ref_texts": "[27] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "27"
            ],
            "1": "As in [19] and [27], we down-sample the videos from 50 fps to 10 fps."
        },
        "Permutation-invariant relational network for multi-person 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.04913",
            "ref_texts": "[26] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "26"
            ],
            "1": "[26] G."
        },
        "HSTFormer: Hierarchical Spatial-Temporal Transformers for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2301.07322",
            "ref_texts": "[23] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "23"
            ],
            "1": "Direct estimation approaches [13, 23] designed end-to-end frameworks to estimate the joints\u2019 3D coordinates directly from images or videos without intermediate 2D pose representations, which are straightforward ways but remain challenges due to the lack of sufficient 3D in-the-wild data."
        },
        "HEMlets posh: learning part-centric heatmap triplets for 3D human pose and shape estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.04894",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017. 1, 2, 7",
            "ref_ids": [
                "32"
            ],
            "1": "A straightforward strategy is to use volumetric heatmaps to represent the likelihood map of each 3D joint location [32].",
            "2": "To further bridge the gap between the 2D image and the target 3D human pose under estimation, some recent works [31], [32], [39], [42] proposed to involve 3D-aware states for intermediate supervisions.",
            "3": "A volumetric representation for 3D jointheatmaps is proposed in [32], with which the 3D pose is regressed in a coarse-to-fine manner.",
            "4": "We follow the standard protocol as in [24], [32], and use 5 subjects (S1, S5, S6, S7, S8) for training and the rest 2 subjects (S9, S11) for evaluation (referred to as Protocol #1)."
        },
        "Three-dimensional (3D) pose estimation from a monocular camera": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/a6/7f/3c/725963d3962dce/US11488418.pdf",
            "ref_texts": " Panteleris , P. , Argyros , A .: Back to RGB : 3D tracking of hands and hand object interactions based on short baseline stereo . In : arXiv preprint arXiv : 1705.05301 . In : (2017 ) 1 . Sun , X. , Shang , J. , Liang , S. , Wei , Y .: Compositional human pose regression . In : ICCV . (2017 ) 2 , 3 , 10 , 15 . Pavlakos , G. , Zhou , X. , Derpanis , K.G. , Daniilidis , K .: Coarse to fine volumetric prediction for single image 3D human pose . In : CVPR . (2017 ) 2 , 3 , 4 , 7 . Panteleris , P. , Oikonomidis , I. , gyros , A .: Using a single RGB "
        },
        "Learning Explicit Contact for Implicit Reconstruction of Hand-held Objects from Monocular Images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.20089",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "38"
            ],
            "1": ", meshes [16,50], point clouds [41,42] or voxels [11,38,43]) and use deep neural networks to predict them."
        },
        "GLA-GCN: Global-local Adaptive Graph Convolutional Network for 3D Human": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2307.05853",
            "ref_texts": "[49] Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. Ordinal depth supervision for 3d human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7307\u20137316, 2018.[50] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "49",
                "50"
            ],
            "1": ", pelvis) and the ground truth 3D pose joints collected via motion capture, which follows [84, 60, 50].",
            "2": "[49] (CVPR\u201918) 48.",
            "3": "[49] (CVPR\u201918) 18.",
            "4": "[49] (CVPR\u201918) 34."
        },
        "Towards holistic real-time human 3d pose estimation using mocapnets": {
            "authors": [],
            "url": "https://scholar.archive.org/work/dtqam6yrdbg43l27zoicpqdrg4/access/wayback/https://www.bmvc2021-virtualconference.com/assets/papers/1334.pdf",
            "ref_texts": ""
        },
        "Multi-person 3D pose estimation from unlabelled data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2212.08731",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , vol. 2017-January, pp. 1263\u20131272, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": "Many of them retrieve 3D human poses from monocular views [22], [23], [24], though they suffer from the unavoidable ill-posed problem of having several potential 3D poses from a single 2D representation.",
            "2": "the variety and amount of data could be much larger), self or semi-supervised learning methods have been studied in many works [31], [23], [32], [27].",
            "3": "[23] G."
        },
        "ConvFormer: Parameter Reduction in Transformer Models for 3D Human Pose Estimation by Leveraging Dynamic Multi-Headed Convolutional Attention": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2304.02147",
            "ref_texts": "[9]G. Pavaalkos, X. Zhou, K. G. Derpanis, and K. Daniilidis, Coarse-to-fine volumetric prediction for single-image 3d human pose, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), (2017), 7025-7034.",
            "ref_ids": [
                "9"
            ],
            "1": "2 Prior Works At the outset of leveraging deep neural networks for 3D HPE, many methods attempted to learn mappings from monocular RGB images to 3D skeletal representations [9,44].",
            "2": "[9] 34.",
            "3": "[9] 22.",
            "4": "[9]G."
        },
        "Fbi-pose: Towards bridging the gap between 2d images and 3d human poses using forward-or-backward information": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1806.09241",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "[20] represented 3D joints in a volume and utilized a set of 3D deconvolutional layers for pose prediction in a coarse-to-fine way.",
            "2": "[20] 67.",
            "3": "[20] 83.",
            "4": "[20] 47.",
            "5": "[20] 61.",
            "6": "[20] G."
        },
        "PoP-Net: Pose over Parts Network for Multi-Person 3D Pose Estimation from a Depth Image": {
            "authors": [
                "Yuliang Guo",
                "Zhong Li",
                "Zekun Li",
                "Xiangyu Du",
                "Shuxue Quan",
                "Yi Xu"
            ],
            "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Guo_PoP-Net_Pose_Over_Parts_Network_for_Multi-Person_3D_Pose_Estimation_WACV_2022_paper.pdf",
            "ref_texts": "[23] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": "There are methods mostly relying on a single image to predict human poses [35, 23, 17] and others based on multiple cameras [27, 5].",
            "2": "predicting multiple poses [3, 16, 37] while others are focusing on single person [35, 19, 23]."
        },
        "Multi-technology correction based 3D human pose estimation for jump analysis in figure skating": {
            "authors": [],
            "url": "https://www.mdpi.com/2504-3900/49/1/95/pdf",
            "ref_texts": "5. Pavlakos, G.; Zhou, X.W.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for singleimage 3d human pose. In Proceeding of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR), Honolulu, HI , USA, 21\u201326 July 2017; pp. 7025\u20137034. ",
            "ref_ids": [
                "5"
            ],
            "1": "Then, according to the prior information such as the length of the bone, to calculate the final 3D pose is done by adding the 3D coordinates of the reference point to the estimated relative coordinates [5,6]."
        },
        "Fast on-board 3d torso pose recovery and forecasting": {
            "authors": [],
            "url": "https://www.cs.cmu.edu/~abhijatb/assets/IROS_torso_pose.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR , pp. 1263\u20131272, IEEE, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "[34] G."
        },
        "K-Order Graph-oriented Transformer with GraAttention for 3D Pose and Shape Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.11328",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "43"
            ],
            "1": "Pavlakos [43] CVPR\u201917 67."
        },
        "Cross-view person identification by matching human poses estimated with confidence on each body joint": {
            "authors": [
                "Guoqiang Liang",
                "Xuguang Lan",
                "Kang Zheng",
                "Song Wang",
                "Nanning Zheng"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/12236/12095",
            "ref_texts": "3D pose from motion for crossview action recognition via nonlinear circulant temporal encoding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 26012608. Insafutdinov, E.; Andriluka, M.; Pishchulin, L.; Tang, S.; Levinkov, E.; Andres, B et al. 2017. ArtTrack: Articulated Multiperson Tracking in the Wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 6457-6465. Ionescu, C.; Papava, D.; Olaru, V.; and Sminchisescu, C. 2014. Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE transactions on Pattern Analysis and Machine Intelligence , 36(7): 1325-1339. Jammalamadaka, N.; Zisserman, A.; Eichner, M.; Ferrari, V.; and Jawahar, C. V. 2012. Has my algorithm succeeded? an evaluator for human pose estimators. In European Conference on Computer Vision . 114-128. Springer, Berlin, Heidelberg. Li, S. and Chan, A. B. 2014. 3d human pose estimation from monocular images with deep convolutional neural network. In Asian Conference on Computer Vision , 332-347. Springer, Cham. Li, W. and Wang, X. 2013. Locally aligned feature transforms across views. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . 3594-3601. Newell, A.; Yang, K.; and Deng, J. 2016. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision , 483-499. Springer International Publishing. Pavlakos, G.; Zhou, X.; Derpanis, K. G.; and Daniilidis, K. 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 7025-7034. Tekin, B.; Katircioglu, I.; Salzmann, M.; Lepetit, V.; and Fua, P. "
        },
        "System for estimating a three dimensional pose of one or more persons in a scene": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/87/60/fe/2e9c24e672d8ef/US11521373.pdf",
            "ref_texts": " resentations . (Oct. 2017 ) pp . 1-4 . G. Pavlakos , X. Zhou , and K. Daniilidis . Ordinal depth supervision for 3D human pose estimation . In IEEE Conference on Computer Vision and Pattern Recognition . (Jun . 2018 ) pp . 7307-7316 . G. Pavlakos , X. Zhou , K. G. Derpanis , and K. Daniilidis . Coarse to fine volumetric prediction for single image 3D human pose . In IEEE Conference on Computer Vision and Pattern Recognition . (Jul . 2017 ) pp . 1-10 . G. Pavlakos , X. Zhou , K. G. Derpanis , and K. Daniilidis . Harvesting multiple views for marker less 3d human pose annotations . In IEEE Conference on Computer Vision and Pattern Recognition . (Jul . 2017 ) pp . 6988-6997 . H. Rhodin , J. Sporri , I. Katircioglu , V. Constantin , F. Meyer , E. Muller , M. Salzmann , and P. Fua . Learning monocular 3d human pose estimation from multi view images . In IEEE Conference on Computer Vision and Pattern Recognition . (Mar. 2018 ) pp . 1-10 . G. Rogez , P. Weinzaepfel , and C. Schmid . Lcr net : Localization classification regression for human pose . In IEEE Conference on Computer Vision and Pattern Recognition . (Jul . 2017 ) pp . 3433 "
        },
        "Self-attention network for human pose estimation": {
            "authors": [
                "Hailun Xia",
                "Tianyang Zhang"
            ],
            "url": "https://www.mdpi.com/2076-3417/11/4/1826/pdf",
            "ref_texts": "17. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Proc. International Conference on Computer Vision and Pattern Recognition (CVPR), Venice, Italy, 21\u201326 July 2017; pp. 1263\u20131272.",
            "ref_ids": [
                "17"
            ],
            "1": "The second one directly infers the 3D pose from RGB images [7,17,18].",
            "2": "The authors of [17] proposed a volumetric representation for 3D poses and adopted a coarse-to-fine strategy to refine the prediction.",
            "3": "CoarseToFine \n[17] 67.",
            "4": "There are three main findings: (1) Introducing a self-attention mechanism is effective and the proposed SAN outperforms many different type of methods in terms of results, including the end-to-end method [7,17] and two-stage method [16,19].",
            "5": "CoarseToFine [17] 67."
        },
        "An articulated structure-aware network for 3D human pose estimation": {
            "authors": [],
            "url": "http://proceedings.mlr.press/v101/tang19a/tang19a.pdf",
            "ref_texts": "61 Short Title Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision , pages 483{499, 2016. Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarseto-ffne volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025{7034, 2017. Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. Ordinal depth supervision for 3d human pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7307{7316, 2018. Ibrahim Radwan, Abhinav Dhall, and Roland Goecke. Monocular image 3d human pose estimation under self-occlusion. In Proceedings of the IEEE International Conference on Computer Vision , pages 1888{1895, 2013. Matteo Ruggero Ronchi, Oisin Mac Aodha, Robert Eng, and Pietro Perona. It's all relative: Monocular 3d human pose estimation from weakly supervised data. arXiv preprint arXiv:1805.06880 , 2018. Leonid Sigal, Alexandru O Balan, and Michael J Black. Humaneva: Synchronized video and motion capture dataset and baseline algorithm for evaluation of articulated human motion. International journal of computer vision , 87(1-2):4, 2010. Edgar Simo-Serra, Ariadna Quattoni, Carme Torras, and Francesc Moreno-Noguer. A joint model for 2d and 3d pose estimation from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 3634{3641, 2013. Cristian Sminchisescu. 3d human motion analysis in monocular video: techniques and challenges. In Human Motion , pages 185{211. Springer, 2008. Nitish Srivastava, Geofirey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural networks from overfftting. The Journal of Machine Learning Research , 15(1):1929{1958, 2014. Xiao Sun, Jiaxiang Shang, Shuang Liang, and Yichen Wei. Compositional human pose regression. In Proceedings of the IEEE International Conference on Computer Vision , pages 2602{2611, 2017. Bugra Tekin, Isinsu Katircioglu, Mathieu Salzmann, Vincent Lepetit, and Pascal Fua. Structured prediction of 3d human pose with deep neural networks. arXiv preprint arXiv:1605.05180 , 2016. Juanhui Tu, Mengyuan Liu, and Hong Liu. Skeleton-based human action recognition using spatial temporal 3d convolutional neural networks. In 2018 IEEE International Conference on Multimedia and Expo (ICME) , pages 1{6. IEEE, 2018. Chunyu Wang, Yizhou Wang, Zhouchen Lin, Alan L Yuille, and Wen Gao. Robust estimation of 3d human poses from a single image. In IEEE Conference on Computer Vision and Pattern Recognition , pages 2361{2368, 2014."
        },
        "Multi-task human analysis in still images: 2D/3D pose, depth map, and multi-part segmentation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.03003",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, K.G. Derpanis, K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. CVPR, 2017.",
            "ref_ids": [
                "25"
            ],
            "1": "Following the heatmapsbased methods used in 2D pose estimation [34], we use the target encoding used in [1], [16], [25].",
            "2": "[25] G."
        },
        "Learning unfolded networks with a cyclic group structure": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2211.09238",
            "ref_texts": "6 Learning unfolded networks with a cyclic group structure Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition , 2016. Sergey Iofie and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning , 2015. Diego Marcos, Michele Volpi, Nikos Komodakis, and Devis Tuia. Rotation equivariant vector ffeld networks. In International Conference on Computer Vision , 2017. Ben Mildenhall, Pratul Srinivasan, Matthew Tancik, Jonathan Barron, Ravi Ramamoorthi, and Ren Ng. NeRF: representing scenes as neural radiance ffelds for view synthesis. In European Conference on Computer Vision , 2020. Thanh Nguyen, Raymond Wong, and Chinmay Hegde. On the dynamics of gradient descent for autoencoders. In International Conference on Artiffcial Intelligence and Statistics , 2019. Georgios Pavlakos, Xiaowei Zhou, Konstantinos Derpanis, and Kostas Daniilidis. Coarseto-ffne volumetric prediction for single-image 3D human pose. In IEEE Conference on Computer Vision and Pattern Recognition , 2017. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. OpenAI, 2021. Joseph Redmon and Ali Farhadi. YOLO9000: better, faster, stronger. In IEEE Conference on Computer Vision and Pattern Recognition , 2017. Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \"why should i trust you?\" explaining the predictions of any classiffer. In International Conference on Knowledge Discovery and Data Mining , 2016. Nir Shlezinger, Jay Whang, Yonina Eldar, and Alexandros Dimakis. Model-based deep learning. In arXiv , 2020. Dror Simon and Michael Elad. Rethinking the CSC model for natural images. In Neural Information Processing Systems , 2019. Jeremias Sulam, Aviad Aberdam, Amir Beck, and Michael Elad. On multi-layer basis pursiot, eflcient algorithms and convolutional neural netwroks. IEEE Transactions on Pattern Analysis and Machine Learning , 42(8):1968{1980, 2020. Bahareh Tolooshams, Andrew Song, Simona Temereanca, and Demba Ba. Convolutional dictionary learning based auto-encoders for natural exponential-family distributions. In International Conference on Machine Learning , 2020. Bahareh Tolooshams, Sourav Dey, and Demba Ba. Deep residual autoencoders for expectation maximization-inspired dictionary learning. IEEE Transactions on Neural Networks and Learning Systems , 32(6):2415{2429, 2021."
        },
        "CNN-Based Action Recognition and Pose Estimation for Classifying Animal Behavior from Videos: A Survey": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2301.06187",
            "ref_texts": "[125] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis . 2017. Coarse-to-Fine VolumetricPredictionforSingle-Image3DHumanPose.In 2017IEEEConference onComputerVisionandPatternRecognition(CVPR) .IEEEComputerSociety,Los Alamitos, CA,USA, 1263\u20131272. https://doi.org/10.1109/C VPR.2017.139",
            "ref_ids": [
                "125"
            ],
            "1": "[125] 20173D\u2022Thediscretization of3Dspacearound asubject formonocula r3Dposeestimation.",
            "2": "222\n[125] G."
        },
        "From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2304.00553",
            "ref_texts": "[103] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017.",
            "ref_ids": [
                "103"
            ],
            "1": "A most intuitive representation is the 3D human pose, and lots of effort has been put into single-view 3D pose reconstruction [103, 104, 105, 106].",
            "2": "Some methods [103, 106] directly regress 3D pose from the given image."
        },
        "Pointless Pose: Part Affinity Field-Based 3D Pose Estimation without Detecting Keypoints": {
            "authors": [
                "Jue Wang",
                "Zhigang Luo"
            ],
            "url": "https://www.mdpi.com/2079-9292/10/8/929/pdf",
            "ref_texts": "4. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the Conference on Computer Vision and Pattern Recognition, Honolulu, HI, USA, 21\u201326 July 2017.",
            "ref_ids": [
                "4"
            ],
            "1": "Following [4,13,32,33], we down-sampled the original videos from 50 fps to 10 fps to remove redundancy in both training and evaluation."
        },
        "Explicit Residual Descent for 3D Human Pose Estimation from 2D Joint Locations.": {
            "authors": [],
            "url": "https://www.bmvc2020-conference.com/assets/papers/0151.pdf",
            "ref_texts": "[21] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u2013",
            "ref_ids": [
                "21"
            ],
            "1": "Some works [21, 22, 31] integrate the volumetric representation built upon 2D feature maps with different supervision strategies or regression schemes for single-view 3D pose estimation.",
            "2": "[21] 67.",
            "3": "Walk Jog Box S1 S2 S3 S1 S2 S3 S1 S2 S3 Palvakos[21] 22."
        },
        "Learning Depth-aware Heatmaps for 3D Human Pose Estimation in the Wild.": {
            "authors": [],
            "url": "https://bmvc2019.org/wp-content/uploads/papers/1217-paper.pdf",
            "ref_texts": "[16] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "Existing end-to-end learning approaches attempt to localize 3D coordinates directly from a single image by addressing it as coordinate regression [8, 22], volumetric heatmaps prediction [16, 21] or other variant approaches based on 2D marginal heatmaps [14].",
            "2": "However, high-dimensional representation consumes too much memory and needs to take several training stages to optimize the large-scale network parameters [16].",
            "3": "[16] propose a coarse-to-fine learning procedure for 3D human pose estimation.",
            "4": "It is used in [2, 3, 7, 11, 12, 16, 23, 24, 27, 28, 29].",
            "5": "9 Pavlakos [16] 58."
        },
        "AMPose: Alternately Mixed Global-Local Attention Model for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.04216"
        },
        "Error bounds of projection models in weakly supervised 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2010.12317",
            "ref_texts": "[18] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2016. 1, 2, 3",
            "ref_ids": [
                "18"
            ],
            "1": "They usually build around fully convolutional architectures and spatially encoded regression targets [4, 16, 18, 23].",
            "2": "Identical or similar evaluation protocols are utilized in [14, 18, 24, 27, 28].",
            "3": "1, 3\n[18] G."
        },
        "A Synchronized Reprojection-based Model for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2106.04274",
            "ref_texts": "25.Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "25"
            ],
            "1": "9 Coarse2Fine[25] 67."
        },
        "Optimising 2D Pose Representation: Improve Accuracy, Stability and Generalisability Within Unsupervised 2D-3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.00618",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272, 2017. 2",
            "ref_ids": [
                "28"
            ],
            "1": "The first learns the mapping of 3D joints directly from a 2D image [17, 18, 21, 28, 31]."
        },
        "View Consistency Aware Holistic Triangulation for 3D Human Pose Estimation": {
            "authors": [
                "Xiaoyue Wan",
                "Zhuo Chen",
                "Xu Zhao"
            ],
            "url": "https://arxiv.org/pdf/2302.11301",
            "ref_texts": "7792\u20137801. Gavrila, D.M., Davis, L.S., 1996. 3-d model-based tracking of humans in action: a multi-view approach, in: Proceedings cvpr ieee computer society conference on computer vision and pattern recognition, IEEE. pp. 73\u201380. Guo, Y ., Ma, L., Li, Z., Wang, X., Wang, F., 2021. Monocular 3d multi-person pose estimation via predicting factorized correction factors. Computer Vision and Image Understanding 213, 103278. Habibie, I., Xu, W., Mehta, D., Pons-Moll, G., Theobalt, C., 2019. In the wild human pose estimation using explicit 2d features and intermediate 3d representations, in: Proceedings of the IEEE /CVF conference on computer vision and pattern recognition, pp. 10905\u201310914. Hartley, R., Zisserman, A., 2003. Multiple view geometry in computer vision. Cambridge university press. He, Y ., Yan, R., Fragkiadaki, K., Yu, S.I., 2020. Epipolar transformers, in: Proceedings of the ieee /cvf conference on computer vision and pattern recognition, pp. 7779\u20137788. Hotelling, H., 1933. Analysis of a complex of statistical variables into principal components. Journal of educational psychology 24, 417. Ionescu, C., Papava, D., Olaru, V ., Sminchisescu, C., 2013. Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. IEEE transactions on pattern analysis and machine intelligence 36, 1325\u20131339. Iskakov, K., Burkov, E., Lempitsky, V ., Malkov, Y ., 2019. Learnable triangulation of human pose, in: Proceedings of the IEEE /CVF international conference on computer vision, pp. 7718\u20137727. Kadkhodamohammadi, A., Padoy, N., 2021. A generalizable approach for multi-view 3d human pose regression. Machine Vision and Applications 32, 6. Kendall, A., Martirosyan, H., Dasgupta, S., Henry, P., Kennedy, R., Bachrach, A., Bry, A., 2017. End-to-end learning of geometry and context for deep stereo regression, in: Proceedings of the IEEE international conference on computer vision, pp. 66\u201375. Kocabas, M., Karagoz, S., Akbas, E., 2019. Self-supervised learning of 3d human pose using multi-view geometry, in: Proceedings of the IEEE /CVF conference on computer vision and pattern recognition, pp. 1077\u20131086. Liu, K., Zou, Z., Tang, W., 2020. Learning global pose features in graph convolutional networks for 3d human pose estimation, in: Proceedings of the Asian Conference on Computer Vision.Ma, H., Chen, L., Kong, D., Wang, Z., Liu, X., Tang, H., Yan, X., Xie, Y ., Lin, S.Y ., Xie, X., 2021. Transfusion: Cross-view fusion with transformer for 3d human pose estimation. arXiv preprint arXiv:2110.09554 . Malleson, C., Collomosse, J., Hilton, A., 2020. Real-time multi-person motion capture from multi-view video and imus. International Journal of Computer Vision 128, 1594\u20131611. Martinez, J., Hossain, R., Romero, J., Little, J.J., 2017. A simple yet e fiective baseline for 3d human pose estimation, in: Proceedings of the IEEE international conference on computer vision, pp. 2640\u20132649. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017a. Coarse-to-fine volumetric prediction for single-image 3d human pose, in: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7025\u2013"
        },
        "Parametric human shape reconstruction via bidirectional silhouette guidance": {
            "authors": [
                "Shuang Sun",
                "Chen Li",
                "Zhenhua Guo",
                "Yuwing Tai"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Sun_Parametric_Human_Shape_Reconstruction_via_Bidirectional_Silhouette_Guidance_ICCVW_2019_paper.pdf",
            "ref_texts": "[28] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proc. of Computer Vision and Pattern Recognition , 2017. 2,5,6",
            "ref_ids": [
                "28"
            ],
            "1": "The depth information of a 3D joint can be further refined using a coarse-tofine scheme [28] or supervised by ordinal depth relation label [27].",
            "2": "6M [28,29,14].",
            "3": "[28] 71.",
            "4": "2,5\n[28] G."
        },
        "Learning dynamics from kinematics: Estimating 2d foot pressure maps from video frames": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1811.12607",
            "ref_texts": ""
        },
        "Copyrobot: Interactive mirroring robotics game for asd children": {
            "authors": [],
            "url": "https://www.politesi.polimi.it/bitstream/10589/145547/3/2018_12_Santos.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "[34], the first to introduce deep learning on 3D poses estimation, used a volumetric approach, learning probability distributions in 3D space from 2D poses.",
            "2": "Basically, they tried to enforce joint dependency during the 2D to 3D inference [34].",
            "3": "[34] G."
        },
        "On the role of depth predictions for 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2103.02521",
            "ref_texts": "[26]Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. Coarse-to-ffne volumetric prediction for singleimage 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (2017), pp. 7025{7034.",
            "ref_ids": [
                "26"
            ],
            "1": "[14, 26, 22] are based on the single stage approach while [19, 6, 7, 9, 25, 38] are based on the two stage approach.",
            "2": "[26]Pavlakos, G."
        },
        "Learning Transferable Kinematic Dictionary for 3D Human Pose and Shape Reconstruction": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.00953",
            "ref_texts": "2017. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Pavlakos, G.; Zhu, L.; Zhou, X.; and Daniilidis, K. 2018. Learning to estimate 3D human pose and shape from a single color image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Ramakrishna, V .; Kanade, T.; and Sheikh, Y . 2012. Reconstructing 3d human pose from 2d image landmarks. In European Conference on Computer Vision . Springer. Rogez, G.; and Schmid, C. 2016. Mocap-guided data augmentation for 3d pose estimation in the wild. In Advances in neural information processing systems . Romero, J.; Tzionas, D.; and Black, M. J. 2017. Embodied Hands: Modeling and Capturing Hands and Bodies Together. ACM Transactions on Graphics, (Proc. SIGGRAPH Asia) 36(6).Saini, N.; Price, E.; Tallamraju, R.; Enficiaud, R.; Ludwig, R.; Martinovic, I.; Ahmad, A.; and Black, M. J. 2019. Markerless Outdoor Human Motion Capture Using Multiple Autonomous Micro Aerial Vehicles. In The IEEE International Conference on Computer Vision . Shoemake, K. 1985. Animating rotation with quaternion curves. In ACM SIGGRAPH computer graphics . ACM. Sun, X.; Shang, J.; Liang, S.; and Wei, Y . 2017. Compositional human pose regression. In Proceedings of the IEEE International Conference on Computer Vision . Sun, X.; Xiao, B.; Wei, F.; Liang, S.; and Wei, Y . 2018. Integral human pose regression. In Proceedings of the European Conference on Computer Vision . Tan, V .; Budvytis, I.; and Cipolla, R. 2018. Indirect deep structured learning for 3d human body shape and pose prediction . Toshev, A.; and Szegedy, C. 2014. Deeppose: Human pose estimation via deep neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. Varol, G.; Ceylan, D.; Russell, B.; Yang, J.; Yumer, E.; Laptev, I.; and Schmid, C. 2018. Bodynet: V olumetric inference of 3d human body shapes. In Proceedings of the European Conference on Computer Vision . Wang, C.; Wang, Y .; Lin, Z.; Yuille, A. L.; and Gao, W.",
            "ref_ids": [
                "2017"
            ]
        },
        "Camera Motion Agnostic 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2112.00343",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In CVPR , 2017. 1[32] Georgios Pavlakos, Luyang Zhu, Xiaowei Zhou, and Kostas Daniilidis. Learning to estimate 3d human pose and shape from a single color image. In CVPR , 2018. 2, 3, 4",
            "ref_ids": [
                "31",
                "32"
            ],
            "1": "Introduction 3D human pose estimation [7,11,13,16\u201319,26,28,31,33] is an important topic in computer vision that can be applied to many applications, such as virtual/augmented reality, human action recognition, and human behavior understanding.",
            "2": "The global pose is generally defined on the basis of the camera coordinate system in existing methods [13, 16, 18, 24, 32]; thus, the estimated 3D human pose is coupled to the camera motion.",
            "3": "[13, 18, 29, 32] belong to the model-based approach.",
            "4": "[32] used keypoints and silhouettes as an intermediate representation for predicting SMPL parameters.",
            "5": "Unlike existing methods [13,16,18,24,32], the proposed method generates a global human mesh defined in the world coordinate system by adding the translation to the 3D human mesh Mas follows: Mg(\u0012;ff;T ) =M(\u0012;ff) +T; (1) whereT2R3denotes the global translation, which is one of the outputs of the proposed method."
        },
        "Deep pose consensus networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1803.08190",
            "ref_texts": "9. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-fine volumetric prediction for single-image 3D human pose. In: Proc. of the IEEE Computer Vision and Pattern Recognition. (2017) 1263\u20131272",
            "ref_ids": [
                "9"
            ],
            "1": "[9] proposed a different representation for 3D poses other than 3D coordinates.",
            "2": "3 Pavlakos et al [9] 67.",
            "3": "Following the practices in [9, 11, 14], we evaluated on all subjects, separately in each action.",
            "4": "0 Pavlakos et al [9] 51.",
            "5": "[9] 22.",
            "6": "We also compared the performance of the proposed method on the HumanEva-I data set with various methods [9, 11, 14, 21, 34, 36\u201340]."
        },
        "A comparative study of matrix completion and recovery techniques for human pose estimation": {
            "authors": [],
            "url": "http://users.ics.forth.gr/~argyros/mypapers/2018_06_PETRA_Bautembach.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. 2016. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Computer Vision and Pattern Recognition . https://doi.org/10.1109/CVPR.",
            "ref_ids": [
                "33"
            ],
            "1": "Deep-learning based methods [3,13,14,18,33,38] for human pose estimation use large datasets to learn the space of natural human poses."
        },
        "Residual deep monocular 3D human pose estimation using CVAE synthetic data": {
            "authors": [],
            "url": "https://iopscience.iop.org/article/10.1088/1742-6596/1873/1/012003/pdf",
            "ref_texts": "[14] Pavlakos, G. , Zhou, X. , Derpanis, K. G. , & Daniilidis, K. . (2017). Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. IEEE Conference on C omputer Vision & Pattern Recognition. IEEE. ",
            "ref_ids": [
                "14"
            ],
            "1": "3D coordinates are obtained by direct regression from 2D images[13][14][15].",
            "2": "Pavlakos G, et al[14].",
            "3": "al (2017)[14] 67.",
            "4": "[14] Pavlakos, G."
        },
        "3-D human pose estimation in traditional martial art videos": {
            "authors": [],
            "url": "http://www.ijmlc.org/vol10/943-AM0022.pdf",
            "ref_texts": "[28] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse -tofine volumetric prediction for singleimage 3D human pose,\u201d in Proc. ",
            "ref_ids": [
                "28"
            ],
            "1": "[28] 51.",
            "2": "[28] Yes First, a person box detection component roughly localizes the person in the input RGB image.",
            "3": "[28] Yes For 2D human pose estimation, authors discretize the space around the subject and use a ConvNet to predict pe r voxel likelihoods for each joint from a single color image; a subsequent optimization step to recover 3D pose.",
            "4": "[28] G."
        },
        "3D Human Pose Estimation with a Catadioptric Sensor in Unconstrained Environments Using an Annealed Particle Filter": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/20/23/6985/pdf",
            "ref_texts": "6. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), Venice, Italy, 21\u201326 July 2017; pp. 1263\u20131272.",
            "ref_ids": [
                "6"
            ],
            "1": "[6] proposed a method for fine discretization of the 3D pose by considering the problem as a 3D key point location issue.",
            "2": "[6] Human3."
        },
        "Learning-based 3D human motion capture and animation synthesis": {
            "authors": [],
            "url": "https://publikationen.sulb.uni-saarland.de/bitstream/20.500.11880/36046/1/Thesis_Habibie.pdf",
            "ref_texts": "\u201cBody 2hands: Learning to infer 3d hands from conversational gesture body dynamics.\u201d In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 11865 \u201311874 . Omran, Mohamed, Christoph Lassner, Gerard Pons-Moll, Peter V . Gehler, and Bernt Schiele (Sept. 2018 ). \u201cNeural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation.\u201d In: 3DV. Pavlakos, Georgios, Xiaowei Zhou, and Kostas Daniilidis (2018 ). \u201cOrdinal Depth Supervision for 3D Human Pose Estimation.\u201d In: Computer Vision and Pattern Recognition (CVPR) . Pavlakos, Georgios, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis (2017 ). \u201cCoarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose.\u201d In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . Pavllo, Dario, Christoph Feichtenhofer, David Grangier, and Michael Auli (2019 ). \u201c3D human pose estimation in video with temporal convolutions and semi-supervised training.\u201d In: CVPR . Pham, Hai Xuan, Yuting Wang, and Vladimir Pavlovic (2018 ). \u201cEnd-toend Learning for 3D Facial Animation from Speech.\u201d In: ICMI . Pons-Moll, Gerard, David J. Fleet, and Bodo Rosenhahn (2014 ). \u201cPosebits for Monocular Human Pose Estimation.\u201d In: Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) . Columbus, Ohio, USA, pp. 2345 \u20132352 . Rao, K Sreenivasa and KE Manjunath (2017 ).Speech recognition using articulatory and excitation source features . Springer. Rempe, Davis, Tolga Birdal, Aaron Hertzmann, Jimei Yang, Srinath Sridhar, and Leonidas J. Guibas (2021 ). \u201cHuMoR: 3D Human Motion Model for Robust Pose Estimation.\u201d In: International Conference on Computer Vision (ICCV) . Rezende, Danilo and Shakir Mohamed (2015 ). \u201cVariational inference with normalizing flows.\u201d In: International conference on machine learning. PMLR, pp. 1530 \u20131538 ."
        },
        "Learning Monocular 3D Human Pose Estimation With Skeletal Interpolation": {
            "authors": [
                "Ziyi Chen",
                "Akihiro Sugimoto",
                "Hong Lai"
            ],
            "url": "https://openreview.net/pdf?id=m4X_VPt0MKl",
            "ref_texts": "[3] Georgios Pavlakos, Xiaowei Zhou, K. Derpanis, and Kostas Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1263\u20131272, 2017.",
            "ref_ids": [
                "3"
            ],
            "1": "One-stage models [2, 3] simply map perceived intensities to 3D pose representation, whose generalization ability suffers from the limited variation of indoor training pairs."
        },
        "Adversarial learning semantic volume for 2d/3d face shape regression in the wild": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=gafjGfv8uR",
            "ref_texts": "4528 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL. 28, NO. 9, SEPTEMBER 2019 Very recently, instead of adopting the maximum operation, Sun et al. [26] propose to infer the landmark coordinate from its heatmap through the integral operation, which allows endto-end training and shows its effectiveness on human poseestimation. B. 3D Landmark Localization Two-step strategy is one of the popular solutions to 3D landmark localization problems which performs 2D landmarkestimations at first and then predicts the depth information for these 2D landmarks [14]\u2013[16]. On the other hand, Pavlakos et al. [11] introduce the volumetric representation for 3D body joints and show that predicting joints in a discretized 3D space could be more effective for 3D human pose estimation. The volumetric representation proposed in [11] could be viewed as a natural extension of the 2D heatmap, which is highly demanding for memory and computation. Althoughregressing such a representation in a coarse-to-fine manner could alleviate this problem [11], it still cannot avoid the curse of dimensionality when the number of target landmarksincreases. Therefore, this method can not be easily generalized to other 3D object landmark localization problems. In contrast, we propose to encode the positions of all landmarks in a single volume with the dimensionality fixed regardless of the number of landmarks, providing a much more efficient solution forgeneric 3D landmark localization. For 3D landmark localization in the wild, one of the significant challenges is the lack of annotated data. Recently,several attempts have been made to tackle this problem in a weakly supervised manner. For instance, Tung et al. [27] combine adversarial priors with the reconstruction loss from reprojection of 3D predictions for weakly supervised 2D-to-3D lifting. Zhou et al. [17] introduce a geometric constraint for 3D human pose to regularize the learning of 3D pose estimation under the weakly supervised setting. Further, Yang et al. [19] extend it under an adversarial learning framework by introduc-ing a multi-source discriminator to enforce the pose estimator to generate plausible poses on unannotated in-the-wild images. However, little to no work has investigated weakly supervised learning for the task of 3D facial landmark localization. In this work, we treat 2D annotations as weak labels and develop anovel framework to leverage 2D annotated data for 3D facial landmark localization under the weakly supervised setting. C. Adversarial Learning for Dense Prediction As an emerging technique, Generative Adversarial Networks (GANs) [28] have achieved impressive results in various tasks such as image generation and editing. A typical GAN comprises two competing modules: a generator and adiscriminator. The discriminator learns to distinguish between samples produced by the generat or and real samples, while the generator learns to produce samples that are indistinguishable from real ones. Various improvements [29]\u2013[32] have been proposed for more stable and easy training of GANs, andtheir applications are far beyond image generation. Among them, side information [33], [34] and auxiliary tasks [32] are exploited in adversarial learning to enhance performance ofthe generator, which also facilitates traditional tasks such as classification [35] and regression [36]. Moreover, the conditional GANs [31], [37] have been adopted as a generalpurpose solution for dense prediction problems such as imagestyle transfer, image segmentation, human pose estimation and parsing. These problems typically involve pixel-level mapping from input images to structured label maps, which has inher-ent relationships with heatmap regression based methods for landmark localization. For image segmentation, Hung et al. [38] design a fullyconvolutional discriminator to enforce the outputs of the segmentation network more spatially close to the ground-truth,so that unlabeled images can be leveraged to enhance the segmentation model. Similar ideas have also been applied in human parsing. Liu et al. [39] introduce adversarial networks on both feature maps and structured labels for crossdomain human parsing. Luo et al. [40] develop the MacroMicro adversarial network to e nforce the local and semantic consistency of the parsing results. For human pose estimation, Chou et al. [41] propose to impose the adversarial loss upon heatmaps, which encourages the pose estimator to produce reasonable poses. Chen et al. [42] design a multi-task network to generate both pose heatmaps and occlusion heatmaps,where two discriminators are adopted to distinguish between plausible estimations and implausible ones. The key to the success of the previous work is the idea of the adversarial learning strategy that helps the produced label maps more geometrically reasonable. In this work, we exploit adversariallearning to encourage the predicted volumes, which could be viewed as label maps with 3D structures, to be more geometrically reasonable under t he weakly supervised setting. III. M ETHOD As illustrated in Fig. 1, the backbone of the proposed method consists of two parts, i.e. a volume estimator and a coordinate regressor. In addition, an auxiliary regression volume discriminator is proposed for adversarial training of our network. In the following subsections, we firstly introducethe proposed volumetric representation for the 3D face shape, then we present the joint voxel and coordinate regression for unified 2D and 3D landmark localization. Finally, we describethe adversarial training strategy for 3D landmark localization in a weakly supervised manner. A. Semantic Volumetric Representation Previous works [11], [43] have shown that encoding the landmark positions into heatmap-like or volumetric representations could provide much more discriminative information than naively concatenating the coordinate vectors of 2D or 3Dlandmarks. This kind of dense supervision makes it easier for fully convolutional networks to learn pixel to pixel mappings, and has been widely used in tasks such as facial landmark localization [8] and human pose estimation [10], [43]. For 3D landmark localization, the volumetric representation proposed in [11] encodes the position of a specific landmark in a volume with a 3D Gaussian centered around the ground truth position. This idea extends the typically used 2D Authorized licensed use limited to: INSTITUTE OF AUTOMATION CAS. Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore. Restrictions apply. ZHANG et al. : ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4529 Fig. 1. Illustration of the proposed framework. The backbone network of our method consists of a volume estimator Gand a coordinate regressor P. Besides, an auxiliary regression volume discriminator Dis employed to encourage the volume estimator to ge nerate plausible volumes, where the encoder of the auto-encoder based discriminator sha res weights with the coordinate regressor. heatmap in a natural manner, wh ich leads to a representation with much larger dimensionality. Although regressing sucha representation in a coarse-to-fine manner could alleviate this problem, the curse of dimensionality cannot be avoided when the number of target landmarks increases. Instead ofrepresenting each landmark individually in a single volume, we propose the semantic volumetric representation to encode positions of all target landmarks in a more compact manner while preserving their semantic relationship through different colors. Specifically, for the 3D face shape swith Ntarget landmarks {s n}N n=1,Ndifferent colors {cn}N n=1are bound with each landmark, where cn=[cn 1,cn 2,cn 3]is a triplet denoting the color value of R, G and B channel for the n-th landmark respectively. Coordinates of all target landmarks are converted into a colored (i.e. 3 channels in this case) 3D volume Vwith the size of w\u00d7h\u00d7d.L e t Vl,i,j,kdenote the l-th channel color value of the voxel located at (i,j,k).F o rt h e n-th landmark located at sn=(xn,yn,zn), its contribution to Vl,i,j,kcan be written as: vn l,i,j,k=cn l1",
            "ref_ids": [
                "26",
                "14",
                "16",
                "11",
                "11",
                "11",
                "27",
                "17",
                "19",
                "28",
                "29",
                "32",
                "33",
                "34",
                "32",
                "35",
                "36",
                "31",
                "37",
                "38",
                "39",
                "40",
                "41",
                "42",
                "11",
                "43",
                "8",
                "10",
                "43",
                "11"
            ],
            "1": "28, NO.",
            "2": "9, SEPTEMBER 2019 Adversarial Learning Semantic V olume for 2D/3D Face Shape Regression in the Wild Hongwen Zhang ,Q iL i , and Zhenan Sun ,Senior Member, IEEE Abstract \u2014 Regression-based methods have revolutionized 2D landmark localization with the exploitation of deep neuralnetworks and massive annotated datasets in the wild.",
            "3": "For 2D facial landmark localization, nearly-saturated performance [1], [2] has been achieved on Manuscript received October 5, 2018; revised February 25, 2019; accepted April 3, 2019.",
            "4": "Date of publication April 19, 2019; date of current version July 16, 2019.",
            "5": "This work was supported in part by the National NaturalScience Foundation of China under G rant U1836217, Grant 61427811, Grant 61573360, Grant 61721004, Grant 61702513, and Grant 61806197, and in part by the National Key Research and Development Program of China under Grant 2017YFC0821602 and Grant 2016YFB1001000.",
            "6": "Sun are with the Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern Recognition, Instituteof Automation, Chinese Academy of Sciences, CAS Center for Excellence in Brain Science and Intelligence Tec hnology, Beijing 100190, China, and also with the University of Chinese Academy of Sciences, Beijing 101408, China(e-mail: hongwen.",
            "7": "Li is with the Center for Research on Intelligent Perception and Computing, National Laboratory of Pattern R ecognition, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China (e-mail: qli@nlpr.",
            "8": "Digital Object Identifier 10.",
            "9": "1109/TIP.",
            "10": "2019.",
            "11": "2911114near-frontal face images tha nks to the exploitation of deep neural networks and the availability of massive annotated facedatasets.",
            "12": "On the other hand, heatmap regression based methods [2], [8] estimate the heatmap for each individual landmark instead.",
            "13": "The heatmap regression strategy avoids the inefficient learning of non-linear mapping from feature space to landmark posi-tions, thus has greatly facilitated solving landmark localization problems including face alignment [2], [8] and human pose estimation [9], [10].",
            "14": "In [11], Pavlakos it et al.",
            "15": "Although existing methods could produce reliable results for those synthetic datasets, it is barelysatisfactory when applying them to real-world images due to 1057-7149 \u00a9 2019 I EEE.",
            "16": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "17": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4527 the gap between two domains.",
            "18": "Typical two-step approaches [14]\u2013[16] perform 2D landmark localization at first and then obtain the 3D face shape throughdepth estimation or 3D face model fitting.",
            "19": "There are several attempts to make use of the priorknowledge of geometric structure via designing handcrafted geometric constraints [17], [18].",
            "20": "In addition, adversarial learning recently is also exploited to i mprove the performance of 3D human pose estimation [19].",
            "21": "Compared with the conventional volumetric representation [11], the proposed volumetric representation is more compact while still preservingthe semantic information of la ndmarks.",
            "22": "To avoid inefficient learning of the pixel-to-coordinate mapping, heatmap regression based methods [2], [8], [10] cast landmark localization asregressing the heatmaps of landmarks instead of coordinate vectors.",
            "23": "For example,Stacked Hourglass Networks [10] uses the symmetric topology and intermediate supervision, which has been demonstrated to be effective in both applications of human pose estimation [10] and face alignment [2].",
            "24": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "25": "4528 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "26": "28, NO.",
            "27": "9, SEPTEMBER 2019 Very recently, instead of adopting the maximum operation, Sun et al.",
            "28": "[26] propose to infer the landmark coordinate from its heatmap through the integral operation, which allows endto-end training and shows its effectiveness on human poseestimation.",
            "29": "3D Landmark Localization Two-step strategy is one of the popular solutions to 3D landmark localization problems which performs 2D landmarkestimations at first and then predicts the depth information for these 2D landmarks [14]\u2013[16].",
            "30": "[11] introduce the volumetric representation for 3D body joints and show that predicting joints in a discretized 3D space could be more effective for 3D human pose estimation.",
            "31": "The volumetric representation proposed in [11] could be viewed as a natural extension of the 2D heatmap, which is highly demanding for memory and computation.",
            "32": "Althoughregressing such a representation in a coarse-to-fine manner could alleviate this problem [11], it still cannot avoid the curse of dimensionality when the number of target landmarksincreases.",
            "33": "[27] combine adversarial priors with the reconstruction loss from reprojection of 3D predictions for weakly supervised 2D-to-3D lifting.",
            "34": "[17] introduce a geometric constraint for 3D human pose to regularize the learning of 3D pose estimation under the weakly supervised setting.",
            "35": "[19] extend it under an adversarial learning framework by introduc-ing a multi-source discriminator to enforce the pose estimator to generate plausible poses on unannotated in-the-wild images.",
            "36": "Adversarial Learning for Dense Prediction As an emerging technique, Generative Adversarial Networks (GANs) [28] have achieved impressive results in various tasks such as image generation and editing.",
            "37": "Various improvements [29]\u2013[32] have been proposed for more stable and easy training of GANs, andtheir applications are far beyond image generation.",
            "38": "Among them, side information [33], [34] and auxiliary tasks [32] are exploited in adversarial learning to enhance performance ofthe generator, which also facilitates traditional tasks such as classification [35] and regression [36].",
            "39": "Moreover, the conditional GANs [31], [37] have been adopted as a generalpurpose solution for dense prediction problems such as imagestyle transfer, image segmentation, human pose estimation and parsing.",
            "40": "[38] design a fullyconvolutional discriminator to enforce the outputs of the segmentation network more spatially close to the ground-truth,so that unlabeled images can be leveraged to enhance the segmentation model.",
            "41": "[39] introduce adversarial networks on both feature maps and structured labels for crossdomain human parsing.",
            "42": "[40] develop the MacroMicro adversarial network to e nforce the local and semantic consistency of the parsing results.",
            "43": "[41] propose to impose the adversarial loss upon heatmaps, which encourages the pose estimator to produce reasonable poses.",
            "44": "[42] design a multi-task network to generate both pose heatmaps and occlusion heatmaps,where two discriminators are adopted to distinguish between plausible estimations and implausible ones.",
            "45": "Semantic Volumetric Representation Previous works [11], [43] have shown that encoding the landmark positions into heatmap-like or volumetric representations could provide much more discriminative information than naively concatenating the coordinate vectors of 2D or 3Dlandmarks.",
            "46": "This kind of dense supervision makes it easier for fully convolutional networks to learn pixel to pixel mappings, and has been widely used in tasks such as facial landmark localization [8] and human pose estimation [10], [43].",
            "47": "For 3D landmark localization, the volumetric representation proposed in [11] encodes the position of a specific landmark in a volume with a 3D Gaussian centered around the ground truth position.",
            "48": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "49": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4529 Fig.",
            "50": "Inspired by previous works [10], [11] on 2D and 3D human pose estimation, we also adopt the Stacked Hourglass Networks [10] with intermediate supervision and skip connection.",
            "51": "Specifi-cally, the volume estimator consists of Mstacked Hourglass modules [10] of which supervisions are ground-truth volumes denoted as V={V m}M m=1.",
            "52": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "53": "28, NO.",
            "54": "9, SEPTEMBER 2019 Fig.",
            "55": "As pointed out in [11], making accurate prediction along thezdimension is much more challenging than another two dimensions.",
            "56": "2) Coordinate Regressor: Typical coordinate regression based methods predict the coordinate vectors or their incre-ments directly from image features, while typical heatmap regression based methods [8], [10], [44] retrieve the coordinates of landmarks from the peak points of the correspondingheatmaps.",
            "57": "(7) The loss function for the coordinate regressor Pis also unified as: Lcoord(s|V,I)=/braceleftBigg/vextenddouble/vextenddouble[s]2D\u2212[P(V,I)]2D/vextenddouble/vextenddouble2\n2, ifI\u2208I2D\n/bardbls\u2212P(V,I)/bardbl2\n2, ifI\u2208I3D, (8) where [\u00b7]2Ddenotes the operator extracting 2D coordinates from 3D coordinate vector.",
            "58": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "59": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4531 At the fine-tuning stage, the coordinate regressor is attached to the volume estimator, and the whole network is fine-tuned with joint supervision of both ground-truth volumes and coordinate vectors.",
            "60": "Formally, both LrealandLfa k eadopt the voxel-wise mean squared error loss, which could be writtenas: L real(V,I)=M/summationdisplay m=1/vextenddouble/vextenddoubleVm\u2212Dm(V,I)/vextenddouble/vextenddouble2\n2 Lfa k e(\u02c6V,I)=M/summationdisplay m=1/vextenddouble/vextenddouble/vextenddouble\u02c6Vm\u2212Dm(\u02c6V,I)/vextenddouble/vextenddouble/vextenddouble2\n2, (10) Algorithm 1 The Training Process of the Proposed Method where Dm(\u00b7,\u00b7)denotes the m-th volume reconstructed by the discriminator.",
            "61": "As shown in previous work on GAN technique, utilizing side information in the GAN framework could improve the training procedure [32].",
            "62": "Therefore, the overall loss function for training the discriminator is written as follows: L D=/summationdisplay I\u2208I3DLreal(V,I)+\u03bbauxLcoord(s|V,I)\n+/summationdisplay I\u2208I2D\u222aI3D/parenleftBig \u2212\u03bctLfa k e(\u02c6V,I)+\u03bbauxLcoord(s|\u02c6V,I)/parenrightBig , (11) where the weight \u03bbaux is used to balance the auxiliary regression loss and reconstruction loss.",
            "63": "Inspired by previous work [30], [41], we introduce a variable \u03bct\u2208[0,1]to control the learning procedure of the discriminator and generator.",
            "64": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "65": "4532 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "66": "28, NO.",
            "67": "9, SEPTEMBER 2019 Specifically, besides the volume regression loss, the volume estimator Gis optimized with the training signals backpropagated from the discriminator and the coordinate regressor, including the coordinate regression loss Lcoord(s|\u02c6V,I)and the adversarial loss Ladv(\u02c6V,I),w h e r e Ladv(\u02c6V,I)=M/summationdisplay m=1/vextenddouble/vextenddouble/vextenddouble\u02c6Vm\u2212D(\u02c6Vm,I)/vextenddouble/vextenddouble/vextenddouble2\n2.",
            "68": "(14) We also pretrain the volume estimator and coordinate regressor before adopting the adversarial training strategy.",
            "69": "Following the setting of [11], four Hourglass modules are stacked together as the volume estimator (i.",
            "70": "(9), (11) and (14) are set as \u03bb coord=1, \u03bbaux=0.",
            "71": "During training, data augmentation techniques, such as rotation (\u00b140\u00c2\u00b0), scaling (0 .",
            "72": "In the experiments, the network is pre-trained for 20 epochs on a 3D dataset, and then the model is fine-tuned for 10 epochs on the same 3D dataset or trained for 20 epochs on the mixture of 2D and 3D datasets.",
            "73": "Weadopt the ADAM [48] optimiza tion algorithm with an initial learning rate of 2 .",
            "74": "5\u00d710\n\u22124to train the model, and reduce the learning rate to 2 .",
            "75": "5\u00d710\u22125after 20 epochs.",
            "76": "The most time-consuming part of our model is the volume estimator since it takes about 10ms for one Hourglass module to processan image.",
            "77": "The 3DFAW dataset is divided intothree subsets: training set, validation set and test set, containing 13969, 4725 and 4912 face images, respectively.",
            "78": "For each face, 683D landmarks are retrieved from the parameters of the 3D morphable model, using the released code of [13].",
            "79": "org/competitions/10261 Authorized licensed use limited to: INSTITUTE OF AUTOMATION CAS.",
            "80": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "81": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4533 AFLW [54] is a large-scale real-world dataset for facial landmark localization, whic h contains 25,993 faces covering large variations in appearance and environmental conditions.",
            "82": "To obtain 2D landmarks under 3D perspective, we use the algorithm proposed in [2] to augment the annotations to 68 landmarks.",
            "83": "The 68 3D landmarks anno-tated in AFLW2000-3D are consistent with those of 300W-LP.",
            "84": "CVGTCE is proposed in the 3DFAW Challenge and aims at evaluation of the cross-view consistency of the predicted landmarks, which is defined as follows: CVGTCE (s,\u02c6s,p)=1 NN/summationdisplay n=1/vextenddouble/vextenddouble(\u03b1Rsn+t)\u2212\u02c6sn/vextenddouble/vextenddouble 2 ri(16) where the parameter p={\u03b1,R,t}denotes the rigid transformation, i.",
            "85": "scale, rotation and translation, which are obtained by minimizing the follow objective function: {\u03b1,R,t}=arg min \u03b1,R,tN/summationdisplay n=1/vextenddouble/vextenddouble\u02c6sn\u2212/parenleftbig \u03b1Rsn+t/parenrightbig/vextenddouble/vextenddouble 2(17) For evaluation on AFLW2000-3D, the metric is chosen as the Normalized Mean Error (NME), which is defined asthe average point-to-point Euclidean error normalized by the square root of the bounding box size.",
            "86": "Note that the ground truth 3D landmarks of the test set are not available to the participants, and the numbers for all methods are taken from the CodaLab leaderboard and literature [12], [58].",
            "87": "[58] which is built upon a 3D variant of cascaded regression method.",
            "88": "[58], belong to heatmap regression based methods and coordinate regression based methods respectively.",
            "89": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "90": "4534 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "91": "28, NO.",
            "92": "9, SEPTEMBER 2019 TABLE II COMPARISONS OF CROSS VIEW GROUND TRUTH CONSISTENCY ERROR (CVGTCE) AND GROUND TRUTH ERROR (GTE) ON THE TEST SET OF 3DFAW TABLE III COMPARISON OF NORMALIZED MEAN ERROR (NME) ONAFLW2000-3D Fig.",
            "93": "68 landmarks with 3D c oordinate are considered in the evaluation.",
            "94": "68 landmarks with 2D c oordinate are considered in the evaluation.",
            "95": "The comparison with existing methods for 21 and 68 landmarks are shown in Table IV.",
            "96": "The inferior performance on th e evaluation of 21 landmarks is also in part due to the inconsistency of the annotation schemes, since the ground-truth 21 landmarks with visible labels provided in AFLW are not perfectly aligned with the corresponding subset of 68 landmarks.",
            "97": "When considering all 68 landmarks, the testing case is consistent with the trainingand our method outperforms others considerably.",
            "98": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "99": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4535 TABLE IV COMPARISON OF NME (%) ONAFLW2000-3D.",
            "100": "a) Number of hourglass modules: We vary the number of stacked Hourglass modules from 1 to 8 for comprehensive analyses.",
            "101": "The following three subsets selected from the original 68 landmark annotations areused as new target landmark shapes for training and evaluation.",
            "102": "The third subset contains the remaining 51 points after removing the 17 points of the face\u2019s boundary from 68 points.",
            "103": "For fair comparison, the bounding box size calculated from 68 points is used as the normalization distance for the evaluation of all subsets.",
            "104": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "105": "4536 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "106": "28, NO.",
            "107": "9, SEPTEMBER 2019 Fig.",
            "108": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "109": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4537 TABLE VIII\n2D F ACIAL LANDMARK LOCALIZATION PERFORMANCE (NME %) OFAPPROACHES USING DIFFERENT TRAINING STRATEGIES ON AFLW2000-3D TABLE IX\n3D F ACIAL LANDMARK LOCALIZATION PERFORMANCE (NME %) OF APPROACHES ADOPTING ONE-STAGE VERSUS TWO-STAGE TRAINING SCHEME ON AFLW2000-3D Fig.",
            "110": "8.",
            "111": "8.",
            "112": "10.",
            "113": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "114": "4538 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "115": "28, NO.",
            "116": "9, SEPTEMBER 2019 Fig.",
            "117": "11.",
            "118": "10.",
            "119": "11, where we fix one parameter of them and vary another parameter forcomparison.",
            "120": "11a and 11d, increasing either \u03bb advor\u03bbauxhas similar effect on the training procedure.",
            "121": "11b and 11c, where curves of L real are similar, while curves of Lfa k ebecome lower with the increasing of \u03bbadv.",
            "122": "11e and 11f.",
            "123": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "124": ": ADVERSARIAL LEARNING SEMANTIC VOLUME FOR 2D/3D FACE SHAPE REGRESSION IN THE WILD 4539 ACKNOWLEDGMENT The authors would like to thank the associate editor and anonymous reviewers for their constructive comments andsuggestions, and Zhihang Li, Jie Cao, and Dr.",
            "125": "2017, pp.",
            "126": "79\u201387.",
            "127": "2017, pp.",
            "128": "1021\u20131030.",
            "129": "107, no.",
            "130": "177\u2013190, 2014.",
            "131": "532\u2013539.",
            "132": "2014, pp.",
            "133": "1685\u20131692.",
            "134": "4998\u20135006.",
            "135": "2016, pp.",
            "136": "3409\u20133417.",
            "137": "[8] A.",
            "138": ", 2016, pp.",
            "139": "86.",
            "140": "1\u201386.",
            "141": "Cham, Switzerland: Springer, 2016, pp.",
            "142": "717\u2013732.",
            "143": "[10] A.",
            "144": "Cham, Switzerland: Springer, 2016, pp.",
            "145": "483\u2013499.",
            "146": "[11] G.",
            "147": "2017, pp.",
            "148": "7025\u20137034.",
            "149": "Springer, 2016, pp.",
            "150": "511\u2013520.",
            "151": "2016, pp.",
            "152": "146\u2013155.",
            "153": "[14] R.",
            "154": "C h a m , Switzerland: Springer, 2016, pp.",
            "155": "Cham, Switzerland: Springer, 2016, pp.",
            "156": "616\u2013624.",
            "157": "[16] C.",
            "158": "Cham, Switzerland: Springer, 2016, pp.",
            "159": "[17] X.",
            "160": "2017, pp.",
            "161": "398\u2013407.",
            "162": "[18] X.",
            "163": "2017, pp.",
            "164": "[19] W.",
            "165": "2018, pp.",
            "166": "2018, pp.",
            "167": "2202\u20132208.",
            "168": "3476\u20133483.",
            "169": "38, no.",
            "170": "918\u2013930, May 2016.",
            "171": "Cham, Switzerland: Springer, 2016, pp.",
            "172": "2016, pp.",
            "173": "4177\u20134187.",
            "174": "2017, pp.",
            "175": "1831\u20131840.",
            "176": "[26] X.",
            "177": "2018, pp.",
            "178": "529\u2013545.",
            "179": "[27] H.",
            "180": "2017, pp.",
            "181": "4364\u20134372.",
            "182": "[28] I.",
            "183": ", 2014, pp.",
            "184": "2672\u20132680.",
            "185": "[29] J.",
            "186": ", 2017.",
            "187": "(2017).",
            "188": "org/abs/1703.",
            "189": "10717\n[31] M.",
            "190": "(2014).",
            "191": "org/abs/1411.",
            "192": "1784\n[32] A.",
            "193": ", 2017, pp.",
            "194": "2642\u20132651.",
            "195": "[33] T.",
            "196": ", 2016, pp.",
            "197": "2234\u20132242.",
            "198": "[34] X.",
            "199": ", 2016, pp.",
            "200": "2172\u20132180.",
            "201": "[35] Z.",
            "202": ", May 2018, pp.",
            "203": "[36] M.",
            "204": "2018, pp.",
            "205": "2806\u20132810.",
            "206": "[37] P.",
            "207": "2017, pp.",
            "208": "1125\u20131134.",
            "209": "[38] W.",
            "210": ", 2018, p.",
            "211": "[39] S.",
            "212": ", 2018, pp.",
            "213": "7146\u20137153.",
            "214": "[40] Y .",
            "215": "Cham, Switzerland: Springer, 2018, pp.",
            "216": "418\u2013434.",
            "217": "[41] C.",
            "218": "2018, pp.",
            "219": "17\u201330.",
            "220": "[42] Y .",
            "221": "2017, pp.",
            "222": "[43] J.",
            "223": ", 2014, pp.",
            "224": "1799\u20131807.",
            "225": "2016, pp.",
            "226": "4724\u20134732.",
            "227": "1912\u20131920.",
            "228": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore.",
            "229": "4540 IEEE TRANSACTIONS ON IMAGE PROCESSING, VOL.",
            "230": "28, NO.",
            "231": "9, SEPTEMBER 2019\n[46] L.",
            "232": "2017, pp.",
            "233": "5679\u20135688.",
            "234": "35, no.",
            "235": "221\u2013231, Jan.",
            "236": "[48] D.",
            "237": "(FG) , 2008, pp.",
            "238": "32, no.",
            "239": "10, pp.",
            "240": "2014.",
            "241": "28, no.",
            "242": "807\u2013813, 2010.",
            "243": "58, pp.",
            "244": "2017.",
            "245": "397\u2013403.",
            "246": "2011, pp.",
            "247": "2144\u20132151.",
            "248": "2017, pp.",
            "249": "4000\u20134009.",
            "250": "Cham, Switzerland: Springer, 2018, pp.",
            "251": "Cham, Switzerland: Springer, 2016, pp.",
            "252": "581\u2013589.",
            "253": "[58] S.",
            "254": "40, no.",
            "255": "2018.",
            "256": "Workshops , 2017, pp.",
            "257": "1619\u20131628.",
            "258": "2017, pp.",
            "259": "4733\u20134742.",
            "260": "2017, pp.",
            "261": "1633\u20131642.",
            "262": "41, no.",
            "263": "121\u2013135, Jan.",
            "264": "2019.",
            "265": "degree in automation from the China University of Petroleum, Qingdao, China, in 2011 and the Ph.",
            "266": "degree in pattern recogni-tion and intelligent systems from CASIA in 2016.",
            "267": "degree in industrial automation from the Dalian University of Technology, Dalian, China, in 1999, the M.",
            "268": "Downloaded on February 22,2020 at 08:45:42 UTC from IEEE Xplore."
        },
        "Geometric Pose Affordance: Monocular 3D Human Pose Estimation with Scene Constraints": {
            "authors": [
                "Zhe Wang",
                "Liyan Chen",
                "Shaurya Rathore",
                "Daeyun Shin",
                "Charless Fowlkes"
            ],
            "url": "https://openreview.net/pdf?id=SyggmmnUwr",
            "ref_texts": ". Ionescu, C., Papava, D., Olaru, V ., Sminchisescu, C., 2014. Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments. PAMI . Joo, H., Simon, T., Sheikh, Y ., 2016. Total capture: A 3d deformation model for tracking faces, hands, and bodies, in: CVPR.Li, X., Liu, S., Kim, K., Wang, X., Yang, M.H., Kautz, J., 2019. Putting humans in a scene: Learning a fiordance in 3d indoor environments, in: CVPR. von Marcard, T., Henschel, R., Black, M.J., Rosenhahn, B., Pons-Moll, G., 2018. Recovering accurate 3d human pose in the wild using imus and a moving camera. ECCV . Martinez, J., Hossain, R., Romero, J., Little, J.J., 2017. A simple yet e fiective baseline for 3d human pose estimation, in: ICCV . Matzen, K., Snavely, N., 2013. Nyc3dcars: A dataset of 3d vehicles in geographic context, in: ICCV . Mehta, D., Rhodin, H., Casas, D., Fua, P., Sotnychenko, O., Xu, W., Theobalt, C., 2017. Monocular 3d human pose estimation in the wild using improved cnn supervision, in: 3DV . Monszpart, A., Guerrero, P., Ceylan, D., Yumer, E., Mitra, N.J., 2018. imapper: Interaction-guided joint scene and human motion mapping from monocular videos, in: arxiv. Moon, G., Chang, J., Lee, K.M., 2019. Camera distance-aware top-down approach for 3d multi-person pose estimation from a single rgb image, in: ICCV . Moon, G., Lee, K.M., 2020. I2l-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image, in: ECCV . Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K., 2017. Coarse-to-fine volumetric prediction for single-image 3D human pose, in: CVPR. Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn: Towards real-time object detection with region proposal networks. NIPS . Rhodin, H., Salzmann, M., Fua, P., 2018a. Unsupervised geometry-aware representation for 3d human pose estimation, in: ECCV . Rhodin, H., Sp \u00a8orri, J., Katircioglu, I., Constantin, V ., Meyer, F., M \u00a8uller, E., Salzmann, M., Fua, P., 2018b. Learning monocular 3d human pose estimation from multi-view images. Rogez, G., Weinzaepfel, P., Schmid, C., 2019. Lcr-net ++: Multi-person 2d and 3d pose detection in natural images. PAMI . Rother, C., Kolmogorov, V ., Blake, A., 2004. \u201d grabcut\u201d interactive foreground extraction using iterated graph cuts, in: ToG. Shin, D., Ren, Z., Sudderth, E., Fowlkes, C., 2019. 3d scene reconstruction with multi-layer depth and epipolar transformers, in: ICCV . Sigal, L., Balan, A.O., Black, M.J., 2010. Humaneva: Synchronizedvideo and motion capture dataset and baseline algorithm forevaluation of articulated human motion, in: IJCV . Song, S., Yu, F., Zeng, A., Chang, A.X., lis Savva, M., Funkhouser, T., 2017. Semantic scene completion from a single depth image, in: CVPR. Sun, X., Xiao, B., Wei, F., Liang, S., Wei, Y ., 2018. Integral human pose regression, in: ECCV . Taheri, O., Ghorbani, N., Black, M.J., Tzionas, D., 2020. GRAB: A dataset of whole-body human grasping of objects, in: ECCV . Trumble, M., Gilbert, A., Malleson, C., Hilton, A., Collomosse, J., 2017. Total capture: 3d human pose estimation fusing video and inertial sensors, in: BMVC."
        },
        "Unified Pose Sequence Modeling": {
            "authors": [],
            "url": "https://eprints.lancs.ac.uk/id/eprint/189826/1/CVPR2023_Lingeng_Tianjiao_unifiedskeleton_dynamic.pdf",
            "ref_texts": "[53] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "53"
            ],
            "1": "In 3D Pose Estimation [24, 41, 45, 84, 95, 96], we predict the 3D coordinates of a human\u2019s joints, with the input being either RGB images [53, 70] or 2D poses [24, 41, 45, 84, 95, 96]."
        },
        "Spatio-temporal Self-Attention for Egocentric 3D Pose Estimation": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=F_P8Dtg43vF",
            "ref_texts": "[14] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarseto-fine volumetric prediction for single-image 3d human pose. InProceedings of the IEEE conference on computer vision and pattern recognition, pages 7025\u20137034, 2017.",
            "ref_ids": [
                "14"
            ],
            "1": "Outside-in Static Human Pose Estimationinitially regressed directly to 3D pose from images, without intermediate 2D representation [11\u201315]; [14,15] considered the use of volumetric heatmaps to utilize 3D features in images on popular outside-in datasets such as Human3."
        },
        "Integrated In-vehicle Monitoring System Using 3D Human Pose Estimation and Seat Belt Segmentation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.07946",
            "ref_texts": ""
        },
        "Leveraging the Learnable Vertex-Vertex Relationship to Generalize Human Pose and Mesh Reconstruction for In-the-Wild Scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2202.07228"
        },
        "Human pose estimation from sparse 3D Data on low power systems": {
            "authors": [],
            "url": "https://spiral.imperial.ac.uk/bitstream/10044/1/83254/1/Vasileiadis-M-2020-PhD-Thesis.pdf",
            "ref_texts": "[Pavlakos et al., 2017] Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. (2017). Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034.",
            "ref_ids": [
                "Pavlakos et al\\., 2017"
            ]
        },
        "Automated Human Motion Analysis and Synthesis": {
            "authors": [],
            "url": "https://infoscience.epfl.ch/record/300270/files/EPFL_TH8976.pdf",
            "ref_texts": "[125] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis. Coarse-To-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "125"
            ],
            "1": "1 Active Human Pose Estimation Most recent approaches to 3D pose estimation rely on deep networks that regress pose from monocular images [75,109,110,125,126,131,139,159,165,167,175,184,195].",
            "2": "[125] G."
        },
        "Machine Learning for Human Action Recognition and Pose Estimation based on 3D Information": {
            "authors": [],
            "url": "https://theses.hal.science/tel-02492463/file/72722_CARBONERA%20LUVIZON_2019_archivage.pdf",
            "ref_texts": "[99] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 9, 32, 47, 50, 54, 67, 84, 99",
            "ref_ids": [
                "99"
            ],
            "1": "[99] proposed the volumetric stacked hourglass architecture, but the method suffers from the significant increase in the number of parameters and in the required memory to store all the gradients.",
            "2": "Compared to [99], we show in our work that (i) smaller volumetric heat maps can be used with soft-argmax and still improve results, since soft-argmax is a continuous regression function, and (ii), the volumetric representation can be fully replaced by predicting 2D depth maps, that encode the depth related to each body joint, resulting in even lower computational complexity and better results.",
            "3": "However, recent detection based methods for both 2D and 3D pose estimation [156, 22, 99] are based on heat maps prediction, which are then converted to coordinates by applying the maximum a posteriori (MAP) estimation, usually called argmax .",
            "4": "We followed the common evaluation protocol [131, 99, 88, 19] by taking five subjects for training (S1, S5, S6, S7, S8) and evaluating on two subjects (S9, S11) on one every 64 frames.",
            "5": "Differently from the Stacked Hourglass [93, 99] architectures, where only the higher resolution features are supervised, we use intermediate supervision at every level of the pyramids.",
            "6": "The same is not true for detection based approach, like in [99], since the predictions are quantized by the argmax function.",
            "7": "Recent methods based on deep convolutional neural networks (CNNs) have achieved impressive results on both 2D and 3D pose estimation tasks thanks to the rise of new architectures and the availability of large amounts of data [93, 99].",
            "8": "[99] 2017 71.",
            "9": "[99] 67.",
            "10": "[99] 96.",
            "11": "10\n[99] G."
        },
        "Computer Vision and Abnormal Patient Gait Assessment a Comparison of Machine Learning Models": {
            "authors": [
                "Aisvarya Chandramohan"
            ],
            "url": "https://arxiv.org/pdf/2004.02810",
            "ref_texts": "[19] G. Pavlakos, X. Zhou, K. G. Derpanis and K. Daniilidis, \u201cCoarse -to-fine volumetric prediction for single -image 3D human pose.,\u201d in In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. ",
            "ref_ids": [
                "19"
            ],
            "1": "The current tech niques on DNN for 3D human pose estimation focus on a single view, and a complex setting \n[14] [19].",
            "2": "[19] G."
        },
        "Generative Multi-View Based 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3479645.3479708",
            "ref_texts": "[43] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. 2017. Coarse-to-fine volumetric prediction for single-image 3d human pose. In In Conference on Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "43"
            ],
            "1": "There are numerous approaches to handle generating 3D human poses from monocular images [10,17,34\u2013\n37,39,42,43,53].",
            "2": "for training [35,37,43,44,48,53,57,59,60,74].",
            "3": "[43] G."
        },
        "Survey on 3D Human Pose Estimation of Deep Learning": {
            "authors": [],
            "url": "http://fcst.ceaj.org/EN/article/downloadArticleFile.do?attachType=PDF&id=3211"
        },
        "Multi-view Generative Networks for 3D Pose Estimation": {
            "authors": [],
            "url": "https://www.dpublication.com/wp-content/uploads/2020/12/04-353.pdf",
            "ref_texts": "3D Multi -Person Pose Estimation from a Single RGB Image. In ICCV . G. Ning, Z. Zhang, Z. He. (2018) Knowledge -Guided Deep Fractal Neural Networks for Human Pose Estimation. In Transactions on Multimedia. G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis. (2017) Harvesting Multiple Views for Marker -Less 3D Human Pose Annotations. In CVPR . G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis. (2017) Coarse -to-fine volumetric prediction for single -image 3d human pose. In CVPR . G. Rogez, Cordelia Schmid. (2016). MoCap -guided data augmentation for 3D pose estimation in the wild. In NIPS . H. F. Tung, A. W. Harley, W. Seto, K. Fragkiadaki. (2017) Adversarial inverse graphics networks: Learning 2d -to-3d lifting and image -to-image translation from unpaired supervision. In ICCV . H. Joo . (2015 ) Panoptic Studio: A Massively Multiview System for S ocial Motion Capture. In ICCV. I. Habibie, W. Xu, D. Mehta, G. Pons -Moll t, C. Theobalt. (2019) In the Wild Human Pose Estimation Using Explicit 2D Features and Intermediate 3D Representations. In CVPR . I. Goodfellow, J. Pouget -Abadie, M. Mirza, B. Xu,D. W arde-Farley, S. Ozair, A. Courville, Y. Bengio. (2014) Generative adversarial nets. In NIPS . "
        },
        "Motion capture research: 3D human pose recovery based on RGB video sequences": {
            "authors": [],
            "url": "https://www.mdpi.com/2076-3417/9/17/3613/pdf",
            "ref_texts": "28. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Honolulu, HI, USA, 21\u201326 July 2017; pp. 1263\u20131272.",
            "ref_ids": [
                "28"
            ],
            "1": "According to the different processes, they can be divided into the two-step method [27], and the direct method [28];\n(3) Human pose recovery based on 3D human models, which estimates the parameters of the parametric human-body model, generally using the parameterized SMPL model [103]."
        },
        "Human Motion Analysis Using 3D Skeleton Representation in The Context of Real-World Applications: From Home-Based Rehabilitation to Sensing In The Wild": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/45950/1/RenatoBaptista_PhD_thesis.pdf",
            "ref_texts": "[93] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in CVPR , 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "93"
            ],
            "1": "Recently, and thanks to the advances in deep learning techniques, 3D human pose estimation has become more accessible [33]\u2013\n[38], [91]\u2013[93].",
            "2": "[93] presented a coarse-to-fine learning approach, where a voxel representation for each joint is considered as the regression target.",
            "3": "Our work builds on the recent effective CNN-based methods for the estimation of 3D skeletons from a single RGB image [33], [79], [93].",
            "4": "[93] G."
        },
        "Optimising 2D Pose Representation: Improving Accuracy, Stability and Generalisability inUnsupervised 2D-3D Human Pose Estimation": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=2lbtqs4enl",
            "ref_texts": "2668, 2017. doi: 10.1109/ICCV .2017.288. Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal Fua, Oleksandr Sotnychenko, Weipeng Xu, and Christian Theobalt. Monocular 3d human pose estimation in the wild using improved cnn supervision. In 3D Vision (3DV), 2017 Fifth International Conference on . IEEE, 2017a. doi: 10.1109/3dv.2017.00064. URL http: //gvv.mpi-inf.mpg.de/3dhp_dataset . Dushyant Mehta, Srinath Sridhar, Oleksandr Sotnychenko, Helge Rhodin, Mohammad Shafiei, Hans-Peter Seidel, Weipeng Xu, Dan Casas, and Christian Theobalt. Vnect: Real-time 3d human pose estimation with a single rgb camera. volume 36, 2017b. doi: 10.1145/3072959.3073596. URL http://gvv.mpi-inf. mpg.de/projects/VNect/ . Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling (eds.), Computer Vision \u2013 ECCV 2016 , pp. 483\u2013499, Cham, 2016. Springer International Publishing. ISBN 978-3-319-46484-8. Mark Nishimura, David B. Lindell, Christopher Metzler, and Gordon Wetzstein. Disambiguating monocular depth estimation with a single transient. In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm (eds.), Computer Vision \u2013 ECCV 2020 , pp. 139\u2013155, Cham, 2020. Springer International Publishing. ISBN 978-3-030-58589-1. Sungheon Park and Nojun Kwak. 3d human pose estimation with relational networks. In British Machine Vision Conference 2018, BMVC 2018, Newcastle, UK, September 3-6, 2018 , pp. 129. BMV A Press, 2018. URLhttp://bmvc2018.org/contents/papers/0530.pdf . Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1263\u20131272, 2017. Georgios Pavlakos, Xiaowei Zhou, and Kostas Daniilidis. Ordinal depth supervision for 3d human pose estimation. In 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , pp. 7307\u20137316, 2018. doi: 10.1109/CVPR.2018.00763. Dario Pavllo, Christoph Feichtenhofer, David Grangier, and Michael Auli. 3d human pose estimation in video with temporal convolutions and semi-supervised training. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 7745\u20137754, 2019. doi: 10.1109/CVPR.2019.00794. Matteo Ruggero Ronchi, Oisin Mac Aodha, Robert Eng, and Pietro Perona. It\u2019s all relative: Monocular 3d human pose estimation from weakly supervised data. In British Machine Vision Conference 2018, BMVC 2018, Northumbria University, Newcastle, UK, September 3-6, 2018 , pp. 300, 2018. URL http://bmvc2018.org/contents/papers/0182.pdf . Shibani Santurkar, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. How does batch normalization help optimization? In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. CesaBianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper/2018/file/"
        },
        "A Survey of Sensor Modalities for Human Activity Recognition": {
            "authors": [],
            "url": "https://bruceyo.github.io/publication/kdir2020survey/kdir2020survey.pdf",
            "ref_texts": ""
        },
        "From Dense 2D to Sparse 3D Trajectories for Human Action Detection and Recognition": {
            "authors": [],
            "url": "https://orbilu.uni.lu/bitstream/10993/43167/1/phd_thesis.pdf",
            "ref_texts": "[61] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , IEEE, 2017, pp. 1263\u20131272.",
            "ref_ids": [
                "61"
            ],
            "1": "As in [60], [61], VNect makes use of Convolutional Neural Networks (CNN) models.",
            "2": "Motivated by the very recent encouraging progress on pose estimation from a single RGB image [35], [61], [134], we introduce a novel way of approaching the viewpoint invariant action recognition problem using a single 2D or RGB camera.",
            "3": "The VNect system was selected over related ones [35], [61], [134], because of its real-time performance and its ability to ensure temporal coherence.",
            "4": "[61] G."
        },
        "PoseGate-Former: Transformer Encoder with Trainable Gate for 3D Human Pose Estimation Using Weakly Supervised Learning": {
            "authors": [],
            "url": "https://opus.lib.uts.edu.au/bitstream/10453/154191/2/sub_453.pdf",
            "ref_texts": "8. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2017)",
            "ref_ids": [
                "8"
            ],
            "1": "There are two main approaches to estimate 3D human pose from monocular images: supervised approach and a weakly-supervised approach [4{6,8,11,12].",
            "2": "[8] 67.",
            "3": "[8] 22."
        },
        "Graph Neural Networks For 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://spectrum.library.concordia.ca/id/eprint/992048/13/Hassan_MASc_S2023.pdf",
            "ref_texts": "[9] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u00aaCoarse-to-fine volumetric prediction for single-image 3D human pose,\u00ba in Proc. Conference on Computer Vision and Pattern Recognition , pp. 7025\u00b17034, 2017.",
            "ref_ids": [
                "9"
            ],
            "1": "Existing 3D human pose estimation methods can be broadly categorized into two main streams: single-stage [8] and two-stage approaches [9,10].",
            "2": "[9] 47.",
            "3": "It is a challenging problem due 27 in large part to the complex and articulated nature of the human body, as well as the difficulty of estimating 3D information from 2D images [9,66], which are often adversely affected by occlusion and lighting.",
            "4": "[9] G."
        },
        "Back to the future: Joint aware temporal deep learning 3D human pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2002.11251",
            "ref_texts": "20. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 7025{7034 (2017)",
            "ref_ids": [
                "20"
            ],
            "1": "[15] [29] [29] [18] directly estimating 3D poses from image data and 2D joint keypoints can be lifted to 3D representations [9] [18] [20] [28] [2] [24] [19] Coarse to ffne discretization can further improve accuracy.",
            "2": "[20] [26] use a series of high-to-low resolution networks to enhance spatial precision.",
            "3": "6M [20] [28] [18] [27] [6] [19] [30]\n[17] [22] results, we continue to adopt a 17-joint skeleton, train on the same ffve subjects (S1, S5, S6, S7, S8) and test on two subjects (S9 and S11).",
            "4": "Protocol 1is the mean per-joint position error (MPJPE) in millimeters calculated as the Euclidean distance between predicted joint positions and ground-truth joint positions and follows [16] [29] [33] [18] [20] [22]."
        },
        "Computer-vision based rapid entire body analysis (REBA) estimation": {
            "authors": [
                "Jonathan Tomalty"
            ],
            "url": "https://journalofindustrializedconstruction.com/index.php/mocs/article/download/269/233",
            "ref_texts": "103013. Fang, W., Love, P. E., Luo, H., & Ding, L. (2020). Computer vision for behaviour -based safety in construction: A review and future directions. Advanced Engineering Informatics, 43, 100980. Kim, W., Sung, J., Saakes, D., Huang, C., & Xiong, S. (2021). Ergonomic postural assessment using a new open -source human pose estimation technology (OpenPose). Intern ational Journal of Industrial Ergonomics, 84, 103164. Konstantinidis, D., Dimitropoulos, K., & Daras, P. (2021, June). Towards Real -Time Generalized Ergonomic Risk Assessment for the Prevention of Musculoskeletal Disorders. In The 14th PErvasive Technologi es Related to Assistive Environments Conference (pp. 466 -472). Li, X., Han, S., G\u00fcl, M., & Al -Hussein, M. (2019). Automated post -3D visualization ergonomic analysis system for rapid workplace design in modular construction. Automation in Construction, 98, 160-174. Li, X., Han, S., G\u00fcl, M., & Al -Hussein, M. (2017). Automated Ergonomic Risk Assessment based on 3D Visualization. In ISARC. Proceedings of the International Symposium on Automation and Robotics in Construction (Vol. 34). IAARC Publications. Massir isFern\u00e1ndez, M., Fern\u00e1ndez, J. \u00c1., Bajo, J. M., & Delrieux, C. A. (2020). Ergonomic risk assessment based on computer vision and machine learning. Computers & Industrial Engineering, 149, 106816. Martinez, J., Hossain, R., Romero, J., & Little, J. J. (2017 ). A simple yet effective baseline for 3d human pose estimation. In Proceedings of the IEEE international conference on computer vision (pp. 2640 -2649). Moon, G., Chang, J. Y., & Lee, K. M. (2019). Camera distance -aware top -down approach for 3d multi -perso n pose estimation from a single rgb image. In Proceedings of the ieee/cvf international conference on computer vision (pp. 10133 -10142). Mu\u00f1oz, A., Mart\u00ed, A., Mahiques, X., Gracia, L., Solanes, J. E., & Tornero, J. (2020). Camera 3D positioning mixed reali ty-based interface to improve worker safety, ergonomics and productivity. CIRP Journal of Manufacturing Science and Technology, 28, 24 -37. Nath, N. D., Chaspari, T., & Behzadan, A. H. (2018). Automated ergonomic risk monitoring using body -mounted sensors a nd machine learning. Advanced Engineering Informatics, 38, 514 526. Pavlakos, G., Zhou, X., Derpanis, K. G., & Daniilidis, K. (2017). Coarse -to-fine volumetric prediction for single -image 3D human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7025 -7034). Poitras, I., Dupuis, F., Bielmann, M., Campeau -Lecours, A., Mercier, C., Bouyer, L. J., & Roy, J. S. (2019). Validity and reliability of wearable sensors for joint angle estimation: A systematic revi ew. Sensors, 19(7), 1555. Seo, J., Yin, K., & Lee, S. (2016, January). Automated postural ergonomic assessment using a computer vision -based posture classification. In Construction research congress 2016 (pp. ",
            "ref_ids": [
                "103013"
            ]
        },
        "Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies from Single RGB Images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2106.11536",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarseto-fine volumetric prediction for single-image 3D human pose,\u201d in IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "22"
            ],
            "1": "The onestage methods usually use a single cropped image as the input to a CNN, and directly obtain root-relative 3D joint positions [18]\u2013[20], parent-relative joint positions [21], or voxel joint probability map [22], [23].",
            "2": "Following the standard protocol for 3D pose estimation [22] in Human3.",
            "3": "For evaluation, we adopt averaged skeleton dimensions computed from the training set to rescale our reconstruction human, as did in [22].",
            "4": "[22] G."
        },
        "On the Design of 2D Human Pose Estimation Networks using Accelerated Neuroevolution and Novel Keypoint Representations": {
            "authors": [],
            "url": "https://uwspace.uwaterloo.ca/bitstream/handle/10012/18215/McNally_William.pdf?sequence=3&isAllowed=y",
            "ref_texts": "[68] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in CVPR , 2017.",
            "ref_ids": [
                "68"
            ],
            "1": "6M [61], HumanEva [62], MPI-INF-3DHP [63]) to support the development of 3D human pose estimation algorithms [64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86].",
            "2": "[68] G."
        },
        "Not all parts are created equal: 3d human pose estimation by modeling bi-directional dependencies of body parts": {
            "authors": [
                "Greg Hampshire"
            ],
            "url": "https://opus.lib.uts.edu.au/bitstream/10453/137277/3/Binder1.pdf",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "[22] proposed a volumetric representation for 3D joints and used a coarseto-fine strategy to refine the prediction iteratively.",
            "2": "[22] 67.",
            "3": "[22] 47.",
            "4": "Following [48, 22, 45, 21], we down sampled the original videos from 50fps to 10fps to remove redundancy."
        },
        "TriPose: A Weakly-Supervised 3D Human Pose Estimation via Triangulation from Video": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.06599",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
            "ref_ids": [
                "28"
            ],
            "1": "It is however an ill-posed problem and most of the proposed solutions rely on supervised training that requires 3D annotations [22, 29, 11, 34, 5, 19, 27, 28]."
        },
        "Estimating 3D Motion and Forces from Monocular Videos": {
            "authors": [],
            "url": "https://hal.science/tel-04141548/document",
            "ref_texts": "90 BIBLIOGRAPHY. Mordatch, I., Todorov, E., and Popovi\u0107, Z. Discovery of complex behaviors through contact-invariant optimization. ACM Transactions on Graphics (TOG) , 31(4): 43, 2012. 20, 21 Moreno-Noguer, F. 3d human pose estimation from a single image via distance matrix regression. In CVPR, 2017. 16 Newell, A., Yang, K., and Deng, J. Stacked hourglass networks for human pose estimation. In ECCV, 2016. 17 Newell, A., Huang, Z., and Deng, J. Associative embedding: End-to-end learning for joint detection and grouping. In NIPS, 2017. 17 Oberweger, M., Rad, M., and Lepetit, V. Making Deep Heatmaps Robust to Partial Occlusions for 3D Object Pose Estimation. In ECCV, 2018. 19 Pavlakos, G., Zhou, X., Derpanis, K.G., andDaniilidis, K. Coarse-to-finevolumetric prediction for single-image 3d human pose. In CVPR, 2017. 16 Peng, X. B., Abbeel, P., Levine, S., and van de Panne, M. Deepmimic: Exampleguided deep reinforcement learning of physics-based character skills. ACM Trans. Graph., 37(4):143:1\u2013143:14, Jul 2018. ISSN 0730-0301. doi: 10.1145/3197517."
        },
        "Filling the joints: Completion and recovery of incomplete 3D human poses": {
            "authors": [],
            "url": "https://www.mdpi.com/2227-7080/6/4/97/pdf",
            "ref_texts": "46. Pavlakos, G.; Zhou, X.; Derpanis, K.G.; Daniilidis, K. Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. In Proceedings of the 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Honolulu, HI, USA, 21\u201326 July 2017; pp. 1263\u20131272. [CrossRef]",
            "ref_ids": [
                "46"
            ]
        },
        "An efficient approach for sequential human performance capture from monocular video": {
            "authors": [],
            "url": "https://www.ri.cmu.edu/app/uploads/2022/08/Jianchun-thesis-final.pdf",
            "ref_texts": "[32]Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 7025\u20137034, 2017. 2.3",
            "ref_ids": [
                "32"
            ],
            "1": "3 Human Pose and Shape Estimation Initially, human pose estimation refers to localize the body keypoint in 2D [6,42] and 3D [28,32]."
        },
        "Deep learning and trigonometric adjustment in estimation of lower extremity angles": {
            "authors": [],
            "url": "https://spectrum.library.concordia.ca/id/eprint/987059/1/Chalangari_MASc_F2020.pdf",
            "ref_texts": "[42] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \\Coarse-to-ffne volumetric prediction for single-image 3d human pose,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025{7034.",
            "ref_ids": [
                "42"
            ],
            "1": "13 Figure 10: Sample frame overlaid by 2D keypoints from Detectron and its corresponding 3D reconstruction in camera space The input to these networks could either be a monocular image or a video sequence and in terms of their method, they could either implement an end-to-end input-to-3D joints [36], [37], or lifting 2D joint detection to 3D predictions [26], [38], [39], [40], [41], [42].",
            "2": "[42] decided to avoid approaching the pose estimation problem 15 Figure 11: Architecture of a traditional RNN (from [43]).",
            "3": "[42] G."
        },
        "Model-based Control for Robot Manipulation Tasks with High-dimensional State Spaces": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/144618/Githinji-bilkitg-SM-EECS-2022-thesis.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR, abs/1611.07828, 2016.",
            "ref_ids": [
                "31"
            ],
            "1": "Inspired by divide-and-conquer paradigms computer vision that quickly reduce the problem search space, we propose an adaptive control framework that varies the low-dimensional state representation in a coarse-to-fine manner to benefit local tracking of a long horizon trajectory [36, 31, 58]."
        },
        "Balanced Feature Fusion for Grouped 3D Pose Estimation": {
            "authors": [],
            "url": "https://dspace5.zcu.cz/bitstream/11025/49583/1/B59-full.pdf",
            "ref_texts": "[Pav17a] Pavlakos, G., Zhou, X., Derpanis, K. G., Daniilidis, K. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7025-7034). 2017.",
            "ref_ids": [
                "Pav17a"
            ],
            "1": "[Pav17a, Tek16a] directly predict the 3D human joints from the input image or video through neural networks, which is called one-step regression method.",
            "2": "Following previous studies [Mar17a, Pav17a, Fan18a, Pav19a, Liu20a, Sha21a], we adopt five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9 and S11) for testing.",
            "3": "[Pav17a] Pavlakos, G."
        },
        "Using Animal Motion Capture to Learn Neural Representations": {
            "authors": [],
            "url": "https://infoscience.epfl.ch/record/293821/files/EPFL_TH9124.pdf",
            "ref_texts": "[168] G. Pavlakos, X. Zhou, K. Derpanis, G. Konstantinos, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose\u201d, in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "168"
            ],
            "1": "[168] G."
        },
        "Continuous Learning of Inverse Problems with Applications to Structure from Motion": {
            "authors": [],
            "url": "https://openresearch.surrey.ac.uk/view/delivery/44SUR_INST/12152228770002346/13152228760002346",
            "ref_texts": "[82] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "82"
            ],
            "1": "For the modelling step, the different approaches can be categorised according to the following aspects: \u2022Camera setting: pose estimation can be approached either from single [82, 116, 117] or multiple [83, 123] view images.",
            "2": "Inspired by the recent use of heatmaps rather than 2D landmarks in 2D human pose estimation, Pavlakos [82] used a coarse-to-fine approach to predict per-voxel likelihood,or 3D heatmaps, instead of the 3D joint locations.",
            "3": "Notable examples include Pavlakos [82], who used a coarse-to-fine approach to predict for each joint a per-voxel likelihood, or 3D heatmap, drawing inspiration from the popular 2D pose estimation trend of replacing pixel-sized landmark detection with heatmaps.",
            "4": "[82] 67.",
            "5": "[82] 17j 51.",
            "6": "[82] G."
        },
        "How worms move in 3D": {
            "authors": [
                "Thomas P. Ilett"
            ],
            "url": "https://etheses.whiterose.ac.uk/32946/1/Ilett_TP_Computing_PhD_2023.pdf",
            "ref_texts": ""
        },
        "CGAP2: Context and gap aware predictive pose framework for early detection of gestures": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.09216",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR , abs/1611.07828, 2016. 2",
            "ref_ids": [
                "24"
            ],
            "1": "in[24] discretize the output dimensions to voxels and use 2D poses for intermediate supervision in their networks."
        },
        "Practical algorithms for vision-based human activity recognition and human action evaluation": {
            "authors": [],
            "url": "https://theses.lib.polyu.edu.hk/bitstream/200/11050/3/5515.pdf",
            "ref_texts": "[91] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \"Coarse -to-fine volumetric prediction f or single -image 3D human pose,\" in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, 2017: IEEE, pp. 12631272. ",
            "ref_ids": [
                "91"
            ],
            "1": "The cheapest RGB cameras are also able to retrieve 2D skeleton [89] or 3D skeleton [90], [91], which require higher computationa l cost and might hinder the development of real -time \n \n \n29 \n prototype applications.",
            "2": "[91] G."
        },
        "Semantic estimation of 3d body shape and pose using minimal cameras": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.03030",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017.",
            "ref_ids": [
                "24"
            ],
            "1": "While Pavlakos et al [24] used a simple volumetric representation in a 3D convnet for pose estimation and Wei et al [44] performed related work in aligning pairs of joints to estimate 3D human pose."
        },
        "Monocular 3D Human Pose-Estimation Networks for Coherent Humanoid-Model Driving": {
            "authors": [],
            "url": "https://www.researchsquare.com/article/rs-2214932/latest.pdf",
            "ref_texts": ""
        },
        "\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53ca\u5e94\u7528\u7efc\u8ff0": {
            "authors": [],
            "url": "https://www.researching.cn/ArticlePdf/m00002/2023/60/3/0312010.pdf",
            "ref_texts": "[122]Pavlakos G , Zhou X W , Derpanis K G , et al . Coarse -tofine volumetric prediction for single -image 3D human pose [C]\u22252017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR ), July 21-26, 2017 , Honolulu , HI, USA . New York : IEEE Press , 2017 : ",
            "ref_ids": [
                "122",
                "C"
            ],
            "1": "0875 s after \u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6700\u521d\u5e38\u7528\u56fe\u6a21\u578b[116]\u548c\u5168\u5c40\u7279\u5f81[117]\n\u7684\u65b9\u5f0f\u6765\u89e3\u7b97\u4eba\u4f53\u59ff\u6001 ,DeepPose[118]\u9996\u6279\u5c06\u6df1\u5ea6\u5b66\u4e60\n\u5f15\u5165\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u540e ,\u51fa\u73b0\u4e86\u8bb8\u591a\u4f18\u79c0\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\n\u4e60 \u7684 \u4eba \u4f53 \u59ff \u6001 \u4f30 \u8ba1 \u7b97 \u6cd5 ,\u5982CPM[119]\u3001CPN[120]\u3001 HigherHRNet[121]\u3001MSPN[122]\u7b49,\u4e3a\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u624e\u5b9e\u7684\u7406\u8bba\u57fa\u7840 \u3002\n\u6839\u636e\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u5e94\u7528\u6574\u4f53\u4efb\u52a1\u7684\u76ee\u7684 ,\u5c06\u4eba\u4f53\n\u59ff\u6001\u4f30\u8ba1\u7684\u5e94\u7528\u5206\u4e3a\u4e24\u7c7b :\u5c06\u59ff\u6001\u4f30\u8ba1\u4f5c\u4e3a\u6574\u4f53\u4efb\u52a1\n\u4e2d\u7684\u4e00\u73af ,\u5982\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b \u3001\u4eba\u4f53\u884c\u4e3a\u5206\u6790 \u3001\u4eba\u4f53\u8ddf\u8e2a\n\u7b49,\u5c06\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4f5c\u4e3a\u5173\u952e\u73af\u8282 ,\u5e76\u4e0e\u5176\u4ed6\u6280\u672f\u76f8\u7ed3\n\u5408\u5b9e\u73b0\u4efb\u52a1 ;\u76f4\u63a5\u5c06\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u5e94\u7528\u4e8e\u5404\u9886\u57df ,\u5982\u5404\n\u79cd\u8fd0\u52a8\u573a\u666f \u3001\u4ea4\u901a\u9886\u57df \u3001\u5b89\u9632\u9886\u57df \u3001\u533b\u7597\u9886\u57df\u7b49 \u3002\n\u5728\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b\u4e2d ,\u901a\u8fc7\u4e86\u89e3\u524d\u540e\u591a\u5e45\u56fe\u50cf\u7684\n\u4eba\u4f53\u59ff\u6001 ,\u6765\u8bc6\u522b\u4eba\u4f53\u7684\u52a8\u4f5c ,\u662f\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7684\u5e38\n\u7528\u5e94\u7528\u4e4b\u4e00 \u3002Liu\u7b49[123]\u9996\u5148\u5bf9\u56fe\u50cf\u4e2d\u7684\u4eba\u4f53\u59ff\u6001\u8fdb\n\u884c\u4f30\u8ba1,\u7136\u540e\u5c06\u59ff\u6001\u7684 heatmap \u7528\u4e8e\u589e\u5f3a\u57fa\u4e8e\u9aa8\u67b6\u7684\n\u52a8\u4f5c\u8bc6\u522b ,\u5982\u56fe44\u6240\u793a\u3002Luvizon \u7b49[124]\u91c7\u7528\u591a\u4efb\u52a1\n\u6846\u67b6\u4ece\u9759\u6b62\u56fe\u50cf\u4e2d\u5b9e\u73b0 2D\u548c3D\u7684\u59ff\u6001\u4f30\u8ba1 ,\u7136\u540e\n\u4ece\u89c6\u9891\u5e8f\u5217\u4e2d\u5b8c\u6210\u52a8\u4f5c\u8bc6\u522b \u3002Yan\u7b49[125]\u5f15\u5165\u65f6\u95f4\u59ff\n\u6001\u5377\u79ef,\u6709\u6548\u5730\u7f16\u7801\u591a\u4e2a\u59ff\u6001\u7684\u6a21\u6001 ,\u7528\u4e8e\u52a8\u4f5c\n\u8bc6\u522b\u3002\n\u5728\u4eba\u4f53\u8ddf\u8e2a\u9886\u57df ,\u540c\u6837\u4e5f\u662f\u4ee5\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4e3a\u57fa\n\u7840\u3002Wang\u7b49[126]\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb HRNet\u7684\u4eba\u4f53\u59ff\u6001\n\u4f30\u8ba1\u548c\u8ddf\u8e2a\u65b9\u6cd5 ,\u5982\u56fe45\u6240\u793a,\u91c7\u7528\u526a\u8f91\u8ddf\u8e2a\u7f51\u7edc ,\u901a\n\u8fc7\u5229\u7528\u89c6\u9891\u524d\u540e\u5e27\u7684\u5173\u7cfb\u6765\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\u548c\u6297\u906e\u6321\u80fd\n\u529b\u3002VoxelTrack[127]\u57fa\u4e8e\u591a\u89c6\u56fe\u5bf9\u4eba\u4f53\u8fdb\u884c\u59ff\u6001\u4f30\u8ba1\n\u548c\u8ddf\u8e2a,\u5c06\u591a\u89c6\u56fe\u7684\u4fe1\u606f\u5408\u6210\u4e09\u7ef4\u4f53\u7d20\u8868\u5f81 ,\u80fd\u591f\u6709\u6548\u5730\u6297\u906e\u6321 ,\u63d0\u5347\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u8ddf\u8e2a\u7684\u7cbe\u786e\u5ea6 \u3002\n\u5728\u4eba\u4f53\u884c\u4e3a\u5206\u6790\u4e2d ,\u9996\u5148\u5bf9\u4eba\u4f53\u7684\u59ff\u6001\u8fdb\u884c\u4f30\u8ba1 ,\n\u7136\u540e\u5bf9\u59ff\u6001\u8fdb\u884c\u5206\u7c7b ,\u5b9e\u73b0\u4eba\u4f53\u884c\u4e3a\u7684\u5206\u6790 \u3002\u5510\u6c38\n\u6b63[128]\u63d0\u51fa\u7684\u57fa\u4e8e\u9aa8\u67b6\u7684 FP-Net\u5b9e\u73b0\u4e86\u6297\u906e\u6321\u4eba\u4f53\u6b63\n\u9762\u59ff\u6001\u4f30\u8ba1 ,\u5e76\u5c06\u5176\u4e0e\u4eba\u4f53\u8ddf\u8e2a\u7b97\u6cd5\u7ed3\u5408 ,\u5e94\u7528\u4e8e\u6559\u5ba4\n\u91cc\u5b66\u751f\u7684\u884c\u4e3a\u5206\u6790 \u3002\n\u56fe42 \u822a\u7a7a\u53d1\u52a8\u673a\u4f4e\u538b\u6da1\u8f6e\u8f74\u81ea\u52a8\u5316\u88c5\u914d\u8bbe\u5907[112] Fig.",
            "2": "44 Human action recognition[123]\n0312010-25\n\u7279\u9080\u7efc\u8ff0 \u7b2c 60 \u5377\u7b2c 3 \u671f/2023 \u5e74 2 \u6708/\u6fc0\u5149\u4e0e\u5149\u7535\u5b50\u5b66\u8fdb\u5c55\n\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u6700\u521d\u5e38\u7528\u56fe\u6a21\u578b[116]\u548c\u5168\u5c40\u7279\u5f81[117]\n\u7684\u65b9\u5f0f\u6765\u89e3\u7b97\u4eba\u4f53\u59ff\u6001 ,DeepPose[118]\u9996\u6279\u5c06\u6df1\u5ea6\u5b66\u4e60\n\u5f15\u5165\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u540e ,\u51fa\u73b0\u4e86\u8bb8\u591a\u4f18\u79c0\u7684\u57fa\u4e8e\u6df1\u5ea6\u5b66\n\u4e60 \u7684 \u4eba \u4f53 \u59ff \u6001 \u4f30 \u8ba1 \u7b97 \u6cd5 ,\u5982CPM[119]\u3001CPN[120]\u3001 HigherHRNet[121]\u3001MSPN[122]\u7b49,\u4e3a\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u624e\u5b9e\u7684\u7406\u8bba\u57fa\u7840 \u3002\n\u6839\u636e\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u5e94\u7528\u6574\u4f53\u4efb\u52a1\u7684\u76ee\u7684 ,\u5c06\u4eba\u4f53\n\u59ff\u6001\u4f30\u8ba1\u7684\u5e94\u7528\u5206\u4e3a\u4e24\u7c7b :\u5c06\u59ff\u6001\u4f30\u8ba1\u4f5c\u4e3a\u6574\u4f53\u4efb\u52a1\n\u4e2d\u7684\u4e00\u73af ,\u5982\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b \u3001\u4eba\u4f53\u884c\u4e3a\u5206\u6790 \u3001\u4eba\u4f53\u8ddf\u8e2a\n\u7b49,\u5c06\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4f5c\u4e3a\u5173\u952e\u73af\u8282 ,\u5e76\u4e0e\u5176\u4ed6\u6280\u672f\u76f8\u7ed3\n\u5408\u5b9e\u73b0\u4efb\u52a1 ;\u76f4\u63a5\u5c06\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u5e94\u7528\u4e8e\u5404\u9886\u57df ,\u5982\u5404\n\u79cd\u8fd0\u52a8\u573a\u666f \u3001\u4ea4\u901a\u9886\u57df \u3001\u5b89\u9632\u9886\u57df \u3001\u533b\u7597\u9886\u57df\u7b49 \u3002\n\u5728\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b\u4e2d ,\u901a\u8fc7\u4e86\u89e3\u524d\u540e\u591a\u5e45\u56fe\u50cf\u7684\n\u4eba\u4f53\u59ff\u6001 ,\u6765\u8bc6\u522b\u4eba\u4f53\u7684\u52a8\u4f5c ,\u662f\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7684\u5e38\n\u7528\u5e94\u7528\u4e4b\u4e00 \u3002Liu\u7b49[123]\u9996\u5148\u5bf9\u56fe\u50cf\u4e2d\u7684\u4eba\u4f53\u59ff\u6001\u8fdb\n\u884c\u4f30\u8ba1,\u7136\u540e\u5c06\u59ff\u6001\u7684 heatmap \u7528\u4e8e\u589e\u5f3a\u57fa\u4e8e\u9aa8\u67b6\u7684\n\u52a8\u4f5c\u8bc6\u522b ,\u5982\u56fe44\u6240\u793a\u3002Luvizon \u7b49[124]\u91c7\u7528\u591a\u4efb\u52a1\n\u6846\u67b6\u4ece\u9759\u6b62\u56fe\u50cf\u4e2d\u5b9e\u73b0 2D\u548c3D\u7684\u59ff\u6001\u4f30\u8ba1 ,\u7136\u540e\n\u4ece\u89c6\u9891\u5e8f\u5217\u4e2d\u5b8c\u6210\u52a8\u4f5c\u8bc6\u522b \u3002Yan\u7b49[125]\u5f15\u5165\u65f6\u95f4\u59ff\n\u6001\u5377\u79ef,\u6709\u6548\u5730\u7f16\u7801\u591a\u4e2a\u59ff\u6001\u7684\u6a21\u6001 ,\u7528\u4e8e\u52a8\u4f5c\n\u8bc6\u522b\u3002\n\u5728\u4eba\u4f53\u8ddf\u8e2a\u9886\u57df ,\u540c\u6837\u4e5f\u662f\u4ee5\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u4e3a\u57fa\n\u7840\u3002Wang\u7b49[126]\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb HRNet\u7684\u4eba\u4f53\u59ff\u6001\n\u4f30\u8ba1\u548c\u8ddf\u8e2a\u65b9\u6cd5 ,\u5982\u56fe45\u6240\u793a,\u91c7\u7528\u526a\u8f91\u8ddf\u8e2a\u7f51\u7edc ,\u901a\n\u8fc7\u5229\u7528\u89c6\u9891\u524d\u540e\u5e27\u7684\u5173\u7cfb\u6765\u63d0\u5347\u4f30\u8ba1\u7cbe\u5ea6\u548c\u6297\u906e\u6321\u80fd\n\u529b\u3002VoxelTrack[127]\u57fa\u4e8e\u591a\u89c6\u56fe\u5bf9\u4eba\u4f53\u8fdb\u884c\u59ff\u6001\u4f30\u8ba1\n\u548c\u8ddf\u8e2a,\u5c06\u591a\u89c6\u56fe\u7684\u4fe1\u606f\u5408\u6210\u4e09\u7ef4\u4f53\u7d20\u8868\u5f81 ,\u80fd\u591f\u6709\u6548\u5730\u6297\u906e\u6321 ,\u63d0\u5347\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u548c\u8ddf\u8e2a\u7684\u7cbe\u786e\u5ea6 \u3002\n\u5728\u4eba\u4f53\u884c\u4e3a\u5206\u6790\u4e2d ,\u9996\u5148\u5bf9\u4eba\u4f53\u7684\u59ff\u6001\u8fdb\u884c\u4f30\u8ba1 ,\n\u7136\u540e\u5bf9\u59ff\u6001\u8fdb\u884c\u5206\u7c7b ,\u5b9e\u73b0\u4eba\u4f53\u884c\u4e3a\u7684\u5206\u6790 \u3002\u5510\u6c38\n\u6b63[128]\u63d0\u51fa\u7684\u57fa\u4e8e\u9aa8\u67b6\u7684 FP-Net\u5b9e\u73b0\u4e86\u6297\u906e\u6321\u4eba\u4f53\u6b63\n\u9762\u59ff\u6001\u4f30\u8ba1 ,\u5e76\u5c06\u5176\u4e0e\u4eba\u4f53\u8ddf\u8e2a\u7b97\u6cd5\u7ed3\u5408 ,\u5e94\u7528\u4e8e\u6559\u5ba4\n\u91cc\u5b66\u751f\u7684\u884c\u4e3a\u5206\u6790 \u3002\n\u56fe42 \u822a\u7a7a\u53d1\u52a8\u673a\u4f4e\u538b\u6da1\u8f6e\u8f74\u81ea\u52a8\u5316\u88c5\u914d\u8bbe\u5907[112] Fig.",
            "3": "A J combined corner and edge detector [C]\u2225Proceedings of the Alvey Vision Conference \n1988 , August 31-September 2, 1988 , Manchester , UK .",
            "4": "Adaptive tracking and model registration across distinct aspects [C]\u2225Proceedings \n1995 IEEE/RSJ International Conference on Intelligent Robots and Systems , August 5-9, 1995 , Pittsburgh , PA, USA .",
            "5": "ORB : an efficient alternative to SIFT or SURF [C]\u22252011 International Conference on Computer Vision , November 613, 2011 , Barcelona , Spain .",
            "6": "Analysis and solutions of the three point perspective pose estimation problem [C]\u2225Proceedings of 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition , June 3-6, 1991 , Maui , HI, USA .",
            "7": "Revisiting the P nP problem : a fast , general and optimal solution [C]\u22252013 IEEE International Conference on Computer Vision , December 1-8, 2013 , Sydney , NSW , Australia .",
            "8": "BB8: a scalable , accurate , robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "9": "6-DoF object pose from semantic keypoints [C]\u22252017 IEEE International Conference on Robotics and Automation (ICRA ), May \n29-June 3, 2017 , Singapore .",
            "10": "Real -time seamless single shot 6D object pose prediction [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "11": "PVNet : pixel -wise voting network for 6DoF pose estimation [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "12": "CDPN : coordinates -based disentangled pose network for real -time RGB -based 6DoF object pose estimation [C]\u22252019 IEEE/CVF International Conference on Computer Vision (ICCV ), October 27-November 2, 2019 , Seoul , Republic of Korea .",
            "13": "DPOD : 6D pose object detector and refiner [C]\u22252019 IEEE/CVF International Conference on Computer Vision (ICCV ), October 27November 2, 2019 , Seoul , Republic of Korea .",
            "14": "Single -stage 6D object pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "15": "EPro -PnP : generalized end -to-end probabilistic perspective -n-points for monocular object pose estimation [C]\u22252022 IEEE/ CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 18-24, 2022 , New Orleans , LA, USA .",
            "16": "GDR -net: geometry -guided direct regression network for monocular \n6D object pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "17": "Learning attraction field representation for robust line segment detection [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "18": "Simultaneous pose and correspondence determination using line features [C]\u22252003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition , June 18-20, 2003 , Madison , WI , USA .",
            "19": "Globally optimal pose estimation from line correspondences [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "20": "RAPID -a video rate object tracker [C]\u2225Proceedings of the British Machine Vision Conference , September , 1990 , Oxford .",
            "21": "Combining edge and texture information for real -time accurate 3D camera tracking [C]\u2225Third IEEE and ACM International Symposium on Mixed and Augmented Reality , November 5, 2004 , Arlington , VA , USA .",
            "22": "Using multiple hypothesis in model -based tracking [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "23": "EPOS : estimating 6D pose of objects with symmetries [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "24": "StablePose : learning \n6D object poses from geometrically stable patches [C]\u2225\n2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "25": "Real -time monocular pose estimation of 3D objects using temporally consistent local color histograms [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "26": "Real -time 3D model -based tracking using edge and keypoint features for robotic manipulation [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "27": "Globally optimal pose estimation from line correspondences [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "28": "RAPID -a video rate object tracker [C]\u2225Proceedings of the British Machine Vision Conference , September , 1990 , Oxford .",
            "29": "Combining edge and texture information for real -time accurate 3D camera tracking [C]\u2225Third IEEE and ACM International Symposium on Mixed and Augmented Reality , November 5, 2004 , Arlington , VA , USA .",
            "30": "Using multiple hypothesis in model -based tracking [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "31": "EPOS : estimating 6D pose of objects with symmetries [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "32": "StablePose : learning \n6D object poses from geometrically stable patches [C]\u2225\n2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "33": "Real -time monocular pose estimation of 3D objects using temporally consistent local color histograms [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "34": "Real -time 3D model -based tracking using edge and keypoint features for robotic manipulation [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "35": "Robust 3D visual tracking using particle filtering on the SE (3) group [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "36": "Real -time model based rigid object pose estimation and tracking combining dense and sparse visual cues [C]\u22252013 IEEE Conference on Computer Vision and Pattern Recognition , June 2328, 2013 , Portland , OR , USA .",
            "37": "Segmentation -driven \n6D object pose estimation [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 15-20, 2019 , Long Beach , CA , USA .",
            "38": "HybridPose : 6D object pose estimation under hybrid representations [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "39": "KeyPose : multi -view 3D labeling and keypoint estimation for transparent objects [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "40": "Stereo R -CNN based 3D object detection for autonomous driving [C]\u22252019 IEEE/ CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "41": "End -toend learning of geometry and context for deep stereo regression [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "42": "Persistent point feature histograms for 3D point clouds [C]\u222510th International Conference on Intel Autonomous System \n(IAS -10), July 24, 2008 , Baden -Baden , Germany .",
            "43": "Fast point feature histograms (FPFH ) for 3D registration [C]\u22252009 IEEE International Conference on Robotics and Automation , May 12-17, 2009 , Kobe , Japan .",
            "44": "0: LiDAR -inertial -camera odometry with sliding -window plane -feature tracking [C]\u22252020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS ), October 24-January 24, 2021 , Las Vegas , NV , USA .",
            "45": "Improvement of shipboard landing performance of shipborne UAV using multi -sensor fusion [C]\u2225Proceedings of 2019 International Conference on Computer Science , Communications and Big Data , March 24-25, 2019 , Beijing , China .",
            "46": "FFB 6D: a full flow bidirectional fusion network for 6D pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "47": "PVN 3D: a deep point -wise 3D keypoints voting network for 6DoF pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "48": "DenseFusion : 6D object pose estimation by iterative dense fusion [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "49": "Trinocular ground system to control UAVs [C]\u22252009 IEEE/RSJ International Conference on Intelligent Robots and Systems , October 10-15, 2009 , St.",
            "50": "Autoland project : fixed -wing UAV landing on a fast patrol boat using computer vision [C]\u2225OCEANS 2015 -Seattle , October \n27-31, 2019 , Seattle , WA , USA .",
            "51": "Unmanned aerial vehicle tracking using a particle filter based approach [C]\u2225\n2019 IEEE Underwater Technology (UT), April 16-19, \n2019 , Kaohsiung , Taiwan , China .",
            "52": "STS -128 on -orbit demonstration of the TriDAR targetless rendezvous and docking sensor [C]\u2225\n2010 IEEE Aerospace Conference , March 6-13, 2010 , Big Sky , MT , USA .",
            "53": "Improvement of shipboard landing performance of shipborne UAV using multi -sensor fusion [C]\u2225Proceedings of 2019 International Conference on Computer Science , Communications and Big Data , March 24-25, 2019 , Beijing , China .",
            "54": "FFB 6D: a full flow bidirectional fusion network for 6D pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "55": "PVN 3D: a deep point -wise 3D keypoints voting network for 6DoF pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "56": "DenseFusion : 6D object pose estimation by iterative dense fusion [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "57": "Trinocular ground system to control UAVs [C]\u22252009 IEEE/RSJ International Conference on Intelligent Robots and Systems , October 10-15, 2009 , St.",
            "58": "Autoland project : fixed -wing UAV landing on a fast patrol boat using computer vision [C]\u2225OCEANS 2015 -Seattle , October \n27-31, 2019 , Seattle , WA , USA .",
            "59": "Unmanned aerial vehicle tracking using a particle filter based approach [C]\u2225\n2019 IEEE Underwater Technology (UT), April 16-19, \n2019 , Kaohsiung , Taiwan , China .",
            "60": "STS -128 on -orbit demonstration of the TriDAR targetless rendezvous and docking sensor [C]\u2225\n2010 IEEE Aerospace Conference , March 6-13, 2010 , Big Sky , MT , USA .",
            "61": "Randomized trees for human pose detection [C]\u22252008 IEEE Conference on Computer Vision and Pattern Recognition , June 23-28, 2008 , Anchorage , AK , USA .",
            "62": "DeepPose : human pose estimation via deep neural networks [C]\u22252014 IEEE Conference on Computer Vision and Pattern Recognition , June 23-28, 2014 , Columbus , OH , USA .",
            "63": "Convolutional pose machines [C]\u22252016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR ), June 27-30, 2016 , Las Vegas , NV , USA .",
            "64": "Cascaded pyramid network for multi -person pose estimation [C]\u2225\n2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT, USA .",
            "65": "HigherHRNet : scale -aware representation learning for bottom -up human pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "66": "[122]Pavlakos G , Zhou X W , Derpanis K G , et al .",
            "67": "Coarse -tofine volumetric prediction for single -image 3D human pose [C]\u22252017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR ), July 21-26, 2017 , Honolulu , HI, USA .",
            "68": "Recognizing human actions as the evolution of pose estimation maps [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "69": "2D/3D pose estimation and action recognition using multitask deep learning [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "70": "PA3D: pose -action 3D machine for video recognition [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 15-20, 2019 , Long Beach , CA , USA .",
            "71": "Combining detection and tracking for human pose estimation in videos [C]\u2225\n2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "72": "Clustered pose and nonlinear appearance models for human pose estimation [C]\u2225 Proceedings of the British Machine Vision Conference \n2010 , August 31-September 3, Aberystwyth .",
            "73": "Human 3D pose estimation in a lying position by RGB -D images for medical diagnosis and rehabilitation [C]\u22252020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society , July 20-24, \n2020 , Montreal , Canada .",
            "74": "In -bed human pose estimation from unseen and privacy -preserving image domains [C]\u22252022 IEEE 19th International Symposium on Biomedical Imaging (ISBI ), March 2831, 2022 , Kolkata , India .",
            "75": "Human 3D pose estimation in a lying position by RGB -D images for medical diagnosis and rehabilitation [C]\u22252020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society , July 20-24, \n2020 , Montreal , Canada .",
            "76": "In -bed human pose estimation from unseen and privacy -preserving image domains [C]\u22252022 IEEE 19th International Symposium on Biomedical Imaging (ISBI ), March 2831, 2022 , Kolkata , India ."
        },
        "Multimodal 3D Human Pose Estimation from a Single Image": {
            "authors": [],
            "url": "https://facstaff.elon.edu/sspurlock/papers/spurlock19_mdnpose.pdf",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Conference on Computer Vision and Pattern Recognition . IEEE, 2017. 1, 2, 4, 6",
            "ref_ids": [
                "16"
            ],
            "1": "proposes a volumetric representation to predict 3D heatmaps rather than coordinates [16].",
            "2": ", [12, 16]), while other approaches focus on the kinematic chain, defining parent-child relationships between, for example, knee and ankle, or elbow and wrist (e.",
            "3": "Other methods propose an end-to-end training model, but require strictly 3D annotations, limiting their application to data collected in a lab environment [16, 18].",
            "4": "Following the most common formulation of the problem, the camera frame serves as the coordinate system, with the first two dimensions corresponding to image coordinates, and the third indicating depth in millimeters [23, 12, 16].",
            "5": ", [16, 23, 12]), where a hybrid (2D + 3D labels) dataset is created by combining the training sets of the Human3.",
            "6": "CVPR-17 [16] 67.",
            "7": "CVPR-17 [16] 83.",
            "8": "2, 3, 4\n[16] G."
        },
        "Towards Efficient and Reliable Skeleton-Based Human Pose Modeling": {
            "authors": [],
            "url": "https://rucore.libraries.rutgers.edu/rutgers-lib/66983/PDF/1/play/",
            "ref_texts": "[68] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp. 1263\u2013",
            "ref_ids": [
                "68"
            ],
            "1": "A couple of algorithms directly predicted 3D pose from the image [67], while others combined 2D heatmaps with volumetric representation [68], pairwise distance matrix estimation [69] or image cues [70] for 3D human pose regression.",
            "2": "Therefore, we choose to predict 3D pose in the camera coordinate system [76, 93, 68, 78], which makes the 2D to 3D regression problem similar across different cameras.",
            "3": "During testing, to calibrate the scale of the outputs, we require that the sum of length of all 3D bones is equal to that of a canonical skeleton as shown in [68, 67, 97].",
            "4": "[68] 67.",
            "5": "[68] G."
        },
        "Hierarchical Modeling of Human-Object Interactions: from Concurrent Action Parsing to Physics-Based Grasping": {
            "authors": [],
            "url": "https://escholarship.org/content/qt5xw3c92h/qt5xw3c92h.pdf",
            "ref_texts": "[PZD17] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. \\Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose.\" InCVPR , pp. 1263{1272, 2017.",
            "ref_ids": [
                "PZD17"
            ],
            "1": "0\n[PZD17] 67.",
            "2": "[PZD17] 79."
        },
        "Adversarially parameterized optimization for 3d human pose estimation": {
            "authors": [],
            "url": "https://eprints.qut.edu.au/115073/1/adversarial_param_opt.pdf",
            "ref_texts": "[32] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. arXiv preprint arXiv:1611.07828 , 2016. 2,6",
            "ref_ids": [
                "32"
            ],
            "1": "Despite this, recent advances in deep learning have been used to regress 3D joint locations directly [4] [42] [32].",
            "2": "Some are undoubtably more accurate [23] [43] [32] [25], while others use slightly different metrics, training data and/or report different metrics [4] [24]\n[49] [50].",
            "3": "2\n[32] G."
        },
        "Development of a non-invasive motion capture system for swimming biomechanics": {
            "authors": [],
            "url": "https://e-space.mmu.ac.uk/628369/1/GA%20PhD%20thesis%20MMU.pdf",
            "ref_texts": "[54] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \\Coarse-to-ffne volumetric prediction for single-image 3d human pose,\" in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 7025{7034, 2017.",
            "ref_ids": [
                "54"
            ],
            "1": "Indeed, the Stacked Hourglass algorithm is the de facto baseline model for 2D pose detection: it is often used as an intermediary step in complex pipelines that require automatic 2D pose detection (such as 2D-to-3D algorithms [21,54,57]), and many newer algorithms for 2D pose detection are essentially modiffed Stacked Hourglass networks [6{8, 185, 186].",
            "2": "[54] G."
        },
        "Improving 3D human pose estimation in-the-wild": {
            "authors": [],
            "url": "https://www.ideals.illinois.edu/items/124614/bitstreams/409598/object?dl=1",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "22"
            ],
            "1": "Another method is single stage predictors, which directly predict the 3D pose from the image [1, 21, 22, 23, 24, 25, 26, 27, 28, 29].",
            "2": "[22] proposed volumetric heatmaps instead of direct coordinate regression.",
            "3": "6M, we follow the most common experimental setup [5, 9, 22, 60] by using five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9, S11) for testing.",
            "4": "[22] G."
        },
        "Learning Body Shape and Pose from Dense Correspondences": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.11955"
        },
        "Multi-hop Modulated Graph Convolutional Networks for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://bmvc2022.mpi-inf.mpg.de/0207.pdf",
            "ref_texts": "[20] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proc. IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "Most existing 3D pose estimation methods use an end-to-end pipeline [14, 20, 25, 26, 30] via a convolutional neural network (CNN) from an image, or a two-stage pipeline [4, 6, 16, 22, 31].",
            "2": "The first category of approaches directly predicts the 3D pose from the image [17, 19, 20, 26, 33, 34].",
            "3": "[20] proposed a fine discretisation of the 3D space around the subject and trained a CNN to predict the per-voxel likelihood for each body joint."
        },
        "\u57fa\u4e8e\u59ff\u6001\u4f30\u8ba1\u7684\u52a8\u7269\u884c\u4e3a\u8bc6\u522b\u7814\u7a76\u8fdb\u5c55": {
            "authors": [],
            "url": "http://zgnydxxb.cnjournals.com/zgnydxxb/ch/reader/create_pdf.aspx?file_no=20230603&year_id=2023&quarter_id=6&falg=1",
            "ref_texts": "[73]PavlakosG,ZhouXW,DerpanisKG,DaniilidisK.Coarse-to-fine volumetricpredictionforsingle-image3Dhumanpose[C].In:IEEE ConferenceonComputerVisionandPatternRecognition,Honolulu, HI,USA:IEEE,2017:1263-1272",
            "ref_ids": [
                "73",
                "C"
            ],
            "1": "2dhumanpose estimation:Newbenchmarkandstateoftheartanalysis[C].",
            "2": "MicrosoftCOCO:Commonobjectsincontext[C].",
            "3": "ClusteredPoseandNonlinearAppearance ModelsforHumanPoseEstimation[C].",
            "4": "Fastgloballyoptimal2dhumandetectionwith loopygraphmodels[C].",
            "5": "Pictorialstructuresrevisited:People detectionandarticulatedposeestimation[C].",
            "6": "Recoveringhumanbodyconfigurations usingpairwiseconstraintsbetweenparts[C].",
            "7": "Single-imageinsectposeestimationby graphbasedgeometricmodelsandrandomforests[C].",
            "8": "Histogramsoforientedgradientsforhumandetection [C].",
            "9": "Objectrecognitionfromlocalscale-invariantfeatures[C].",
            "10": "Deeppose:Humanposeestimationviadeepneural networks[C].",
            "11": "End-to-endlearningof deformablemixtureofpartsanddeepconvolutionalneuralnetworksfor humanposeestimation[C].",
            "12": "Convolutionalpose machines[C].",
            "13": "Stackedhourglassnetworksforhumanpose estimation[C].",
            "14": "Combininglocalappearanceand holisticview:Dual-sourcedeepneuralnetworksforhumanpose estimation[C].",
            "15": "Deepercut:Adeeper,stronger,andfastermulti-personposeestimation model[C].",
            "16": "Deepresiduallearningforimage recognition[C].",
            "17": "Aniterativeimageregistrationtechniquewithan applicationtostereovision[C].",
            "18": "Hrnet:Hamiltonianrescaling networkforimagedownscaling[C].",
            "19": "Crossdomainadaptationforanimalposeestimation[C].",
            "20": "Ssd:singleshotmultiboxdetector[C].",
            "21": "Richfeaturehierarchiesfor accurateobjectdetectionandsemanticsegmentation[C].",
            "22": "Fastr-cnn[C].",
            "23": "Humanobjectidentificationfor human-robotinteractionbyusingfastR-CNN[C].",
            "24": "Towardsaccuratemulti-personposeestimationinthewild [C].",
            "25": "MaskR-CNN[C].",
            "26": "Youonlylookonce: Unified,real-timeobjectdetection[C].",
            "27": "Receptivefieldblocknetforaccurateandfastobject detection[C].",
            "28": "Deepcut:Jointsubsetpartitionandlabelingfor multipersonposeestimation[C].",
            "29": "Realtimemulti-person2dpose estimationusingpartaffinityfields[C].",
            "30": "Jointmulti-personpose estimationandsemanticpartsegmentation[C].",
            "31": "U-net:Convolutionalnetworksfor biomedicalimagesegmentation[C].",
            "32": "Asimpleyeteffective baselinefor3dhumanposeestimation[C].",
            "33": "Learningtofuse2D and3Dimagecuesformonocularbodyposeestimation[C].",
            "34": "Generatingmultiplehypothesesfor3dhumanpose estimationwithmixturedensitynetwork[C].",
            "35": "3Dhumanposeestimation=2Dposeestimation +matching[C].",
            "36": "DRPose3D: depthrankingin3dhumanposeestimation[C].",
            "37": "3Dhumanposeestimationfrommonocularimages withdeepconvolutionalneuralnetwork[C].",
            "38": "In:AsianConferenceon ComputerVision,Singapore:Springer,Cham,2014:332-347\n[73]PavlakosG,ZhouXW,DerpanisKG,DaniilidisK.",
            "39": "Coarse-to-fine volumetricpredictionforsingle-image3Dhumanpose[C].",
            "40": "Lcr-net:Localization-classificationregressionforhumanpose[C].",
            "41": "Integralhumanposeregression [C].",
            "42": "WILDTRACK:AmulticameraHDdatasetfordenseunscriptedpedestriandetection[C].",
            "43": "Animalpose estimationfromvideodatawithahierarchicalvonMises-Fisher-Gaussian model[C].",
            "44": "ATRW:abenchmarkforAmur tigerre-identificationinthewild[C].",
            "45": "Articulatedmotion discoveryusingpairsoftrajectories[C].",
            "46": "AcinoSet:A3Dposeestimationdatasetand baselinemodelsforCheetahsinthewild[C].",
            "47": "Simpleonlineand realtimetracking[C]."
        },
        "2d/3d human pose estimation using deep convolutional neural nets": {
            "authors": [],
            "url": "https://open.metu.edu.tr/bitstream/handle/11511/27978/index.pdf",
            "ref_texts": "[70] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "70"
            ],
            "1": "[70] were the first to consider 3D human pose estimation as a 3D keypoint localization problem in a voxel space.",
            "2": "[70] (CVPR\u201917) 71.",
            "3": "Our self supervised (SS) model performs quite well compared to the recent fully 3D supervised methods [70, 101, 100, 67] which require abundant labeled data to 45 learn.",
            "4": "59\n[70] G."
        },
        "DiffPose: Toward More Reliable 3D Pose Estimation (Supplementary)": {
            "authors": [],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/supplemental/Gong_DiffPose_Toward_More_CVPR_2023_supplemental.pdf",
            "ref_texts": "[14] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In IEEE CVPR , pages 7025\u20137034, 2017. 2",
            "ref_ids": [
                "14"
            ],
            "1": "7 Pavlakos [14] 34."
        },
        "Generic video-based motion capture data retrieval": {
            "authors": [],
            "url": "http://www.apsipa.org/proceedings/2019/pdfs/272.pdf",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7025\u20137034, 2017.",
            "ref_ids": [
                "23"
            ],
            "1": "Another class of methods adopts the strategy to directly learn the 3D poses from monocular images [21], [22], [23].",
            "2": "[23] G."
        },
        "Category Map Guided Ordinal Depth Prediction for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://dl.acm.org/doi/pdf/10.1145/3473258.3473303",
            "ref_texts": "[14] Pavlakos G, Zhou X, Derpanis K G, et al. Coarse-to-fine volumetric prediction for single-image 3D human pose[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 7025-7034.",
            "ref_ids": [
                "14",
                "C"
            ],
            "1": "1 One-stage approach One-stage approaches usually directly regress 3D pose from images [14,33,35].",
            "2": "[14] proposed a volumetric heatmap to 41\n ICBBT \u201921, May 21\u201323, 2021, Xi\u2019an, China Liguo Jiang depict the joint location probability in space, and used a coarse-tofine strategy to refine the volumetric heatmaps prediction.",
            "3": "Following the standard protocols for 3D pose estimation [14] in Human3.",
            "4": "We evaluated on \u201cWalking\u201d and \u201cJogging\u201d actions following [14].",
            "5": "[14] 67.",
            "6": "[14] 47.",
            "7": "Method Walking Jogging Avg S1 S2 S3 S1 S2 S3\n[14] 22.",
            "8": "A simple yet effective baseline for 3d human pose estimation[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "9": "Not All Parts Are Created Equal: 3D Pose Estimation by Modeling Bi-directional Dependencies of Body Parts[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "10": "Lea3rning pose grammar to encode human body configuration for 3d pose estimation[C]//Proceedings of the AAAI Conference on Artificial Intelligence.",
            "11": "Semantic graph convolutional networks for 3D human pose regression[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "12": "Learning to fuse 2d and 3d image cues for monocular body pose estimation[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "13": "Exploiting spatial-temporal relationships for 3d pose estimation via graph convolutional networks[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "14": "3d human pose estimation in video with temporal convolutions and semi-supervised training[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "15": "Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.",
            "16": "Imagenet: A large-scale hierarchical image database[C]//2009 IEEE conference on computer vision and pattern recognition.",
            "17": "HEMlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "18": "[14] Pavlakos G, Zhou X, Derpanis K G, et al.",
            "19": "Coarse-to-fine volumetric prediction for single-image 3D human pose[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "20": "Compressed Volumetric Heatmaps for MultiPerson 3D Pose Estimation[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.",
            "21": "Deep multitask architecture for integrated 2d and 3d human sensing[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "22": "Towards 3d human pose estimation in the wild: a weakly-supervised approach[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "23": "3d human pose estimation in the wild by adversarial learning[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "24": "Integral human pose regression[C]//Proceedings of the European Conference on Computer Vision (ECCV).",
            "25": "Convolutional pose machines[C]//Proceedings of the IEEE conference on Computer Vision and Pattern Recognition.",
            "26": "Towards accurate multi-person pose estimation in the wild[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "27": "In the wild human pose estimation using explicit 2d features and intermediate 3d representations[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "28": "Stacked hourglass network for robust facial landmark localisation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops.",
            "29": "2d human pose estimation: New benchmark and state of the art analysis[C]//Proceedings of the IEEE Conference on computer Vision and Pattern Recognition.",
            "30": "Cascaded pyramid network for multi-person pose estimation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.",
            "31": "Exploiting temporal information for 3d human pose estimation[C]//Proceedings of the European Conference on Computer Vision (ECCV).",
            "32": "Deep residual learning for image recognition[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.",
            "33": "Pytorch: An imperative style, high-performance deep learning library[C]//Advances in neural information processing systems.",
            "34": "Ordinal depth supervision for 3d human pose estimation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "35": "Compositional human pose regression[C]//Proceedings of the IEEE International Conference on Computer Vision."
        },
        "Evaluating the performance of simulated IMU data for animal activity recognition": {
            "authors": [],
            "url": "http://essay.utwente.nl/88458/1/Vanwinsen_BA_EEMCS.pdf",
            "ref_texts": "[27] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR , abs/1611.07828, 2016. URL http: //arxiv.org/abs/1611.07828.",
            "ref_ids": [
                "27"
            ],
            "1": "[22, 27].",
            "2": "[27] by using lower-resolution heatmaps throughout the network.",
            "3": "[27] G."
        },
        "Learning Generalizable Visual Patterns Without Human Supervision": {
            "authors": [],
            "url": "https://boris.unibe.ch/168473/1/phd_simon_jenni.pdf",
            "ref_texts": ""
        },
        "A Training Method For VideoPose3D with Ideology of Action Recognition": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2206.06430"
        },
        "Acquiring Motor Skills Through Motion Imitation and Reinforcement Learning": {
            "authors": [],
            "url": "https://digitalassets.lib.berkeley.edu/techreports/ucb/incoming/EECS-2021-267.pdf",
            "ref_texts": ""
        },
        "Multi-modal analysis for the automatic evaluation of epilepsy": {
            "authors": [
                "David Esteban",
                "Ahmedt Aristizabal"
            ],
            "url": "https://eprints.qut.edu.au/132537/1/David_Ahmedt%20Aristizabal_Thesis.pdf",
            "ref_texts": "[Pavlakos et al., 2017] Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. (2017). Coarse-tofine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pages 1263\u20131272.",
            "ref_ids": [
                "Pavlakos et al\\., 2017"
            ]
        },
        "Deep Learning for Motion Recognition": {
            "authors": [
                "Sara Daraei"
            ],
            "url": "http://d-scholarship.pitt.edu/42049/1/Thesis_SaraDaraei.pdf",
            "ref_texts": "[126] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ,p a g e s7 0 2 5 \u2013 7 0 3 4 , 2017.",
            "ref_ids": [
                "126"
            ],
            "1": "The modern era of deep learning as defined by [109] started in 2006 [126, 26, 245] and since around 2011 it has been actively used and made a tremendous impact in a variety of domains such as image processing, computer vision, natural language processing, machine translation, medical information processing and image analysis, art, and so many others."
        },
        "Biomechanical Models and Robotic Systems for Human Motion Assessment": {
            "authors": [],
            "url": "https://digitalassets.lib.berkeley.edu/techreports/ucb/incoming/EECS-2021-22.pdf",
            "ref_texts": ""
        },
        "Sign language detection": {
            "authors": [],
            "url": "https://polynoe.lib.uniwa.gr/xmlui/bitstream/handle/11400/4425/0014-%20%20%20%20%20-%20Sign%20Language%20Detection.pdf?sequence=1",
            "ref_texts": "20. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse -to-Fine Volumetric Prediction for Single -Image 3d Human Pose. arXiv preprint arXiv:1611.07828, 2016. ",
            "ref_ids": [
                "20"
            ]
        },
        "Monocular 3D Pose Recovery via Nonconvex Sparsity with Theoretical Analysis": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.11295",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for singleimage 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 1",
            "ref_ids": [
                "30"
            ],
            "1": "[30] [29] predict the 3D landmarks by considering a ranking loss of by the ordinal relationship built upon estimated depth.",
            "2": "1\n[30] G."
        },
        "3D Single Person Pose Estimation Method Based on Deep Learning.": {
            "authors": [],
            "url": "https://scholar.archive.org/work/wz25ffq5vramxfcys5tsero2g4/access/wayback/https://ebooks.iospress.nl/pdf/doi/10.3233/FAIA200726",
            "ref_texts": "[19] Pavlakos G, Zhou X, Derpanis K G, et al. Coarse-to-fine volumetric prediction for single-image 3D human pose[C]//Proceedings of the IEEE Co nference on Computer Vision and Pattern Recognition. ",
            "ref_ids": [
                "19",
                "C"
            ],
            "1": "[19] used two separate networks to solve the pro blem of 3D human pose estimation from a single color image.",
            "2": "Occlusion-aware networks for 3d human pose estimation in video[C]//Proceedings of the IEEE International Conf erence on Computer Vision.",
            "3": "Lightweight 3D Human Pose Estimation Network Training Using Teacher-Student Learning[C]//The IEEE Winter Co nference on Applications of Computer Vision.",
            "4": "DeepFuse: An IMU-Aware Network for Real-Time 3D Human Pose Estimation from Multi-View Image[C]//The IEEE Wi nter Conference on Applications of Computer Vision.",
            "5": "Adversarial posenet: A structure-awa re convolutional network for human pose estimation[C]//Proceedings of the IE EE International Confe rence on Computer Vision.",
            "6": "Self adversarial training for human pose estimation[C]//2018 AsiaPacific Signal and Information Processing Associat ion Annual Summit an d Conference (APSIPA ASC).",
            "7": "Deep high -resolution representation learning for human pose estimation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.",
            "8": "Deep kinematic pose regression[C]//European Conference on Computer Vision.",
            "9": "Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition.",
            "10": "Sparseness meets deepness: 3d human pose estimation from monocular video[C]//Proceedings of the IEEE conf erence on computer visio n and pattern recognition.",
            "11": "Lif ting from the deep: Convolutional 3d pose estimation from a single image[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "12": "3d human pose estimation= 2d pose estimation+ matching[C]//Proceedings of the IEEE Conference on Computer Visio n and Pattern Recognition.",
            "13": "3d human pose estimation fr om a single image via distance matrix regression[C]//Proceedings of the IE EE Conference on Computer Vision and Pattern Recognition.",
            "14": "A simple yet effective baseline for 3d human pose estimation[C]//Proceedings of the IEEE International Conference on Computer Vision.",
            "15": "[19] Pavlakos G, Zhou X, Derpanis K G, et al.",
            "16": "Coarse-to-fine volumetric prediction for single-image 3D human pose[C]//Proceedings of the IEEE Co nference on Computer Vision and Pattern Recognition.",
            "17": "To wards 3d human po se estimation in the wild: a weakly -supervised approach[C]//Proceedings of the IE EE International Conference on Comp uter Vision.",
            "18": "Ordinal depth supervision for 3d human pose estimation[C]//Proceedings of the IE EE Conference on Computer V ision and Pattern Recognition.",
            "19": "3d human pose estimation in the wild by adversarial learning[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "20": "3d human pose estimation in video with temporal convolutions and semi-supervised training[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.",
            "21": "Generating multiple hypotheses for 3d human pose estimation with mixture density network[C]//Proceedings of the IE EE Conference on Computer Vision and Pattern Recognition.",
            "22": "Panoptic studio: A massively multiview system for social motion capture[C]//Proceedings of the IEEE International Conference on Com puter Vision.",
            "23": "Monocular 3d hum an pose estimation in the wild using improved cnn supervision[C]//2017 international conference on 3D vision (3DV)."
        },
        "Expressive Whole-Body 3D Multi-Person Pose and Shape Estimation from a Single Image": {
            "authors": [],
            "url": "https://s-space.snu.ac.kr/bitstream/10371/175282/1/000000165777.pdf",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \\Coarse-to-ffne volumetric prediction for single-image 3d human pose,\" in CVPR , 2017.",
            "ref_ids": [
                "29"
            ],
            "1": "Prior information on the bone length [29] or the groundtruth [28] has been commonly used for the localization of the root.",
            "2": "[29] extended the U-net shaped network to estimate a 3D heatmap for each joint.",
            "3": "For example, many works [28, 29, 32, 33] estimate the 2D image coordinates and root-relative depth values of keypoints.",
            "4": "[29] and Moon et al.",
            "5": "Detection-based 3D human pose and mesh estimation methods [21, 28, 29, 35] have achieved high 3D positional pose accuracy by utilizing both local and global features.",
            "6": "[29] G."
        },
        "Machine Learning for Human Performance Capture from Multi-Viewpoint Video": {
            "authors": [],
            "url": "https://openresearch.surrey.ac.uk/esploro/fulltext/doctoral/Machine-learning-for-human-performance-capture/99514385602346?repId=12139438260002346&mId=13140527520002346&institution=44SUR_INST",
            "ref_texts": "[55] Pavlakos, G., Zhou, X., Derpanis, K. G., and Daniilidis, K. (2017). Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proc. Computer Vision and Pattern Recognition .",
            "ref_ids": [
                "55"
            ],
            "1": "[55] used a simple volumetric representation in a 3D convnet for pose estimation.",
            "2": "[55] Pavlakos, G."
        },
        "Supplementary Materials Revitalizing Optimization for 3D Human Pose and Shape Estimation: A Sparse Constrained Formulation": {
            "authors": [],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/supplemental/Fan_Revitalizing_Optimization_for_ICCV_2021_supplemental.pdf",
            "ref_texts": "[17] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 9",
            "ref_ids": [
                "17"
            ],
            "1": "Following the standard training-testing protocol in [17], we use subjects S1, S5-S8 for training."
        },
        "Real-Time Action Classification using Intermediate Skeletal Pose Estimation": {
            "authors": [],
            "url": "https://repository.lib.fit.edu/bitstream/handle/11141/3211/ZISISTEGOS-THESIS-2020.pdf?sequence=1",
            "ref_texts": "[59] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. CoRR, abs/1611.07828, 2016.",
            "ref_ids": [
                "59"
            ],
            "1": "The second category consists of approaches that try to estimate the model parameters directly from pixels, usually through the usage of a joint heat-map [37] [71] [59] [80]."
        },
        "Using Sensors and AI to Enable On-Demand Virtual Physical Therapist and Balance Evaluation at Home": {
            "authors": [],
            "url": "https://escholarship.org/content/qt72h862hn/qt72h862hn.pdf",
            "ref_texts": "[102] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pos,\u201d Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017) , Hawaii, USA, Jul. 2017.",
            "ref_ids": [
                "102"
            ],
            "1": "Motivated by the use of Convolutional Neural Network (CNN) in pose estimation problems [102,103], we propose to use CNN in our CoM estimation model as estimating the human\u2019s CoM position is similar to estimating the joint positions (i.",
            "2": "For example, the right shank connecting the right knee joint and the right ankle joint is rendered in light blue (RGB = [0, 102, 153]).",
            "3": "113\n[102] G."
        },
        "Towards Multi-Person 3D Pose Estimation in Natural Videos": {
            "authors": [
                "Tiffany Mc"
            ],
            "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/45769/GU_washington_0250E_21594.pdf?sequence=1",
            "ref_texts": "[39] Pavlakos, G., Zhou, X., Derpanis, K.G. and Daniilidis, K.. Coarse -to-fine volumetric prediction for single -image 3D human pose. In Computer Vision and Pattern Recognition (C VPR), IEEE Conference on (pp. 1263 -1272), 2017 . ",
            "ref_ids": [
                "39"
            ],
            "1": "[39] Pavlakos, G."
        },
        "\u6df1\u5ea6\u5b66\u4e60\u7684\u4e09\u7ef4\u4eba\u4f53\u59ff\u6001\u4f30\u8ba1\u7efc\u8ff0": {
            "authors": [],
            "url": "http://fcst.ceaj.org/CN/article/downloadArticleFile.do?attachType=PDF&id=3211"
        },
        "Context-aware human modelling": {
            "authors": [],
            "url": "https://upcommons.upc.edu/bitstream/handle/2117/329328/research_plan_Enric%20(2).pdf",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017, pp. 7025\u20137034.",
            "ref_ids": [
                "16"
            ],
            "1": "2 Human Pose Estimation Since the release of large-scale MoCap datasets [12, 13, 14], there has been a growing interest in the problem of estimating 3D human pose from single images [15, 12, 16, 17, 18, 19, 20, 21].",
            "2": "[16] propose a U-Net architecture to recover jointwise 3D heatmaps.",
            "3": "[16] G."
        },
        "Synthetic occlusion augmentation for 3D human pose estimation with volumetric heatmaps": {
            "authors": [],
            "url": "https://www.vision.rwth-aachen.de/media/papers/synthetic_occl_augm/posetrack3d-sarandi.pdf",
            "ref_texts": "17. Pavlakos, G., Zhou, X., Derpanis, K.G., Daniilidis, K.: Coarse-to-ffne volumetric prediction for single-image 3d human pose. In: CVPR (2017)",
            "ref_ids": [
                "17"
            ],
            "1": "This includes volumetric [17][24] and marginal heatmaps [14].",
            "2": "in the interpretation of the volumetric heatmap's axes [17]: X and Y correspond to image space and the depth axis to camera space, relative to the person center."
        },
        "Human torso pose forecasting in the real world": {
            "authors": [],
            "url": "https://www.ri.cmu.edu/app/uploads/2019/08/Abhijat_MSR_Thesis.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017. 2.3",
            "ref_ids": [
                "35"
            ],
            "1": "Several end-to-end models have been trained on this task that regress the individual skeletal keypoints [31, 32, 35, 40, 41, 47]."
        },
        "Deeply learned 2d tool pose estimation for robot-to-camera registration": {
            "authors": [],
            "url": "https://homes.esat.kuleuven.be/~konijn/publications/2017/e129966.pdf"
        },
        "Vision-based human gestures recognition for human-robot interaction": {
            "authors": [],
            "url": "https://theses.hal.science/tel-02310606/file/MAZHAR_2019_archivage.pdf",
            "ref_texts": "[127] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u2013",
            "ref_ids": [
                "127"
            ],
            "1": "3D human pose estimation methods can also be categorized into two groups; one-stage approaches [114,126,127] which directly regress 3D pose from images and two-stage methods [122,128\u2013130] that first estimate 2D pose in the form of joint location confidence maps and then lift this 2D prediction to 3D pose either by a constraint deep regression strategy [131,132] or by matching the predictions with 2D projections of existing 3D poses from a database [129] or by fitting a 3D model on this 2D prediction [122,128].",
            "2": "1 Discriminative Approaches As mentioned above, discriminative methods tend to predict 3D pose directly from image data, which can either be monocular images [113,134,114,135,127,136], depth images [112,125,137] or short image sequences [115]."
        },
        "Understanding the sources of error for 3D human pose estimation from monocular images and videos": {
            "authors": [
                "Johnny Canuck"
            ],
            "url": "https://open.library.ubc.ca/media/download/pdf/24/1.0361162/4",
            "ref_texts": "[87] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017.",
            "ref_ids": [
                "87"
            ],
            "1": "With the recent success of Deep Learning in the area of Computer Vision, many systems have tried to exploit the powerful discriminative ability of deep networks, to directly estimate 3D poses from RGB images by training the architecture endto-end [63, 65, 73, 74, 81, 85, 87, 112, 116, 118, 133].",
            "2": "However, most of the recent work based on deep-learning techniques [51, 63, 73, 74, 87, 116, 117] typically uses model-free representation of 3D human pose.",
            "3": "Although most of the methods [63, 73, 74, 87, 116, 117] using a model-free representation regress the 3D joint location directly, Pavlakos et al.",
            "4": "[87] predicts volumetric heatmap for each joint, which gives the likelihood 17 of the presence of a joint in a particular 3D spatial location.",
            "5": "[63, 65, 73, 81, 85, 87, 96, 112, 116, 118\u2013120, 133].",
            "6": "[87] also develops an end-to-end CNN based model to predict 3D pose.",
            "7": "1 Mapping 2D pose to 3D We chose to use 2D and 3D locations of joints as inputs and outputs, instead of inferring 3D pose from images directly by training the model end-to-end which many of the recent techniques did [63, 65, 73, 81, 85, 87, 96, 112, 116, 119, 120, 133] because we wanted validate the efficiency of dividing the 3D pose estimation task.",
            "8": "3D probabilities or volumetric heatmap of joints [87], 3D motion parameters [133] or coefficients of basis pose [2, 16, 92, 132, 134].",
            "9": "There are a number of works that have predicted 3D pose in camera coordinate frame [29, 64, 87, 117, 133, 134].",
            "10": "4 Pavlakos et al [87] (MA) 67.",
            "11": "0 Pavlakos et al [87] (MA) 17j \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "12": "[87] by 4 :4 mm, who trained an end-to-end model from image by extending the stacked-hourglass 2D pose estimator to make it estimate volumetric heatmaps.",
            "13": "[87] by 9 :0 mm and Tekin et al.",
            "14": "[87] and Tekin et al.",
            "15": "9 Pavlakos et al [87] 22.",
            "16": "[87], who had the previous best results by training their network end-to-end, hypothesized that regressing 3D points directly is more difficult than predicting a volumetric heatmap.",
            "17": "[87] which extends the stacked-hourglass network to predict 3D volumetric heatmaps for each joints.",
            "18": "This is a standard protocol used the methods which have trained a CNN end-to-end for estimating 3D pose from images directly [73, 87, 119].",
            "19": "3 \u2013 Pavlakos et al [87] 71.",
            "20": "7 Pavlakos et al [87] (MA) 67.",
            "21": "[87] by 20 mm (almost 28% better) on protocol #1.",
            "22": "1 Pavlakos et al [87] (MA) 17j \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 51.",
            "23": "[87] claimed that it is more difficult to regress 3D joint locations directly than predicting the volumetric heatmaps of joints, whereas our first network proved that 3D joint locations can be predicted with high accuracy from something as simple as 2D coordinates of joints.",
            "24": "!pages 18, 28\n[87] G."
        },
        "Identifying people using temporal and spatial changes in local movements measured from body sway": {
            "authors": [],
            "url": "https://pattern.eecs.tottori-u.ac.jp/pdf/2017-ACPR-body-sway.pdf"
        },
        "Architectures d'apprentissage profond pour la reconnaissance d'actions humaines dans des s\u00e9quences vid\u00e9o RGB-D monoculaires: application \u00e0 la surveillance \u2026": {
            "authors": [],
            "url": "https://theses.hal.science/tel-02879316/document",
            "ref_texts": ""
        },
        "A Robust Billboard-based Free-viewpoint Video Synthesizing Algorithm for Sports Scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1908.02446",
            "ref_texts": "[51] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , Jul 2017.",
            "ref_ids": [
                "51"
            ],
            "1": "Many recent works [51], [52], [53] follow an end-to-end learning paradigm consisting of a Convolutional Network for 2D/3D body joint localization and a subsequent optimization step to regress to a 3D pose."
        },
        "Temporal Interpolation of human point clouds using neural networks and body part segmentation": {
            "authors": [],
            "url": "https://upcommons.upc.edu/bitstream/handle/2117/339743/152733.pdf?sequence=1",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse -to-Fine Volumetric Prediction for Single -Image 3D Human Pose,\u201d arXiv:1611.07828 [cs] , Jul. 2017, Accessed: Jun. 06, 2020. [Online]. Availa ble: http://arxiv.org/abs/1611.07828. ",
            "ref_ids": [
                "23",
                "cs",
                "Online"
            ],
            "1": "Master thesis \n Temporal Interpolation of human point clouds using neural networks and body part segmentation \n \n Author : Ignacio Reimat Corbella Supervisors : Irene Viola, Pablo Cesar Tutor : Antonio Chica \n A thesis submitted in fulfillment of the requirements for the Master in Innovation and Research in Informatics \u2013 Computer Graphics and Virtual Reality from : \n \n Research condu cted at Centrum Wiskunde & Informatica in Amsterdam \n \n \n\n2 \n Abstract In the context of social VR, one of the media formats that is gaining popularity is that of a point cloud.",
            "2": ", how audio, video and graphics are captured, delivered and rendered at users\u2019 homes) demonstrating a significant improvement of the feeling of being there together and the photorealistic quality of the content.",
            "3": "These architectures have been applied to multiple research fields such as computer vision, speech recognition, natural language pro cessing, audio recognition, social network filtering, bioinformatics, and medical image analysis .",
            "4": "In order to prove our results, we are going to use existing point cloud error metrics.",
            "5": "There are several CNN contributions based on discriminative methods used to predict \n3D human pos e [23], [24] .",
            "6": "Dataset Characteristics Microsoft Voxelized Upper Bodies 5 dynamic point cloud sequences \nCaptured using 4 frontal RGB cameras \n8iVFB v2 4 dynamic point cloud sequences \n1200 frames (30 fps) = 10 seconds per action \nCapture d using 42 RGB cameras from multiple directions \nResolution \u2248 700.",
            "7": "Dataset Characteristics Standford EVAL depthmaps captured from a single point of view \n3 subjects performing 8 sequences each ITOP 100K real -world depth images \nMultiple camera viewpoints \n20 people performing 15 actions \n3d joints Berkeley MHAD 12 people performing 11 actions each \n5 different capturing systems : \noptical motion \n4 multi -view stereo camera arrays \n2 Microsoft Kinects, \n6 wireless accelerometers \n4 microphones Surreal 6 million frames \nsynthetically -generated \nhuman motion capture data \nground truth pose \ndepth maps \nsegmentation masks \n22 \n UBC3V synthetic \n16 characters \n19.",
            "8": "Evaluation and Results In this chapter we present the results of the performed experiments in order to prove our hypothesis, showing visual results and objective metrics.",
            "9": "3 shows the performance metrics for the different blocks of the system .",
            "10": "6GHz, 16GB RAM and a NVIDIA RTX 2080Ti graphics card with 11GB GDDR6.",
            "11": "Its characteristics are a processor Intel i7-7700HQ working at 2.",
            "12": "8GHz , 16GB RAM and a NVIDIA GTX 1070 Max -Q graphics card with 8GB GD DR5.",
            "13": "Next , we present the objective error metrics obtained with the evaluation set , corresponding to 200 point clouds .",
            "14": "We have computed the point to point and point to plane metrics, using MSE and Hausdorff distance , between the ground truth point cloud and the predicted point cloud.",
            "15": "Box plot of the error metrics (zoomed in) in Experiment 1 A median value always smaller for the model \ud835\udc40\u210e\ud835\udc52\ud835\udc4e\ud835\udc51\ud835\udc60, tells us that this model makes better predictions in most of the cases , except for some outliers.",
            "16": "The model was saved on epoch 779 The error metrics are presented in Figure 39, Figure 40, Figure 41, Figure 42 and Figure 43.",
            "17": "Boxplot of the error metrics (zoom in) in Experiment 2 Figure 44 shows the visual results of the prediction of heads using both models.",
            "18": "The model was saved on epoch 266 The error metrics are presented in Figure 46, Figure 47, Figure 48, Figure 49 and Figure 50.",
            "19": "Boxplot of the error metrics (zoomed in) in Experiment 3 The visual results in Figure 51 show also that the predictions differ greatly from the desired value , being closer to the groundtruth the predictions using Mhands .",
            "20": "The model was saved on epoch 241 The error metrics are shown in Figure 53, Figure 54, Figure 55, Figure 56 and Figure 57.",
            "21": "Box plot of the error metrics in Experiment 4 The visual results are shown in Figure 58.",
            "22": "This might be due to the characteristics of the body part itself , having a similar shape to that of the skeleton , and obtaining benefit from the effect discussed in Section 5.",
            "23": "The model was saved on epoch 339 The error metrics are presented in Figure 60, Figure 61, Figure 62, Figure 63 and Figure 64.",
            "24": "Boxplot of the error metrics in Experiment 5 The visual comparisons in Figure 65 clearly show , that the predictions using Mchests are closer to the desired value , proving once again our main hypothesis .",
            "25": "Again , because of the availability of dynamic point cloud datasets with our desired characteristics , we decided that the selected dataset was our best option.",
            "26": "We could also explore other error metrics considering not only the geometry, but also the color.",
            "27": "From the point of view of the interpolation system we have identified five lines of action for futur e work: 1) explore different error metrics to implement the loss function; 2) retrain our models with a larger dataset to check if that increases the performance; 3) explore the results of training a single model with all the different body parts , to test if that gives better results than having a specific mode l for each body part; 4) explore the results of reassembling all the interpolated parts together; 5) reimplement the upsampling module in order to achieve real time performance.",
            "28": "01411 [cs] , Jul.",
            "29": "[Online].",
            "30": "01692 [cs] , Aug.",
            "31": "[Online].",
            "32": "07514 [cs] , Mar.",
            "33": "[Online].",
            "34": "05362 [cs] , Mar.",
            "35": "[Online].",
            "36": "06396 [cs] , Nov.",
            "37": "[Online].",
            "38": "01222 [cs] , Oct.",
            "39": "[Online].",
            "40": "[Online].",
            "41": "Bronstein, \u201cRecent Trends, Applications, and Perspectives in 3D Shape Similarity Assessment,\u201d Computer Graphics Forum , vol.",
            "42": "07829 [cs] , Jun.",
            "43": "[23] G.",
            "44": "07828 [cs] , Jul.",
            "45": "[Online].",
            "46": "08229 [cs] , Sep.",
            "47": "[Online].",
            "48": "05389 [cs] , Jul.",
            "49": "[Online].",
            "50": "00134 [cs] , Apr.",
            "51": "[Online].",
            "52": "03098 [cs] , Aug.",
            "53": "[Online].",
            "54": "Graphics , pp.",
            "55": "07076 [cs] , Jul.",
            "56": "[Online].",
            "57": "Bajcsy, \u201cBerkeley MHAD: A comprehensive Multimodal Human Action Database,\u201d in 2013 IEEE Workshop on Applications of Computer Vision (WACV) , Jan.",
            "58": "Kuhn, \u201cThe Hungarian method for the assignment problem,\u201d Naval Research Logistics , vol."
        },
        "Applications of Silicon Retinas: from Neuroscience to Computer Vision": {
            "authors": [],
            "url": "https://scholar.archive.org/work/7yxrfiazajcdrhdshnenbujiby/access/wayback/https://www.zora.uzh.ch/id/eprint/217905/1/Thesis_Gemma.pdf",
            "ref_texts": "[139] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3D human pose,\u201d in IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, pp.",
            "ref_ids": [
                "139"
            ],
            "1": "Other methods directly predict the 3D pose without separately predicting the 2D pose: [142] simultaneously minimizes the 2D heatmaps and 3D pose, while [139] directly outputs a dense 3D volume with separate voxel likelihoods for each joint.",
            "2": "[139] G."
        },
        "Semi-Supervised Learning of Disentangled Representations for Cross-Modal Translation": {
            "authors": [],
            "url": "http://iccvm.org/2021/papers/Poster-1.pdf",
            "ref_texts": "[44] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 7025\u20137034, 2017. 5",
            "ref_ids": [
                "44"
            ],
            "1": "[44] 71.",
            "2": "5, 6\n[44] G."
        },
        "Deep Learning Analysis of Human Pose and Actions": {
            "authors": [],
            "url": "https://opal.latrobe.edu.au/ndownloader/files/38777829",
            "ref_texts": "[83] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis and Kostas Daniilidis. \u2018Coarse-to-fine volumetric prediction for single-image 3D human pose\u2019. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition . IEEE. 2017, pp. 1263\u20131272 (cit. on pp. 7, 9, 83, 84, 86, 88, 108, 116, 152).",
            "ref_ids": [
                "83"
            ],
            "1": "2automated human -centric analysis 7 In the more specific context of three-dimensional coordinate regression, some existing works choose to represent heatmaps in 3D space [83, 65], which is a logical extension of the heatmaps used successfully in 2D pose estimation.",
            "2": "In contrast, existing heatmap-based 3D pose estimation models usually represent joint locations with memory-intensive volumetric heatmaps [65, 83] or simply use fully-connected output layers instead [69, 108].",
            "3": "[83] partially ease memory requirements by gradually building up the depth resolution of activations throughout the network in a coarse-to-fine fashion.",
            "4": "The accuracy metrics for this approach are highly competitive with the state-of-the-art results published in existing literature [83, 65, 69, 108, 72, 17], positioning MPMMs as a viable alternative to volumetric heatmaps.",
            "5": "2 mpmms with soft -argmax In this section, marginal probability mass maps (MPMMs) will be conceptually derived from the volumetric heatmaps used by some of the existing work in 3D pose estimation [65, 83].",
            "6": "This drawback is identified and partially mitigated within existing work by reducing the resolution of the volumetric heatmaps in some way [65, 83].",
            "7": "root joint depth to help normalise the joint locations, which is standard practice amongst existing works [83, 108, 133].",
            "8": "[83] 71.",
            "9": "It was discovered that the task of monocular 3D human pose estimation could be solved using 2D marginalisations of the volumetric heatmaps used in existing work [65, 83], thus eliminating the memory-intensive practice of predicting volumetric heatmaps directly."
        },
        "Human body parts segmentation via stacked and multi-task learning": {
            "authors": [],
            "url": "https://openaccess.uoc.edu/bitstream/10609/103966/1/phd_thesis_dani-1.pdf",
            "ref_texts": "98 Bibliography. M. Omran, C. Lassner, G. Pons-Moll, P. Gehler, and B. Schiele. Neural body fftting: Unifying deep learning and model based human pose and shape estimation. In 2018 International Conference on 3D Vision (3DV) , pages 484{494. IEEE, 2018. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-ffne volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition, 2017. CVPR 2017. IEEE Computer Society Conference on , pages 1263{1272. IEEE, 2017. L. Pishchulin, M. Andriluka, P. Gehler, and B. Schiele. Poselet conditioned pictorial structures. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 588{595, 2013a. L. Pishchulin, M. Andriluka, P. Gehler, and B. Schiele. Strong appearance and expressive spatial models for human pose estimation. In Proceedings of the IEEE international conference on Computer Vision , pages 3487{3494, 2013b. A.-I. Popa, M. Zanffr, and C. Sminchisescu. Deep multitask architecture for integrated 2d and 3d human sensing. In Conference on Computer Vision and Pattern Recognition , volume 1, page 5, 2017. E. Puertas, M. Bautista, D. Sanchez, S. Escalera, and O. Pujol. Learning to segment humans by stacking their body parts. In European Conference on Computer Vision , pages 685{697. Springer, 2014. E. Puertas, S. Escalera, and O. Pujol. Generalized multi-scale stacked sequential learning for multi-class classiffcation. Pattern Analysis and Applications , 18(2):247{261, 2015. V. Ramakrishna, D. Munoz, M. Hebert, J. A. Bagnell, and Y. Sheikh. Pose machines: Articulated pose estimation via inference machines. In European Conference on Computer Vision , pages 33{47. Springer, 2014. D. Ramanan. Learning to parse images of articulated bodies. In Advances in neural information processing systems , pages 1129{1136, 2006. D. Ramanan, D. A. Forsyth, and A. Zisserman. Strike a pose: Tracking people by ffnding stylized poses. In Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on , volume 1, pages 271{278. IEEE, 2005. D. Ramanan, D. Forsyth, and A. Zisserman. Tracking people by learning their appearance. PAMI , 29(1):65 {81, jan. 2007. Bibliography. 99 M. Reyes, G. Dominguez, and S. Escalera. Featureweighting in dynamic timewarping for gesture recognition in depth data. In Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on , pages 1182{1188. IEEE, 2011. C. Rother, V. Kolmogorov, and A. Blake. \"grabcut\": interactive foreground extraction using iterated graph cuts. ACM Trans. Graph. , 23(3):309{314, Aug. 2004a. ISSN"
        },
        "Deep Learning based Human Pose Estimation": {
            "authors": [
                "Yang Li"
            ],
            "url": "https://opus.lib.uts.edu.au/bitstream/10453/149022/2/02Whole.pdf",
            "ref_texts": "[63]G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-finevolumetric prediction for single-image 3d human pose,\u201d in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2 0 1 7 ,p p .7025\u20137034.",
            "ref_ids": [
                "63"
            ],
            "1": "The single-stage method [82, 63, 30, 81, 80, 104]directly predict depth values of human joints from monocular images through CNNs.",
            "2": "[63] discretized the 3D space around the target position, proposed a more natural 3D pose representation, and trained a CNN topredict the probability value of the voxel corresponding to each human joint.",
            "3": "The first class of methods [82, 63, 56, 30, 81] directly predict the depthfrom monocular images through the deep convolutional neural networks (DCNNs).",
            "4": "Some of them [82, 63, 56, 30, 81] predict 3D poses directly from single imagesthrough the deep convolutional neural networks (CNNs).",
            "5": "[63] trained a CNN to predict the voxellikelihoods for each human joint through a fine discretization of the 3D space.",
            "6": "[63]G."
        },
        "Robust Video Object Tracking via Camera Self-calibration": {
            "authors": [],
            "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/43951/Tang_washington_0250E_20501.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[91] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-ffne volumetric prediction for single-image 3D human pose. In Proc. CVPR , pages 7025{7034, 2017.",
            "ref_ids": [
                "91"
            ],
            "1": "[91] propose a voxel representation for each joint as the regression target, and design a coarse-to-ffne learning strategy.",
            "2": "[91] 74."
        },
        "Deep Neural Networks for Human Motion Analysis in Biomechanics Applications": {
            "authors": [],
            "url": "https://rucore.libraries.rutgers.edu/rutgers-lib/60894/PDF/1/play/",
            "ref_texts": "[81] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \"Coarse -to-fine volumetric prediction for single -image 3D human pose,\" in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , 2017, pp. 1263 -1272. ",
            "ref_ids": [
                "81"
            ],
            "1": "While [77-80] represents interme diate 2D pose as 2D coordinates of the joints, [21, 81, 82] define it by a set of heatmaps that encode the probability of observing a specific joint at the corresponding image location.",
            "2": "[81] train a DNN with 2D joints heatmaps as an intermediate representation to predict per voxel likelihood for each joint in the 3D space instead of directly regre ssing the 3D joint coordinates.",
            "3": "8 \n[81] 67.",
            "4": "0 \n[81] 83.",
            "5": "[81] G."
        },
        "Fast 3D Post Estimation of Human Based on Optical Flow and Particle Filter": {
            "authors": [],
            "url": "http://www.jsoftware.us/vol14/400-JSW15407.pdf",
            "ref_texts": "[4] Pavlakos , G., Zhou, X., Derpanis, K. G. , & Daniilidis , K. (2016 ). Coarse -to-fine volumetric prediction for single -image 3D human pose . Retrieved from : https://ui.adsabs.harvard. edu/ \\#abs/2016arXiv161107828P ",
            "ref_ids": [
                "4"
            ],
            "1": "[4] proceeded from a single color image through a conv olution network (ConvNet) for 2D joint positioning and subsequent optimization steps to restore 3D human pose.",
            "2": "[4] Pavlakos , G."
        },
        "Joint Representation of Multiple Geometric Priors via a Shape Decomposition Model for Single Monocular 3D Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.13466",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, K. G. Derpanis, K. Daniilidis, Coarse-to-ffne volumetric prediction for single-image 3D human pose, in: Computer Vision and Pattern Recognition, 2017, pp. 1263{1272.",
            "ref_ids": [
                "31"
            ],
            "1": "As the deep convolutional networks yield signiffcant performance in many areas, various ConvNets architectures are designed to estimate the 3D pose [28, 7, 29, 30, 31, 32, 33].",
            "2": "[31] 67.",
            "3": "In addition, the proposed approach without reffned initialization (Ours ) still achieves the best performance than all unsupervised and many supervised learning approaches [62, 30, 31] by more than 25% and 15% on average respectively.",
            "4": "[31] 47.",
            "5": "[31] 22.",
            "6": "[31] G."
        },
        "Fast On-Board 3D Human Torso Pose Recovery and Forecasting": {
            "authors": [],
            "url": "https://www.andrew.cmu.edu/user/abhijatb/assets/HUMANOIDS_torso_pose.pdf",
            "ref_texts": "[36] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-tofine volumetric prediction for single-image 3d human pose,\u201d in CVPR .",
            "ref_ids": [
                "36"
            ],
            "1": "[36] G."
        },
        "Guiding 3D human pose estimation using feet pressure sensors": {
            "authors": [],
            "url": "https://riunet.upv.es/bitstream/handle/10251/192974/Sintes%20-%20Guiding%203D%20human%20pose%20estimation%20using%20feet%20pressure%20sensors.pdf?sequence=2"
        },
        "Distillation of part experts for whole-body pose estimation": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/f2/a1/81/60fb47dd39c122/US11651608.pdf",
            "ref_texts": " estimation from monocular RGB . In : 3DV (2018 ) . Mehta , D. , Sridhar , S. , Sotnychenko , O. , Rhodin , H. , Shafiei , M. , Seidel , H.P. , Xu , W. , Casas , D. , Theobalt , C .: V Nect : Real time 3D human pose estimation with a single RGB camera . ACM Transac tions on Graphics (2017 ) . Moon , G. , Chang , J.Y. , Lee , K.M .: Camera distance aware top down approach for 3D multi person pose estimation from a single RGB image . In : ICCV (2019 ) . Mueller , F. , Bernard , F. , Sotnychenko , O. , Mehta , D. , Sridhar , S. , Casas , D. , Theobalt , C .: GANerated hands for real time 3D hand tracking from monocular RGB . In : CVPR (2018 ) . Paszke , A. , Gross , S. , Massa , F. , Lerer , A. , Bradbury , J. , Chanan , G. , Killeen , T. , Lin , Z. , Gimelshein , N. , Antiga , L. , Desmaison , A. , Kopf , A. , Yang , E. , DeVito , Z. , Raison , M. , Tejani , A. , Chilamkurthy , S. , Steiner , B. , Fang , L. , Bai , J. , Chintala , S .: Pytorch : An imperative style , high performance deep learning library . In : NeurIPS 2019 . Pavlakos , G. , Choutas , V. , Ghorbani , N. , Bolkart , T. , Osman , A.A. , Tzionas , D. , Black , M.J .: Expressive body capture : 3D hands , face , and body from a single image . In : CVPR (2019 ) . Pavlakos , G. , Zhou , X. , Derpanis , K.G. , Daniilidis , K .: Coarse to fine volumetric prediction for single image 3D human pose . In : CVPR (2017 ) . Ren , S. , He , K. , Girshick , R. , Sun , J .: Faster R CNN : Towards real time object detection with region proposal networks . In : NIPS (2015 ) . Rogez , G. , Schmid , C .: Mocap guided data augmentation for 3D pose estimation in the wild . In : NIPS (2016 ) . Rogez , G. , Weinzaepfel , P. , Schmid , C .: LCR Net ++ : Multi person 2D and 3D pose detection in natural images . IEEE trans . PAMI (2019 ) . Romero , J. , Tzionas , D. , Black , M.J .: Embodied hands : modeling and capturing hands and bodies together . ACM Transactions on Graphics (2017 ) . Spurr , A. , Song , J. , Park , S. , Hilliges , O .: Cross modal deep varia tional hand pose estimation . In : CVPR (2018 ) . Supani , U.S. , Rogez , G. , Yang , Y. , Shotton , J. , Ramanan , D .: Depth based hand pose estimation : Methods , data , and challenges . International Journal of Computer Vision (2018 ) . US 11,494,932 B2 "
        },
        "Articulated body mesh estimation using three-dimensional (3D) body keypoints": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/87/eb/55/270b9c9108bee3/US11361507.pdf",
            "ref_texts": ""
        },
        "Vyhodnocen\u00ed p\u0159esnosti extrakce 3D pozice kojenc\u016f z RGB obr\u00e1zk\u016f pomoc\u00ed RGB-D kamer a syst\u00e9mu sledov\u00e1n\u00ed pohybu": {
            "authors": [],
            "url": "https://dspace.cvut.cz/bitstream/handle/10467/108794/F3-BP-2023-Vaculinova-Noemi-Infant_3D_pose_extraction.pdf?sequence=-1",
            "ref_texts": "[6]G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d CoRR, vol. abs/1611.07828, 2016.",
            "ref_ids": [
                "6"
            ],
            "1": "[6] represent the joints with volumetric probability heatmaps.",
            "2": "[6]G."
        },
        "Real-time Online Human Tracking with a Stereo Camera for Person-Following Robots": {
            "authors": [],
            "url": "https://yorkspace.library.yorku.ca/xmlui/bitstream/handle/10315/37376/Chen_BaoXin_2019_Masters.pdf?sequence=2",
            "ref_texts": "[9] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G Derpanis, and 85 Kostas Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "9"
            ],
            "1": "1 Motivation There has been tremendous progress in computer vision leading to many useful practical applications, such as Object detection [1] [2], Object tracking [3] [4], Image classification [5] [6], Image Segmentation [2] [7], Body Pose Estimation [8] [9], Style Transfer [10] [11], etc."
        },
        "3D Hand Pose Estimation from Single RGB Camera": {
            "authors": [],
            "url": "https://er.ucu.edu.ua/bitstream/handle/1/1327/Chernytska%20-%203D%20Hand%20Pose%20Estimation%20from%20Single%20RGB%20Camera%20-%20master%20thesis.pdf",
            "ref_texts": "[21] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse-to-fine volumetric prediction for single-image 3d human pose,\u201d in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pp. 1263\u20131272, IEEE, 2017.",
            "ref_ids": [
                "21"
            ],
            "1": "Approach [21] uses volumetric representation for 3D pose.",
            "2": "[21] G."
        },
        "3D Scene and Event Understanding by Joint Spatio-temporal Inference and Reasoning": {
            "authors": [],
            "url": "https://escholarship.org/content/qt3w1664f1/qt3w1664f1.pdf",
            "ref_texts": "[PZD17] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. \\Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose.\" In IEEE Conference on Computer Vision and Pattern Recognition , 2017.",
            "ref_ids": [
                "PZD17"
            ],
            "1": "[PZD17] represented 3D joints as points in a discretized 3D space and proposed a coarse-to-ffne approach for iterative reffnement.",
            "2": "We compare our method with 10 state-of-the-art methods [IPO14, TRL16, DWL16, CR17, SNP16, RS16, BKL16, PZD17, NWZ17, ZHS17, MHR17] and report quantitative comparisons in Table 7.",
            "3": "The large drop of performance (17% { 41%) of previous 2D-3D reconstruction models [PZD17, NWZ17, ZHS17, MHR17], which demonstrates the blind spot of previous evaluation protocols and the over-fftting problem of those models.",
            "4": "We compare our method with 6 state-of-the-art methods [SQT13, KG14, YIK16, Mor17, PZD17, MHR17].",
            "5": "[PZD17] G."
        },
        "3D human body mesh generation from 2D images using body silhouette, bone orientation, and joints triangulation": {
            "authors": [],
            "url": "https://espace.etsmtl.ca/id/eprint/2769/1/AJANOHOUN_Jordy.pdf",
            "ref_texts": "10 19. Loper, M., Mahmood, N., Romero, J., Pons-Moll, G. & Black, M. J. (2015). SMPL: A Skinned Multi-Person Linear Model. ACM Transactions on Graphics , 34(6), 248:1\u2013248:16. Loper, M. M. & Black, M. J. (2014). OpenDR: An Approximate Differentiable Renderer. European Conference on Computer Vision (ECCV) , 8695, 154\u2013169. Madadi, M., Bertiche, H. & Escalera, S. (2020). SMPLR: Deep learning based SMPL reverse for 3D human pose and shape recovery. Pattern Recognition , 106, 107472. Newell, A., Yang, K. & Deng, J. (2016). Stacked Hourglass Networks for Human Pose Estimation. European Conference on Computer Vision (ECCV) , pp. 483\u2013499. Nocedal, J. & Wright, S. J. (2006). Numerical optimization (ed. 2). Springer. Omran, M., Lassner, C., Pons-Moll, G., Gehler, P. V. & Schiele, B. (2018). Neural Body Fitting: Unifying Deep Learning and Model-Based Human Pose and Shape Estimation. International Conference on 3D Vision (3DV) , pp. 484\u2013494. Pavlakos, G., Zhou, X., Derpanis, K. G. & Daniilidis, K. (2017a). Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1263-1272. Pavlakos, G., Zhou, X., Derpanis, K. G. & Daniilidis, K. (2017b, July). Harvesting Multiple Views for Marker-Less 3D Human Pose Annotations. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 1253-1262. Pavlakos, G., Zhu, L., Zhou, X. & Daniilidis, K. (2018). Learning to Estimate 3D Human Pose and Shape from a Single Color Image. IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , pp. 459\u2013468. Pishchulin, L., Insafutdinov, E., Tang, S., Andres, B., Andriluka, M., Gehler, P. & Schiele, B."
        },
        "3D Reconstruction, Weakly-Supervised Learning, and Supervised Learning Methods for 3D Human Pose Estimation": {
            "authors": [],
            "url": "https://s-space.snu.ac.kr/bitstream/10371/152572/1/000000155042.pdf",
            "ref_texts": "[85] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3d human pose. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on , pages 1263\u20131272. IEEE, 2017.",
            "ref_ids": [
                "85"
            ],
            "1": "[85] proposed a volumetric representation that gradually increases the resolution of the depth from heatmaps of 2D pose.",
            "2": "The proposed method is compared to the recently proposed methods that estimates 3D pose from a single image [85, 71, 29, 18, 126, 74, 130, 105].",
            "3": "[85] 67.",
            "4": "[85] 83.",
            "5": "[85] G."
        },
        "3D Human pose estimation on Taiji sequence": {
            "authors": [],
            "url": "https://etda.libraries.psu.edu/files/final_submissions/17625",
            "ref_texts": ""
        },
        "Learning, Moving, and Predicting with Global Motion Representations": {
            "authors": [],
            "url": "https://core.ac.uk/download/pdf/219379415.pdf",
            "ref_texts": "111 L. A. Palmer, A. C. Rosenquist, and R. J. Tusa. The retinotopic organization of lateral suprasylvian visual areas in the cat. Journal of Comparative Neurology , 177(2):237\u2013256, 1978. S. E. Palmer, O. Marre, M. J. Berry, and W. Bialek. Predictive information in a sensory population. Proceedings of the National Academy of Sciences , 112(22):6908\u20136913, 2015. D. Pathak, R. Girshick, P. Doll \u00b4ar, T. Darrell, and B. Hariharan. Learning features by watching objects move. In CVPR , 2017. V . P\u02d8atr\u02d8aucean, A. Handa, and R. Cipolla. Spatio-temporal video autoencoder with differentiable memory. In ICLR Workshop , 2016. G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. J. A. Perrone and L. S. Stone. A model of self-motion estimation within primate extrastriate visual cortex. Vision Research , 34(21):2917 \u2013 2938, 1994. J. A. Perrone and L. S. Stone. Emulating the visual receptive-field properties of MST neurons with a template model of heading estimation. Journal of Neuroscience , 18(15):5958\u20135975, 1998. G. Pons-Moll, J. Romero, N. Mahmood, and M. J. Black. Dyna: A model of dynamic human shape in motion. ACM Transactions on Graphics , 34(4):120:1\u2013120:14, 2015. C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3d classification and segmentation. In CVPR , 2017. A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. In ICLR , 2016. A. Ranjan and M. J. Black. Optical flow estimation using a spatial pyramid network. In CVPR , 2017. M. Ranzato, A. Szlam, J. Bruna, M. Mathieu, R. Collobert, and S. Chopra. Video (language) modeling: a baseline for generative models of natural videos. In arXiv e-prints , 2014. M. B. Reiser and M. H. Dickinson. Visual motion speed determines a behavioral switch from forward flight to expansion avoidance in Drosophila. The Journal of Experimental Biology , 216"
        },
        "Supplementary Document: Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB": {
            "authors": [],
            "url": "https://virtualhumans.mpi-inf.mpg.de/papers/mehta2018multiperson/mehta2018multiperson_supp.pdf",
            "ref_texts": "[13] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-ffne volumetric prediction for singleimage 3D human pose. In CVPR 2017-IEEE Conference on Computer Vision & Pattern Recognition , 2017.[14] G. Rogez, P. Weinzaepfel, and C. Schmid. Lcr-net: Localization-classiffcation-regression for human pose. InCVPR 2017-IEEE Conference on Computer Vision & Pattern Recognition , 2017.",
            "ref_ids": [
                "13",
                "14"
            ],
            "1": "Joint-wise accuracy comparison of our method and LCR-net [14] on the single person MPI-INF-3DHP test set.",
            "2": "Joint-wise Analysis Figure 2 shows joint-wise accuracy comparison of our approach with LCR-net [14] on the single person MPI-INF-3DHP test set.",
            "3": "Qualitative comparison of LCR-net [14] and our method.",
            "4": "Pavlakos et al [13] 60.",
            "5": "6 LCR-net [14] 76.",
            "6": "Pavlakos et al [13] 92.",
            "7": "5 LCR-net [14] 127.",
            "8": "Comparison of our method and LCR-net [14] on our proposed multi-person test set, here visualized as joint-wise breakdown of PCK for all 20 sequences, as well as the difierence in accuracy between our method and LCR-net.",
            "9": "7 LCR-net [14] 70.",
            "10": "[13] G.",
            "11": "[14] G."
        },
        "Ordinal Depth Supervision for 3D Human Pose Estimation Supplementary material": {
            "authors": [],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/Supplemental/3718-supp.pdf",
            "ref_texts": "[8] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In CVPR , 2017. 2",
            "ref_ids": [
                "8"
            ],
            "1": "For the experiment with the two hourglasses we adopt the coarse-to-fine scheme of [8], to be compatible with them.",
            "2": "Using the predicted 2D location in pixel coordinates and assuming the camera intrinsics are known, we can reconstruct the 3D pose and be comparable with [8], that we use as a baseline here.",
            "3": "2\n[8] G."
        },
        "3D human pose estimation using part affinity field": {
            "authors": [],
            "url": "https://core.ac.uk/download/pdf/158324790.pdf",
            "ref_texts": ""
        },
        "Nghi\u00ean c\u1ee9u m\u00f4 ph\u1ecfng d\u00e1ng ng\u01b0\u1eddi tr\u00ean kh\u00f4ng gian ba chi\u1ec1u t\u1eeb h\u00ecnh \u1ea3nh hai chi\u1ec1u s\u1eed d\u1ee5ng ph\u01b0\u01a1ng ph\u00e1p h\u1ecdc s\u00e2u": {
            "authors": [],
            "url": "https://jst-ud.vn/jst-ud/article/download/7841/5552",
            "ref_texts": "[6] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis, \u201cCoarse to-fine volumetric prediction for single -image 3D human pose\u201d, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017, 7025 -7034. ",
            "ref_ids": [
                "6"
            ],
            "1": "Tuy nhi\u00ean, ph\u1ea7n l\u1edbn c\u00e1c m\u00f4 h\u00ecnh v\u1eabn c\u00f2n d\u1ef1a v\u00e0o \u0111\u1ea7u v\u00e0o l\u00e0 d\u00e1ng ng\u01b0\u1eddi hai chi\u1ec1u c\u00f3 s\u1eb5n t\u1eeb c\u00e1c m\u00f4 h\u00ecnh d\u1ef1ng d\u00e1ng ng\u01b0\u1eddi hai chi\u1ec1u [6] , [7], ho\u1eb7c l\u00e0 ch\u1ec9 t\u1eadp trung v\u00e0o c\u00e1c ph\u01b0\u01a1ng th\u1ee9c \u00e1nh x\u1ea1 t\u1eeb 2D sang 3D [8] \n[9].",
            "2": "[6] G."
        },
        "Fine-Grained Object Recognition Under Limited Training Data": {
            "authors": [],
            "url": "https://ir.library.oregonstate.edu/downloads/pg15bm18b",
            "ref_texts": "[108] Georgios Pavlakos, Xiaowei Zhou, Konstantinos G. Derpanis, and Kostas Daniilidis. Coarse-to-Fine V olumetric Prediction for Single-Image 3D Human Pose. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , July 2017.",
            "ref_ids": [
                "108"
            ],
            "1": "[108].",
            "2": "9 Pavlakos 2017 [108] 24.",
            "3": "04 Pavlakos 2017 [108] 58.",
            "4": "14 Pavlakos 2017 [108] 76."
        },
        "Derin \u00f6\u011frenme kullan\u0131larak g\u00f6r\u00fcnt\u00fclerden insan duru\u015f tespiti": {
            "authors": [],
            "url": "https://acikerisim.sakarya.edu.tr/bitstream/handle/20.500.12619/97194/T09577.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, K . G. Derpanis, and K. Daniilidis, \u201cCoarse -to-fine volumetric prediction for single -image 3D human pose,\u201d Proc. 30th IEEE Conf. Comput. Vis. Pattern Recognition, CVPR 2017 , vol. 2017 -Janua, pp. ",
            "ref_ids": [
                "3"
            ],
            "1": "Pavlokos ve ark [3], yapm\u0131\u015f oldu\u011fu \u00e7al\u0131\u015fmada renkli tek bir g\u00f6r\u00fcnt\u00fcden 3B insan poz tahmini sorusu ele al\u0131nm\u0131\u015ft\u0131r.",
            "2": "6M 3600000 %80,1 Sarafianos ve ark [6] YOLOv4 -P6 COCO 1500000 %75,4 Pavlokos ve ark [3] RSTV+KDE KTH Football II 800 %71,9 Rhodin ve ark [7] MPJPE and NMPJPE Human3.",
            "3": "[3] G."
        },
        "Apprentissage automatique pour la reconnaissance d'action humaine et l'estimation de pose \u00e0 partir de l'information 3D": {
            "authors": [
                "Diogo Luvizon"
            ],
            "url": "https://www.theses.fr/2019CERG1015.pdf",
            "ref_texts": "[99] G. Pavlakos, X. Zhou, K. G. Derpanis, and K. Daniilidis. Coarse-to-fine volumetric prediction for single-image 3D human pose. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , 2017. 9, 32, 47, 50, 54, 67, 84, 99",
            "ref_ids": [
                "99"
            ],
            "1": "[99] proposed the volumetric stacked hourglass architecture, but the method suffers from the significant increase in the number of parameters and in the required memory to store all the gradients.",
            "2": "Compared to [99], we show in our work that (i) smaller volumetric heat maps can be used with soft-argmax and still improve results, since soft-argmax is a continuous regression function, and (ii), the volumetric representation can be fully replaced by predicting 2D depth maps, that encode the depth related to each body joint, resulting in even lower computational complexity and better results.",
            "3": "However, recent detection based methods for both 2D and 3D pose estimation [156, 22, 99] are based on heat maps prediction, which are then converted to coordinates by applying the maximum a posteriori (MAP) estimation, usually called argmax .",
            "4": "We followed the common evaluation protocol [131, 99, 88, 19] by taking five subjects for training (S1, S5, S6, S7, S8) and evaluating on two subjects (S9, S11) on one every 64 frames.",
            "5": "Differently from the Stacked Hourglass [93, 99] architectures, where only the higher resolution features are supervised, we use intermediate supervision at every level of the pyramids.",
            "6": "The same is not true for detection based approach, like in [99], since the predictions are quantized by the argmax function.",
            "7": "Recent methods based on deep convolutional neural networks (CNNs) have achieved impressive results on both 2D and 3D pose estimation tasks thanks to the rise of new architectures and the availability of large amounts of data [93, 99].",
            "8": "[99] 2017 71.",
            "9": "[99] 67.",
            "10": "[99] 96.",
            "11": "10\n[99] G."
        }
    }
}