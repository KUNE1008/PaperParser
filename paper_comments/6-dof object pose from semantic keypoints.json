{
    "title": "6-dof object pose from semantic keypoints",
    "id": 6,
    "valid_pdf_number": "232/310",
    "matched_pdf_number": "171/232",
    "matched_rate": 0.7370689655172413,
    "citations": {
        "Posecnn: A convolutional neural network for 6d object pose estimation in cluttered scenes": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1711.00199",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DOF object pose from semantic keypoints. IEEE International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "In feature-based methods, local features are extracted from either points of interest or every pixel in the image and matched to features on the 3D models to establish the 2D3D correspondences, from which 6D poses can be recovered [20, 25, 30, 22].",
            "2": "A straightforward way for localizing the 2D object center is to directly detect the center point as in existing key point detection methods [22, 7]."
        },
        "Bottom-up object detection by grouping extreme and center points": {
            "authors": [
                "Xingyi Zhou",
                "Jiacheng Zhuo",
                "Philipp Krahenbuhl"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhou_Bottom-Up_Object_Detection_by_Grouping_Extreme_and_Center_Points_CVPR_2019_paper.pdf",
            "ref_texts": "[36] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 3",
            "ref_ids": [
                "36"
            ],
            "1": ", human joint estimation [3,5,15,30,49] or chair corner point estimation [36,53], commonly uses a fully convolutional encoderdecoder network to predict a multi-channel heatmap for each type of keypoint (e."
        },
        "Densefusion: 6d object pose estimation by iterative dense fusion": {
            "authors": [
                "Chen Wang",
                "Danfei Xu",
                "Yuke Zhu",
                "Roberto Martin",
                "Cewu Lu",
                "Li Fei",
                "Silvio Savarese"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_DenseFusion_6D_Object_Pose_Estimation_by_Iterative_Dense_Fusion_CVPR_2019_paper.pdf",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d Arxiv preprint arxiv:1703.04670 , 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "Newer methods address the challenge by learning to predict the 2D keypoints [3,22,32,34,35] and solve the poses by P nP [10].",
            "2": "[22] G."
        },
        "Pvnet: Pixel-wise voting network for 6dof pose estimation": {
            "authors": [
                "Sida Peng",
                "Yuan Liu",
                "Qixing Huang",
                "Xiaowei Zhou",
                "Hujun Bao"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2019/papers/Peng_PVNet_Pixel-Wise_Voting_Network_for_6DoF_Pose_Estimation_CVPR_2019_paper.pdf",
            "ref_texts": "[29] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 1,3",
            "ref_ids": [
                "29"
            ],
            "1": "Some recent methods [29,30,36] use CNNs to first regress 2D keypoints and then compute 6D pose parameters using the Perspective-n-Point (PnP) algorithm.",
            "2": "Motivated by the success of 2D human pose estimation [26], another category of methods [29,27] outputs pixel-wise heatmaps of keypoints to address the issue of occlusion.",
            "3": "Inspired by recent methods [29,30,36], we estimate the object pose using a two-stage pipeline: we first detect 2D object keypoints using CNNs and then compute 6D pose parameters using the PnP algorithm.",
            "4": "5\n[29] G."
        },
        "Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization": {
            "authors": [],
            "url": "http://proceedings.mlr.press/v139/miller21b/miller21b.pdf",
            "ref_texts": ".14444 . Pan, S. J. and Yang, Q. A survey on transfer learning. IEEE Transactions on Knowledge and Data Engineering , 2010. https://ieeexplore.ieee.org/document /5288526 . Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. 6-dof object pose from semantic keypoints. In2017 IEEE international conference on robotics and automation (ICRA) , pp. 2011\u20132018. IEEE, 2017. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V ., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V ., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., and Duchesnay, E. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research , 2011.https://www.jm lr.org/papers/v12/pedregosa11a.html . Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and Zettlemoyer, L. Deep contextualized word representations. In Conference of the North American Chapter of the Association for Computational Linguistics (NAACL) , 2018.https://arxiv.org/ab s/1802.05365 . Quionero-Candela, J., Sugiyama, M., Schwaighofer, A., and Lawrence, N. D. Dataset Shift in Machine Learning . The MIT Press, 2009. Rad, M. and Lepetit, V . Bb8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In Proceedings of the IEEE International Conference on Computer Vision , pp. 3828\u20133836, 2017. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., Sastry, G., Askell, A., Mishkin, P., Clark, J., et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning (ICML) , 2021.https://arxiv. org/abs/2103.00020 . Radosavovic, I., Kosaraju, R. P., Girshick, R., He, K., and Doll\u00b4ar, P. Designing network design spaces. In Conference on Computer Vision and Pattern Recognition (CVPR) , 2020.https://arxiv.org/abs/20"
        },
        "Deep learning on monocular object pose detection and tracking: A comprehensive overview": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.14291",
            "ref_texts": "[114] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. 6-dof object pose from semantic keypoints. In2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2011\u20132018.",
            "ref_ids": [
                "114"
            ],
            "1": "After that, this kind of two-stage pipeline method is adopted by many works [60,109,114,176], addressing different challenges such as occlusion and truncation."
        },
        "Deep object pose estimation for semantic robotic grasping of household objects": {
            "authors": [
                "Anonymous Submission"
            ],
            "url": "https://arxiv.org/pdf/1809.10790",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DoF object pose from semantic keypoints. In ICRA , pages 2011\u20132018, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "For alternate approaches to related problems, see [33, 34, 35, 36, 37].",
            "2": "[34] G."
        },
        "3d bounding box estimation using deep learning and geometry": {
            "authors": [
                "Arsalan Mousavian",
                "Dragomir Anguelov",
                "John Flynn",
                "Jana Kosecka"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2017/papers/Mousavian_3D_Bounding_Box_CVPR_2017_paper.pdf",
            "ref_texts": "[14] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 3,6,8",
            "ref_ids": [
                "14"
            ],
            "1": "Pavlakos et al [14], used CNN to localize the keypoints and they used the keypoints and their 3D coordinates from meshes to recover the pose.",
            "2": "Table 2shows that MultiBin modules are more effective than discretized classification [21] and also keypoint based method of [14] which is based on localizing keypoints and solving a sophisticated optimization to recover the pose.",
            "3": "6 MedErr ([14]) 8.",
            "4": "2\n[14] G."
        },
        "Pvn3d: A deep point-wise 3d keypoints voting network for 6dof pose estimation": {
            "authors": [
                "Yisheng He",
                "Wei Sun",
                "Haibin Huang",
                "Jianran Liu",
                "Haoqiang Fan",
                "Jian Sun"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/He_PVN3D_A_Deep_Point-Wise_3D_Keypoints_Voting_Network_for_6DoF_CVPR_2020_paper.pdf",
            "ref_texts": "[36] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1",
            "ref_ids": [
                "36"
            ],
            "1": "Instead, recent works utilized DNNs to detect 2D keypoints of an object, and computed 6D pose parameters with Perspectiven-Point (PnP) algorithms [37,36,41,47].",
            "2": "2\n[36] G."
        },
        "Cdpn: Coordinates-based disentangled pose network for real-time rgb-based 6-dof object pose estimation": {
            "authors": [
                "Zhigang Li",
                "Gu Wang",
                "Xiangyang Ji"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_CDPN_Coordinates-Based_Disentangled_Pose_Network_for_Real-Time_RGB-Based_6-DoF_Object_ICCV_2019_paper.pdf",
            "ref_texts": "[19] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "proaches either directly regress 6-DoF object pose from image [8, 28] or predict 2D keypoints in image and indirectly solve the pose via PnP [20, 19].",
            "2": "[19, 29] predicted semantic keypoints for pose and viewpoint estimation with an hourglassbased network [17, 5]."
        },
        "Few-shot object detection and viewpoint estimation for objects in the wild": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.12107",
            "ref_texts": "[65] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in IEEE International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "65"
            ],
            "1": "Deeplearning methods for viewpoint estimation follow roughly three different paths: direct estimation of Euler angles [9], [56], [57], [58], [59], template-based matching [60], [61] that encodes images in latent spaces and compares them against a dictionary of pre-defined viewpoints, and keypoint detection relying on 3D bounding box corners [62], [63], [64] or semantic keypoints [8], [65].",
            "2": "[65] G."
        },
        "inerf: Inverting neural radiance fields for pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2012.05877",
            "ref_texts": "[27] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DOF object pose from semantic keypoints. ICRA , 2017.",
            "ref_ids": [
                "27"
            ],
            "1": "Recent approaches based on deep learning have proposed to 1) directly estimate objects pose using CNNbased architectures [32], [40], [46] or 2) estimate 2D keypoints [27], [35], [37], [38] and solve for pose using the PnP-RANSAC algorithm."
        },
        "Onepose: One-shot object pose estimation without cad models": {
            "authors": [
                "Jiaming Sun",
                "Zihao Wang",
                "Siyu Zhang",
                "Xingyi He",
                "Hongcheng Zhao",
                "Guofeng Zhang",
                "Xiaowei Zhou"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Sun_OnePose_One-Shot_Object_Pose_Estimation_Without_CAD_Models_CVPR_2022_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. ICRA , 2017. 2",
            "ref_ids": [
                "25"
            ],
            "1": "In contrast, the latter type of methods first find correspondences between image pixels and 3D object coordinates either by regression [22, 24, 25] or by voting [26, 27], and then compute the pose with Perspective-n-Points (PnP)."
        },
        "Hybridpose: 6d object pose estimation under hybrid representations": {
            "authors": [
                "Chen Song",
                "Jiaru Song",
                "Qixing Huang"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Song_HybridPose_6D_Object_Pose_Estimation_Under_Hybrid_Representations_CVPR_2020_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u2013",
            "ref_ids": [
                "32"
            ],
            "1": "To express the geometric information in an RGB image, a prevalent intermediate representation is keypoints, which achieves stateof-the-art performance [34,32,36].",
            "2": "Pose estimation via intermediate representation is sensitive to outliers in predictions, which are introduced by occlusion and cluttered backgrounds [37,32, 40].",
            "3": "To mitigate pose error, several works assign different weights to different predicted elements in the 2D-3D alignment stage [34,32]."
        },
        "Epos: Estimating 6d pose of objects with symmetries": {
            "authors": [
                "Tomas Hodan",
                "Daniel Barath",
                "Jiri Matas"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Hodan_EPOS_Estimating_6D_Pose_of_Objects_With_Symmetries_CVPR_2020_paper.pdf",
            "ref_texts": "[49] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. ICRA , 2017. 2, 3",
            "ref_ids": [
                "49"
            ],
            "1": "A popular approach is to establish 2D-3D correspondences by predicting the 2D projections of a fixed set of 3D keypoints, which are pre-selected for each object model, and solve for the object pose using P nP-RANSAC [52, 49, 47, 61, 65, 15, 29, 50].",
            "2": "In particular, classificationbased methods predict for each pixel up to one corresponding 3D location [4, 46], or for each 3D keypoint up to one 2D location which is typically given by the maximum response in a predicted heatmap [49, 47, 15]."
        },
        "Segmentation-driven 6d object pose estimation": {
            "authors": [
                "Yinlin Hu",
                "Joachim Hugonot",
                "Pascal Fua",
                "Mathieu Salzmann"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2019/papers/Hu_Segmentation-Driven_6D_Object_Pose_Estimation_CVPR_2019_paper.pdf",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In International Conference on Robotics and Automation , 2017. 2",
            "ref_ids": [
                "34"
            ],
            "1": "Over the years, much effort has been invested in designing local feature descriptors that are invariant to various transformations [27,40,41,42,34,32], so that they can be matched more robustly [29,30,14]."
        },
        "H3dnet: 3d object detection using hybrid geometric primitives": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2006.05682",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation, ICRA 2017, Singapore, Singapore, May 29 June 3, 2017. pp. 2011{",
            "ref_ids": [
                "25"
            ],
            "1": "This regression methodology, which is motivated from the recent success of keypoint-based pose regression for 6D object pose estimation [19, 25, 11, 21, 26, 36], displays two appealing advantages for 3D object detection."
        },
        "Single-stage 6d object pose estimation": {
            "authors": [
                "Yinlin Hu",
                "Pascal Fua",
                "Wei Wang",
                "Mathieu Salzmann"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Hu_Single-Stage_6D_Object_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In International Conference on Robotics and Automation , 2017. 2",
            "ref_ids": [
                "35"
            ],
            "1": "Over the years, many methods have been proposed to improve 3D-to-2D matching [28,42,43,44,35,33], relying on diverse techniques, such as template-matching [10,11], edge-matching [22, 27], and 3D model-based matching [14,26,12]."
        },
        "Making deep heatmaps robust to partial occlusions for 3d object pose estimation": {
            "authors": [
                "Markus Oberweger",
                "Mahdi Rad",
                "Vincent Lepetit"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCV_2018/papers/Markus_Oberweger_Making_Deep_Heatmaps_ECCV_2018_paper.pdf",
            "ref_texts": "6. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis , K.: 6-DoF Object Pose from Semantic Keypoints. In: International Conference on In telligent Robots and Systems. (2018)",
            "ref_ids": [
                "6"
            ],
            "1": "Similarly, in [6], 2D key points were predicted in the form of a set of heatmaps as we do in this work."
        },
        "6-pack: Category-level 6d pose tracker with anchor-based keypoints": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1910.10750",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d ArXiv preprint arXiv:1703.04670 , 2017.",
            "ref_ids": [
                "33"
            ],
            "1": "Most relevant to us is a class of methods that combines the classical keypoint matching ideas and modern learning techniques by directly predicting either category-level semantic keypoints [33, 44] or 3D bounding box corners [25, 42, 43].",
            "2": "Our method is inspired by recent works on learning to predict 3D keypoints for 6D object pose estimation [33, 41, 44].",
            "3": "[33] G."
        },
        "Neural correspondence field for object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.00113",
            "ref_texts": "60. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF object pose from semantic keypoints. ICRA (2017) 3",
            "ref_ids": [
                "60"
            ],
            "1": ", by predicting the 2D projections of a fixed set of 3D keypoints pre-selected for each object model, have also been proposed [63, 60, 54, 73, 76, 27, 61]."
        },
        "3d pose regression using convolutional neural networks": {
            "authors": [
                "Siddharth Mahendran",
                "Haider Ali",
                "Rene Vidal"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2017_workshops/papers/w31/Mahendran_3D_Pose_Regression_ICCV_2017_paper.pdf",
            "ref_texts": "[12] N. A. Nystrom, M. J. Levine, R. Z. Roskies, and J. R. Scott. Bridges: A uniquely flexible hpc resource for new communities and data analytics. In Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure, XSEDE \u201915, pages 30:1\u201330:8, New York, NY , USA, 2015. ACM.[13] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In IEEE International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "12",
                "13"
            ],
            "1": "Methods in the first category, such as [21] and [13], predict 2D keypoints from an image and then use 3D object models to predict the 3D pose given these keypoints.",
            "2": "Specifically, it used the Bridges system [12], which is supported by NSF award number ACI-1445606, at the Pittsburgh Supercomputing Center (PSC).",
            "3": "[12] N.",
            "4": "[13] G."
        },
        "Deep model-based 6d pose refinement in rgb": {
            "authors": [
                "Fabian Manhardt",
                "Wadim Kehl",
                "Nassir Navab",
                "Federico Tombari"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Fabian_Manhardt_Deep_Model-Based_6D_ECCV_2018_paper.pdf",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidi s, K.: 6-DoF Object Pose from Semantic Keypoints. In: ICRA (2017)",
            "ref_ids": [
                "25"
            ],
            "1": "In [28] a method is presented that ins tead regresses the projected 3D bounding box and recovers the pose from t hese 2D3D correspondences whereas the authors in [25] infer keypoint heatmaps t hat are then used for 6D pose computation."
        },
        "Satellite pose estimation with deep landmark regression and nonlinear pose refinement": {
            "authors": [
                "Bo Chen",
                "Jiewei Cao",
                "Alvaro Parra",
                "Jun Chin"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/R6D/Chen_Satellite_Pose_Estimation_with_Deep_Landmark_Regression_and_Nonlinear_Pose_ICCVW_2019_paper.pdf",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2,3",
            "ref_ids": [
                "25"
            ],
            "1": "Inspired by works that combine the strength of deep neural networks and geometric optimisation [26,25, 35], our approach contains three main components: 1.",
            "2": "While the keypoint matching problem can be solved using machine learning, deep CNN-based feature learning methods typically fix the 2D-3D keypoint associations and learn to predict the image locations of each corresponding 3D keypoint such as [26,25,35].",
            "3": "For in-stance, [25] uses semantic keypoints while [35] chooses the vertices of the 3D bounding box of an object.",
            "4": "3\n[25] G."
        },
        "Discobox: Weakly supervised instance segmentation and semantic correspondence from box supervision": {
            "authors": [
                "Shiyi Lan",
                "Zhiding Yu",
                "Christopher Choy",
                "Subhashree Radhakrishnan",
                "Guilin Liu",
                "Yuke Zhu",
                "Larry S. Davis",
                "Anima Anandkumar"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Lan_DiscoBox_Weakly_Supervised_Instance_Segmentation_and_Semantic_Correspondence_From_Box_ICCV_2021_paper.pdf",
            "ref_texts": "[33] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In ICRA , 2017. 1",
            "ref_ids": [
                "33"
            ]
        },
        "Coupled iterative refinement for 6d multi-object pose estimation": {
            "authors": [
                "Lahav Lipson",
                "Zachary Teed",
                "Ankit Goyal",
                "Jia Deng"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Lipson_Coupled_Iterative_Refinement_for_6D_Multi-Object_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1",
            "ref_ids": [
                "27"
            ]
        },
        "Wide-depth-range 6d object pose estimation in space": {
            "authors": [
                "Yinlin Hu",
                "Sebastien Speierer",
                "Wenzel Jakob",
                "Pascal Fua",
                "Mathieu Salzmann"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Wide-Depth-Range_6D_Object_Pose_Estimation_in_Space_CVPR_2021_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "30"
            ],
            "1": "consists of first establishing 3D-to-2D correspondences, and then compute the pose using a PnP solver [27,41,30]."
        },
        "Keypoint transformer: Solving joint identification in challenging hands and object interactions for accurate 3d pose estimation": {
            "authors": [
                "Shreyas Hampali",
                "Sayan Deb",
                "Mahdi Rad",
                "Vincent Lepetit"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Hampali_Keypoint_Transformer_Solving_Joint_Identification_in_Challenging_Hands_and_Object_CVPR_2022_paper.pdf",
            "ref_texts": "[38] Georgios Pavlakos, Nikos Kolotouros, and Kostas Daniilidis. TexturePose: Supervising Human Mesh Estimation with Texture Consistency. In International Conference on Computer Vision , 2019. 5, 8[39] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In International Conference on Robotics and Automation (ICRA) , 2017. 8",
            "ref_ids": [
                "38",
                "39"
            ],
            "1": "Previous methods [14,15,19,38,40] have noted that regressing model parameters such as joint angles is less accurate in terms of joint error than regressing the joint locations directly.",
            "2": "5D representations are similar, the joint angle representation results in lower accuracy, in line with the observation from previous works [14, 15, 19, 38, 40].",
            "3": "As we rely on keypoints, we believe that our approach is more general and could be applied to other problems, such as human and other articulated objects pose prediction and object category pose prediction [39].",
            "4": "5\n[38] Georgios Pavlakos, Nikos Kolotouros, and Kostas Daniilidis."
        },
        "A survey of simultaneous localization and mapping with an envision in 6G wireless networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1909.05214",
            "ref_texts": "[156] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstan tinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In2017 IEEE International Conference on Robotics and Automat ion (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "156"
            ],
            "1": "[156] gets semantic key points predicted by a convolutional network (convnet)."
        },
        "3d pose estimation and 3d model retrieval for objects in the wild": {
            "authors": [
                "Alexander Grabner",
                "Peter M. Roth",
                "Vincent Lepetit"
            ],
            "url": "https://openaccess.thecvf.com/content_cvpr_2018/papers/Grabner_3D_Pose_Estimation_CVPR_2018_paper.pdf",
            "ref_texts": "[17] G. Pavlakos, X. Zhou, A. Chan, K. Derpanis, and K. Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In International Conference on Robotics and Automation , pages 2011\u20132018, 2017. 2,3,6",
            "ref_ids": [
                "17"
            ],
            "1": "[17] predicts semantic keypoints and trains a deformable shape model which takes keypoint uncertainties into account.",
            "2": "Similar to previous works [15,17,26], we also assume the object category to be known, as it is a useful prior for both pose estimation and model retrieval.",
            "3": "3026\n category-specific aero bike boat bottle bus car chair table mbike sofa train tv mean MedErr ([17]) 11.",
            "4": "5 N/A MedErr ([17]*) 8.",
            "5": "3\n[17] G."
        },
        "End-to-end learnable geometric vision by backpropagating pnp optimization": {
            "authors": [
                "Bo Chen",
                "Alvaro Parra",
                "Jiewei Cao",
                "Nan Li",
                "Jun Chin"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_End-to-End_Learnable_Geometric_Vision_by_Backpropagating_PnP_Optimization_CVPR_2020_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "35"
            ],
            "1": "Other pose estimation approaches that combine deep learning with geometric optimization (PnP solver) [35,37, 47,36,10] adopt a two-stage strategy: first learn to predict the 2D landmarks or fiducial points from the input image, then perform pose estimation by solving PnP on the 2D-3D correspondences."
        },
        "Omni-swarm: A decentralized omnidirectional visual\u2013inertial\u2013uwb state estimation system for aerial swarms": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2103.04131",
            "ref_texts": "[52] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6DoF Object Pose from Semantic Keypoints,\u201d in Proc. of the IEEE Intl. Conf. on Robot. and Autom. (ICRA) . IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "52"
            ],
            "1": "4) 6-DoF Pose Estimator: The VDT adopts a CNN-based 6-Dof pose estimator [52], [53] to extract the accurate 6-DoF relative pose estimation of the visual target files as the function PoseEstimation .",
            "2": "[52] G."
        },
        "Symmetry and uncertainty-aware object slam for 6dof object pose estimation": {
            "authors": [
                "Nathaniel Merrill",
                "Yuliang Guo",
                "Xingxing Zuo",
                "Xinyu Huang",
                "Stefan Leutenegger",
                "Xi Peng",
                "Liu Ren",
                "Guoquan Huang"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Merrill_Symmetry_and_Uncertainty-Aware_Object_SLAM_for_6DoF_Object_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In International Conference on Robotics and Automation (ICRA) , 2017. 2,3,12",
            "ref_ids": [
                "25"
            ],
            "1": "Another trend is to either estimate the 2D projected locations of sparse 3D semantic points from the CAD model [25,26,28], or to regress the 3D coordinates from the dense 2D pixels within object masks [22,33], and then solves a perspective npoint (PnP) problem to estimate object poses.",
            "2": "Some works have retrieved a weight directly from the output of the keypoint network [25,26] to be used in PnP as a scalar measure of certainty [25] or Gaussian covariance matrix [26], while [30] adapted the Bayesian method of [10] to estimate a covariance matrix for the keypoints by sampling over a randomized batch.",
            "3": "The backbone architecture of our keypoint network is the stacked hourglass network [20], which has been shown to be a good choice for object pose estimation [23,25,30]."
        },
        "Stereobj-1m: Large-scale stereo image dataset for 6d object pose estimation": {
            "authors": [
                "Xingyu Liu",
                "Shun Iwase",
                "Kris M. Kitani"
            ],
            "url": "http://openaccess.thecvf.com/content/ICCV2021/papers/Liu_StereOBJ-1M_Large-Scale_Stereo_Image_Dataset_for_6D_Object_Pose_Estimation_ICCV_2021_paper.pdf",
            "ref_texts": "[26] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "26"
            ],
            "1": "Previous work has explored deep learning methods for localing keypoints of an object [31, 26, 17, 8, 13] or a human [30, 24, 2] from a RGB image."
        },
        "Factoring shape, pose, and layout from the 2d image of a 3d scene": {
            "authors": [
                "Shubham Tulsiani",
                "Saurabh Gupta",
                "David F. Fouhey",
                "Alexei A. Efros",
                "Jitendra Malik"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.pdf",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "23"
            ],
            "1": "For instance, researchers have predicted 3D object pose [23,32], low-dimensional parametric shapes [8,34], and surface normals [28].",
            "2": "8\n[23] G."
        },
        "Camera-to-robot pose estimation from a single image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.09231",
            "ref_texts": "[38] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in ICRA , 2017.",
            "ref_ids": [
                "38"
            ],
            "1": "Recent leading methods are similar to the approach proposed here: A network is trained to predict object keypoints in the 2D image, followed by P nP [7] to estimate the pose of the object in the camera coordinate frame [14], [10], [36], [11], [15], [37], or alternatively, a deformable shape model is fit to the detect keypoints [38].",
            "2": "[38] G."
        },
        "Zero-shot category-level object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2204.03635",
            "ref_texts": "33. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF Object Pose from Semantic Keypoints. In: ICRA (2017)",
            "ref_ids": [
                "33"
            ],
            "1": "e there is no intra-category variation between objects) [49]; that we have access to labelled pose datasets for all object categories [3, 10, 22, 33, 46, 50, 54]; and/or that we have access to a realistic CAD model for each object category the model will encounter [9,21,52].",
            "2": "Approaches to category-level pose estimation can be broadly delineated into: those defining pose explicitly through the use of reference CAD models [21,36,39,39,52]; those which learn category-level representations against which test-time observations can be in some way matched to give relative pose estimates [8, 9, 12, 33, 41, 45, 46, 54]; and those that learn to directly predict pose estimates for a category from observations [3,10,22,50].",
            "3": "[9, 29, 33, 41, 46]) treat each object category distinctly, either by training a separate model per category, or by using different templates (e."
        },
        "Keypoint-graph-driven learning framework for object pose estimation": {
            "authors": [
                "Shaobo Zhang",
                "Wanqing Zhao",
                "Ziyu Guan",
                "Xianlin Peng",
                "Jinye Peng"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.pdf",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, A. Chan, K.s Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 1,2",
            "ref_ids": [
                "25"
            ],
            "1": "Recently, deep learning approaches [13,39,4,29,34,10,26,24,25,18,3] have shown impressive results of pose estimation in RGB\n*Corresponding authorimages.",
            "2": "Some keypoint-based approaches [27,25,34,10,26,31,42] build the correspondence using sparse 2D keypoints on objects as an intermediate representation for pose estimation.",
            "3": "1,2\n[25] G."
        },
        "Robust category-level 6d pose estimation with coarse-to-fine rendering of neural features": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.05624",
            "ref_texts": "22. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation (ICRA). pp. 2011\u20132018 (2017). https://doi.org/10.1109/ICRA.2017.7989233",
            "ref_ids": [
                "22"
            ],
            "1": "Keypoint-based methods [22,38] first detect semantic keypoints and then predict 3D object pose by solving a Perspective-nPoint problem."
        },
        "Single-view robot pose and joint angle estimation via render & compare": {
            "authors": [
                "Yann Labbe",
                "Justin Carpentier",
                "Mathieu Aubry",
                "Josef Sivic"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Labbe_Single-View_Robot_Pose_and_Joint_Angle_Estimation_via_Render__CVPR_2021_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "43"
            ],
            "1": "For rigid objects, however, methods based on 2D keypoints [34,3,7,6,45,52,23,50,44,43,18] have been recently outperformed by render & compare methods that forgo explicit detection of 2D keypoints but instead use the entire shape of the object by comparing the rendered view of the 3D model to the input image and iteratively refining the object\u2019s 6D pose [59,31,25].",
            "2": "A set of sparse [45,52,23,50,44,43,18] or dense [56,41,49,59] features is detected on the object in the image using a CNN and theresulting 2D-to-3D correspondences are used to recover the camera pose using PnP [29]."
        },
        "Deep learning system for cuboid detection": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/30/6d/6f/837b6788c13344/US11328443.pdf",
            "ref_texts": ""
        },
        "Object pose estimation with statistical guarantees: Conformal keypoint detection and geometric uncertainty propagation": {
            "authors": [
                "Heng Yang",
                "Marco Pavone"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf",
            "ref_texts": "[71] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE Intl. Conf. on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1, 2,4",
            "ref_ids": [
                "71"
            ],
            "1": "One of the most popular paradigms for object pose estimation is a two-stage pipeline [20,71,72,79,81,85,89,101], where the first stage detects (semantic) keypoints of the objects on the image, and the second stage computes the object pose by solving an optimization known as Perspectiven-Points (PnP) that minimizes reprojection errors of the detected keypoints.",
            "2": "Given an input image, we assume a neural network [71] is available to generate heatmap predictions of the object keypoints (Fig.",
            "3": "Sparse methods define a handful of keypoints and predict locations of the keypoints via direct regression [74,89], probabilistic heatmap [67,71], or voting [72].",
            "4": "In this paper, we provide rigorous guarantees by applying conformal prediction to an existing keypoint detection method (the heatmap [71]) and leveraging old and new techniques in computer vision to derive formal error bounds.",
            "5": "We choose the heatmap approach in [71,79] as the prediction function: given an image x,[79] outputs a set of heatmaps f(x)=(f(x)1,.",
            "6": "1The heatmap in the original paper [71] is not a valid probability distribution as it contains negative values and do not sum up to 1."
        },
        "Neural view synthesis and matching for semi-supervised few-shot learning of 3d pose": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/3a61ed715ee66c48bacf237fa7bb5289-Paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "35"
            ],
            "1": "In contrast, [25,35,59] solve the object pose estimation problem via a two-step approach, which involves keypoint detection and solving a Perspective-n-Point (PnP) process."
        },
        "Vs-net: Voting with segmentation for visual localization": {
            "authors": [
                "Zhaoyang Huang",
                "Han Zhou",
                "Yijin Li",
                "Bangbang Yang",
                "Yan Xu",
                "Xiaowei Zhou",
                "Hujun Bao",
                "Guofeng Zhang",
                "Hongsheng Li"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_VS-Net_Voting_With_Segmentation_for_Visual_Localization_CVPR_2021_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "37"
            ],
            "1": "Keypoint is widely utilized as an intermediate representation in object pose estimation [38,20,34,37,50]."
        },
        "Keypointnet: A large-scale 3d keypoint dataset aggregated from numerous human annotations": {
            "authors": [
                "Yang You",
                "Yujing Lou",
                "Chengkun Li",
                "Zhoujun Cheng",
                "Liangwei Li",
                "Lizhuang Ma",
                "Cewu Lu",
                "Weiming Wang"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/You_KeypointNet_A_Large-Scale_3D_Keypoint_Dataset_Aggregated_From_Numerous_Human_CVPR_2020_paper.pdf",
            "ref_texts": "[25] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u2013",
            "ref_ids": [
                "25"
            ],
            "1": "[25] and Kim et al."
        },
        "ROBIN: a graph-theoretic approach to reject outliers in robust estimation using invariants": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.03659",
            "ref_texts": ""
        },
        "Object pose estimation using mid-level visual representations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2203.01449"
        },
        "Deep 6-DOF tracking": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1703.09771",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. arXiv preprint arXiv:1703.04670 , 2017.",
            "ref_ids": [
                "25"
            ],
            "1": "Deep neural networks have also been used to solve 3D geometric problems such as estimating the pose of a known object in a single image [4, 11, 25, 33], learning robust descriptors for pose estimation [9, 16, 19], inferring a transformation between two input images [10, 24], or estimating the camera pose from a single RGB image [17].",
            "2": "[25] G."
        },
        "Sar-net: Shape alignment and recovery network for category-level 6d object pose and size estimation": {
            "authors": [
                "Haitao Lin",
                "Zichang Liu",
                "Chilam Cheang",
                "Yanwei Fu",
                "Guodong Guo",
                "Xiangyang Xue"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2022/papers/Lin_SAR-Net_Shape_Alignment_and_Recovery_Network_for_Category-Level_6D_Object_CVPR_2022_paper.pdf",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 3",
            "ref_ids": [
                "38"
            ],
            "1": "Another line of works [29,36,38,39,42,50,65] first regress object coordinates or keypoints in 2D images and then recover poses by Perspective-n-Point algorithm [25], e."
        },
        "Pose from shape: Deep pose estimation for arbitrary 3d objects": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1906.05105",
            "ref_texts": "[34] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "Increasingly robust local feature descriptors [27, 34, 45, 46] and more effective variants of PnP algorithms [6, 21, 24, 53] have been used in this type of pipeline.",
            "2": "Most methods estimate the 2D position in the test image of the projections of the object 3D bounding box [10, 32, 39, 43] or object semantic keypoints [9, 34] to find 2D-to-3D correspondences and then apply a variant of the PnP algorithm, as feature-matching methods.",
            "3": "1 Pavlakos [34]* 81 78 44 79 96 90 80 \u2013 \u2013 74 79 66 \u2013 8."
        },
        "Ove6d: Object viewpoint encoding for depth-based 6d object pose estimation": {
            "authors": [
                "Dingding Cai",
                "Janne Heikkila",
                "Esa Rahtu"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Cai_OVE6D_Object_Viewpoint_Encoding_for_Depth-Based_6D_Object_Pose_Estimation_CVPR_2022_paper.pdf",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 2",
            "ref_ids": [
                "35"
            ],
            "1": "Related Work Pose estimation from RGB data Most RGB-based object 6D pose estimation methods [1,20,33,35,36,38,44,57] attempt to establish sparse or dense 2D-3D correspondences between the 2D coordinates in the RGB image and the 3D coordinates on the object 3D model surface."
        },
        "Self-supervised viewpoint learning from image collections": {
            "authors": [
                "Siva Karthik",
                "Varun Jampani",
                "Shalini De",
                "Sifei Liu",
                "Umar Iqbal",
                "Carsten Rother",
                "Jan Kautz"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Mustikovela_Self-Supervised_Viewpoint_Learning_From_Image_Collections_CVPR_2020_paper.pdf",
            "ref_texts": "[47] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "47"
            ],
            "1": "Related Work Viewpoint estimation Several successful learning-based viewpoint estimation techniques have been developed for general object categories that either regress orientation directly [39,38,55,62,36,48]; locate 2D keypoints and fit them to 3D keypoints [16,47,75]; or predict 3D shape and viewpoint parameters [33]."
        },
        "Monocinis: Camera independent monocular 3d object detection using instance segmentation": {
            "authors": [
                "Jonas Heylen",
                "Mark De",
                "Bruno Dawagne",
                "Marc Proesmans",
                "Luc Van",
                "Wim Abbeloos",
                "Hazem Abdelkawy",
                "Daniel Olmeda"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021W/3DODI/papers/Heylen_MonoCInIS_Camera_Independent_Monocular_3D_Object_Detection_Using_Instance_Segmentation_ICCVW_2021_paper.pdf",
            "ref_texts": "[43] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in 2017 IEEE International Conference on Robotics and Automation , pp. 2011\u20132018, IEEE, 2017.",
            "ref_ids": [
                "43"
            ],
            "1": "[43] predicts keypoints using heatmaps.",
            "2": "Note that the 2D positions of the absolute RPs are not limited by the image boundaries, as opposed to methods which predict heatmaps [43].",
            "3": "[43] G."
        },
        "Single-stage keypoint-based category-level object pose estimation from an RGB image": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2109.06161",
            "ref_texts": "[5] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in ICRA , 2017, pp.",
            "ref_ids": [
                "5"
            ],
            "1": "A few recent works have considered category-level object pose estimation [5], [6], [7], [8], [9], [10], [11].",
            "2": "[5] G."
        },
        "Starmap for category-agnostic keypoint and viewpoint estimation": {
            "authors": [
                "Xingyi Zhou",
                "Arjun Karpur",
                "Linjie Luo",
                "Qixing Huang"
            ],
            "url": "https://openaccess.thecvf.com/content_ECCV_2018/papers/Xingyi_Zhou_Category-Agnostic_Semantic_Keypoint_ECCV_2018_paper.pdf",
            "ref_texts": "24. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidi s, K.: 6-dof object pose from semantic keypoints. In: Robotics and Automation (IC RA), 2017 IEEE International Conference on. pp. 2011\u20132018. IEEE (2017) 1,2,3,4,5,7,10,11, 12",
            "ref_ids": [
                "24"
            ],
            "1": "Accurate semantic keypoint detection forms the basis for many visual understandingtasks,includinghumanposeestimation[4,22,25,51],handposeestimation[46,52],viewpointestimation[24,35],featurematching[15],fine-grained image classification [47], and 3D reconstruction [36,39,10,9].",
            "2": "Existing methods define a fixed number of semantic keypoints for eac h object category in isolation [35,24,40,22].",
            "3": "Specifically, StarMap combines the separate keypoint heat maps in prev ious approaches [35,24] into a single heat map, and thus unifies the detection of different keypoints.",
            "4": "We report state-of-the-art performance compared to previous viewpoint estimat ion methods [28,24,19,35] with ablation studies on each component.",
            "5": "[24] stacked keypoint heatmaps from different object categories together for multi-category object keypoint es timation.",
            "6": ", estimating an object\u2019s orientation in a given frame, is a practical problem in computer vision an d robotics [11,24].",
            "7": "[24] proposed to use detected semantic keypoint followed by a PnP algorithm [12] to solve for the resulting viewpoint matrix and achieved state-of-the-art results.",
            "8": "To generalize heatmaps to multiple categories, a popular approach is to stack all heatmaps from all categories [35,24] (resulting in/summationtextNcoutput channels, where Ncis the number of keypoints of category c).",
            "9": "Inthosecases,awe ak-perspective camera model is often applied to approximate the 3D-to-2D transformation for keypoint estimation [49,24], by changing Eq.",
            "10": "[24] 84.",
            "11": "[24] Oracle Id 92.",
            "12": "We show 3 state-of-the-art methods [15,35,24] forcategory-specific keypoint localization for comparison.",
            "13": "The evaluation of [24] is done by ourselves based on their published model.",
            "14": "Our performance is slightly worse than [24], who uses the same Hourglass architecture but with stacked category-specific channels output (/summationtext cNcoutput channels in total), which is expected.",
            "15": "For a fair comparison, we also allow [24] to change its output order with the oracle nearest location (to eliminate t he common left-right flip error [26]).",
            "16": "2% higher than that of Pavlakos et al [24].",
            "17": "Weconsidertwometricsthatarecommonlyappliedintheliterature[35,24,19,28], namely, Median Error, which is the median of the rotation angle error, and Ac StarMap 11 aero bike boat bottle bus car chair table mbike sofa train tv mean MedErr (Tulsiani [35])13.",
            "18": "6 MedErr (Pavlakos [24])8.",
            "19": "8075 Acc\u03c0\n6(Pavlakos [24])0.",
            "20": "Note that it is also possible to directly align CanViewFeature with StarM ap for viewpoint estimation by a weak-perspective PnP [24] algorithm (PnPin Table2)."
        },
        "Gsnet: Joint vehicle pose and shape reconstruction with geometrical and scene-aware supervision": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2007.13124",
            "ref_texts": "38. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation (ICRA) (2017)",
            "ref_ids": [
                "38"
            ],
            "1": "In [38,45,59], 2D regional image features are extracted and matched with the features on 3D model to establish 2D-3D relation which thus require suflcient textures for matching."
        },
        "Megapose: 6d pose estimation of novel objects via render & compare": {
            "authors": [
                "Anonymous Submission"
            ],
            "url": "https://arxiv.org/pdf/2212.06870",
            "ref_texts": "[45] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017.",
            "ref_ids": [
                "45"
            ],
            "1": "These have been replaced by learning-based methods with convolutional neural networks that directly regress sets of sparse [41,42,27,43,44,45,46] or dense [47,48,49,50,3,44] features.",
            "2": "[45] G."
        },
        "Focal length and object pose estimation via render and compare": {
            "authors": [
                "Georgy Ponimatkin",
                "Yann Labbe",
                "Bryan Russell",
                "Mathieu Aubry",
                "Josef Sivic"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Ponimatkin_Focal_Length_and_Object_Pose_Estimation_via_Render_and_Compare_CVPR_2022_paper.pdf",
            "ref_texts": "[32] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In ICRA , pages 2011\u20132018. IEEE, 2017. 2",
            "ref_ids": [
                "32"
            ],
            "1": "Previous approaches for this task primarily rely on establishing local 2D-3D correspondences between an image 3825\n and a 3D model using either hand-crafted [2,3,7,8,17,27] or CNN features [12,19,20,31,32,34,35,38,41,42,47,48], followed by robust camera pose estimation using PnP [23].",
            "2": "Both of these strategies rely on shallow hand-designed image features and have been revisited with learnable deep convolutional neural networks (CNNs)\n[19,20,31,32,34,35,38,41,42,47,48]."
        },
        "Unsupervised learning of category-specific symmetric 3d keypoints from point sets": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.07619",
            "ref_texts": "20. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: ICRA. (2017)",
            "ref_ids": [
                "20"
            ],
            "1": "In this regard, the task of learning to detect keypoints from several supervision examples, has achieved many successes [20,28].",
            "2": "Related works do not address all these problems, but instead opt for; dropping categoryspeciffcity and using aligned data [26], employing manual supervision on 2D Unsupervised Learning of Category-Speciffc Symmetric 3D Keypoints 3 images [20], or using aligned 3D and multiple 2D images with known pose [27].",
            "3": "Our proposed learning method does not assume aligned shapes [27], pre-computed basis shapes [20] or known planes of symmetry [36] and all quantities are learned in an end-to-end manner.",
            "4": "A similar task is also solved in [20] for 6-degrees of freedom (DoF) estimation which uses low-rank shape prior to condition keypoints in 3D.",
            "5": "Although, the low-rank shape modeling is a powerful tool, [20] requires supervision for heatmap prediction and relies on aligned shapes and pre-computed shape basis."
        },
        "Probabilistic orientation estimation with matrix fisher distributions": {
            "authors": [],
            "url": "https://proceedings.neurips.cc/paper/2020/file/33cc2b872dfe481abef0f61af181dfcf-Paper.pdf",
            "ref_texts": "[19] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "The keypoints can be associated either with physical points [19] or with virtual points such as the corners of an object\u2019s bounding box [6].",
            "2": "[19] 14 :16\u0000 \u0000 \u0002 Tulsiani and Malik [24] 13 :60 81 :0\u0000 \u0002 Su et al."
        },
        "Reactive semantic planning in unexplored semantic environments using deep perceptual feedback": {
            "authors": [
                "Vasileios Vasilopoulos",
                "Georgios Pavlakos",
                "Sean Bowman",
                "Diego Caporale",
                "Kostas Daniilidis",
                "George J. Pappas",
                "Daniel Koditschek"
            ],
            "url": "http://ras.papercept.net/images/temp/IROS/files/2487.pdf",
            "ref_texts": "[8] Ghost Robotics, \u201cSpirit 40.\u201d [Online]. Available: http://ghostrobotics.io [9] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6DoF object pose from semantic keypoints,\u201d in IEEE Int. Conf. Robotics and Automation , May 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "8",
                "Online",
                "9"
            ],
            "1": "1: Ghost Spirit [8] following a human, while avoiding some familiar and some novel obstacles in a previously unexplored environment.",
            "2": "Familiar obstacles are recognized and localized using visually detected semantic keypoints (bottom left inset) [9], combined with geometric features (top left inset) [10] and avoided by a local deformation of space (Fig.",
            "3": "Some few notable exceptions include considerations of optimality in unknown spaces [16], online modifications to temporal logic specifications [17] or deep learning algorithms [18] that assure safety against obstacles, or the use of trajectory optimization along with offline computed reachable sets [19] for online policy adaptations.",
            "4": "Summary of Contributions 1) Architectural Contributions: In [11], we introduced a Deep Vision based object recognition system [9] as an \u201coracle\u201d for informing a doubly reactive motion planner [5], [20], incorporating a Semantic SLAM engine [10] to integrate observations and semantic labels over time.",
            "5": "4: The online reactive planning architecture: Advancing beyond [11], camera output is run through a perceptual pipeline incorporating three separate neural networks (run onboard at 4Hz) whose function is to: (a) detect familiar obstacles and humans [27]; (b) localize corresponding semantic keypoints [9]; and (c) perform a 3D human mesh estimation [21].",
            "6": "6-a exemplifies the (well-known [29]) performance degradation of RRTXin the presence of narrow passages: as the corridor narrows (while always larger than the robot\u2019s diameter), the minimum number of (offline-computed) samples needed for successful replanning and safe navigation increases in a nonlinear manner.",
            "7": "We suggest the robustness of these feedback controllers by performing several experiments on the more dynamic Ghost Spirit legged robot [8], using a rough approximation to the quasi-static differential drive motion model.",
            "8": "If one of the specified object classes is detected, then we follow the semantic keypoints approach of [9] to estimate keypoints of the object on the image plane5.",
            "9": "The training data for the particular instances of interest are collected with a semi-automatic 5Note that while both the YOLOv3 detector [27] and the keypoint estimation algorithm [9] are empirically very robust (e.",
            "10": "procedure, similarly to [9].",
            "11": "[8] Ghost Robotics, \u201cSpirit 40.",
            "12": "\u201d [Online].",
            "13": "io [9] G.",
            "14": "[19] S.",
            "15": "[Online].",
            "16": "[29] J.",
            "17": "[Online]."
        },
        "Efficient data layouts for convolutional neural networks": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/ac/dd/00/eb34acdb4b5885/US11182645.pdf",
            "ref_texts": ""
        },
        "Nemo: Neural mesh models of contrastive features for robust 3d pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2101.12378",
            "ref_texts": "6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pp. 2011\u20132018. IEEE, 2017. 2, 3 Sida Peng, Yuan Liu, Qixing Huang, Xiaowei Zhou, and Hujun Bao. Pvnet: Pixel-wise voting network for 6dof pose estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 4561\u20134570, 2019. 3 Nikhila Ravi, Jeremy Reizenstein, David Novotny, Taylor Gordon, Wan-Yen Lo, Justin Johnson, and Georgia Gkioxari. Accelerating 3d deep learning with pytorch3d. arXiv:2007.08501 , 2020."
        },
        "Learning to detect scene landmarks for camera localization": {
            "authors": [
                "Tien Do",
                "Ondrej Miksik",
                "Joseph De",
                "Hyun Soo",
                "Sudipta N. Sinha"
            ],
            "url": "http://openaccess.thecvf.com/content/CVPR2022/papers/Do_Learning_To_Detect_Scene_Landmarks_for_Camera_Localization_CVPR_2022_paper.pdf",
            "ref_texts": "[51] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA, 2017. 2,3",
            "ref_ids": [
                "51"
            ],
            "1": "Our idea is inspired by the 11132\n recent success of landmark detection in human pose estimation [46,86] and keypoint recognition for objects [34, 51,77] and faces [18].",
            "2": "These were initially proposed to find the 6DoF pose of small objects using random forests [34], random ferns [49], and nowadays, CNNs [48, 51,52,55]."
        },
        "ViewNet: unsupervised viewpoint estimation from conditional generation": {
            "authors": [
                "Octave Mariotti",
                "Oisin Mac",
                "Hakan Bilen"
            ],
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Mariotti_ViewNet_Unsupervised_Viewpoint_Estimation_From_Conditional_Generation_ICCV_2021_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018, 2017.",
            "ref_ids": [
                "43"
            ],
            "1": "Alternatively, one can be used to learn the other, as one can recover pose by aligning keypoints [43], or discover them by enforcing a pose-aware sparse representation of objects [52] Recent work has proposed modeling the topology of the viewpoint space by quantifying the uncertainty with a von Misses distribution [44], learning 2D image embeddings that are equivariant to 3D pose [13], employing a spherical exponential mapping at the regression output [32], or introducing cylindrical convolutions [27]."
        },
        "Carfusion: Combining point tracking and part detection for dynamic 3d reconstruction of vehicles": {
            "authors": [
                "Dinesh Reddy",
                "Minh Vo",
                "Srinivasa G. Narasimhan"
            ],
            "url": "http://openaccess.thecvf.com/content_cvpr_2018/papers/Reddy_CarFusion_Combining_Point_CVPR_2018_paper.pdf",
            "ref_texts": "[33] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017.",
            "ref_ids": [
                "33"
            ],
            "1": "Multi-stage pipelines involve detecting and segmenting objects in the scene, estimating 3D poses, fitting shape models to the segment masks, enabling coarse to 1907\n\nfine improvement [19, 28, 33].",
            "2": "[33] G."
        },
        "Augmented reality display device with deep learning sensors": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/2a/a4/67/7d5b8e3163368a/US11120266.pdf",
            "ref_texts": ""
        },
        "Deep neural network for iris identification": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/37/fb/ac/5d2c79a5dfecc2/US11568035.pdf"
        },
        "Reconstructing vehicles from a single image: Shape priors for road scene understanding": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1609.09468"
        },
        "Optimal pose and shape estimation for category-level 3d object perception": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.08383",
            "ref_texts": "[56] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. InIEEE Intl. Conf. on Robotics and Automation (ICRA) , 2017. 1, 2, 3",
            "ref_ids": [
                "56"
            ],
            "1": "Similarly, domestic applications require estimating the location and shape of objects to support more effective interaction and manipulation [23, 48, 56].",
            "2": "Pipelines using deep learning have seen great successes in areas such as human pose estimation [29, 50, 52, 75, 76], and pose estimation of household objects [23, 48, 56].",
            "3": "Such approaches first recover the position of semantic keypoints [56] in the images with neural networks, and then recover the 3D pose of the object by solving a geometric optimization problem [31, 53, 56, 57, 64].",
            "4": "[56] use a stacked hourglass neural network [52] for 2D semantic keypoint detection, and then employ block coordinate descent to resolve the object pose.",
            "5": ", [56]).",
            "6": "1\n[56] G."
        },
        "Pfrl: Pose-free reinforcement learning for 6d pose estimation": {
            "authors": [
                "Jianzhun Shao",
                "Yuhang Jiang",
                "Gu Wang",
                "Zhigang Li",
                "Xiangyang Ji"
            ],
            "url": "http://openaccess.thecvf.com/content_CVPR_2020/papers/Shao_PFRL_Pose-Free_Reinforcement_Learning_for_6D_Pose_Estimation_CVPR_2020_paper.pdf",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u2013",
            "ref_ids": [
                "24"
            ],
            "1": "Some people [24, 29, 25] followed the conventional way to build the 2D3D correspondences and subsequently solve the pose via Figure 1.",
            "2": "Some works followed the traditional way by training the model to build the 2D-3D correspondences by 1) detecting the pre-defined keypoints from image [24, 29, 36, 41] or 2) predicting the 3D coordinates for object pixels [2, 37, 40, 16]."
        },
        "Learning deep network for detecting 3d object keypoints and 6d poses": {
            "authors": [
                "Wanqing Zhao",
                "Shaobo Zhang",
                "Ziyu Guan",
                "Wei Zhao",
                "Jinye Peng",
                "Jianping Fan"
            ],
            "url": "https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Learning_Deep_Network_for_Detecting_3D_Object_Keypoints_and_6D_CVPR_2020_paper.pdf",
            "ref_texts": "[24] G. Pavlakos, X. Zhou, A. Chan, K. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017.",
            "ref_ids": [
                "24"
            ],
            "1": "Earlier methods in this direction calculate the 6D object pose through the matching of local features and 2D-3D correspondences [2, 24].",
            "2": "Manual-feature-based methods [28, 2, 24] usually consist of two stages.",
            "3": "[24] G."
        },
        "Conservative wasserstein training for pose estimation": {
            "authors": [
                "Xiaofeng Liu",
                "Yang Zou",
                "Tong Che",
                "Peng Ding",
                "Ping Jia",
                "Jane You",
                "Vijaya Kumar"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Conservative_Wasserstein_Training_for_Pose_Estimation_ICCV_2019_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011\u20132018. IEEE, 2017. 2,8",
            "ref_ids": [
                "43"
            ],
            "1": "The keypoints can be either semantic [43,62,38] or the eight corners of a 3D bounding box encapsulating the object [48,17].",
            "2": "[43] Hourglass 0.",
            "3": "[43] Hourglass 11."
        },
        "Se3-pose-nets: Structured deep dynamics models for visuomotor control": {
            "authors": [],
            "url": "https://rse-lab.cs.washington.edu/papers/se3posenets_icra18.pdf",
            "ref_texts": "[17] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in ICRA . IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "17"
            ],
            "1": "Pose estimation: There has also been a lot of recent work on object and camera pose estimation from RGB/D data using learning methods [17]\u2013[19], most of which use some form of explicit supervision.",
            "2": "[17] G."
        },
        "Real-time object pose estimation with pose interpreter networks": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.01099",
            "ref_texts": "[23] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in Robotics and Automation (ICRA), 2017 IEEE International Conference on . IEEE, 2017, pp.",
            "ref_ids": [
                "23"
            ],
            "1": "[23].",
            "2": "[23] G."
        },
        "Sc6d: Symmetry-agnostic and correspondence-free 6d object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2208.02129",
            "ref_texts": "[31] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 2",
            "ref_ids": [
                "31"
            ],
            "1": "Correspondence-based 6D pose estimation The correspondence-based methods [4, 45, 31, 33, 34, 29, 54, 16, 49, 40] are the dominating approach for the 6D object pose estimation."
        },
        "PoET: Pose Estimation Transformer for Single-View, Multi-Object 6D Pose Estimation": {
            "authors": [
                "Anonymous Submission"
            ],
            "url": "https://proceedings.mlr.press/v205/jantos23a/jantos23a.pdf",
            "ref_texts": "[14] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "14"
            ],
            "1": "In feature-based methods, local features are extracted from the image and then matched to the 3D model to determine correspondences [14].",
            "2": "[14] G."
        },
        "Room layout estimation methods and techniques": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/f1/0d/16/3ac0181e2d02ec/US10657376.pdf"
        },
        "3d-relnet: Joint object and relational network for 3d prediction": {
            "authors": [
                "Nilesh Kulkarni",
                "Ishan Misra",
                "Shubham Tulsiani",
                "Abhinav Gupta"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Kulkarni_3D-RelNet_Joint_Object_and_Relational_Network_for_3D_Prediction_ICCV_2019_paper.pdf",
            "ref_texts": "[37] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 2",
            "ref_ids": [
                "37"
            ],
            "1": "Current CNN based incarnations of these approaches, driven by the abundant success of deep learning and availability of annotated data, have further im-proved the results for pose estimation [45,37], and have also been extended to joint shape and pose inference of the objects present in a scene [29,44]."
        },
        "Lifting autoencoders: Unsupervised learning of a fully-disentangled 3d morphable model using deep non-rigid structure from motion": {
            "authors": [
                "Mihir Sahasrabudhe",
                "Zhixin Shu",
                "Edward Bartrum",
                "Riza Alp",
                "Dimitris Samaras",
                "Iasonas Kokkinos"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/GMDL/Sahasrabudhe_Lifting_AutoEncoders_Unsupervised_Learning_of_a_Fully-Disentangled_3D_Morphable_Model_ICCVW_2019_paper.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 8",
            "ref_ids": [
                "31"
            ],
            "1": "Furthermore we use a feedforward, single-shot camera and shape regression network, while in principle this is a problem that could require iterative model fitting techniques to align a 3D deformable model to 2D landmarks [31].",
            "2": "2, 4\n[31] G."
        },
        "Optimal and robust category-level perception: Object pose and shape estimation from 2D and 3D semantic keypoints": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2206.12498",
            "ref_texts": ""
        },
        "PointPoseNet: Point pose network for robust 6D object pose estimation": {
            "authors": [
                "Wei Chen",
                "Jinming Duan",
                "Hector Basevi",
                "Hyung Jin",
                "Ales Leonardis"
            ],
            "url": "http://openaccess.thecvf.com/content_WACV_2020/papers/Chen_PonitPoseNet_Point_Pose_Network_for_Robust_6D_Object_Pose_Estimation_WACV_2020_paper.pdf",
            "ref_texts": "[21] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "21"
            ],
            "1": "Instead of regressing 6D pose directly, some other methods [25, 27, 20, 33, 22, 21] make use of 2D keypoints as an intermediate representation for pose estimation.",
            "2": "[21] G."
        },
        "Constructing category-specific models for monocular object-slam": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1802.09292",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, A. Chan, K. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in Proceedings of the IEEE Conference on Robotics and Automation (In Press) , 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "[16] G."
        },
        "Neural network for eye image segmentation and image quality estimation": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/6b/02/e5/db2a449253f7dd/US11100644.pdf",
            "ref_texts": ""
        },
        "Cnn-based pose estimation system for close-proximity operations around uncooperative spacecraft": {
            "authors": [],
            "url": "https://pure.tudelft.nl/ws/files/68364012/6.2020_1457.pdf",
            "ref_texts": "[15]Pavlakos, G., Zhou, X., Chan, A., Derpanis, K., and Daniilidis, K., \u201c6-DoF Object Pose from Semantic Keypoints,\u201d IEEE International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "15"
            ],
            "1": "The coordinates of the heatmap\u2019s peak intensity characterize the predicted feature location, withtheintensity andtheshapeindicatingtheconfidenceof locatingthecorrespondingkeypointat thisposition[15].",
            "2": "[15], the pose estimation is solved by assigning weights to each feature based on their heatmap\u2019s peak intensities, in order to penalize inaccurate detections.",
            "3": "[15,16],andotherarchitecturessuchastheU-net[21],orvariantsofthehourglass,were testedinrecentyears.",
            "4": "[15],theadoptedarchitectureiscomposedofonly one encoder/decoderblock, constituting asingle hourglass module.",
            "5": "[15]Pavlakos, G."
        },
        "Estimating 6D pose from localizing designated surface keypoints": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1812.01387",
            "ref_texts": "[20] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "[20] estimates locations of semantic keypoints instead.",
            "2": "[20] G."
        },
        "Automatic tool landmark detection for stereo vision in robot-assisted retinal surgery": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1709.05665",
            "ref_texts": ""
        },
        "CoKe: Contrastive Learning for Robust Keypoint Detection": {
            "authors": [
                "Yutong Bai",
                "Angtian Wang",
                "Adam Kortylewski",
                "Alan Yuille"
            ],
            "url": "https://openaccess.thecvf.com/content/WACV2023/papers/Bai_CoKe_Contrastive_Learning_for_Robust_Keypoint_Detection_WACV_2023_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1, 2",
            "ref_ids": [
                "30"
            ],
            "1": "Accurate keypoint detections are of central importance for many visual understanding tasks, including viewpoint estimation [30], human pose estimation [5], action recognition [26], feature matching [24], image classification [46], and 3D reconstruction [20].",
            "2": ", the detection of human joints [5, 28, 36, 37] or distinct locations on rigid objects [42, 38, 30, 48].",
            "3": "[38], proposed to integrate the structural information between keypoints explicitly by integrating 2D and 3D models, which inspired a number of follow-up works, in particular for rigid objects [48, 38, 30]."
        },
        "Toward real-world category-level articulation pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2105.03260",
            "ref_texts": ""
        },
        "A mixed classification-regression framework for 3d pose estimation from 2d images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1805.03225",
            "ref_texts": "[18] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "18"
            ],
            "1": "The first group of methods includes the works of [2, 5, 18, 19, 24].",
            "2": "The works of [18, 24] train on 2D keypoints that correspond to semantic keypoints defined on 3D object models."
        },
        "PPR-Net++: accurate 6-D pose estimation in stacked scenarios": {
            "authors": [],
            "url": "https://cg.cs.tsinghua.edu.cn/people/~Yongjin/PPR-Net_Accurate_6-D_Pose_Estimation_in_Stacked_Scenarios.pdf",
            "ref_texts": "[14] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in Proc. IEEE Int. Conf. Robot. Autom. (ICRA) , May 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "14"
            ],
            "1": "Once thecorrespondences are established, from which 6-D poses can be recovered [14].",
            "2": "[14] G."
        },
        "Occlusion-robust object pose estimation with holistic representation": {
            "authors": [
                "Bo Chen",
                "Jun Chin",
                "Marius Klimavicius"
            ],
            "url": "http://openaccess.thecvf.com/content/WACV2022/papers/Chen_Occlusion-Robust_Object_Pose_Estimation_With_Holistic_Representation_WACV_2022_paper.pdf",
            "ref_texts": "[43] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017. 1",
            "ref_ids": [
                "43"
            ],
            "1": "Rather than directly regressing the pose, two-stage approaches [23, 25, 35, 41, 42, 44, 46, 64, 51, 43, 57] first predict landmarks on the object to establish 2D-3D correspondences, then use a Perspective-n-Point (PnP) like algorithm to solve for the pose."
        },
        "Iris boundary estimation using cornea curvature": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/0c/55/9f/8dee32508adea8/US10296792.pdf",
            "ref_texts": ""
        },
        "3d pose estimation for fine-grained object categories": {
            "authors": [
                "Yaming Wang",
                "Xiao Tan",
                "Yi Yang",
                "Xiao Liu",
                "Errui Ding",
                "Feng Zhou",
                "Larry S. Davis"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Wang_3D_Pose_Estimation_for_Fine-Grained_Object_Categories_ECCVW_2018_paper.pdf",
            "ref_texts": "17. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidi s, K.: 6-DOF object pose from semantic keypoints. In: ICRA. pp. 2011\u20132018 (2017)",
            "ref_ids": [
                "17"
            ],
            "1": "Compared to most previous works [33,25,17], our method does not require the intermediate prediction of 2D/3D key points.",
            "2": "Ther e are very few works except [17,14] that directly regresses the continuous pose par ameters.",
            "3": "Although [17] estimates a weak-perspective model for object categories an d is able to lay the 3D models onto 2D images for visualization, its quantitativ e evaluation is still limited to 3D rotations.",
            "4": "Following [25,17], the first metric, Rotation Error , focuses on the quality of viewpoint estimation only.",
            "5": "For eR, following [25,17], we set the threshold to be\u03c0\n6."
        },
        "Adaptive multi-scale detection of acoustic events": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.06878",
            "ref_texts": "[58] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "58"
            ],
            "1": "As this structure has achieved good results, other tasks begin to benefit from it [57], [58], [59].",
            "2": "[58] G."
        },
        "Cross-domain 3d equivariant image embeddings": {
            "authors": [
                "Carlos Esteves",
                "Avneesh Sud",
                "Zhengyi Luo",
                "Kostas Daniilidis",
                "Ameesh Makadia"
            ],
            "url": "http://proceedings.mlr.press/v97/esteves19a/esteves19a.pdf",
            "ref_texts": "(2):145\u2013179, 2008. Kulkarni, T. D., Whitney, W. F., Kohli, P., and Tenenbaum, J. Deep convolutional inverse graphics network. In Advances in Neural Information Processing Systems (NIPS) , 2015. Mahendran, S., Ali, H., and Vidal, R. 3d pose regression using convolutional neural networks. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) , 2017. Mahjourian, R., Wicke, M., and Angelova, A. Unsupervised learning of depth and ego-motion from monocular video using 3d geometric constraints. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. Makadia, A. and Daniilidis, K. Spherical correlation of visual representations for 3d model retrieval. International Journal of Computer Vision (IJCV) , 89(2):193\u2013210, 2010. Cross-Domain 3D Equivariant Image Embeddings Mousavian, A., Anguelov, D., Flynn, J., and Kosecka, J. 3d bounding box estimation using deep learning and geometry. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2017. Newell, A., Yang, K., and Deng, J. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision (ECCV) , pp. 483\u2013499. Springer, 2016. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. 6-DoF object pose from semantic keypoints. InInternational Conference on Robotics and Automation (ICRA) , 2017. Rad, M. and Lepetit, V . BB8: A scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In IEEE International Conference on Computer Vision (ICCV) , 2017. Radford, A., Metz, L., and Chintala, S. Unsupervised representation learning with deep convolutional generative adversarial networks. CoRR , abs/1511.06434, 2015. Rhodin, H., Salzmann, M., and Fua, P. Unsupervised geometry-aware representation for 3d human pose estimation. In The European Conference on Computer Vision (ECCV) , September 2018. Ronneberger, O., Fischer, P., and Brox, T. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) , 2015. Saxena, A., Driemeyer, J., and Ng, A. Y . Learning 3-d object orientation from images. In IEEE International Conference on Robotics and Automation (ICRA) , 2009. Sedaghat, N. and Brox, T. Unsupervised generation of a viewpoint annotated car dataset from videos. In IEEE International Conference on Computer Vision (ICCV) , 2015. Su, H., Qi, C. R., Li, Y ., and Guibas, L. J. Render for cnn: Viewpoint estimation in images using cnns trained with rendered 3d model views. In The IEEE International Conference on Computer Vision (ICCV) , December 2015. Sun, X., Wu, J., Zhang, X., Zhang, Z., Zhang, C., Xue, T., Tenenbaum, J. B., and Freeman, W. T. Pix3d: Dataset and methods for single-image 3d shape modeling. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. Suwajanakorn, S., Snavely, N., Tompson, J. J., and Norouzi, M. Discovery of latent 3d keypoints via end-to-end geometric reasoning. In Advances in Neural Information Processing Systems (NIPS) , pp. 2063\u20132074, 2018.Tatarchenko, M., Dosovitskiy, A., and Brox, T. Multi-view 3d models from single images with a convolutional network. In The European Conference on Computer Vision (ECCV) , pp. 322\u2013337, 2016. Tulsiani, S. and Malik, J. Viewpoints and keypoints. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2015. Tulsiani, S., Zhou, T., Efros, A. A., and Malik, J. Multi-view supervision for single-view reconstruction via differentiable ray consistency. In IEEE Conference on Computer Vision and Pattern Regognition (CVPR) , 2017. Wang, T.-C., Liu, M.-Y ., Zhu, J.-Y ., Tao, A., Kautz, J., and Catanzaro, B. High-resolution image synthesis and semantic manipulation with conditional gans. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , 2018. Weiler, M., Geiger, M., Welling, M., Boomsma, W., and Cohen, T. 3d steerable cnns: Learning rotationally equivariant features in volumetric data. In Bengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., and Garnett, R. (eds.), Advances in Neural Information Processing Systems . 2018. Worrall, D. E., Garbin, S. J., Turmukhambetov, D., and Brostow, G. J. Harmonic networks: Deep translation and rotation equivariance. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR) , volume 2, 2017a. Worrall, D. E., Garbin, S. J., Turmukhambetov, D., and Brostow, G. J. Interpretable transformations with encoderdecoder networks. In The IEEE International Conference on Computer Vision (ICCV) , Oct 2017b. Wu, Z., Song, S., Khosla, A., Yu, F., Zhang, L., Tang, X., and Xiao, J. 3d shapenets: A deep representation for volumetric shapes. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR , 2015. Xiang, Y ., Mottaghi, R., and Savarese, S. Beyond pascal: A benchmark for 3d object detection in the wild. In IEEE Winter Conference on Applications of Computer Vision (WACV) , 2014. Xiang, Y ., Kim, W., Chen, W., Ji, J., Choy, C., Su, H., Mottaghi, R., Guibas, L., and Savarese, S. Objectnet3d: A large scale database for 3d object recognition. In European Conference Computer Vision (ECCV) , 2016. Yan, X., Yang, J., Yumer, E., Guo, Y ., and Lee, H. Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision. In Advances in Neural Information Processing Systems (NIPS) , 2016. Cross-Domain 3D Equivariant Image Embeddings Yang, J., Reed, S. E., Yang, M.-H., and Lee, H. Weaklysupervised disentangling with recurrent transformations for 3d view synthesis. In Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M., and Garnett, R. (eds.), Advances in Neural Information Processing Systems (NIPS) , pp."
        },
        "Deepurl: Deep pose estimation framework for underwater relative localization": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2003.05523",
            "ref_texts": "[27] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in Proc. ICRA , 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "27"
            ],
            "1": "The classical approach for 6D object pose estimation involves extracting local features from the input image, matching them with features from a 3D model to establish 2D-to3D correspondences from which a 6D pose can be obtained through the PnP algorithm [7], [8], [10], [27].",
            "2": "[27] G."
        },
        "End-to-end 6-dof object pose estimation through differentiable rasterization": {
            "authors": [
                "Andrea Palazzi",
                "Luca Bergamini",
                "Simone Calderara",
                "Rita Cucchiara"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11131/Palazzi_End-to-end_6-DoF_Object_Pose_Estimation_through_Differentiable_Rasterization_ECCVW_2018_paper.pdf",
            "ref_texts": "28. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidi s, K.: 6-dof object pose from semantic keypoints. In: Robotics and Automation (IC RA), 2017 IEEE International Conference on. pp. 2011\u20132018. IEEE (2017)",
            "ref_ids": [
                "28"
            ],
            "1": "Building upon this success, recent m ethods [50,28] combine CNN-extracted keypoints and deformable shape models i n 4 A.",
            "2": "90 Pavlakos et al[28] 6."
        },
        "Virtual user input controls in a mixed reality environment": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/ef/ba/db/d3a66ed7296cc4/US11150777.pdf",
            "ref_texts": ""
        },
        "W-posenet: Dense correspondence regularized pixel pair pose regression": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.11888",
            "ref_texts": "[18] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in ICRA , 2017.",
            "ref_ids": [
                "18"
            ],
            "1": "Intuitively, compared to sparse semantic keypoints pre-defined in keypoint-based methods [16], [17], [18], [19], [20], dense correspondence mapping in our scheme treats each pixel as a keypoint to regress its corresponding 3D coordinate in object model space, which makes each pixel-wise feature more discriminative, and thus our pixel-wise feature encoding is more robust to occlusion.",
            "2": "Existing methods can be categorized into two groups: object detection based [19], [27] and dense heatmap based [17], [18].",
            "3": "The latter group of methods [17], [18] pay more attention to discovering latent correlation across all the keypoints and thus are more robust to inter-object occlusion.",
            "4": "[18] G."
        },
        "6D object pose estimation using keypoints and part affinity fields": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2107.02057",
            "ref_texts": "14. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF object pose from semantic keypoints. In: IEEE International Conference on Robotics and Automation (ICRA). pp. 2011\u20132018 (2017)",
            "ref_ids": [
                "14"
            ],
            "1": "In recent years, two-stage approaches, which first detect keypoints and then solve a Perspective-n-Point (PnP) problem to infer the object pose [14,15,16], have been shown to provide robust and accurate results.",
            "2": "[14] define keypointsontheobjectsurfaceandinferthemasmaximaofpixel-wiseheatmaps."
        },
        "Vehicle pose and shape estimation through multiple monocular vision": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1802.03515",
            "ref_texts": "[6] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis and K. Daniilidis, \u201c6-DoF Object Pose from Semantic Keypoints,\u201d in Proc. 2017 IEEE Int. Conf. on Robotics and Automation (ICRA) , Singapore, Singapore, 2017.",
            "ref_ids": [
                "6"
            ],
            "1": "Some latest works [6], [7] combined semantic keypoints with simple models.",
            "2": "Even if [6], [7] have shape adjustment in their process, this problem remains unsolved.",
            "3": "Single Camera Iteration: For each camera, we can estimate 3D pose from single image with a general model asapproaches presented by [6] and [7].",
            "4": "THREE METHODS (STEREOSCOPIC , 6D OF[6], O URS)ARE COMPARED .",
            "5": "30\n6DoF-LINCON [6] 18.",
            "6": "42\n6DoF-TOYOTA [6] 37.",
            "7": "10\n6DoF-BMW [6] 29.",
            "8": "12\n6DoF-mean [6] 28.",
            "9": "Keypoints localization errors in 3D space are shown in Table I, including comparisons with stereoscopic baseline a state-of-the-art method [6].",
            "10": "[6] uses only single image, so we recorded the best result of two images.",
            "11": "After testing algorithms on three different kinds of vehicle (each has more than 100 images), we reach the conclusion that less keypoint distance error is achieved compared with single image approach [6].",
            "12": "64\n6DoF-weak [6] 7.",
            "13": "99 N/A\n6DoF-full [6] 5.",
            "14": "[6] G."
        },
        "A Unifying View of Geometry, Semantics, and Data Association in SLAM.": {
            "authors": [
                "Nikolay Atanasov",
                "Sean L. Bowman",
                "Kostas Daniilidis",
                "George J. Pappas"
            ],
            "url": "https://georgejpappas.org/papers/Paper254.pdf",
            "ref_texts": "[Pavlakos et al., 2017 ]G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE ICRA, pages 2011\u20132018, 2017.",
            "ref_ids": [
                "Pavlakos et al\\., 2017 "
            ]
        },
        "Three-dimensional pose estimation of symmetrical objects": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/51/6f/86/023e44ba3f3883/US10373369.pdf"
        },
        "Strumononet: Structure-aware monocular 3d prediction": {
            "authors": [
                "Zhenpei Yang",
                "Li Erran",
                "Qixing Huang"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_StruMonoNet_Structure-Aware_Monocular_3D_Prediction_CVPR_2021_paper.pdf",
            "ref_texts": "[28] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation, ICRA 2017, Singapore, Singapore, May 29 June 3, 2017 , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "28"
            ],
            "1": "Examples include learning a machine translator between two minor languages by composing machine translators via a mother language [19], solving 6D object pose prediction via intermediate keypoint detections [1,31,28,36,27,29,34], and predicting 3D human poses through 2D keypoint predictions [44]."
        },
        "Video based Object 6D Pose Estimation using Transformers": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.13540",
            "ref_texts": "[39] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "39"
            ],
            "1": "In feature based methods, local features are extracted, and correspondence between known 3D objects and local 2D features is established using PnP to recover 6D poses [43,39]."
        },
        "Control barrier functions for nonholonomic systems under risk signal temporal logic specifications": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.02111"
        },
        "Estimating 6D aircraft pose from keypoints and structures": {
            "authors": [
                "Runze Fan",
                "Bing X",
                "Zhenzhong Wei"
            ],
            "url": "https://www.mdpi.com/2072-4292/13/4/663/pdf"
        },
        "Reactive navigation in partially known non-convex environments": {
            "authors": [],
            "url": "https://core.ac.uk/download/pdf/214217047.pdf",
            "ref_texts": "22. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF object pose from semantic keypoints. In: IEEE International Conference on Robotics and Automation. pp. 2011{2018 (May 2017)",
            "ref_ids": [
                "22"
            ],
            "1": "Recent developments in semantic SLAM [9] and object pose and triangular mesh extraction using convolutional neural net architectures [16,18,22] now provide an avenue for incorporating partial prior knowledge within a deterministic framework well suited to the vector ffeld planning methods reviewed above.",
            "2": "Since recently developed technology [16,18,22] provides means of performing obstacle identiffcation in the form of triangular meshes, in this work we focus on polygonal obstacles on the plane and derive implicit representations using so called \\R-functions\" from the constructive solid geometry literature [25].",
            "3": "Experimental validation of our algorithm with deep learning techniques for object pose and triangular mesh recognition [22] is currently underway."
        },
        "Few-shot viewpoint estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1905.04957",
            "ref_texts": "[22] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic key-points. In ICRA , 2017.",
            "ref_ids": [
                "22"
            ],
            "1": "With convolutional neural networks (CNNs) and the availability of many labeled examples [3, 44, 45], much progress has been made in estimating the viewpoint of known categories of objects [5, 16, 22].",
            "2": "They use different network architectures, including those that estimate angular values directly [10, 16, 32, 38, 43]; encode images in latent spaces to match them against a dictionary of ground truth viewpoints [15, 33]; or detect projections of 3D bounding boxes [5, 23, 35, 36] or of semantic keypoints [22, 46], which along with known [22] or estimated [5, 46] 3D object structures are used to compute viewpoint."
        },
        "MaskedFusion: Mask-based 6D object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.07771",
            "ref_texts": "16. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation (ICRA). pp. 2011{2018. IEEE (2017)",
            "ref_ids": [
                "16"
            ],
            "1": "Methods [2], [15], [16], [17], [23], [25], [26] that use RGB images as input usually rely on the detection and matching of keypoints from the objects in a scene with the 3D render and use the PnP [6] algorithm to solve the pose of that object.",
            "2": "Methods that use RGB images as input [2], [15], [16], [17], [23], [25], [26] usually rely on the detection and matching of keypoints from the objects in a scene with the 3D render and use the PnP [6] algorithm to solve the pose of that object."
        },
        "Learning local rgb-to-cad correspondences for object pose estimation": {
            "authors": [
                "Georgios Georgakis",
                "Srikrishna Karanam",
                "Ziyan Wu",
                "Jana Kosecka"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCV_2019/papers/Georgakis_Learning_Local_RGB-to-CAD_Correspondences_for_Object_Pose_Estimation_ICCV_2019_paper.pdf",
            "ref_texts": "[27] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation 8975",
            "ref_ids": [
                "27"
            ],
            "1": "These methods are usually motivated by the presence of occlusions [27, 12] and require keypoint annotations.",
            "2": "[27], were considered for comparison but unfortunately they require semantic keypoint annotations during training which Pix3D does not provide."
        },
        "CNNs based viewpoint estimation for volume visualization": {
            "authors": [
                "Neng Shi",
                "Yubo Tao"
            ],
            "url": "https://arxiv.org/pdf/1807.07449",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. 6-DoF Object Pose from Semantic Keypoints. In IEEE International Conference on Robotics and Automation . 2011\u20132018.",
            "ref_ids": [
                "24"
            ],
            "1": "/T_hese 2D keypoints can be semantic keypoints de/f_ined on 3D object models [24,44]."
        },
        "Coke: Localized contrastive learning for robust keypoint detection": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2009.14115",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1, 2",
            "ref_ids": [
                "30"
            ],
            "1": "Accurate keypoint detections are of central importance for many visual understanding tasks, including viewpoint estimation [30], human pose estimation [5], action recognition [26], feature matching [24], image classification [46], and 3D reconstruction [20].",
            "2": ", the detection of human joints [5, 28, 36, 37] or distinct locations on rigid objects [42, 38, 30, 48].",
            "3": "[38], proposed to integrate the structural information between keypoints explicitly by integrating 2D and 3D models, which inspired a number of follow-up works, in particular for rigid objects [48, 38, 30]."
        },
        "Training a neural network with representations of user interface devices": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/04/2c/10/bf47a4824ba956/US20220245404A1.pdf"
        },
        "Robust rgb-based 6-dof pose estimation without real pose annotations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.08391",
            "ref_texts": "22. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation (ICRA). pp. 2011{2018. IEEE (2017)",
            "ref_ids": [
                "22"
            ],
            "1": "Therefore, recent advances in the ffeld have focused on a deeplearning-based approach [10,32,28,22,24,29,7,23,14,3,33,31,20].",
            "2": "In [23,22] the keypoints are deffned as semantic object parts."
        },
        "Discovering Deformable Keypoint Pyramids": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860531.pdf",
            "ref_texts": "[39]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "39"
            ],
            "1": "These advantages have been explored by researchers over many years for a large number of applications spanning pose estimation for humans [3], animals [33], and objects [39], face recognition [34], tactile sensing [26], reinforcement learning in video games [24, 35] , and robotics [2, 4, 32, 40]."
        },
        "Vote from the center: 6 dof pose estimation in rgb-d images by radial keypoint voting": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2104.02527",
            "ref_texts": "35. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE international conference on robotics and automation (ICRA). pp. 2011\u20132018. IEEE (2017)",
            "ref_ids": [
                "35"
            ],
            "1": "Keywords: 6 DoF pose estimation, keypoint voting 1 Introduction Object pose estimation is an enabling technology for many applications including robot manipulation, human-robot interaction, augmented reality, and autonomous driving [36,35,45].",
            "2": "Keypoint klies at the intersection of S1\u2229S2, and all other Si regress 2D keypoints and use Perspective-n-Point (PnP) to estimate the 6 DoF pose parameters [35,43]."
        },
        "Fully convolutional geometric features for category-level object alignment": {
            "authors": [
                "Qiaojun Feng",
                "Nikolay Atanasov"
            ],
            "url": "https://arxiv.org/pdf/2103.04494",
            "ref_texts": "[3] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF Object Pose from Semantic Keypoints,\u201d in IEEE International Conference on Robotics and Automation (ICRA) , 2017, pp. 2011\u2013",
            "ref_ids": [
                "3"
            ],
            "1": ", chair legs, back support, seat) to obtain such matchings across instances [3].",
            "2": "Category-level semantic keypoints [3] are predicted on RGB images and a deformable shape model is fitted to recover the pose.",
            "3": "[3] G."
        },
        "Improving 3d object detection for pedestrians with virtual multi-view synthesis orientation estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.06777",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in Robotics and Automation (ICRA), 2017 IEEE International Conference on . IEEE, 2017, pp.",
            "ref_ids": [
                "25"
            ],
            "1": "Using keypoint detections [21], [22], [23], [24] and CAD models [25], [26] have been shown to be effective in gaining semantic understanding of objects of interest.",
            "2": "More recently, [25], [26] use 3D CAD models and convolutional neural networks (CNNs) to detect keypoints to learn 3D pose.",
            "3": "[25] G."
        },
        "SD-pose: Semantic decomposition for cross-domain 6D object pose estimation": {
            "authors": [
                "Zhigang Li",
                "Yinlin Hu",
                "Mathieu Salzmann",
                "Xiangyang Ji"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/16298/16105",
            "ref_texts": "2019 IEEE/CVF International Conference on Computer Vision (ICCV) . Massa, F.; Marlet, R.; and Aubry, M. 2016. Crafting a multi-task CNN for viewpoint estimation. arXiv preprint arXiv:1609.03894 . Park, K.; Patten, T.; and Vincze, M. 2019. Pix2Pose: PixelWise Coordinate Regression of Objects for 6D Pose Estimation. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K. G.; and Daniilidis, K. 2017. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on, 2011\u20132018. IEEE. Peng, S.; Liu, Y .; Huang, Q.; Zhou, X.; and Bao, H. 2019. PVNet: Pixel-wise V oting Network for 6DoF Pose Estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 4561\u20134570. Rad, M.; and Lepetit, V . 2017. BB8: A Scalable, Accurate, Robust to Partial Occlusion Method for Predicting the 3D Poses of Challenging Objects without Using Depth. In IEEE International Conference on Computer Vision (ICCV). Rad, M.; Oberweger, M.; Lepetit, V .; Lepetit, V .; and Lepetit, V . 2018. Domain Transfer for 3D Pose Estimation from Color Images without Manual Annotations. Asian Conference on Computer Vision (ACCV) ."
        },
        "Geometric change detection in digital twins": {
            "authors": [
                "Tiril Sundby",
                "Julia Maria",
                "Adil Rasheed",
                "Mandar Tabib",
                "Omer San"
            ],
            "url": "https://www.mdpi.com/2673-6470/1/2/9/pdf",
            "ref_texts": "20. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-DoF Object Pose from Semantic Keypoints. arXiv 2017 , arXiv:1703.04670.",
            "ref_ids": [
                "20"
            ]
        },
        "Gp2c: Geometric projection parameter consensus for joint 3d pose and focal length estimation in the wild": {
            "authors": [
                "Alexander Grabner",
                "Peter M. Roth",
                "Vincent Lepetit"
            ],
            "url": "https://openaccess.thecvf.com/content_ICCV_2019/papers/Grabner_GP2C_Geometric_Projection_Parameter_Consensus_for_Joint_3D_Pose_and_ICCV_2019_paper.pdf",
            "ref_texts": "[30] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos Derpanis, and Kostas Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In International Conference on Robotics and Automation , pages 2011\u20132018, 2017. 2",
            "ref_ids": [
                "30"
            ],
            "1": "In this context, recent approaches use CNNs to predict the 2D locations of the projections of 3D keypoints from RGB images [30,32].",
            "2": "While [32] recovers the 3D pose from the predicted 2D locations and a given 3D model using a PnP algorithm, [30] recovers the 3D pose from the predicted 2D locations alone using a trained deformable shape model."
        },
        "Robust 6-DoF Pose Estimation under Hybrid Constraints": {
            "authors": [
                "Hong Ren",
                "Lin Lin",
                "Yanjie Wang",
                "Xin Dong"
            ],
            "url": "https://www.mdpi.com/1424-8220/22/22/8758/pdf",
            "ref_texts": "5. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-DoF object pose from semantic keypoints. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 29 May\u20133 June 2017; pp. 2011\u20132018.",
            "ref_ids": [
                "5"
            ]
        },
        "ASM-Net: Category-level pose and shape estimation using parametric deformation": {
            "authors": [],
            "url": "https://www.bmvc2021-virtualconference.com/assets/papers/1277.pdf",
            "ref_texts": "[18] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF Object Pose from Semantic Keypoints. In Proceedings of IEEE International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "18"
            ],
            "1": "To our knowledge, the first paper on this subject was that of [18].",
            "2": "[18] proposed a method to estimate the object shape by representing it as a parameter and optimizing it alternately with the pose."
        },
        "DRNet: A depth-based regression network for 6D object pose estimation": {
            "authors": [
                "Lei Jin",
                "Xiaojuan Wang",
                "Mingshu He",
                "Jingyue Wang"
            ],
            "url": "https://www.mdpi.com/1424-8220/21/5/1692/pdf",
            "ref_texts": "27. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-dof object pose from semantic keypoints. arXiv 2017 , arXiv:1703.04670.",
            "ref_ids": [
                "27"
            ],
            "1": "[27] used semantic keypoints to Sensors 2021 ,21, 1692 3 of 14 make the 6-DoF object pose reappear for both instance-based and class-based scenarios with a cluttered background."
        },
        "Geometric correspondence fields: Learned differentiable rendering for 3d pose refinement in the wild": {
            "authors": [],
            "url": "https://vincentlepetit.github.io/files/papers/comp_grabner_eccv20.pdf",
            "ref_texts": "42. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K., Daniilidis, K.: 6-DoF Object Pose from Semantic Keypoints. In: International Conference on Roboti cs and Automation. pp. 2011\u20132018 (2017)",
            "ref_ids": [
                "42"
            ],
            "1": "In contrast, correspondence-based methods predict keypoint locat ions and recover 3D poses from 2D-3D correspondences using P nP algorithms [43,45] or trained shape models [42].",
            "2": "In this context, different methods pre dict sparse object-specific keypoints [42,43,44], sparse virtual control points [9,45,47] , or dense unsupervised 2D-3D correspondences [2,3,10,21,50]."
        },
        "Ensemble of 6 DoF Pose estimation from state-of-the-art deep methods.": {
            "authors": [
                "Ibon Merino"
            ],
            "url": "https://addi.ehu.es/bitstream/handle/10810/61846/1-s2.0-S0925231223003934-main.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[22] G. Pavlakos, X. Zhou, A. Chan, K.G. Derpanis, K. Daniilidis, 6-dof object pose from semantic keypoints, in: 2017 IEEE international conference on robotics and automation (ICRA), IEEE, 2017, pp. 2011\u20132018 .",
            "ref_ids": [
                "22"
            ],
            "1": "One of those methods estimates semantic keypoints and fits a deformable shape model to the 2D detections [22].",
            "2": "[22] G."
        },
        "Detect globally, label locally: Learning accurate 6-dof object pose estimation by joint segmentation and coordinate regression": {
            "authors": [
                "Apurv Nigam",
                "Adrian Penate",
                "Lourdes Agapito"
            ],
            "url": "https://accedacris.ulpgc.es/bitstream/10553/117927/1/Detect%20Globally%2C%20Label%20Locally-%20Learning%20Accurate%206-DOF%20Object%20Pose%20Estimation%20by%20Joint%20Segmentation%20and%20Coordinate%20Regression.pdf",
            "ref_texts": "[27] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DOF object pose from semantic keypoints,\u201d in Proc. Int. Conf. Robot. Automat. , 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "27"
            ],
            "1": "Object-class, as opposed to instance specific, pose estimation is tackled in [27] by learning semantic descriptors for each part of an object category and then solving the pose with a deformable shape model.",
            "2": "[27] G."
        },
        "A survey of simultaneous localization and mapping with an envision in 6g wireless networks": {
            "authors": [
                "Jun Zhang"
            ],
            "url": "https://whubaichuan.github.io/data/JoGPS_v17_Issue2.pdf#page=75",
            "ref_texts": "[156] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpa nis, and Kostas Daniilidis. 6 -dof object pose from semantic keypoints. In 2017 IEEE International Confere nce on Robotics and Automation ",
            "ref_ids": [
                "156"
            ],
            "1": "VIO SLAM based on deep learning can be seen in [156] ."
        },
        "Semantic correspondence via 2d-3d-2d cycle": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2004.09061",
            "ref_texts": "39. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE international conference on robotics and automation (ICRA). pp. 2011{2018. IEEE (2017)",
            "ref_ids": [
                "39"
            ],
            "1": "In addition to ShapeNet, [39,21,61,62] provide additional keypoint or correspondence annotations for object semantic understandings."
        },
        "6D Pose Estimation for Textureless Objects on RGB Frames using Multi-View Optimization": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.11554",
            "ref_texts": "[37] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) , pp. 2011\u20132018, IEEE, 2017.",
            "ref_ids": [
                "37"
            ],
            "1": "In comparison, some recent works leverage CNNs to first predict 2D object keypoints [36], [37], [26] or dense 2D-3D correspondences [38], [39], [27], [40], and then compute the pose through 2D-3D correspondences with a PnP algorithm [41].",
            "2": "[37] G."
        },
        "Perch 2.0: Fast and accurate gpu-based perception via search for object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.00326",
            "ref_texts": "[7] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DOF object pose from semantic keypoints,\u201d in ICRA , 2017, pp.",
            "ref_ids": [
                "7"
            ],
            "1": "Others localize object keypoints in image space [6], [7], [10], [12], [14], [15], [19] which often results in ambiguities for objects with symmetries or requires explicit handling of symmetries.",
            "2": "[7] G."
        },
        "CheckerPose: Progressive Dense Keypoint Localization for Object Pose Estimation with Graph Neural Network": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.16874",
            "ref_texts": "[50] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 2, 4",
            "ref_ids": [
                "50"
            ],
            "1": "Instead of direct estimation, correspondence guided methods [50, 56, 68, 46, 22, 51, 21, 23, 81, 48, 38, 75, 10, 64] follow a two-stage framework: they first predict a set of correspondences between 3D object frame coordinates and 2D image plane coordinates, and then recover the pose from the 3D-2D correspondences with a PnP algorithm [32, 30, 11, 73, 6].",
            "2": "Keypoint-localization based methods [50, 56, 68, 46, 22, 51, 21, 23] estimate the 2D coordinates for a sparse set of predefined 3D keypoints, while dense methods [81, 48, 38, 75, 10, 64] predict the 3D object frame coordinate of each 2D image pixel.",
            "3": ", heatmaps [50, 46] and vector-fields [51, 22]), our representation needs only 2d+ 1binary bits for each keypoint, thus greatly reduces the memory usage for dense keypoint localization."
        },
        "Linear-Covariance Loss for End-to-End Learning of 6D Pose Estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.11516",
            "ref_texts": "[38] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1, 2",
            "ref_ids": [
                "38"
            ],
            "1": "More recently, most works [5, 20, 22, 32, 34, 37, 38, 40, 41, 42, 43] draw inspiration from geometry and seek to predict 2D-3D corresponImageNoisy 2D-3D matchingPosteriordistributionResidual variances of correspondencesSolution distributionlossposepg.",
            "2": "[38] use heatmaps to predict the 2D locations of semantic keypoints."
        },
        "Improving car model classification through vehicle keypoint localization": {
            "authors": [],
            "url": "https://iris.unimore.it/bitstream/11380/1229971/1/VISAPP%202021.pdf",
            "ref_texts": "5 Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE. 6 Simoni, A., Bergamini, L., Palazzi, A., Calderara, S., and Cucchiara, R. (2020). Future urban scenes generation through vehicles synthesis. In International Conference on Pattern Recognition (ICPR) . 1, 5 Simonyan, K. and Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 . 6 Tulsiani, S. and Malik, J. (2015). Viewpoints and keypoints. InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 1510\u20131519. 6 Wang, J., Sun, K., Cheng, T., Jiang, B., Deng, C., Zhao, Y ., Liu, D., Mu, Y ., Tan, M., Wang, X., et al. (2020). Deep high-resolution representation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence . 6 Xiang, Y ., Mottaghi, R., and Savarese, S. (2014). Beyond pascal: A benchmark for 3d object detection in the wild. In IEEE winter conference on applications of computer vision , pages 75\u201382. IEEE. 2, 4 Xiao, M., Kortylewski, A., Wu, R., Qiao, S., Shen, W., and Yuille, A. (2019). Tdapnet: Prototype network with recurrent top-down attention for robust object classification under partial occlusion. arXiv preprint arXiv:1909.03879 . 1 Xie, S., Girshick, R., Doll \u00b4ar, P., Tu, Z., and He, K. (2017). Aggregated residual transformations for deep neural networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages 1492\u2013"
        },
        "DeepRM: Deep Recurrent Matching for 6D Pose Refinement": {
            "authors": [
                "Alexander Avery",
                "Andreas Savakis"
            ],
            "url": "https://openaccess.thecvf.com/content/CVPR2023W/RHOBIN/papers/Avery_DeepRM_Deep_Recurrent_Matching_for_6D_Pose_Refinement_CVPRW_2023_paper.pdf",
            "ref_texts": ""
        },
        "Category-Level Global Camera Pose Estimation with Multi-Hypothesis Point Cloud Correspondences": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.14419",
            "ref_texts": "[16] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "More recently, deep learning approaches have been used to build 2D-3D correspondences [13]\u2013[16]."
        },
        "Localization and mapping using instance-specific mesh models": {
            "authors": [
                "Qiaojun Feng",
                "Yue Meng",
                "Mo Shan",
                "Nikolay Atanasov"
            ],
            "url": "https://arxiv.org/pdf/2103.04493",
            "ref_texts": "[14] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF Object Pose from Semantic Keypoints,\u201d in IEEE International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "14"
            ],
            "1": "A major research challenge today is to exploit information provided by deep learning, such as category-specific object keypoints [13], [14], semantic edges [15], and segmentation masks [16], in VIO and SLAM algorithms to build rich models of the shape, structure, and function of objects.",
            "2": "We utilize semantic keypoints [13], [14], [17] and segmentation masks [16] trained on opensource datasets [18] as observations for optimizing the error functions.",
            "3": "The stacked hourglass model [13] is used by several works [14], [27] to extract mid-level object parts and, in turn, perform factor graph inference to recover the global positions and orientations of objects detected from a monocular camera.",
            "4": "[14] G."
        },
        "Region pixel voting network (RPVNet) for 6D pose estimation from monocular image": {
            "authors": [
                "Feng Xiong",
                "Chengju Liu",
                "Qijun Chen"
            ],
            "url": "https://www.mdpi.com/2076-3417/11/2/743/pdf",
            "ref_texts": "23. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-DoF object pose from semantic keypoints. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation, ICRA 2017, Singapore, 29 May\u20133 June 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 2011\u20132018.",
            "ref_ids": [
                "23"
            ],
            "1": "[23] used Faster R-CNN [24] and an hourglass architecture to predict the keypoints\u2019 heatmaps."
        },
        "Robust Category-Level 3D Pose Estimation from Synthetic Data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2305.16124",
            "ref_texts": "[24] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 2",
            "ref_ids": [
                "24"
            ],
            "1": "Keypointbased methods [24, 41] first detect semantic keypoints and then predict the optimal 3D pose by solving a Perspectiven-Point problem."
        },
        "Rapid pose label generation through sparse representation of unknown objects": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2011.03790",
            "ref_texts": "[1] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "1"
            ],
            "1": "In the past few years, powerful CNNs have been successfully employed for this purpose enabling object pose estimation under difficult circumstances [1], [2].",
            "2": "For the purpose of training the 6-DoF pose estimation pipeline adopted by us [1], we define L= ff(I(t) s;L(t) s;b(t) s)ts t=1gNs s=1gwhere L(t) s2R2\u0002Nkis the 2D keypoint annotation in the image I(t) sfor the Nkkeypoints chosen on the object and b(t) s2R3represents the x; ypixel coordinates of the center and side length hof an upright bounding-box square around the object in the image.",
            "3": "Note that this approach is similar to the method of label generation in [1], [11].",
            "4": "We adopt a keypoint-based pose estimation approach [1], [20], where a stacked-hourglass network is used for keypoint predictions on RGB images cropped by an object bounding-box detector network (such as SSD [21], YOLO [22]).",
            "5": "The YOLO network was trained on the default hyperparameters while the stacked-hourglass network was trained on mostly the same hyperparameters as [1] (though we implemented the keypoint detector in PyTorch instead of Lua originally).",
            "6": "[1] G."
        },
        "Personalized neural network for eye tracking": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/41/59/f2/3829b9d1a1b803/US10977820.pdf",
            "ref_texts": ""
        },
        "Review on 6D Object Pose Estimation with the focus on Indoor Scene Understanding": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2212.01920",
            "ref_texts": "[57] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. CoRR , abs/1703.04670, 2017.",
            "ref_ids": [
                "57"
            ],
            "1": "In Semantic keypoint [57] the keypoints are predicted using hourglass [54] network.",
            "2": "Although some techniques are trying to define a deformable shape priors [57] to address the unavailability of CAD models for all the instances, but still not performing well for all the categories, especially the ones with more appearance change within the category.",
            "3": "[57] G."
        },
        "Pose proposal critic: Robust pose refinement by learning reprojection errors": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2005.06262",
            "ref_texts": "[12] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, May 2017.",
            "ref_ids": [
                "12"
            ],
            "1": "Other methods instead output heatmaps in order to encode said keypoint locations [12, 13]."
        },
        "Deep learning based pose estimation in space": {
            "authors": [],
            "url": "https://robotics.estec.esa.int/i-SAIRAS/isairas2018/Papers/Session%203c/4_isairas2018_deep_ver1-39-77-Hirano-Daichi.pdf",
            "ref_texts": ""
        },
        "DeepHMap++: Combined projection grouping and correspondence learning for full DoF pose estimation": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/19/5/1032/pdf",
            "ref_texts": "37. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-dof object pose from semantic keypoints. In Proceedings of the IEEE International Conference on Robotics and Automation, Singapore, 29 May\u20133 June 2017.",
            "ref_ids": [
                "37"
            ],
            "1": "Different from virtual control points mentioned above, semantic keypoints [37] have also been proved to be an effective intermediate cue."
        },
        "FC-TrackNet: Fast Convergence Net for 6D Pose Tracking in Synthetic Domains": {
            "authors": [
                "Di Jia",
                "Qian Wang",
                "Jun Cao",
                "Peng Cai",
                "Zhiyang Jin"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/download/27077/26849",
            "ref_texts": "7487184. Jonathan, T.; Thang, T.; Balakumar, S.; Yu, X.; Dieter, F.; and Stan, B. 2018. Deep Object Pose Estimation for Semantic Robotic Grasping of Household Objects. Paper presented at the 2nd Con-ference on Robot Learning. Zurich, CH, October 29-31. Kehl, W.; Manhardt, F.; Tombari, F.; Ilic, S.; and Navab, N. 2017. SSD-6D: Making RGB -Based 3D Detection and 6D Pose Estimation Great Again. In proceedings of the International Conference on Computer Vision.Venice: Institute of Electrical and Electronics Engineers. doi.org/10.1109/ICCV. 2019. 00777. Li, Y.; Wang, G.; Ji, X.; and Fox, D. 2020. DeepIM: Deep Iterative Matching for 6D Pose Estimation. Int J Comput Vis 128: 657 \u2013678. doi.org/10.1007/s11263019-01250 -9. Li, Z.; Wang, G.; and Ji, X. 2019. CDPN: Coordinates -Based Disentangled Pose Network for Real -Time RGB -Based 6 -DoF Object Pose Estimation. In proceedings of the International Conference on Computer Vision.Se oul: Institute of Electrical and Electronics Engineers. doi.org/10.1109/ICCV. 2019. 00777. Mitash, C.; Bowen, W.; Kostas, B.; and Abdeslam, B. 2020. Scene-level Pose Estimation for Multiple Instances of Densely Packed Objects. Paper presented at the Confer ence on Robot Learning. Boston, MA, October 30-November 1. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K. G.; and Daniilidis, K. 2017. 6-DoF object pose from semantic keypoints. In proceedings of the IEEE International Conference on Robotics and Auto-mation .Singapore: Institute of Electrical and Electronics Engineers. doi.org/10.1109/ICRA. 2017. 7989233. Peng, S.; Zhou, X.; Liu, Y.; Lin, H.; Huang, Q.; and Bao, H. 2020. PVNet: Pixel-Wise Voting Network for 6DoF Object Pose Estimation. IEEE Transactions on Pattern Analysis and Machine Intelligence 44(6): 3212 \u20133223. doi.org/10.1109/TPAMI. 2020. 3047388. Sundermeyer, M.; Marton, Z.-C.; Durner, M.; Brucker, M.; and Triebel, R. 2018. Implicit 3D Orientation Learning for 6D Object Detection from RGB Images. Paper presented at the European Conference on Computer Vision. Munich, DE, September 8-14. Tobin, J.; Fong, R.; Ray, A.; Schneider, J.; Zaremba, W.; and Abbeel, P. 2017. Domain randomization for transferring deep neural networks from simulation to the real world. In proceedings of the Intelligent Robots and Systems.Venice: Institute of Electrical and Electronics Engineers. doi.org/10.1109/IROS. 2017. 8202133. Wang, C.; Xu, D.; Zhu, Y.; Mart\u00edn -Mart\u00edn, R.; Lu, C.; Fei-Fei, L.; and Savarese, S. 2019. DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion. In proceedings of the Computer Vision and Pattern Recognition.California: Computer Vision and Pattern Recog nition. doi.org/10.1109/CVPR. 2019. 00346. Wen, B.; Mitash, C.; Ren, B.; and Bekris, K. E. 2020. se(3) -TrackNet: Data -driven 6D Pose Tracking by Calibrating Image Residuals in Synthetic Domains. In proceedings of the Intelligent Robots and Systems.Nevada: Institute of Electrical and Electronics Engineers. doi.org/10.1109/IROS45743. 2020. 9341314. W\u00fcthrich, M.; Pastor, P.; Kalakrishnan, M.; Bohg, J.; and Schaal, S. 2013. Probabilistic object tracking using a range camera. In proceedings of the Intelligent Ro bots and Systems.Tokyo: Institute of Electrical and Electronics Engineers. doi.org/10.1109/IROS. 2013. ",
            "ref_ids": [
                "7487184"
            ]
        },
        "Cpnp: Consistent pose estimator for perspective-n-point problem with bias elimination": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2209.05824",
            "ref_texts": "[28] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in Proceedings of IEEE International Conference on Robotics and Automation (ICRA) , 2017, pp.",
            "ref_ids": [
                "28"
            ],
            "1": "LHM [27] and FP [28] initialized the estimate with a weak perspective approximation and refined the estimate via successive iterations.",
            "2": "[28] G."
        },
        "TransPose: A Transformer-based 6D Object Pose Estimation Network with Depth Refinement": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2307.05561",
            "ref_texts": "[48] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp. 2011\u2013",
            "ref_ids": [
                "48"
            ],
            "1": "To address this problem, some methods obtain keypoints through pixel-wise heatmaps [47], [48].",
            "2": "For the evaluation of the overall pose estimation, the average distance (ADD) metric, as suggested in [48], is used.",
            "3": "[48] G."
        },
        "Comparative assessment of image processing algorithms for the pose estimation of uncooperative spacecraft": {
            "authors": [],
            "url": "https://pure.tudelft.nl/ws/files/55547301/IWSCFF_2019.pdf",
            "ref_texts": "[12] G. Pavlakos, X. Zhou, A. Chan, K. Derpanis, and K. Daniilidis, \u201c6-DoF Object Pose from Semantic Keypoints,\u201d IEEE International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "12"
            ],
            "1": "[12] G."
        },
        "Convolutional networks for object category and 3D pose estimation from 2D images": {
            "authors": [
                "Siddharth Mahendran",
                "Haider Ali",
                "Rene Vidal"
            ],
            "url": "http://openaccess.thecvf.com/content_ECCVW_2018/papers/11129/Mahendran_Convolutional_Networks_for_Object_Category_and_3D_Pose_Estimation_from_ECCVW_2018_paper.pdf",
            "ref_texts": "4. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis , K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE International Conference on Robotics and Automation (ICRA). (May 2017) 2011\u20132018",
            "ref_ids": [
                "4"
            ],
            "1": "[4] and Wu et al."
        },
        "Iterative pose refinement for object pose estimation based on RGBD data": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/20/15/4114/pdf",
            "ref_texts": "4. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K. G.; Daniilidis, K. 6-DOF object pose from semantic keypoints. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Marina Bay Sands, Singapore, 29 May\u201332 June 2017.",
            "ref_ids": [
                "4"
            ]
        },
        "Probabilistic vehicle reconstruction using a multi-task CNN": {
            "authors": [
                "Max Coenen",
                "Franz Rottensteiner"
            ],
            "url": "http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVRSUAD/Coenen_Probabilistic_Vehicle_Reconstruction_Using_a_Multi-Task_CNN_ICCVW_2019_paper.pdf",
            "ref_texts": "[30] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018, 2017.",
            "ref_ids": [
                "30"
            ],
            "1": "Instead, recent approaches leveraged keypoint detections to be used for model alignment [1, 9, 27, 30].",
            "2": "To avoid the error source of incorrect keypoint localisations, in contrast to [1, 30, 26], we build our probabilistic model directly on the raw keypoint heatmaps obtained by our CNN.",
            "3": "Traditionally, handcrafted features are used in [2, 7, 22, 23, 42] for the model to keypoint alignment, while recently CNNs are applied to detect keypoints [1, 3, 9, 27, 30].",
            "4": "[30] G."
        },
        "Part-level car parsing and reconstruction from single street view": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1811.10837",
            "ref_texts": "[25] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011\u20132018. IEEE, 2017. 1, 3",
            "ref_ids": [
                "25"
            ],
            "1": "based on single image have been proposed recently to advance the state-of-the-art for car pose and/or shape estimation [46, 45, 25, 38, 26, 33, 5, 24, 3, 41].",
            "2": "proposed a convex relaxation approach to estimate 3D shape given a set of 2D key points [45] and a stacked hourglass network to localize these semantic key points [25].",
            "3": "1, 3, 5, 6\n[25] G."
        },
        "Pam: Point-wise attention module for 6d object pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2008.05242",
            "ref_texts": "[17] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "17"
            ],
            "1": "In [16], [17], [18], [19], [20], [21], [22] regressed the coordinates of sparse 2D keypoints by learning features from RGB using CNN structure.",
            "2": "In [17], [23], [21], a 2D keypoints were obtained on an RGB image through a heatmap representation in as for the methods using keypoints, 6D poses were found through the PnP algorithm for the relationship between 2D-3D using the keypoints obtained by the 2-stage method.",
            "3": "In [17], [23], [23], a heatmap was created in pixel wise using the CNN structure and the region with the largest value was estimated as a keypoint.",
            "4": "[17] G."
        },
        "AI-Based Multi-Object Relative State Estimation with Self-Calibration Capabilities": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2303.00371",
            "ref_texts": "[15] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "15"
            ],
            "1": "Classical approaches are either template-based, where the object pose is determined by finding a matching template for the current image [14], or feature-based, where keypoints are extracted from the image and then matched to the 3D object model [15].",
            "2": "[15] G."
        },
        "Real-time detection of 2d tool landmarks with synthetic training data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2210.11991",
            "ref_texts": "(2019). Photorealistic image synthesis for object instance detection. In 2019 IEEE International Conference on Image Processing (ICIP) , pages 66\u201370. Ioffe, S. and Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. CoRR , abs/1502.03167. Kingma, D. P. and Ba, J. (2017). Adam: A method for stochastic optimization. Law, H. and Deng, J. (2020). Cornernet: Detecting objects as paired keypoints. International Journal of Computer Vision , 128. Long, J., Zhang, N., and Darrell, T. (2014). Do convnets learn correspondence? CoRR , abs/1411.1091. Lowe, D. (2004). Distinctive image features from scaleinvariant keypoints. International Journal of Computer Vision , 60:91\u2013.Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In Leibe, B., Matas, J., Sebe, N., and Welling, M., editors, Computer Vision \u2013 ECCV 2016 , pages 483\u2013499, Cham. Springer International Publishing. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). Pvnet: Pixel-wise voting network for 6dof pose estimation. pages 4556\u20134565. P\u00b4erez, P., Gangnet, M., and Blake, A. (2003). Poisson image editing. ACM Trans. Graph. , 22(3):313\u2013318. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. (2014). Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research , 15(56):1929\u20131958. Toshev, A. and Szegedy, C. (2014). Deeppose: Human pose estimation via deep neural networks. In 2014 IEEE Conference on Computer Vision and Pattern Recognition, pages 1653\u20131660. Tulsiani, S. and Malik, J. (2014). Viewpoints and keypoints. CoRR , abs/1411.6067. Wei, S., Ramakrishna, V ., Kanade, T., and Sheikh, Y ."
        },
        "Estimating metric poses of dynamic objects using monocular visual-inertial fusion": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1808.06753",
            "ref_texts": "[15] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d arXiv preprint arXiv:1703.04670 , 2017.",
            "ref_ids": [
                "15"
            ],
            "1": "proposed an efficient convolutional network to first locate reliable pre-defined semantic keypoints and then estimate the 6-DoF pose with only a monocular camera [15].",
            "2": "[15] G."
        },
        "Marker-less 3d object recognition and 6D pose estimation for homogeneous textureless objects: An rgb-d approach": {
            "authors": [],
            "url": "https://www.mdpi.com/1424-8220/20/18/5098/pdf",
            "ref_texts": "38. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-dof object pose from semantic keypoints. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation (ICRA), Singapore, 29 May\u20133 June 2017; pp. 2011\u20132018.",
            "ref_ids": [
                "38"
            ],
            "1": "The network proposed by [38] can handle irregular shape textureless objects."
        },
        "Improving drone localisation around wind turbines using monocular model-based tracking": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1902.10474",
            "ref_texts": "[11] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in Robotics and Automation (ICRA), 2017 IEEE International Conference on . IEEE, 2017, pp.",
            "ref_ids": [
                "11"
            ],
            "1": "In [11], the authors use a CNN to generate heatmaps of model feature points.",
            "2": "[11] G."
        },
        "An Appearance-and-Structure Fusion Network for Object Viewpoint Estimation.": {
            "authors": [
                "Yueying Kao",
                "Weiming Li",
                "Zairan Wang",
                "Dongqing Zou",
                "Ran He",
                "Qiang Wang",
                "Minsu Ahn",
                "Sunghoon Hong"
            ],
            "url": "https://www.ijcai.org/Proceedings/2018/0684.pdf",
            "ref_texts": "[Pavlakos et al., 2017 ]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and KostasDaniilidis. 6-dof object pose from semantic keypoints.InInternational Conference on Robotics and Automation, pages 2011 \u2013 2018, 2017.",
            "ref_ids": [
                "Pavlakos et al\\., 2017 "
            ]
        },
        "Toward 6 dof object pose estimation with minimum dataset": {
            "authors": [
                "Kota Suzui",
                "Yusuke Yoshiyasu",
                "Antonio Gabas",
                "Fumio Kanehiro",
                "Eiichi Yoshida"
            ],
            "url": "https://staff.aist.go.jp/e.yoshida/papers/Suzui-SII2019.pdf"
        },
        "\u201cReading Pictures Instead of Looking\u201d: RGB-D Image-Based Action Recognition via Capsule Network and Kalman Filter": {
            "authors": [
                "Botong Zhao",
                "Yanjie Wang",
                "Keke Su",
                "Hong Ren",
                "Haichao Sun"
            ],
            "url": "https://www.mdpi.com/1424-8220/21/6/2217/pdf",
            "ref_texts": "31. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K.G.; Daniilidis, K. 6-DoF object pose from semantic keypoints. In Proceedings of the 2017 IEEE International Conference on Robotics and Automation, ICRA 2017, Singapore, 29 May\u20133 June 2017; IEEE: Piscataway, NJ, USA, 2017; pp. 2011\u20132018.",
            "ref_ids": [
                "31"
            ]
        },
        "Single-image mesh reconstruction and pose estimation via generative normal map": {
            "authors": [
                "Nan Xiang",
                "Li Wang",
                "Tao Jiang",
                "Yanran Li",
                "Xiaosong Yang",
                "Jianjun Zhang"
            ],
            "url": "http://eprints.bournemouth.ac.uk/32587/1/p79-xiang.pdf",
            "ref_texts": "[14] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 2017. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2011\u20132018.",
            "ref_ids": [
                "14"
            ],
            "1": "Many recent studies specialized in using deep learning methods to learn pose estimation from the 2D image [9,10,14,17].",
            "2": "[14] trained a CNN to predict semantic key-points of the object from a single RGB image, then combined the key-points with a predefined deformable model to calculate the pose of the object."
        },
        "Context-aware 6D Pose Estimation of Known Objects using RGB-D data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2212.05560",
            "ref_texts": ""
        },
        "Vision-based docking of a mobile robot": {
            "authors": [],
            "url": "https://easychair.org/publications/preprint_download/V4Zd",
            "ref_texts": "[24] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2017.",
            "ref_ids": [
                "24"
            ],
            "1": "[24] a geometric approach to object pose estimation using semantic keypoints is taken but their published dataset only uses outdoor objects and is thus not applicable to docking.",
            "2": "[24] G."
        },
        "Understanding Pixel-level 2D Image Semantics with 3D Keypoint Knowledge Engine": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2111.10817",
            "ref_texts": "[51] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp. 2011\u2013",
            "ref_ids": [
                "51"
            ],
            "1": "In addition to ShapeNet, [21], [26], [51], [52] provide additional keypoint or correspondence annotations for object semantic understandings.",
            "2": "[51] and Kim et al.",
            "3": "[51] G."
        },
        "Multi-view object pose distribution tracking for pre-grasp planning on mobile robots": {
            "authors": [],
            "url": "https://findresearcher.sdu.dk/ws/files/206261625/Multi_view_pose_distribution_tracking_ICRA2022_camera_ready_2_.pdf",
            "ref_texts": "[26] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "26"
            ],
            "1": "To improve robustness against occlusions,recent works have focused on the prediction of object key-points [26], [27], [28] and then solve the Perspective-n-Point problem for pose estimation.",
            "2": "[26] G."
        },
        "6D object pose estimation with pairwise compatible geometric features": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/138123/ICRA2021PoseEstimation.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[18] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6DoF object pose from semantic keypoints,\u201d in 2017 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "18"
            ],
            "1": "Learning-based image and point cloud features [15], [16], [17], [18], [19] have gained more attention recently.",
            "2": "[18] G."
        },
        "Predicting out-of-view feature points for model-based camera pose estimation": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1803.01577",
            "ref_texts": "[7] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in Robotics and Automation (ICRA), 2017 IEEE International Conference on . IEEE, 2017, pp.",
            "ref_ids": [
                "7"
            ],
            "1": "The work in [7] addresses these problems by choosing not to directly regress the pose of the camera, and instead uses a CNN to extract model feature points in the form of a set of heatmaps.",
            "2": "Similar to the work in [7], our method is split into two parts.",
            "3": "The type of heatmap produced by the CNN in [7] have a direct spatial relationship to the input image.",
            "4": "Given s= 1, labels will be produced that are the same as the work in [7] and will retain the one-to-one spatial relationships.",
            "5": "We compare a number of versions of the proposed network each with difference scale values sas well as the network proposed in [7].",
            "6": "We also compared our work with the network proposed in [7], which we trained on the same data and set the label scaling to1\n2.",
            "7": "We can see that the performance of the network proposed in [7] when trained with s=1\n2 is slightly worse than the performance of our network with the same svalue, especially at the lower percentages.",
            "8": "[7] G."
        },
        "Technical report: Reactive semantic planning in unexplored semantic environments using deep perceptual feedback": {
            "authors": [
                "Daniel E. Koditschek"
            ],
            "url": "https://arxiv.org/pdf/2002.12349",
            "ref_texts": "[8] Ghost Robotics, \u201cSpirit 40.\u201d [Online]. Available: http://ghostrobotics.io [9] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6DoF object pose from semantic keypoints,\u201d in IEEE Int. Conf. Robotics and Automation , May 2017, pp. 2011\u20132018.[10] S. L. Bowman, N. Atanasov, K. Daniilidis, and G. J. Pappas, \u201cProbabilistic data association for semantic SLAM,\u201d in IEEE Int. Conf. Robotics and Automation , May 2017, pp. 1722\u20131729.",
            "ref_ids": [
                "8",
                "Online",
                "9",
                "10"
            ],
            "1": "More modular data driven methods that separate the recruitment of learned visual representation to support learned control policies achieve greater generalization [14], but even carefully This work was supported by AFRL grant FA865015D1845 (subcontract 669737-1), AFOSR grant FA9550-19-1-0265 (Assured Autonomy in Contested Environments), and ONR grant #N00014-16-1-2817, a Vannevar Bush Fellowship held by the last author, sponsored by the Basic Research Office of the Assistant Secretary of Defense for Research and Engineering.",
            "2": "The authors are with the GRASP Lab, University of Pennsylvania, Philadelphia, PA 19104, fvvasilo, pavlakos, seanbow, jdcap, kostas, pappasg, kod g@seas.",
            "3": "1: Ghost Spirit [8] following a human, while avoiding some familiar and some novel obstacles in a previously unexplored environment.",
            "4": "Familiar obstacles are recognized and localized using visually detected semantic keypoints (bottom left inset) [9], combined with geometric features (top left inset) [10] and avoided by a local deformation of space (Fig.",
            "5": "Some few notable exceptions include considerations of optimality in unknown spaces [16], online modifications to temporal logic specifications [17] or deep learning algorithms [18] that assure safety against obstacles, or the use of trajectory optimization along with offline computed reachable sets [19] for online policy adaptations.",
            "6": "Summary of Contributions 1) Architectural Contributions: In [11], we introduced a Deep Vision based object recognition system [9] as an \u201coracle\u201d for informing a doubly reactive motion planner [5], [20], incorporating a Semantic SLAM engine [10] toarXiv:2002.",
            "7": "12349v3 [cs.",
            "8": "RO] 4 May 2020 Start Robot path GoalSensor footprintInstantiated obstacles Robot placementInstantiated obstacle deformed to disk Fragment of unknown obstacle Projected goalLocal freespace Semantic Mapping Mapped Space RecoveryComposition of Purging Transformations h(x)\n<latexit sha1_base64=\"gtVpkhVu73gNhh6UNNrndAv4TDo=\">AAAB/3icbVDLSsNAFJ3UV62vqODGzdAiVISS1IUui25cVrAPaEKZTCft0MkkzEzEELPwH/wCNy4UcetvuOvfOGkraPXAwOGce7lnjhcxKpVlTYzC0vLK6lpxvbSxubW9Y+7utWUYC0xaOGSh6HpIEkY5aSmqGOlGgqDAY6TjjS9zv3NLhKQhv1FJRNwADTn1KUZKS33zwAmQGnl+Osqq3/QuO+6bFatmTQH/EntOKo2yc/I4aSTNvvnpDEIcB4QrzJCUPduKlJsioShmJCs5sSQRwmM0JD1NOQqIdNNp/gweaWUA/VDoxxWcqj83UhRImQSenswjykUvF//zerHyz92U8ihWhOPZIT9mUIUwLwMOqCBYsUQThAXVWSEeIYGw0pWVdAn24pf/kna9Zp/W6te6jQswQxEcgjKoAhucgQa4Ak3QAhjcgyfwAl6NB+PZeDPeZ6MFY76zD37B+PgCaR2ZUw==</latexit>a.",
            "9": "Intermediate Spaces Obstacles in BI map <latexit sha1_base64=\"EXxe9YJQZ9tdDAqSbZmNMFLL8oM=\">AAACBnicdZDLSsNAFIYnXmu9RV2KMFgEVyGRSl2WutFdBXuBNobJdNIOnUnCzEQoISs3voobF4q49Rnc+TZO2lRU9IeBn++cw5zz+zGjUtn2h7GwuLS8slpaK69vbG5tmzu7bRklApMWjlgkuj6ShNGQtBRVjHRjQRD3Gen44/O83rklQtIovFaTmLgcDUMaUIyURp550OdIjTBiaSPzUo7i7OaLXGaeWbGtUzsXtC17bgriFKQCCjU9870/iHDCSagwQ1L2HDtWboqEopiRrNxPJIkRHqMh6WkbIk6km07PyOCRJgMYREK/UMEp/T6RIi7lhPu6M19R/q7l8K9aL1HBmZvSME4UCfHsoyBhUEUwzwQOqCBYsYk2CAuqd4V4hATCSidX1iHML4X/m/aJ5VSt2lW1Um8UcZTAPjgEx8ABNVAHF6AJWgCDO/AAnsCzcW88Gi/G66x1wShm9sAPGW+fZGCZuw==</latexit> Obstacle in DI map <latexit sha1_base64=\"+rjzlXep5c4Z26PgyLofOvLC0Qs=\">AAACBnicdVDLSgMxFM3UV62vqksRgkVwNWRq7WNX1IXuKthWaMeSSTNtaOZBkhHKMCs3/oobF4q49Rvc+Tdm2ioqeuDC4Zx7ufceJ+RMKoTejczc/MLiUnY5t7K6tr6R39xqySAShDZJwANx5WBJOfNpUzHF6VUoKPYcTtvO6CT12zdUSBb4l2ocUtvDA5+5jGClpV5+t+thNSSYx6dJL/ZwmFx/KedJL19AZq2GSlYZIvMIoWK5pgk6LFbLZWiZaIICmKHRy791+wGJPOorwrGUHQuFyo6xUIxwmuS6kaQhJiM8oB1NfexRaceTNxK4r5U+dAOhy1dwon6fiLEn5dhzdGd6ovztpeJfXidSbtWOmR9GivpkusiNOFQBTDOBfSYoUXysCSaC6VshGWKBidLJ5XQIn5/C/0mraFols3JRKtSPZ3FkwQ7YAwfAAhVQB2egAZqAgFtwDx7Bk3FnPBjPxsu0NWPMZrbBDxivH8cFmf8=</latexit> Obstacle in CI map <latexit sha1_base64=\"hrqYYgxsmZyU0UBiWs3BMhAzhZU=\">AAACBnicbVDLSsNAFJ3UV62vqEsRBovgqiRSqMtiN7qrYB/QxjCZTtuhM5MwMxFKyMqNv+LGhSJu/QZ3/o2TNoi2HrhwOOde7r0niBhV2nG+rMLK6tr6RnGztLW9s7tn7x+0VRhLTFo4ZKHsBkgRRgVpaaoZ6UaSIB4w0gkmjczv3BOpaChu9TQiHkcjQYcUI20k3z7uc6THGLGkkfoJR1F696Ncp75ddirODHCZuDkpgxxN3/7sD0IccyI0ZkipnutE2kuQ1BQzkpb6sSIRwhM0Ij1DBeJEecnsjRSeGmUAh6E0JTScqb8nEsSVmvLAdGYnqkUvE//zerEeXngJFVGsicDzRcOYQR3CLBM4oJJgzaaGICypuRXiMZIIa5NcyYTgLr68TNrnFbdaqd1Uy/XLPI4iOAIn4Ay4oAbq4Ao0QQtg8ACewAt4tR6tZ+vNep+3Fqx85hD8gfXxDVdlmbI=</latexit>Fig.",
            "10": "To this end, we arrive at the central formal results (Proposition 1, Theorems 1-2) by employing the smooth \u201cswitch\u201d and \u201cdeforming factor\u201d construction (see (8), (9)), integrated into the prior hybrid systems navigational framework from [11], that had, in turn, relied on the method for generating differential drive inputs from [20].",
            "11": "Obstacle Representation and Convex Decomposition As a natural extension to doubly reactive algorithms for environments cluttered with convex obstacles [3], [5], we 12\n3\n45Qji <latexit sha1_base64=\"h71a3da1ugjPs/8Hh7rsqGZi/Co=\">AAACBXicdVDLSsNAFJ34rPUVdamLwSK4CkkNbd0V3bhswT6gCWEynbRjJw9mJkIJ2bjxV9y4UMSt/+DOv3HSVlDRAwOHc+5h7j1+wqiQpvmhLS2vrK6tlzbKm1vbO7v63n5XxCnHpINjFvO+jwRhNCIdSSUj/YQTFPqM9PzJZeH3bgkXNI6u5TQhbohGEQ0oRlJJnn7kxMou0pkTIjnGiGXtPPeyG4/mnl4xjfNGrWrXoGmYZt2qWgWp1u0zG1pKKVABC7Q8/d0ZxjgNSSQxQ0IMLDORboa4pJiRvOykgiQIT9CIDBSNUEiEm82uyOGJUoYwiLl6kYQz9XsiQ6EQ09BXk8Wm4rdXiH95g1QGDTejUZJKEuH5R0HKoIxhUQkcUk6wZFNFEOZU7QrxGHGEpSqurEr4uhT+T7pVw7INu21XmheLOkrgEByDU2CBOmiCK9ACHYDBHXgAT+BZu9cetRftdT66pC0yB+AHtLdPYJOZzA==</latexit> Qji <latexit sha1_base64=\"/CanIpT+Rr89zmdPBeCZTwZx2rM=\">AAAB+nicdVDLSgMxFM3UV62vqS7dBIvgqkxKse2u6MZlC/YB7TBk0kwbm8kMSUYpYz/FjQtF3Pol7vwbM20FFT0QOJxzL/fk+DFnSjvOh5VbW9/Y3MpvF3Z29/YP7OJhV0WJJLRDIh7Jvo8V5UzQjmaa034sKQ59Tnv+9DLze7dUKhaJaz2LqRvisWABI1gbybOLwxDrCcE8bc+99MZjc88uOWXHcRBCMCOodu4Y0mjUK6gOUWYZlMAKLc9+H44ikoRUaMKxUgPkxNpNsdSMcDovDBNFY0ymeEwHhgocUuWmi+hzeGqUEQwiaZ7QcKF+30hxqNQs9M1kFlT99jLxL2+Q6KDupkzEiaaCLA8FCYc6glkPcMQkJZrPDMFEMpMVkgmWmGjTVsGU8PVT+D/pVsqoWq62q6XmxaqOPDgGJ+AMIFADTXAFWqADCLgDD+AJPFv31qP1Yr0uR3PWaucI/ID19gkm35Sa</latexit> Qji <latexit sha1_base64=\"/CanIpT+Rr89zmdPBeCZTwZx2rM=\">AAAB+nicdVDLSgMxFM3UV62vqS7dBIvgqkxKse2u6MZlC/YB7TBk0kwbm8kMSUYpYz/FjQtF3Pol7vwbM20FFT0QOJxzL/fk+DFnSjvOh5VbW9/Y3MpvF3Z29/YP7OJhV0WJJLRDIh7Jvo8V5UzQjmaa034sKQ59Tnv+9DLze7dUKhaJaz2LqRvisWABI1gbybOLwxDrCcE8bc+99MZjc88uOWXHcRBCMCOodu4Y0mjUK6gOUWYZlMAKLc9+H44ikoRUaMKxUgPkxNpNsdSMcDovDBNFY0ymeEwHhgocUuWmi+hzeGqUEQwiaZ7QcKF+30hxqNQs9M1kFlT99jLxL2+Q6KDupkzEiaaCLA8FCYc6glkPcMQkJZrPDMFEMpMVkgmWmGjTVsGU8PVT+D/pVsqoWq62q6XmxaqOPDgGJ+AMIFADTXAFWqADCLgDD+AJPFv31qP1Yr0uR3PWaucI/ID19gkm35Sa</latexit> Qji <latexit sha1_base64=\"h71a3da1ugjPs/8Hh7rsqGZi/Co=\">AAACBXicdVDLSsNAFJ34rPUVdamLwSK4CkkNbd0V3bhswT6gCWEynbRjJw9mJkIJ2bjxV9y4UMSt/+DOv3HSVlDRAwOHc+5h7j1+wqiQpvmhLS2vrK6tlzbKm1vbO7v63n5XxCnHpINjFvO+jwRhNCIdSSUj/YQTFPqM9PzJZeH3bgkXNI6u5TQhbohGEQ0oRlJJnn7kxMou0pkTIjnGiGXtPPeyG4/mnl4xjfNGrWrXoGmYZt2qWgWp1u0zG1pKKVABC7Q8/d0ZxjgNSSQxQ0IMLDORboa4pJiRvOykgiQIT9CIDBSNUEiEm82uyOGJUoYwiLl6kYQz9XsiQ6EQ09BXk8Wm4rdXiH95g1QGDTejUZJKEuH5R0HKoIxhUQkcUk6wZFNFEOZU7QrxGHGEpSqurEr4uhT+T7pVw7INu21XmheLOkrgEByDU2CBOmiCK9ACHYDBHXgAT+BZu9cetRftdT66pC0yB+AHtLdPYJOZzA==</latexit> x\u21e4 ji <latexit sha1_base64=\"CGoAzNdTMgi8c0DwJ0pa7/HsZMw=\">AAAB+3icbVDLSsNAFL2pr1pfsS7dBIsgLkoiBV0W3bisYB/QxjCZTtqxk0mYmUhLyK+4caGIW3/EnX/jpM1CWw8MHM65l3vm+DGjUtn2t1FaW9/Y3CpvV3Z29/YPzMNqR0aJwKSNIxaJno8kYZSTtqKKkV4sCAp9Rrr+5Cb3u09ESBrxezWLiRuiEacBxUhpyTOrgxCpsR+k0+zh3EsfPZp5Zs2u23NYq8QpSA0KtDzzazCMcBISrjBDUvYdO1ZuioSimJGsMkgkiRGeoBHpa8pRSKSbzrNn1qlWhlYQCf24subq740UhVLOQl9P5knlspeL/3n9RAVXbkp5nCjC8eJQkDBLRVZehDWkgmDFZpogLKjOauExEggrXVdFl+Asf3mVdC7qTqPeuGvUmtdFHWU4hhM4AwcuoQm30II2YJjCM7zCm5EZL8a78bEYLRnFzhH8gfH5A3FQlLU=</latexit> x\u21e4 i <latexit sha1_base64=\"lw6yubGhDLcMQexcgABlZOzhdWE=\">AAAB+XicbVDLSsNAFL2pr1pfUZduBosgLkoiBV0W3bisYB/QxjKZTtqhk0mYmRRLyJ+4caGIW//EnX/jpM1CWw8MHM65l3vm+DFnSjvOt1VaW9/Y3CpvV3Z29/YP7MOjtooSSWiLRDySXR8rypmgLc00p91YUhz6nHb8yW3ud6ZUKhaJBz2LqRfikWABI1gbaWDb/RDrsR+kT9njxSBl2cCuOjVnDrRK3IJUoUBzYH/1hxFJQio04VipnuvE2kux1IxwmlX6iaIxJhM8oj1DBQ6p8tJ58gydGWWIgkiaJzSaq783UhwqNQt9M5nnVMteLv7n9RIdXHspE3GiqSCLQ0HCkY5QXgMaMkmJ5jNDMJHMZEVkjCUm2pRVMSW4y19eJe3Lmluv1e/r1cZNUUcZTuAUzsGFK2jAHTShBQSm8Ayv8Gal1ov1bn0sRktWsXMMf2B9/gDpDpPY</latexit> x\u21e4 i <latexit sha1_base64=\"lw6yubGhDLcMQexcgABlZOzhdWE=\">AAAB+XicbVDLSsNAFL2pr1pfUZduBosgLkoiBV0W3bisYB/QxjKZTtqhk0mYmRRLyJ+4caGIW//EnX/jpM1CWw8MHM65l3vm+DFnSjvOt1VaW9/Y3CpvV3Z29/YP7MOjtooSSWiLRDySXR8rypmgLc00p91YUhz6nHb8yW3ud6ZUKhaJBz2LqRfikWABI1gbaWDb/RDrsR+kT9njxSBl2cCuOjVnDrRK3IJUoUBzYH/1hxFJQio04VipnuvE2kux1IxwmlX6iaIxJhM8oj1DBQ6p8tJ58gydGWWIgkiaJzSaq783UhwqNQt9M5nnVMteLv7n9RIdXHspE3GiqSCLQ0HCkY5QXgMaMkmJ5jNDMJHMZEVkjCUm2pRVMSW4y19eJe3Lmluv1e/r1cZNUUcZTuAUzsGFK2jAHTShBQSm8Ayv8Gal1ov1bn0sRktWsXMMf2B9/gDpDpPY</latexit>\n\u21e2i <latexit sha1_base64=\"JKvasVIiMwF7HAfR4LvQ9Jzi7vQ=\">AAAB7XicbVDLSgNBEOz1GeMr6tHLYBA8hV0J6DHoxWME84BkCbOTTjJmdmaZmRXCkn/w4kERr/6PN//GSbIHTSxoKKq66e6KEsGN9f1vb219Y3Nru7BT3N3bPzgsHR03jUo1wwZTQul2RA0KLrFhuRXYTjTSOBLYisa3M7/1hNpwJR/sJMEwpkPJB5xR66RmV49Uj/dKZb/iz0FWSZCTMuSo90pf3b5iaYzSMkGN6QR+YsOMasuZwGmxmxpMKBvTIXYclTRGE2bza6fk3Cl9MlDalbRkrv6eyGhszCSOXGdM7cgsezPxP6+T2sF1mHGZpBYlWywapIJYRWavkz7XyKyYOEKZ5u5WwkZUU2ZdQEUXQrD88ippXlaCaqV6Xy3XbvI4CnAKZ3ABAVxBDe6gDg1g8AjP8ApvnvJevHfvY9G65uUzJ/AH3ucPnqCPKg==</latexit>Fig.",
            "12": "Finally, we define the deforming factors as the functions \u0017ji:FI map;ji!R, responsible for mapping the boundary of the leaf polygon jionto the boundary of its parentp(ji)(see (9) in Appendix II).",
            "13": "Semantic MappingKeypoint EstimationMonocular ImageDetected KeypointsVIO Mapped Space RecoveryRobot Inputs Posterior Robot State LIDAR30Hz 30Hz 4Hz4Hz DI map ,BI map <latexit sha1_base64=\"j8M+EvL9X1jXx2z+gOSQp9mY5c8=\">AAACKXicbVDLSsNAFJ34rPUVdelmsAgupCRV0GWpLnRXwT6gjWEynbRDZ5IwMxFKyO+48VfcKCjq1h9x0oaibQ8MnDnnXu69x4sYlcqyvoyl5ZXVtfXCRnFza3tn19zbb8owFpg0cMhC0faQJIwGpKGoYqQdCYK4x0jLG15lfuuRCEnD4F6NIuJw1A+oTzFSWnLNapcjNcCIJdepm3AUpQ/JVLpN01M4/dUWFrhmySpbY8B5YuekBHLUXfOt2wtxzEmgMENSdmwrUk6ChKKYkbTYjSWJEB6iPuloGiBOpJOML03hsVZ60A+FfoGCY/VvR4K4lCPu6cpsRznrZeIirxMr/9JJaBDFigR4MsiPGVQhzGKDPSoIVmykCcKC6l0hHiCBsNLhFnUI9uzJ86RZKdtn5crdealay+MogENwBE6ADS5AFdyAOmgADJ7AC3gHH8az8Wp8Gt+T0iUj7zkA/2D8/AJVt6kh</latexit>\u02dcPI\n<latexit sha1_base64=\"AHldxXfTcRqqIT4x9MlXxLk9yME=\">AAACCnicbVDLSsNAFL2pr1pfVZduokVwVZIq6LLoRncV7AOaUCaTSTt0MgkzE6GErN34K25cKOLWL3Dn3zhpA2rrgYFzz7mXufd4MaNSWdaXUVpaXlldK69XNja3tnequ3sdGSUCkzaOWCR6HpKEUU7aiipGerEgKPQY6Xrjq9zv3hMhacTv1CQmboiGnAYUI6WlQfXQUZT5JHVCpEYYsbSVZYOf6kZX1ZpVt6YwF4ldkBoUaA2qn44f4SQkXGGGpOzbVqzcFAlFMSNZxUkkiREeoyHpa8pRSKSbTk/JzGOt+GYQCf24Mqfq74kUhVJOQk935jvKeS8X//P6iQou3JTyOFGE49lHQcJMFZl5LqZPBcGKTTRBWFC9q4lHSCCsdHoVHYI9f/Ii6TTq9mm9cXtWa14WcZThAI7gBGw4hyZcQwvagOEBnuAFXo1H49l4M95nrSWjmNmHPzA+vgHovpur</latexit>30Hz 40Hz10HzObject/Human Detection4Hz 4HzSemantic SpaceMapped SpaceReactive Planner Model Space Vector Field Controller Human mesh estimationDetected Objects/Humans4Hz Human Meshes Goal updates 4HzHuman Obstacles4Hz Fig.",
            "14": "4: The online reactive planning architecture: Advancing beyond [11], camera output is run through a perceptual pipeline incorporating three separate neural networks (run onboard at 4Hz) whose function is to: (a) detect familiar obstacles and humans [29]; (b) localize corresponding semantic keypoints [9]; and (c) perform a 3D human mesh estimation [21].",
            "15": "Keypoint locations on the image, other detected geometric features, and an egomotion estimate provided by visual inertial odometry are used by the semantic mapping module [10] to give updated robot (x) and obstacle poses (~PI).",
            "16": "We suggest the robustness of these feedback controllers by performing several experiments on the more dynamic Ghost Spirit legged robot [8], using a rough approximation to the quasi-static differential drive motion model.",
            "17": "We use the YOLOv3 detector [29] to detect 2D bounding boxes on the image which are then processed based on the class of the detected object.",
            "18": "If one of the specified object classes is detected, then we follow the semantic keypoints approach of [9] to estimate keypoints of the object on the image plane5.",
            "19": "The training data for the particular instances of interest are collected with a semi-automatic procedure, similarly to [9].",
            "20": "Our semantic mapping infrastructure relies on the algorithm presented in [10], and is implemented in C++.",
            "21": "Finally, our reactive controller, running online and onboard the Nvidia Jetson AGX Xavier GPU unit at 30Hz, is also implemented in C++ using Boost Geometry [33] for the underlying polygon operations, and communicates with our 5Note that while both the YOLOv3 detector [29] and the keypoint estimation algorithm [9] are empirically very robust (e.",
            "22": "The robot uses familiar obstacles to both localize itself against them [10] and reactively navigate around them.",
            "23": "501\u2013518, 1992.",
            "24": "196\u2013223, Jul 2018.",
            "25": "2899\u20132906.",
            "26": "97\u2013107, 2016.",
            "27": "[8] Ghost Robotics, \u201cSpirit 40.",
            "28": "\u201d [Online].",
            "29": "io [9] G.",
            "30": "[10] S.",
            "31": "1722\u20131729.",
            "32": "08946 , 2020.",
            "33": "Computer Vision , 2019, pp.",
            "34": "2881\u20132890.",
            "35": "Robotics and Automation , 2019, pp.",
            "36": "583\u2013599, 2016.",
            "37": "Tomlin, \u201cAn Efficient Reachability-Based Framework for Provably Safe Autonomous Navigation in Unknown Environments,\u201d arXiv: 1905.",
            "38": "00532 , 2019.",
            "39": "[19] S.",
            "40": ", \u201cBridging the Gap Between Safety and RealTime Performance in Receding-Horizon Trajectory Design for Mobile Robots,\u201d arXiv: 1809.",
            "41": "Computer Vision , 2019, pp.",
            "42": "235\u2013259, 1983.",
            "43": "797\u2013822, 2015.",
            "44": "239\u2013303, 2007.",
            "45": "CGAL Editorial Board, 2019.",
            "46": "[Online].",
            "47": "181\u2013192, 2002.",
            "48": "799\u2013817, 1985.",
            "49": "[29] J.",
            "50": "[32] TurtleBot2, \u201cOpen-source robot development kit for apps on wheels,\u201d 2019.",
            "51": "[Online].",
            "52": "3298\u20133305.",
            "53": "Symposium on Robotics Research , 2019.",
            "54": "1370\u20131381, 2009.",
            "55": "Springer, 1976.",
            "56": "[39] W.",
            "57": "133\u2013148, 1992.",
            "58": "71\u2013116, 1989.",
            "59": "On the other hand, the singular points of the deforming factor\u0017ji, defined as \u0017ji(x) :=\u0000 x1ji\u0000x\u0003 ji\u0001>nji\u0000 x\u0000x\u0003 ji\u0001>nji(9) with nji:=R\u0019\n2x2ji\u0000x1ji jjx2ji\u0000x1jijj;R\u0019\n2:=\u00140\u00001\n1 0\u0015\n(10) the normal vector corresponding to the shared edge betweenjiandp(ji), are the solutions of the equation (x\u0000 x\u0003 ji)>nji= 0, which lie on the hyperplane passing through x\u0003 jiwith normal vector njiand, due to the construction of Qjias in Definition 2, lie outside of Qjiand do not affect the mapFI map;ji.",
            "60": "Now, in order to prove that hI jiis aC1diffeomorphism away from the vertices of ji, we follow the procedure outlined in [39], also followed in [40], to show that 1)hI jihas a non-singular differential on FI map;jiexcept for the vertices of polygon ji.",
            "61": "When\u001bfljiis not 0, we can compute the jacobian of the map as DxhI ji= (\u0017ji(x)\u00001) (x\u0000x\u0003 ji)r\u001bji(x)>\n+\u001bji(x)(x\u0000x\u0003 ji)r\u0017ji(x)>\n+ [1 +\u001bji(x) (\u0017ji(x)\u00001)]I (11) For the deforming factor \u0017jiwe compute from (9) r\u0017ji(x) =\u0000\u0000 x1ji\u0000x\u0003 ji\u0001>njih\u0000 x\u0000x\u0003 ji\u0001>njii2nji (12) Note that we interestingly get \u0000 x\u0000x\u0003 ji\u0001>r\u0017ji(x) =\u0000\u0017ji(x) (13) From (11) it can be seen that DxhI ji=A+uv>with A= [1 +\u001bji(x) (\u0017ji(x)\u00001)]I,u=x\u0000x\u0003 jiandv=\n(\u0017ji(x)\u00001)r\u001bji(x) +\u001bji(x)r\u0017ji(x).",
            "62": "Therefore, it suffices to show that when \u001bji(x)>0: (x\u0000x\u0003 ji)>rji(x)>0 (19)\n(x\u0000x\u0003 ji)>rfiji(x)<0 (20) Following the procedure outlined in [20] for the implicit representation of polygonal obstacles and assuming that the polygonQjihasmsides, we can describe Qjiwith the implicit function ji=:((1ji^2ji)^:::^mji), with the companion R-function [24] of the logic negation for a functionxdefined as:x:=\u0000x, the companion R-function of the logic conjunction ^for two functions x1;x2defined asx1^x2:=x1+x2\u0000(xp 1+xp 2)1 p, andkjithek-th hyperplane equation describing Qji, given askji(x) :=\n(x\u0000xkji)>nkji.",
            "63": "Following the procedure outlined above for the proof of (19), we can expand each term in the conjunction individually and then combine them to get (x\u0000x\u0003 ji)>rflji(x)<flji(x) (23) We also have rfiji(x) =r \nflji(x) jjx\u0000x\u0003 jijj!\n=jjx\u0000x\u0003 jijjrflji(x)\u0000flji(x)x\u0000x\u0003 ji jjx\u0000x\u0003 jijj jjx\u0000x\u0003 jijj2(24) which gives the desired result using (23)\n(x\u0000x\u0003 ji)rfiji(x) =(x\u0000x\u0003 ji)rflji(x)\u0000flji(x) jjx\u0000x\u0003 jijj<0(25) This concludes the proof that hI jisatisfies Property 1.",
            "64": "Using (1) and writing y= hI(x)andyd=hI(xd), we get dVI dt=2(y\u0000yd)>DxhI_x =\u00002k(y\u0000yd)>\u0000 y\u0000\u0005LF(y)(yd)\u0001\n=\u00002k\u0000 y\u0000\u0005LF(y)(yd) + \u0005LF(y)(yd)\u0000yd\u0001>\n\u0000 y\u0000\u0005LF(y)(yd)\u0001\n=\u00002kjjy\u0000\u0005LF(y)(yd)jj2\n+ 2k\u0000 yd\u0000\u0005LF(y)(yd)\u0001>\u0000 y\u0000\u0005LF(y)(yd)\u0001\n\u0014\u00002kjjy\u0000\u0005LF(y)(yd)jj2\u00140 (28) sincey2LF (y), which implies that \u0000 yd\u0000\u0005LF(y)(yd)\u0001>\u0000 y\u0000\u0005LF(y)(yd)\u0001\n\u00140 (29) since either yd= \u0005LF(y)(yd), orydandyare separated by a hyperplane passing through \u0005LF(y)(yd).",
            "65": "Since the target now moves, we compute the time derivative ofVI, using (29), as dVI dt=2(y\u0000yd)>\u0002 DxhI(x)\u0001_x\u0000DxhI(xd)\u0001_xd\u0003\n=\u00002k(y\u0000yd)>\u0000 y\u0000\u0005LF(y)(yd)\u0001\n\u00002(y\u0000yd)>_yd \u0014\u00002kjjy\u0000\u0005LF(y)(yd)jj2\u00002(y\u0000yd)>_yd If(y\u0000yd)>_yd>0, then the desired resultdVI dt\u0014\n0is immediately derived."
        },
        "Synthetic depth transfer for monocular 3d object pose estimation in the wild": {
            "authors": [
                "Yueying Kao",
                "Weiming Li",
                "Qiang Wang",
                "Zhouchen Lin",
                "Wooshik Kim",
                "Sunghoon Hong"
            ],
            "url": "https://ojs.aaai.org/index.php/AAAI/article/view/6781/6635",
            "ref_texts": "3d bounding box estimation using deep learning and geometry. InCVPR , 7074\u20137082. Pavlakos, G.; Zhou, X.; Chan, A.; Derpanis, K. G.; and Daniilidis, K. 2017. 6-dof object pose from semantic keypoints. In ICRA , 2011 \u2013 2018. Pepik, B.; Stark, M.; Gehler, P.; and Schiele, B. 2012. Teaching 3d geometry to deformable part models. In CVPR , 3362\u20133369. Poirson, P.; Ammirato, P.; Fu, C.-Y .; Liu, W.; Kosecka, J.; and Berg, A. C. 2016. Fast single shot detection and pose estimation. In 3DV , 676\u2013684. Rad, M., and Lepetit, V . 2017. Bb8: a scalable, accurate, robust to partial occlusion method for predicting the 3d poses of challenging objects without using depth. In ICCV , 3828\u20133836. Rad, M.; Oberweger, M.; and Lepetit, V . 2018. Domain transfer for 3d pose estimation from color images without manual annotations.InACCV , 69\u201384. Sahin, C., and Kim, T.-K. 2018. Category-level 6d object pose recovery in depth images. In ECCV , 665\u2013681. Simonyan, K., and Zisserman, A. 2015. Very deep convolutional networks for large-scale image recognition. In ICLR . Sock, J.; Hamidreza Kasaei, S.; Seabra Lopes, L.; and Kim, T.-K."
        },
        "Monocular 3D probe tracking for generating sub-surface optical property maps from diffuse optical spectroscopic imaging": {
            "authors": [
                "Robert Amelard",
                "Jesse H. Lam",
                "Brian Hill",
                "Amanda Durkin",
                "Kyle Cutler",
                "Bruce J. Tromberg"
            ],
            "url": "https://escholarship.org/content/qt7fw4q1pw/qt7fw4q1pw.pdf"
        },
        "Development of Vision Guided Real-Time Trajectory Planning System for Autonomous Ground Refuelling Operations using Hybrid Dataset": {
            "authors": [],
            "url": "https://dspace.lib.cranfield.ac.uk/bitstream/handle/1826/19049/Development_of_vision_guided_real-time_trajectory_planning_system-2023.pdf?sequence=1"
        },
        "3D pose estimation for bin-picking: A data-driven approach using multi-light images": {
            "authors": [],
            "url": "https://kilthub.cmu.edu/ndownloader/files/13320764",
            "ref_texts": "[59] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis, \\6-DoF object pose from semantic keypoints,\" in IEEE International Conference on Robotics and Automation (ICRA) , 2017. 73",
            "ref_ids": [
                "59"
            ],
            "1": "However, the problem of 3D pose estimation from monocular images have received limited attention from the deep learning community until very recently [53, 54, 55, 56, 57, 58, 59]."
        },
        "Kosnet: A unified keypoint, orientation and scale network for probabilistic 6d pose estimation": {
            "authors": [],
            "url": "http://groups.csail.mit.edu/robotics-center/public_papers/Hashimoto20.pdf",
            "ref_texts": "[15] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-Dof Object Pose from Semantic Keypoints,\u201d in IEEE International Conference on Robotics and Automation . IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "15"
            ],
            "1": "This idea was pioneered by the BB8 [14] and Semantic Keypoints [15] networks.",
            "2": "Several other works [15], [19] realize the benefits of heat maps of keypoints in enabling probabilistic fusion.",
            "3": "[15] G."
        },
        "Conditional Link Prediction of Category-Implicit Keypoint Detection": {
            "authors": [
                "Ellen Yi",
                "Rui Fan",
                "Zechun Liu",
                "Zhiqiang Shen"
            ],
            "url": "http://openaccess.thecvf.com/content/WACV2021/papers/Yi-Ge_Conditional_Link_Prediction_of_Category-Implicit_Keypoint_Detection_WACV_2021_paper.pdf",
            "ref_texts": "[19] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "[19, 29, 22, 18], always fail to successively explore CL among keypoints.",
            "2": "8 6-DoF SH [19] CS 84.",
            "3": "8 OracleId TYPE aero bike boat bottle bus car chair table moto sofa train tv mean 6-DoF SH [19] CA 92."
        },
        "Validity Challenges in Machine Learning Benchmarks": {
            "authors": [],
            "url": "https://digitalassets.lib.berkeley.edu/techreports/ucb/incoming/EECS-2022-180.pdf",
            "ref_texts": ""
        },
        "Joint Viewpoint and Keypoint Estimation with Real and Synthetic Data": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.06274",
            "ref_texts": "19. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: IEEE International Conference on Robotics and Automation. pp. 2011{2018 (2017)",
            "ref_ids": [
                "19"
            ],
            "1": "The human pose estimation by [16] has been modiffed by [19,36] to detected 3D keypoints of multiple rigid classes to consequently estimate the translation and rotation of the object by fftting the keypoints into a shape model."
        },
        "6 DoF Pose Regression via Differentiable Rendering": {
            "authors": [],
            "url": "https://re.public.polimi.it/bitstream/11311/1208053/1/6%20DoF%20Pose%20Regression%20via%20Differentiable%20Rendering.pdf",
            "ref_texts": "24. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6dof object pose from semantic keypoints. CoRR abs/1703.04670 (2017), http://arxiv.org/abs/1703.04670",
            "ref_ids": [
                "24"
            ],
            "1": "Instead, some keypoints of the object are regressed first, and then the position and rotation of the object are obtained from them with a PnP algorithm [24,26]."
        },
        "Learning Single-view 3D Reconstruction of Objects and Scenes": {
            "authors": [
                "Shubham Tulsiani"
            ],
            "url": "https://escholarship.org/content/qt3dc5m39p/qt3dc5m39p.pdf",
            "ref_texts": "[106]G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In ICRA, 2017.",
            "ref_ids": [
                "106"
            ],
            "1": "For instance, researchers have predicted 3D object pose [106,142], low-dimensional parametric shapes [37,158], and surface normals [125].",
            "2": "[106]G."
        },
        "Improving Autonomous Navigation and Estimation in Novel Environments": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/143159/Liu_katliu_PhD_AeroAstro_2022_thesis.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[126] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DOF object pose from semantic keypoints. In Proceedings of the IEEE International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "126"
            ],
            "1": "[126] use a dataset 18A case could be made for considering DOPE a method that combines direct annotations and priorigeometricmodels, giventhattheauthorsleveragelarge-scalephoto-realisticsimulatorsenabled bydetailedgeometricmodelsandknownground-truthinsimulationiswhatenablesthe3Dbounding box keypoint annotations.",
            "2": "[126].",
            "3": "[126] G."
        },
        "Pose Guided Feature Learning for 3D Object Tracking on RGB Videos.": {
            "authors": [],
            "url": "https://www.scitepress.org/Papers/2022/108868/108868.pdf",
            "ref_texts": "(2017). Nonlinear Bayesian filtering and learning: A neuronal dynamics for perception. Scientific Reports , 7(1).Majcher, M. and Kwolek, B. (2021). Deep quaternion pose proposals for 6D object pose tracking. In Proceedings of the IEEE/CVF Int. Conf. on Computer Vision (ICCV) Workshops , pages 243\u2013251. Manhardt, F., Wang, G., Busam, B., Nickel, M., Meier, S., Minciullo, L., Ji, X., and Navab, N. (2020). CPS++: Improving class-level 6D pose and shape estimation from monocular images with self-supervised learning. arXiv 2003.05848. Newell, A., Yang, K., and Deng, J. (2016). Stacked hourglass networks for human pose estimation. In ECCV , pages 483\u2013499. Springer. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-DoF object pose from semantic keypoints. In IEEE Int. Conf. on Robotics and Automation (ICRA) , pages 2011\u20132018. Peng, S., Liu, Y ., Huang, Q., Zhou, X., and Bao, H. (2019). PVNet: Pixel-Wise V oting Network for 6DoF Pose Estimation. In IEEE Conf. on Comp. Vision and Patt. Rec., pages 4556\u20134565. Prisacariu, V . A. and Reid, I. D. (2012). PWP3D: RealTime Segmentation and Tracking of 3D Objects. Int. J. Comput. Vision , 98(3):335\u2013354. Rad, M. and Lepetit, V . (2017). BB8: A scalable, accurate, robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth. InIEEE Int. Conf. on Comp. Vision , pages 3848\u20133856. Tekin, B., Sinha, S. N., and Fua, P. (2018). Real-time seamless single shot 6D object pose prediction. In IEEE/CVF Conf. on Comp. Vision and Pattern Rec."
        },
        "Instance-specific 6-dof object pose estimation from minimal annotations": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2207.13264",
            "ref_texts": "[1] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in International Conference on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "1"
            ],
            "1": "In recent years, advances in deep learning based approaches have used powerful convolutional neural networks (CNNs) to process the input image data and generate a pose prediction [1], [2], [3].",
            "2": "\u000fWe propose improvements upon the standard semantickeypoint based approach for 6-DoF pose estimation [1] in situations when the point cloud is available, by recovering pose from 3D positions of the detected 2D keypoints using Orthogonal Procrustes analysis and a spectral-clustering based outlier rejection scheme.",
            "3": "On the other hand, in feature-based methods [1], [10], [11], the pose estimation task is broken into twostages: first detecting 2D features or keypoints on the object as viewed in the image and then using the object 3D model to establish a set of 2D-to-3D point correspondences.",
            "4": "[1] propose to use a stacked-hourglass network which predicts heatmaps for semantic keypoint on the object and then fit a deformable shape-model to the 2D detections.",
            "5": "However, we differ from [1] in two ways.",
            "6": "For instance, [1] generate the 2D keypoint labels by careful manual 3D model to point cloud alignment.",
            "7": "Semantic keypoint localization Inspired by the success of the \u201cstacked-hourglass\u201d deep neural network architecture in human-pose estimation [5], [6], [7], and also more recently in generic 3D object pose estimation [1], we adopt the same network design for keypoint prediction.",
            "8": "[1] G."
        },
        "Robust Object-Level Semantic Visual SLAM Using Semantic Keypoints": {
            "authors": [
                "Sean L. Bowman"
            ],
            "url": "https://scholar.archive.org/work/f76uj43yrbbatetbcbjp2upany/access/wayback/https://fieldrobotics.net/Field_Robotics/Papers_files/Vol2_18.pdf",
            "ref_texts": "524\u00b7Bowman et al. Geiger, A., Lenz, P., and Urtasun, R. (2012). Are we ready for autonomous driving? the kitti vision benchmark suite. In Conference on Computer Vision and Pattern Recognition (CVPR) . Geiger, A., Ziegler, J., and Stiller, C. (2011). StereoScan: Dense 3d Reconstruction in Real-time. In Intelligent Vehicles Symposium (IV) , pages 963\u2013968. Henry, P., Krainin, M., Herbst, E., Ren, X., and Fox, D. (2012). RGB-D mapping: Using Kinect-style depth cameras for dense 3D modeling of indoor environments. The International Journal of Robotics Research (IJRR) , 31(5):647\u2013663. Hesch, J. A., Kottas, D. G., Bowman, S. L., and Roumeliotis, S. I. (2014). Consistency Analysis and Improvement of Vision-aided Inertial Navigation. IEEE Trans. on Robotics (TRO) , 30(1):158\u2013176. Kaess, M., Johannsson, H., Roberts, R., Ila, V., Leonard, J., and Dellaert, F. (2012). iSAM2: Incremental Smoothing and Mapping Using the Bayes Tree. The International Journal of Robotics Research (IJRR) , 31(2):216\u2013235. Kottas, D. G. and Roumeliotis, S. I. (2013). Efficient and Consistent Vision-aided Inertial Navigation using Line Observations. In IEEE Int. Conf. on Robotics and Automation (ICRA) , pages 1540\u20131547. Lianos, N., Sch\u00f6nberger, J. L., Pollefeys, M., and Sattler, T. (2018). VSO: Visual Semantic Odometry. In European Conference on Computer Vision (ECCV) . McCormac, J., Handa, A., Davison, A., and Leutenegger, S. (2017). Semanticfusion: Dense 3d semantic mapping with convolutional neural networks. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 4628\u20134635. Munkres, J. (1957). Algorithms for the Assignment and Transportation Problems. Journal of the Society for Industrial & Applied Mathematics (SIAM) , 5(1):32\u201338. Mur-Artal, R. and Tard\u00f3s, J. D. (2016). ORB-SLAM2: an open-source SLAM system for monocular, stereo and RGB-D cameras. CoRR , abs/1610.06475. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., and Daniilidis, K. (2017). 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. Pillai, S. and Leonard, J. (2015). Monocular slam supported object recognition. In Proceedings of Robotics: Science and Systems (RSS) , Rome, Italy. Pronobis, A. (2011). Semantic Mapping with Mobile Robots . dissertation, KTH Royal Institute of Technology. Redmon, J. and Farhadi, A. (2017). Yolo9000: Better, faster, stronger. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) . Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster r-cnn: Towards real-time object detection with region proposal networks. In Cortes, C., Lawrence, N. D., Lee, D. D., Sugiyama, M., and Garnett, R., editors, Advances in Neural Information Processing Systems 28 , pages 91\u201399. Curran Associates, Inc. Rosinol, A., Abate, M., Chang, Y., and Carlone, L. (2020). Kimera: an open-source library for real-time metric-semantic localization and mapping. In 2020 IEEE International Conference on Robotics and Automation (ICRA) , pages 1689\u20131696. R\u00fcnz, M. and Agapito, L. (2017). Co-fusion: Real-time segmentation, tracking and fusion of multiple objects. In2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 4471\u20134478. St\u00fcckler, J., Waldvogel, B., Schulz, H., and Behnke, S. (2013). Dense real-time mapping of object-class semantics from RGB-D video. Journal of Real-Time Image Processing , pages 1\u201311. Trevor, A. J. B., Rogers, J. G., and Christensen, H. I. (2014). Omnimapper: A modular multimodal mapping framework. In 2014 IEEE International Conference on Robotics and Automation (ICRA) , pages 1983\u20131990. Vineet, V., Miksik, O., Lidegaard, M., Nie\u00dfner, M., Golodetz, S., Prisacariu, V. A., K\u00e4hler, O., Murray, D. W., Izadi, S., Perez, P., and Torr, P. H. S. (2015). Incremental dense semantic stereo fusion for large-scale semantic scene reconstruction. In IEEE International Conference on Robotics and Automation (ICRA) . Zhang, L., Wei, L., Shen, P., Wei, W., Zhu, G., and Song, J. (2018). Semantic slam based on object detection and improved octomap. IEEE Access , 6:75545\u201375559. How to cite this article: Bowman, S. L., Daniilidis, K., & Pappas, G. J. (2022). Robust Object-Level Semantic Visual SLAM Using Semantic Keypoints. Field Robotics, 2 , 513\u2013524. Publisher\u2019s Note: Field Robotics does not accept any legal responsibility for errors, omissions or claims and does not provide any warranty, express or implied, with respect to information published in this article. Field Robotics, April, 2022 \u00b72:513\u2013524"
        },
        "Object 6DoF Pose Estimation for Power Grid Manipulating Robots": {
            "authors": [],
            "url": "http://mvr.whu.edu.cn/pubs/6dof-ICIG-v3-final.pdf",
            "ref_texts": "14. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE international conference on robotics and automation (ICRA). pp. 2011{2018. IEEE (2017)",
            "ref_ids": [
                "14"
            ],
            "1": "Some recent methods [14, 16, 18] use CNNs to regress the 2D key-points, and then use Perspective-n-Point (PnP) algorithm to calculate 6D pose parameters."
        },
        "Optimization of visual SLAM by semantic analysis of the environment": {
            "authors": [],
            "url": "https://theses.hal.science/tel-03967982/document",
            "ref_texts": "199 Bibliography. Park, J. J., Florence, P., Straub, J., Newcombe, R., & Lovegrove, S., (2019), Deepsdf: learning continuous signed distance functions for shape representation, Proceedings of the IEEE/CVF conference on computer vision and pattern recognition , 165\u2013174. Park, K., Sinha, U., Barron, J. T., Bouaziz, S., Goldman, D. B., Seitz, S. M., & MartinBrualla, R., (2021), Nerfies: deformable neural radiance fields, Proceedings of the IEEE/CVF International Conference on Computer Vision , 5865\u20135874. Park, K., Sinha, U., Hedman, P., Barron, J. T., Bouaziz, S., Goldman, D. B., MartinBrualla, R., & Seitz, S. M., (2021), Hypernerf: a higher-dimensional representation for topologically varying neural radiance fields, arXiv preprint arXiv:2106.13228 . Park, K., Patten, T., & Vincze, M., (2019), Pix2Pose: Pixel-wise coordinate regression of objects for 6D pose estimation, IEEE Int. Conf. on Computer Vision , 7668\u20137677. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., & Daniilidis, K., (2017), 6-DoF object posefromsemantickeypoints, IEEE Int. Conf. on Robotics and Automation ,2011\u2013"
        },
        "Visual identification and location algorithm for robot based on the multimodal information": {
            "authors": [],
            "url": "https://www.oejournal.org/data/article/export-pdf?id=5fa4fb94f4d791802438c275",
            "ref_texts": "[7] Pavlakos G, Zhou X W, Chan A, et al. 6-DoF object pose from semantic keypoints[C]// Proceeding of 2017 IEEE International Conference on Robotics and Automation (ICRA), 2017: ",
            "ref_ids": [
                "7",
                "C"
            ],
            "1": "Opto-Electronic Engineering , 2018, 45(2): 170650 \n \n1 \u5f15 \u8a00 \n21\u0c16\u0ca6\n\u1254\u0f72\n\u0eca\n\u0c16\u0ca6\n\u11ad\u1042b \n\u1236\u0111\n\u10bf\n\u10bf QR-Code\u110e\u10a8b Collet [1]\n\u111d\u1116\u0a79\n\u0956\u105b\u0d4c\n\u1228\u0dffb Munoz[2]\n\u0eca\u0111\u0e34\u051b RAPID-HOG\n\u05a53D\n\u0e6d (histogram of oriented gradient\u0111HOG)\u0839\n\u0d4c\u0f43\u0a14\u0eed\u0ed5\u09d8\u0efe\n\u0ecab Zhu[3]\u0e6d\u0f99\n\u08b8\n\u0eca\u0111 b Lai[4]\u0613RGB-D\u0e6d\u0f5e\u0e34 b Rusu[5]\u0ba5\u1219\u0dd8\n\u0111\u110e\u10a8 FPFH\u0d4d\u0459 b Braun[6]\u06f1 Pose-RCNN\u087c3D\u0ea9\u0a8e bPavlakos [7]\u05a5\n\u06be b \n\u0e6d\u0f5e\u0f90\u0f0f\u099f\u10f7\u0586\n\u0569\u111d\u0e6d\u0f5e\u0f90\u0f0f\u0482\u0c86a\u0d4d\u0459\u0f02\u04b5\u0576a\u1219\u0c92\u0a71\n\u0efe\u0e38\n\u0eca\u0d5d\u111d\u0441\u0f9bb \n\u0eca\u1228 (pose)\u10ae\u0eca\u11c2 (position)\u0f5f\n(orientation)\u0bca\n\u0111\n\u065a\u05a5\n\u119c\u0e38\u0d21\n\u0cc2\u0e6d 1\u0cd8 b \n\u1109\u0d7b\u0cc6 \u10e7\u0529\u09d8\u06e9\u0673 \n\u0dd8 \u09eb\u0d94\u090c\u096f \u0e2b\u1198\u0a19\u0456\u0d4c\u0d48\u0d4d\u0459 \u0fc8\u1207\u0907\u1194 \n\u0f5f\u0907\u1194 \u0efe\u0e38\u0d4c\u0d48\u0eca\u1228\u0f5f\u0f90\u0f0f \n\u0efe\u0e38\u0eca\u11c2 \n\u0eca\u11c2\u0f90\u0f0f \u1236 \u0d4d\u0459 \u0ebb\u0e6d\u0f5e\u0d7b\u0cc6 \u1236 \n\u1236\n\u56fe1 \u8bc6\u522b\u5b9a\u4f4d\u7b97\u6cd5\u6846\u67b6 Fig.",
            "2": "Efficient multi-view object recognition and full pose estimation[C]// Proceeding of 2010 IEEE International Conference on Robotics and Automation , 2010: \n2050\u20132055.",
            "3": "Fast 6D pose estimation for texture-less objects from a single RGB image[C]// Proceeding of \n2016 IEEE International Conference on Robotics and Automation , 2016: 5623\u20135630.",
            "4": "Single Image 3D object detection and pose estimation for grasping[C]// Proceeding of \n2014 IEEE International Conference on Robotics and Automation , 2014: 3936\u20133943.",
            "5": "Object recognition with hierarchical kernel descriptors[C]// Proceedings of 2011 IEEE Conference on Computer Vision and Pattern Recognition , 2011: 1729\u20131736.",
            "6": "Fast point feature histograms \n(FPFH) for 3D registration[C]// Proceeding of 2009 IEEE International Conference on Robotics and Automation , 2009: \n3212\u20133217.",
            "7": "Pose-RCNN: Joint object detection and pose estimation using 3D object proposals[C]// Proceeding of the 19th International Conference on Intelligent Transportation Systems (ITSC) , 2016: 1546\u20131551.",
            "8": "[7] Pavlakos G, Zhou X W, Chan A, et al.",
            "9": "6-DoF object pose from semantic keypoints[C]// Proceeding of 2017 IEEE International Conference on Robotics and Automation (ICRA), 2017: \n2011\u20132018.",
            "10": "Basic object shape detection and tracking using perceptual organization[C]// Proceeding of 2009 IEEE International Conference on Advanced Robotics , 2009: \n1\u20136.",
            "11": "3D is here: Point Cloud Library \n(PCL)[C]// Proceeding of 2011 IEEE International Conference on Robotics and Automation , 2011: 1\u20134.",
            "12": "Point Cloud Segmentation Based on FPFH Features[C]// Proceedings of 2016 Chinese Intelligent Systems Conference .",
            "13": "Fast 3D recognition and pose using the viewpoint feature histogram[C]// Proceeding of \n2010 IEEE International Conference on Intelligent Robots and Systems , 2010: 2155\u20132162."
        },
        "\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53ca\u5e94\u7528\u7efc\u8ff0": {
            "authors": [],
            "url": "https://www.researching.cn/ArticlePdf/m00002/2023/60/3/0312010.pdf",
            "ref_texts": "[19]Pavlakos G , Zhou X W , Chan A , et al . 6-DoF object pose from semantic keypoints [C]\u22252017 IEEE International Conference on Robotics and Automation (ICRA ), May ",
            "ref_ids": [
                "19",
                "C"
            ],
            "1": "2 \u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\n\u56fe7\u7ed9\u51fa\u4e86\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\n\u65b9\u6cd5\u7684\u53d1\u5c55\u8fc7\u7a0b \u3002\u8fd9\u7c7b\u65b9\u6cd5\u662f\u901a\u8fc7\u5927\u91cf\u6837\u672c\u8bad\u7ec3\u6df1\u5ea6\n\u795e\u7ecf\u7f51\u7edc ,\u4f7f\u5176\u4e60\u5f97\u70b9\u7279\u5f81\u63d0\u53d6 \u3001\u5339\u914d\u548c\u4f4d\u59ff\u89e3\u7b97\u7684\u65b9\n\u6cd5\u3002\u76f8\u6bd4\u57fa\u4e8e\u7ecf\u5178\u7406\u8bba\u6a21\u578b\u7684\u65b9\u6cd5 ,\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\n\u89c9\u6d4b\u91cf\u65b9\u6cd5\u6781\u5927\u63d0\u5347\u4e86\u9c81\u68d2\u6027 ,\u5728\u5e94\u5bf9\u906e\u6321 \u3001\u80cc\u666f\u5e72\u6270\n\u7b49\u590d\u6742\u60c5\u51b5\u65f6\u6027\u80fd\u7a81\u51fa \u3002\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\n\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5206\u4e3a\u4f7f\u7528\u7a00\u758f\u5173\u952e\u70b9\u548c\u7a20\u5bc6\n\u70b9\u7279\u5f81\u7684 PnP\u8ba1\u7b97\u65b9\u6cd5 ,\u4ee5\u53ca\u57fa\u4e8e\u70b9\u7279\u5f81\u7ea6\u675f\u7684\u76f4\u63a5\u56de\u5f52\u65b9\u6cd5 \u3002\n\u7a00\u758f\u5173\u952e\u70b9\u662f\u4e8b\u5148\u6311\u9009\u548c\u89c4\u5b9a\u76ee\u6807\u4e09\u7ef4 CAD\u6a21\n\u578b\u4e0a\u7684\u663e\u8457\u70b9\u7279\u5f81 ,\u968f\u540e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ece\u56fe\u50cf\u4e2d\u68c0\u6d4b \u3001\n\u63d0\u53d6\u8fd9\u4e9b\u70b9\u7279\u5f81 ,\u5373\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u5b8c\u6210\u5173\u952e\n\u70b9\u7279\u5f81\u63d0\u53d6\u548c 2D-3D\u5339\u914d\u8fc7\u7a0b \u3002\u8fd9\u7c7b\u65b9\u6cd5\u7684\u5173\u952e\u5728\n\u4e8e\u70b9\u7279\u5f81\u7684\u9009\u53d6\u548c\u8868\u793a \u3002\u4f8b\u5982 Rad\u7b49[18]\u63d0\u51fa\u7684 BB8\u7b49\n\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u6a21\u578b\u4e09\u7ef4\u68c0\u6d4b\u6846\u7684 8\u4e2a\u89d2\u70b9,\u7136\u800c\u8fd9\u4e9b\n\u89d2\u70b9\u53ef\u80fd\u504f\u79bb\u76ee\u6807\u533a\u57df ,\u56e0\u6b64\u6d4b\u91cf\u7cbe\u5ea6\u6709\u9650 \u3002\u53e6\u4e00\u79cd\n\u5173\u952e\u70b9\u9009\u53d6\u601d\u8def\u662f\u4f7f\u7528\u8d2a\u5a6a\u7b56\u7565 ,\u5728\u76ee\u6807\u4e09\u7ef4\u6a21\u578b\u4e0a\n\u4f9d\u6b21\u9009\u53d6\u76f8\u4e92\u95f4\u8ddd\u79bb\u6700\u5927\u7684\u70b9[19],\u76ee\u524d\u5c1a\u65e0\u7406\u8bba\u8bc1\u660e\n\u88ab\u9009\u53d6\u5173\u952e\u70b9\u7684\u6700\u4f18\u6027 \u3002\u7a00\u758f\u5173\u952e\u70b9\u53ef\u4ee5\u8868\u793a\u4e3a\u539f\u59cb\n\u5750\u6807\u5f62\u5f0f[20],\u4e5f\u53ef\u4ee5\u901a\u8fc7\u70ed\u5ea6\u56fe[21]\u8868\u793a,\u6216\u8005\u7528\u5982\n\u56fe8(a)\u6240\u793a\u7684\u4e8c\u7ef4\u77e2\u91cf\u573a[22]\u8868\u793a\u3002\u7531\u4e8e\u540e\u4e24\u8005\u66f4\u63a5\n\u8fd1\u5377\u79ef\u7f51\u7edc\u5584\u4e8e\u5904\u7406\u7684\u5f20\u91cf\u5f62\u5f0f\u5f80\u5f80\u63d0\u53d6\u7cbe\u5ea6\u66f4\u9ad8 \u3002\n\u7a20\u5bc6\u70b9\u7279\u5f81\u662f\u6307\u6bcf\u4e2a\u56fe\u50cf\u50cf\u7d20\u4f4d\u7f6e\u5747\u5bf9\u5e94\u4e00\u4e2a\u76ee\n\u6807\u4e09\u7ef4\u70b9 ,\u5f62\u6210\u4e00\u79cd\u9010\u50cf\u7d20\u7a20\u5bc6\u7684 2D-3D\u5339\u914d\u5173\u7cfb ,\n\u8fd9\u7c7b\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027 ,\u80fd\u591f\u63d0\u5347\u4f4d\u59ff\u7cbe\u5ea6\u5e76\u514b\n\u670d\u5c40\u90e8\u906e\u6321\u95ee\u9898 \u3002\u5982\u56fe8(b)\u6240\u793a,\u4e00\u79cd\u76f4\u89c2\u7684\u7a20\u5bc6\u70b9\n\u7279\u5f81\u8868\u793a\u662f\u5c06\u6bcf\u4e2a\u56fe\u50cf\u50cf\u7d20\u5904\u7684\u4e09\u7ef4\u5750\u6807\u5f53\u4f5c\u4e09\u4e2a\u989c\n\u8272\u901a\u9053\u503c ,\u7531\u6b64\u83b7\u5f97\u7528\u4e09\u7ef4\u5f20\u91cf\u8868\u793a\u7a20\u5bc6\u70b9\u7279\u5f81[23]\u3002\n\u53e6\u4e00\u79cd\u65b9\u6848\u662f\u501f\u9274\u8ba1\u7b97\u56fe\u5f62\u5b66\u4e2d\u7684 UV\u8d34\u56fe\u6280\u672f ,\u4e8b\n\u5148\u5236\u4f5c UV\u6620\u5c04,\u5c06\u5750\u6807\u4fe1\u606f\u5b58\u50a8\u5728\u8d34\u56fe\u4e2d ,\u800c\u795e\u7ecf\u7f51\n\u7edc \u53ea \u9700 \u9884 \u6d4b UV\u8d34 \u56fe \u5750 \u6807 \u5373 \u53ef \u7d22 \u5f15 \u5230 \u539f \u59cb \u4e09 \u7ef4\n\u5750\u6807[24]\u3002\n\u65e0\u8bba\u662f\u4f7f\u7528\u7a00\u758f\u5173\u952e\u70b9\u8fd8\u662f\u7a20\u5bc6\u70b9\u7279\u5f81 ,\u6700\u7ec8\u5747\n\u9700\u8981\u501f\u52a9 PnP\u7b97\u6cd5,\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u70b9\u7279\u5f81 2D3D\u5339\u914d\u5173\u7cfb\u6c42\u89e3\u76ee\u6807\u4f4d\u59ff\u53c2\u6570 ,\u5176\u7f3a\u9677\u5728\u4e8e\u795e\u7ecf\u7f51\u7edc\n\u4ec5\u9488\u5bf9\u7279\u5f81\u63d0\u53d6\u548c\u5339\u914d\u8fdb\u884c\u4f18\u5316\u8bad\u7ec3 ,\u672a\u80fd\u5145\u5206\u53d1\u6325\n\u5176\u9488\u5bf9\u4f4d\u59ff\u6d4b\u91cf\u4efb\u52a1\u7684\u6f5c\u529b \u3002\u56e0\u6b64,\u6700\u65b0\u53d1\u5c55\u7684\u70b9\u7279\n\u5f81\u5f15\u5bfc\u7684\u76f4\u63a5\u56de\u5f52\u65b9\u6cd5\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 PnP\u7b97\n\u6cd5[25],\u968f\u540e\u4e0e\u70b9\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u4e00\u5e76\u53c2\u4e0e\u7aef\u5230\u7aef\u4f18\u5316\u8bad\n\u7ec3[26],\u5e76\u7ecf\u5b9e\u9a8c\u8bc1\u660e\u76f8\u6bd4\u4e8e PnP\u7b97\u6cd5\u80fd\u591f\u5f97\u5230\u66f4\u7cbe\u786e\n\u7684\u4f4d\u7f6e\u7ed3\u679c[23]\u3002\u5982\u56fe8(c)\u6240\u793a,\u76f8\u6bd4\u4e8e\u4e00\u822c\u7684\u76f4\u63a5\u56de\n\u5f52\u65b9\u6cd5,\u5229\u7528\u70b9\u7279\u5f81\u5f15\u5bfc\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4f4d\u59ff\u56de\u5f52\u4efb\u52a1 ,\n\u80fd\u591f\u8f85\u52a9\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u900f\u89c6\u6295\u5f71\u7ea6\u675f ,\u63d0\u5347\u8bad\u7ec3\u7684\u6536\n\u655b\u901f\u5ea6\u548c\u7f51\u7edc\u9884\u6d4b\u7cbe\u5ea6[27]\u3002\n\u88681\u6bd4\u5bf9\u4e86\u51e0\u79cd\u4e0d\u540c\u7684\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u4f4d\u59ff\u89c6\u89c9\u6d4b\n\u91cf\u65b9\u6cd5\u7684\u7cbe\u5ea6 \u3001\u901f\u5ea6\u3001\u9002\u7528\u6027\u3002\u5c3d\u7ba1\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u7ecf\u5178\n\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u5728\u8fd1\u5e74\u6765\u7684\u7814\u7a76\u4e2d\u5f97\u5230\u4e86\u957f\u8db3\u7684\u53d1\n\u5c55,\u4f46\u662f\u5176\u7279\u5f81\u70b9\u9009\u53d6\u56f0\u96be \u3001\u8ba1\u7b97\u91cf\u8f83\u5927\u4ee5\u53ca\u5728\u590d\u6742\u73af\n\u5883\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898 ,\u4ecd\u7136\u6ca1\u6709\u5f97\u5230\u89e3\u51b3 \u3002\u800c\u968f\u7740\n\u56fe5 \u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u7ecf\u5178\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53d1\u5c55 \u8fc7\u7a0b Fig.",
            "2": "2 \u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\n\u56fe7\u7ed9\u51fa\u4e86\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\n\u65b9\u6cd5\u7684\u53d1\u5c55\u8fc7\u7a0b \u3002\u8fd9\u7c7b\u65b9\u6cd5\u662f\u901a\u8fc7\u5927\u91cf\u6837\u672c\u8bad\u7ec3\u6df1\u5ea6\n\u795e\u7ecf\u7f51\u7edc ,\u4f7f\u5176\u4e60\u5f97\u70b9\u7279\u5f81\u63d0\u53d6 \u3001\u5339\u914d\u548c\u4f4d\u59ff\u89e3\u7b97\u7684\u65b9\n\u6cd5\u3002\u76f8\u6bd4\u57fa\u4e8e\u7ecf\u5178\u7406\u8bba\u6a21\u578b\u7684\u65b9\u6cd5 ,\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\u89c6\n\u89c9\u6d4b\u91cf\u65b9\u6cd5\u6781\u5927\u63d0\u5347\u4e86\u9c81\u68d2\u6027 ,\u5728\u5e94\u5bf9\u906e\u6321 \u3001\u80cc\u666f\u5e72\u6270\n\u7b49\u590d\u6742\u60c5\u51b5\u65f6\u6027\u80fd\u7a81\u51fa \u3002\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u6df1\u5ea6\u5b66\u4e60\u4f4d\u59ff\n\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53ef\u4ee5\u8fdb\u4e00\u6b65\u5206\u4e3a\u4f7f\u7528\u7a00\u758f\u5173\u952e\u70b9\u548c\u7a20\u5bc6\n\u70b9\u7279\u5f81\u7684 PnP\u8ba1\u7b97\u65b9\u6cd5 ,\u4ee5\u53ca\u57fa\u4e8e\u70b9\u7279\u5f81\u7ea6\u675f\u7684\u76f4\u63a5\u56de\u5f52\u65b9\u6cd5 \u3002\n\u7a00\u758f\u5173\u952e\u70b9\u662f\u4e8b\u5148\u6311\u9009\u548c\u89c4\u5b9a\u76ee\u6807\u4e09\u7ef4 CAD\u6a21\n\u578b\u4e0a\u7684\u663e\u8457\u70b9\u7279\u5f81 ,\u968f\u540e\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u4ece\u56fe\u50cf\u4e2d\u68c0\u6d4b \u3001\n\u63d0\u53d6\u8fd9\u4e9b\u70b9\u7279\u5f81 ,\u5373\u5229\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u5b8c\u6210\u5173\u952e\n\u70b9\u7279\u5f81\u63d0\u53d6\u548c 2D-3D\u5339\u914d\u8fc7\u7a0b \u3002\u8fd9\u7c7b\u65b9\u6cd5\u7684\u5173\u952e\u5728\n\u4e8e\u70b9\u7279\u5f81\u7684\u9009\u53d6\u548c\u8868\u793a \u3002\u4f8b\u5982 Rad\u7b49[18]\u63d0\u51fa\u7684 BB8\u7b49\n\u65b9\u6cd5\u4f7f\u7528\u76ee\u6807\u6a21\u578b\u4e09\u7ef4\u68c0\u6d4b\u6846\u7684 8\u4e2a\u89d2\u70b9,\u7136\u800c\u8fd9\u4e9b\n\u89d2\u70b9\u53ef\u80fd\u504f\u79bb\u76ee\u6807\u533a\u57df ,\u56e0\u6b64\u6d4b\u91cf\u7cbe\u5ea6\u6709\u9650 \u3002\u53e6\u4e00\u79cd\n\u5173\u952e\u70b9\u9009\u53d6\u601d\u8def\u662f\u4f7f\u7528\u8d2a\u5a6a\u7b56\u7565 ,\u5728\u76ee\u6807\u4e09\u7ef4\u6a21\u578b\u4e0a\n\u4f9d\u6b21\u9009\u53d6\u76f8\u4e92\u95f4\u8ddd\u79bb\u6700\u5927\u7684\u70b9[19],\u76ee\u524d\u5c1a\u65e0\u7406\u8bba\u8bc1\u660e\n\u88ab\u9009\u53d6\u5173\u952e\u70b9\u7684\u6700\u4f18\u6027 \u3002\u7a00\u758f\u5173\u952e\u70b9\u53ef\u4ee5\u8868\u793a\u4e3a\u539f\u59cb\n\u5750\u6807\u5f62\u5f0f[20],\u4e5f\u53ef\u4ee5\u901a\u8fc7\u70ed\u5ea6\u56fe[21]\u8868\u793a,\u6216\u8005\u7528\u5982\n\u56fe8(a)\u6240\u793a\u7684\u4e8c\u7ef4\u77e2\u91cf\u573a[22]\u8868\u793a\u3002\u7531\u4e8e\u540e\u4e24\u8005\u66f4\u63a5\n\u8fd1\u5377\u79ef\u7f51\u7edc\u5584\u4e8e\u5904\u7406\u7684\u5f20\u91cf\u5f62\u5f0f\u5f80\u5f80\u63d0\u53d6\u7cbe\u5ea6\u66f4\u9ad8 \u3002\n\u7a20\u5bc6\u70b9\u7279\u5f81\u662f\u6307\u6bcf\u4e2a\u56fe\u50cf\u50cf\u7d20\u4f4d\u7f6e\u5747\u5bf9\u5e94\u4e00\u4e2a\u76ee\n\u6807\u4e09\u7ef4\u70b9 ,\u5f62\u6210\u4e00\u79cd\u9010\u50cf\u7d20\u7a20\u5bc6\u7684 2D-3D\u5339\u914d\u5173\u7cfb ,\n\u8fd9\u7c7b\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027 ,\u80fd\u591f\u63d0\u5347\u4f4d\u59ff\u7cbe\u5ea6\u5e76\u514b\n\u670d\u5c40\u90e8\u906e\u6321\u95ee\u9898 \u3002\u5982\u56fe8(b)\u6240\u793a,\u4e00\u79cd\u76f4\u89c2\u7684\u7a20\u5bc6\u70b9\n\u7279\u5f81\u8868\u793a\u662f\u5c06\u6bcf\u4e2a\u56fe\u50cf\u50cf\u7d20\u5904\u7684\u4e09\u7ef4\u5750\u6807\u5f53\u4f5c\u4e09\u4e2a\u989c\n\u8272\u901a\u9053\u503c ,\u7531\u6b64\u83b7\u5f97\u7528\u4e09\u7ef4\u5f20\u91cf\u8868\u793a\u7a20\u5bc6\u70b9\u7279\u5f81[23]\u3002\n\u53e6\u4e00\u79cd\u65b9\u6848\u662f\u501f\u9274\u8ba1\u7b97\u56fe\u5f62\u5b66\u4e2d\u7684 UV\u8d34\u56fe\u6280\u672f ,\u4e8b\n\u5148\u5236\u4f5c UV\u6620\u5c04,\u5c06\u5750\u6807\u4fe1\u606f\u5b58\u50a8\u5728\u8d34\u56fe\u4e2d ,\u800c\u795e\u7ecf\u7f51\n\u7edc \u53ea \u9700 \u9884 \u6d4b UV\u8d34 \u56fe \u5750 \u6807 \u5373 \u53ef \u7d22 \u5f15 \u5230 \u539f \u59cb \u4e09 \u7ef4\n\u5750\u6807[24]\u3002\n\u65e0\u8bba\u662f\u4f7f\u7528\u7a00\u758f\u5173\u952e\u70b9\u8fd8\u662f\u7a20\u5bc6\u70b9\u7279\u5f81 ,\u6700\u7ec8\u5747\n\u9700\u8981\u501f\u52a9 PnP\u7b97\u6cd5,\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u7684\u70b9\u7279\u5f81 2D3D\u5339\u914d\u5173\u7cfb\u6c42\u89e3\u76ee\u6807\u4f4d\u59ff\u53c2\u6570 ,\u5176\u7f3a\u9677\u5728\u4e8e\u795e\u7ecf\u7f51\u7edc\n\u4ec5\u9488\u5bf9\u7279\u5f81\u63d0\u53d6\u548c\u5339\u914d\u8fdb\u884c\u4f18\u5316\u8bad\u7ec3 ,\u672a\u80fd\u5145\u5206\u53d1\u6325\n\u5176\u9488\u5bf9\u4f4d\u59ff\u6d4b\u91cf\u4efb\u52a1\u7684\u6f5c\u529b \u3002\u56e0\u6b64,\u6700\u65b0\u53d1\u5c55\u7684\u70b9\u7279\n\u5f81\u5f15\u5bfc\u7684\u76f4\u63a5\u56de\u5f52\u65b9\u6cd5\u5229\u7528\u795e\u7ecf\u7f51\u7edc\u66ff\u4ee3 PnP\u7b97\n\u6cd5[25],\u968f\u540e\u4e0e\u70b9\u7279\u5f81\u63d0\u53d6\u6a21\u5757\u4e00\u5e76\u53c2\u4e0e\u7aef\u5230\u7aef\u4f18\u5316\u8bad\n\u7ec3[26],\u5e76\u7ecf\u5b9e\u9a8c\u8bc1\u660e\u76f8\u6bd4\u4e8e PnP\u7b97\u6cd5\u80fd\u591f\u5f97\u5230\u66f4\u7cbe\u786e\n\u7684\u4f4d\u7f6e\u7ed3\u679c[23]\u3002\u5982\u56fe8(c)\u6240\u793a,\u76f8\u6bd4\u4e8e\u4e00\u822c\u7684\u76f4\u63a5\u56de\n\u5f52\u65b9\u6cd5,\u5229\u7528\u70b9\u7279\u5f81\u5f15\u5bfc\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4f4d\u59ff\u56de\u5f52\u4efb\u52a1 ,\n\u80fd\u591f\u8f85\u52a9\u795e\u7ecf\u7f51\u7edc\u7406\u89e3\u900f\u89c6\u6295\u5f71\u7ea6\u675f ,\u63d0\u5347\u8bad\u7ec3\u7684\u6536\n\u655b\u901f\u5ea6\u548c\u7f51\u7edc\u9884\u6d4b\u7cbe\u5ea6[27]\u3002\n\u88681\u6bd4\u5bf9\u4e86\u51e0\u79cd\u4e0d\u540c\u7684\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u4f4d\u59ff\u89c6\u89c9\u6d4b\n\u91cf\u65b9\u6cd5\u7684\u7cbe\u5ea6 \u3001\u901f\u5ea6\u3001\u9002\u7528\u6027\u3002\u5c3d\u7ba1\u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u7ecf\u5178\n\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u5728\u8fd1\u5e74\u6765\u7684\u7814\u7a76\u4e2d\u5f97\u5230\u4e86\u957f\u8db3\u7684\u53d1\n\u5c55,\u4f46\u662f\u5176\u7279\u5f81\u70b9\u9009\u53d6\u56f0\u96be \u3001\u8ba1\u7b97\u91cf\u8f83\u5927\u4ee5\u53ca\u5728\u590d\u6742\u73af\n\u5883\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898 ,\u4ecd\u7136\u6ca1\u6709\u5f97\u5230\u89e3\u51b3 \u3002\u800c\u968f\u7740\n\u56fe5 \u57fa\u4e8e\u70b9\u7279\u5f81\u7684\u7ecf\u5178\u4f4d\u59ff\u89c6\u89c9\u6d4b\u91cf\u65b9\u6cd5\u53d1\u5c55 \u8fc7\u7a0b Fig.",
            "3": "A J combined corner and edge detector [C]\u2225Proceedings of the Alvey Vision Conference \n1988 , August 31-September 2, 1988 , Manchester , UK .",
            "4": "Adaptive tracking and model registration across distinct aspects [C]\u2225Proceedings \n1995 IEEE/RSJ International Conference on Intelligent Robots and Systems , August 5-9, 1995 , Pittsburgh , PA, USA .",
            "5": "ORB : an efficient alternative to SIFT or SURF [C]\u22252011 International Conference on Computer Vision , November 613, 2011 , Barcelona , Spain .",
            "6": "Analysis and solutions of the three point perspective pose estimation problem [C]\u2225Proceedings of 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition , June 3-6, 1991 , Maui , HI, USA .",
            "7": "Revisiting the P nP problem : a fast , general and optimal solution [C]\u22252013 IEEE International Conference on Computer Vision , December 1-8, 2013 , Sydney , NSW , Australia .",
            "8": "BB8: a scalable , accurate , robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "9": "[19]Pavlakos G , Zhou X W , Chan A , et al .",
            "10": "6-DoF object pose from semantic keypoints [C]\u22252017 IEEE International Conference on Robotics and Automation (ICRA ), May \n29-June 3, 2017 , Singapore .",
            "11": "Real -time seamless single shot 6D object pose prediction [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "12": "PVNet : pixel -wise voting network for 6DoF pose estimation [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "13": "CDPN : coordinates -based disentangled pose network for real -time RGB -based 6DoF object pose estimation [C]\u22252019 IEEE/CVF International Conference on Computer Vision (ICCV ), October 27-November 2, 2019 , Seoul , Republic of Korea .",
            "14": "DPOD : 6D pose object detector and refiner [C]\u22252019 IEEE/CVF International Conference on Computer Vision (ICCV ), October 27November 2, 2019 , Seoul , Republic of Korea .",
            "15": "Single -stage 6D object pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "16": "EPro -PnP : generalized end -to-end probabilistic perspective -n-points for monocular object pose estimation [C]\u22252022 IEEE/ CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 18-24, 2022 , New Orleans , LA, USA .",
            "17": "GDR -net: geometry -guided direct regression network for monocular \n6D object pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "18": "Learning attraction field representation for robust line segment detection [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "19": "Simultaneous pose and correspondence determination using line features [C]\u22252003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition , June 18-20, 2003 , Madison , WI , USA .",
            "20": "Globally optimal pose estimation from line correspondences [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "21": "RAPID -a video rate object tracker [C]\u2225Proceedings of the British Machine Vision Conference , September , 1990 , Oxford .",
            "22": "Combining edge and texture information for real -time accurate 3D camera tracking [C]\u2225Third IEEE and ACM International Symposium on Mixed and Augmented Reality , November 5, 2004 , Arlington , VA , USA .",
            "23": "Using multiple hypothesis in model -based tracking [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "24": "EPOS : estimating 6D pose of objects with symmetries [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "25": "StablePose : learning \n6D object poses from geometrically stable patches [C]\u2225\n2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "26": "Real -time monocular pose estimation of 3D objects using temporally consistent local color histograms [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "27": "Real -time 3D model -based tracking using edge and keypoint features for robotic manipulation [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "28": "Globally optimal pose estimation from line correspondences [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "29": "RAPID -a video rate object tracker [C]\u2225Proceedings of the British Machine Vision Conference , September , 1990 , Oxford .",
            "30": "Combining edge and texture information for real -time accurate 3D camera tracking [C]\u2225Third IEEE and ACM International Symposium on Mixed and Augmented Reality , November 5, 2004 , Arlington , VA , USA .",
            "31": "Using multiple hypothesis in model -based tracking [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "32": "EPOS : estimating 6D pose of objects with symmetries [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "33": "StablePose : learning \n6D object poses from geometrically stable patches [C]\u2225\n2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "34": "Real -time monocular pose estimation of 3D objects using temporally consistent local color histograms [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "35": "Real -time 3D model -based tracking using edge and keypoint features for robotic manipulation [C]\u22252010 IEEE International Conference on Robotics and Automation , May 3-7, 2010 , Anchorage , AK , USA .",
            "36": "Robust 3D visual tracking using particle filtering on the SE (3) group [C]\u22252011 IEEE International Conference on Robotics and Automation , May 9-13, 2011 , Shanghai , China .",
            "37": "Real -time model based rigid object pose estimation and tracking combining dense and sparse visual cues [C]\u22252013 IEEE Conference on Computer Vision and Pattern Recognition , June 2328, 2013 , Portland , OR , USA .",
            "38": "Segmentation -driven \n6D object pose estimation [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 15-20, 2019 , Long Beach , CA , USA .",
            "39": "HybridPose : 6D object pose estimation under hybrid representations [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "40": "KeyPose : multi -view 3D labeling and keypoint estimation for transparent objects [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "41": "Stereo R -CNN based 3D object detection for autonomous driving [C]\u22252019 IEEE/ CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "42": "End -toend learning of geometry and context for deep stereo regression [C]\u22252017 IEEE International Conference on Computer Vision (ICCV ), October 22-29, 2017 , Venice , Italy .",
            "43": "Persistent point feature histograms for 3D point clouds [C]\u222510th International Conference on Intel Autonomous System \n(IAS -10), July 24, 2008 , Baden -Baden , Germany .",
            "44": "Fast point feature histograms (FPFH ) for 3D registration [C]\u22252009 IEEE International Conference on Robotics and Automation , May 12-17, 2009 , Kobe , Japan .",
            "45": "0: LiDAR -inertial -camera odometry with sliding -window plane -feature tracking [C]\u22252020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS ), October 24-January 24, 2021 , Las Vegas , NV , USA .",
            "46": "Improvement of shipboard landing performance of shipborne UAV using multi -sensor fusion [C]\u2225Proceedings of 2019 International Conference on Computer Science , Communications and Big Data , March 24-25, 2019 , Beijing , China .",
            "47": "FFB 6D: a full flow bidirectional fusion network for 6D pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "48": "PVN 3D: a deep point -wise 3D keypoints voting network for 6DoF pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "49": "DenseFusion : 6D object pose estimation by iterative dense fusion [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "50": "Trinocular ground system to control UAVs [C]\u22252009 IEEE/RSJ International Conference on Intelligent Robots and Systems , October 10-15, 2009 , St.",
            "51": "Autoland project : fixed -wing UAV landing on a fast patrol boat using computer vision [C]\u2225OCEANS 2015 -Seattle , October \n27-31, 2019 , Seattle , WA , USA .",
            "52": "Unmanned aerial vehicle tracking using a particle filter based approach [C]\u2225\n2019 IEEE Underwater Technology (UT), April 16-19, \n2019 , Kaohsiung , Taiwan , China .",
            "53": "STS -128 on -orbit demonstration of the TriDAR targetless rendezvous and docking sensor [C]\u2225\n2010 IEEE Aerospace Conference , March 6-13, 2010 , Big Sky , MT , USA .",
            "54": "Improvement of shipboard landing performance of shipborne UAV using multi -sensor fusion [C]\u2225Proceedings of 2019 International Conference on Computer Science , Communications and Big Data , March 24-25, 2019 , Beijing , China .",
            "55": "FFB 6D: a full flow bidirectional fusion network for 6D pose estimation [C]\u22252021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 20-25, 2021 , Nashville , TN , USA .",
            "56": "PVN 3D: a deep point -wise 3D keypoints voting network for 6DoF pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June \n13-19, 2020 , Seattle , WA , USA .",
            "57": "DenseFusion : 6D object pose estimation by iterative dense fusion [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 15-20, 2019 , Long Beach , CA, USA .",
            "58": "Trinocular ground system to control UAVs [C]\u22252009 IEEE/RSJ International Conference on Intelligent Robots and Systems , October 10-15, 2009 , St.",
            "59": "Autoland project : fixed -wing UAV landing on a fast patrol boat using computer vision [C]\u2225OCEANS 2015 -Seattle , October \n27-31, 2019 , Seattle , WA , USA .",
            "60": "Unmanned aerial vehicle tracking using a particle filter based approach [C]\u2225\n2019 IEEE Underwater Technology (UT), April 16-19, \n2019 , Kaohsiung , Taiwan , China .",
            "61": "STS -128 on -orbit demonstration of the TriDAR targetless rendezvous and docking sensor [C]\u2225\n2010 IEEE Aerospace Conference , March 6-13, 2010 , Big Sky , MT , USA .",
            "62": "Randomized trees for human pose detection [C]\u22252008 IEEE Conference on Computer Vision and Pattern Recognition , June 23-28, 2008 , Anchorage , AK , USA .",
            "63": "DeepPose : human pose estimation via deep neural networks [C]\u22252014 IEEE Conference on Computer Vision and Pattern Recognition , June 23-28, 2014 , Columbus , OH , USA .",
            "64": "Convolutional pose machines [C]\u22252016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR ), June 27-30, 2016 , Las Vegas , NV , USA .",
            "65": "Cascaded pyramid network for multi -person pose estimation [C]\u2225\n2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT, USA .",
            "66": "HigherHRNet : scale -aware representation learning for bottom -up human pose estimation [C]\u22252020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "67": "Coarse -tofine volumetric prediction for single -image 3D human pose [C]\u22252017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR ), July 21-26, 2017 , Honolulu , HI, USA .",
            "68": "Recognizing human actions as the evolution of pose estimation maps [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "69": "2D/3D pose estimation and action recognition using multitask deep learning [C]\u22252018 IEEE/CVF Conference on Computer Vision and Pattern Recognition , June 18-23, 2018 , Salt Lake City , UT , USA .",
            "70": "PA3D: pose -action 3D machine for video recognition [C]\u22252019 IEEE/CVF Conference on Computer Vision and Pattern Recognition \n(CVPR ), June 15-20, 2019 , Long Beach , CA , USA .",
            "71": "Combining detection and tracking for human pose estimation in videos [C]\u2225\n2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR ), June 13-19, 2020 , Seattle , WA , USA .",
            "72": "Clustered pose and nonlinear appearance models for human pose estimation [C]\u2225 Proceedings of the British Machine Vision Conference \n2010 , August 31-September 3, Aberystwyth .",
            "73": "Human 3D pose estimation in a lying position by RGB -D images for medical diagnosis and rehabilitation [C]\u22252020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society , July 20-24, \n2020 , Montreal , Canada .",
            "74": "In -bed human pose estimation from unseen and privacy -preserving image domains [C]\u22252022 IEEE 19th International Symposium on Biomedical Imaging (ISBI ), March 2831, 2022 , Kolkata , India .",
            "75": "Human 3D pose estimation in a lying position by RGB -D images for medical diagnosis and rehabilitation [C]\u22252020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society , July 20-24, \n2020 , Montreal , Canada .",
            "76": "In -bed human pose estimation from unseen and privacy -preserving image domains [C]\u22252022 IEEE 19th International Symposium on Biomedical Imaging (ISBI ), March 2831, 2022 , Kolkata , India ."
        },
        "\u57fa\u4e8e\u89c6\u89c9\u7684\u975e\u5408\u4f5c\u7a7a\u95f4\u76ee\u6807\u4e09\u7ef4\u59ff\u6001\u4f30\u8ba1\u65b9\u6cd5": {
            "authors": [],
            "url": "https://jeit.ac.cn/article/exportPdf?id=b145724a-a4a0-4311-bbf3-3e1a7d9db0a4"
        },
        "Technical report: reactive navigation in partially known non-convex environments": {
            "authors": [
                "Daniel E. Koditschek"
            ],
            "url": "https://arxiv.org/pdf/1807.08432",
            "ref_texts": "25. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF object pose from semantic keypoints. In: IEEE International Conference on Robotics and Automation. pp. 2011{2018 (May 2017)",
            "ref_ids": [
                "25"
            ],
            "1": "Recent developments in semantic SLAM [9] and object pose and triangular mesh extraction using convolutional neural net architectures [17,19,25] now provide an avenue for incorporating partial prior knowledge within a deterministic framework well suited to the vector ffeld planning methods reviewed above.",
            "2": "Since recently developed technology [17, 19, 25] provides means of performing obstacle identiffcation in the form of triangular meshes, in this work we focus on polygonal obstacles on the plane and derive implicit representations using so called \\R-functions\" from the constructive solid geometry literature [32].",
            "3": "Experimental validation of our algorithm with deep learning techniques for object pose and triangular mesh recognition [25] is currently underway.",
            "4": "We believe that this modular representation of shape will be helpful in the efiort now in progress to instantiate the posited mapping oracle for obstacles with known geometry, whose triangular mesh can be identiffed in real time using state-ofthe-art techniques [17,19,25] in order to extract implicit function representations for polygonal obstacles."
        },
        "Robotic object pose estimation with deep neural networks": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/119699/1078151125-MIT.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[39] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "39"
            ],
            "1": "Feature-based methods match features in images with corresponding parts of 3D models [35, 10, 45, 39], but these matches are done on 2D images."
        },
        "MixedFusion: 6D Object Pose Estimation from Decoupled RGB-Depth Features": {
            "authors": [],
            "url": "https://ailb-web.ing.unimore.it/icpr/media/posters/10918.pdf"
        },
        "Investigating Use of Keypoints for Object Pose Recognition": {
            "authors": [],
            "url": "https://openjournals.uwaterloo.ca/index.php/vsl/article/download/5382/5670",
            "ref_texts": "[17] M. Robson and M. Sridharan, \u201cA keypoint-based object representation for generating task-specific grasps,\u201d in 2022 IEEE International Conference on Automation Science and Engineering, 2022.[18] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "17",
                "18"
            ],
            "1": "These keypoints may be defined as the corners of the 3D object bounding box (as seen in [10, 11]) or a set of points defined relative to the object surface [12\u201318].",
            "2": "This issue has also been pointed out by [18].",
            "3": "[17] M.",
            "4": "[18] G."
        },
        "HandyPose and VehiPose: Pose Estimation of Flexible and Rigid Objects": {
            "authors": [
                "Divyansh Gupta"
            ],
            "url": "https://scholarworks.rit.edu/cgi/viewcontent.cgi?article=12155&context=theses",
            "ref_texts": "[80] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DoF object pose from semantic keypoints,\u201d in IEEE International Conference on Robotics and Automation (ICRA) , 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "80"
            ],
            "1": "[78], [79], and [80].",
            "2": "[80] G."
        },
        "DYNAMIC CONVOLUTIONAL NETWORKS FOR 3-DIMENSIONAL RECONSTRUCTION": {
            "authors": [],
            "url": "http://47.89.192.52/pdf/Technical-Paper-DynamicCNN_Final.pdf",
            "ref_texts": "[7]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA , 2017.",
            "ref_ids": [
                "7"
            ],
            "1": "(1) Some approaches can predict the orientation of the shape [4,5], and others can construct a 3D pose model based on the existing shape [6,7,8]; (2) Other methods predict 3D shapes based on point clouds [9,10], patches [11,12], or geometric primitives [13,14,15]; (3) Others use CNNs to learn distance functions [16]."
        },
        "Task-driven Perception and Manipulation for Constrained Placement with No Shape Priors": {
            "authors": [
                "Kostas E"
            ],
            "url": "http://rl.cs.rutgers.edu/publications/ChaitanyaRAL2020.pdf",
            "ref_texts": "[16] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints,\u201d in ICRA , 2017.",
            "ref_ids": [
                "16"
            ],
            "1": "There has been recent progress in categorylevel pose estimation [13], [14], [15], [16], [17] but given large intra-class shape variation in certain scenarios, it is hard to capture the shape in a single category-level pose representation.",
            "2": "[16] G."
        },
        "Graph-Theoretic Outlier Rejection: From Instance to Category-Level Perception": {
            "authors": [],
            "url": "https://dspace.mit.edu/bitstream/handle/1721.1/139117/shi-jnshi-sm-AeroAstro-2021-thesis.pdf?sequence=1&isAllowed=y",
            "ref_texts": "[82] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In IEEE Intl. Conf. on Robotics and Automation (ICRA) , 2017.",
            "ref_ids": [
                "82"
            ],
            "1": "Similarly, domestic applications require estimating the location and shape of objects to support more effective interaction and manipulation [71, 40, 82].",
            "2": ",images, lidar scans) [118, 82].",
            "3": "In 3D-3D category-level perception, one is asked to recover both the 3D shape and pose of a target object from 3D keypoint detections [82, 40].",
            "4": "Such approaches first recover the position of semantic keypoints [82] in the images with neural networks, and then recover the 3D pose of the object by solving a geometric optimization problem [78, 82, 83, 96, 52].",
            "5": "[82]useastackedhourglassneuralnetwork[77]for 2D semantic keypoint detection, and then employ block coordinate descent to resolve the object pose.",
            "6": ",[82])."
        },
        "Efficient learning methods for robot grasping oriented pose estimation": {
            "authors": [],
            "url": "https://tsukuba.repo.nii.ac.jp/record/2002128/files/DA010090_abstract.pdf",
            "ref_texts": ""
        },
        "6 degrees of freedom pose estimation with differentiable rendering": {
            "authors": [],
            "url": "https://www.politesi.polimi.it/bitstream/10589/177514/3/2021_07_Roggerini_Simpsi.pdf",
            "ref_texts": "[21]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis, and Kostas Daniilidis. \u201c 6-DoF Object Pose from Semantic Keypoints.\u201d In: CoRR abs/1703 .04670 (2017 ). arXiv: 1703.04670 (cit. on p.14).",
            "ref_ids": [
                "21"
            ],
            "1": "(2017 ) [21] is different: they built a Fully Convolutional Neural Network to predict only the keypoints of the object and used the EPnP algorithm [1] on these points, joined with a deformable part CAD model."
        },
        "Liquids & robots: An investigation of techniques for robotic interaction with liquids": {
            "authors": [],
            "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/43352/Schenck_washington_0250E_19357.pdf?sequence=1",
            "ref_texts": "[115] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011{2018. IEEE, 2017.",
            "ref_ids": [
                "115"
            ],
            "1": "1) has been well-studied in the robotics and computer vision literature [84, 160, 20, 53, 59, 119, 147, 115, 158]."
        },
        "Fast and high-quality, GPU-based, deliberative, object-pose estimation": {
            "authors": [],
            "url": "https://scholar.archive.org/work/h3fer3io45hwnauhduvk43rh7e/access/wayback/https://fieldrobotics.net/Field_Robotics/Volume_1_files/2_Agarwal.pdf",
            "ref_texts": "7989357 Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G., & Daniilidis, K. (2017). 6-DOF object pose from semantic keypoints. 2017 IEEE International Conference on Robotics and Automation (ICRA) , 2011\u20132018. https://doi.org/10.1109/icra.2017.7989233 Qiu, D., May, S., & N\u00fcchter, A. (2009). GPU-accelerated nearest neighbor search for 3D registration. In M. Fritz, B. Schiele, & J. H. Piater (Eds.), Lecture Notes in Computer Science: Vol. 5815 .Computer Vision Systems. ICVS 2009 (pp. 194\u2013203). Springer. https://doi.org/10.1007/978-3-642-04667-4_20 Rad, M., & Lepetit, V. (2017). BB8: a scalable, accurate, robust to partial occlusion method for predicting the 3D poses of challenging objects without using depth. 2017 IEEE International Conference on Computer Vision (ICCV) , 3848\u20133856. https://doi.org/10.1109/iccv.2017.413 Rothganger, F., Lazebnik, S., Schmid, C., & Ponce, J. (2006). 3D object modeling and recognition using local affine-invariant image descriptors and multi-view spatial constraints. International Journal of Computer Vision,66(3), 231\u2013259. https://doi.org/10.1007/s11263-005-3674-1 Rusu, R. B., Blodow, N., & Beetz, M. (2009). Fast point feature histograms (FPFH) for 3D registration.2009 IEEE International Conference on Robotics and Automation (ICRA) , 3212\u20133217. https: //doi.org/10.1109/robot.2009.5152473 Rusu, R. B., Bradski, G., Thibaux, R., & Hsu, J. (2010). Fast 3D recognition and pose using the viewpoint feature histogram. 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , 2155\u20132162. https://doi.org/10.1109/iros.2010.5651280 Rusu, R. B., & Cousins, S. (2011). 3D is here: Point Cloud Library (PCL). 2011 IEEE International Conference on Robotics and Automation (ICRA) , 1\u20134. https://doi.org/10.1109/icra.2011.5980567 Saxena, D. M., Saleem, M. S., & Likhachev, M. (2021). Manipulation planning among movable obstacles using physics-based adaptive motion primitives, 6570\u20136576. https://doi.org/10.1109/icra48506.2021.9561221 Segal, A., H\u00e4hnel, D., & Thrun, S. (2009). Generalized-ICP. Robotics: science and systems ,2(4), 435. https://doi.org/10.15607/rss.2009.v.021 Shao, S., Zhao, Z., Li, B., Xiao, T., Yu, G., Zhang, X., & Sun, J. (2018). CrowdHuman: A benchmark for detecting human in a crowd . arXiv: 1805.00123 [cs.CV]. Sharma, G., Wu, W., & Dalal, E. N. (2005). The CIEDE2000 color-difference formula: Implementation notes, supplementary test data, and mathematical observations. Color Research & Application ,30(1), 21\u201330. https://doi.org/10.1002/col.20070 Field Robotics, November, 2021 \u00b71:34\u201369 Fast and high-quality, GPU-based, deliberative, object-pose estimation \u00b769 Stevens, M. R., & Beveridge, J. R. (2000a). The Springer International Series in Engineering and Computer Science: Vol. 589 .Integrating graphics and vision for object recognition . Springer. https://doi.org/10.1007/"
        },
        "Monocular End-to-End Vehicle Pose Estimation for Car Manufacturing": {
            "authors": [],
            "url": "https://opus.lib.uts.edu.au/bitstream/10453/148509/2/acra20_final_Nov20.pdf",
            "ref_texts": "[Pavlakos et al. , 2017 ]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011{2018. IEEE, 2017.",
            "ref_ids": [
                "Pavlakos et al\\. , 2017 "
            ]
        },
        "Zero-Shot Category-Level Object Pose Estimation: Supplementary Material": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990509-supp.pdf",
            "ref_texts": "33. Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-DoF Object Pose from Semantic Keypoints. ICRA (2017)",
            "ref_ids": [
                "33"
            ]
        },
        "Review on 6D Object Pose Estimation With the Focus on Indoor Scene Understanding. 2022\u037e 2 (4): 41": {
            "authors": [],
            "url": "https://www.oajaiml.com/uploads/archivepdf/24821141.pdf",
            "ref_texts": "[61] Pavlakos G, Zhou X, Chan A, Derpanis KG, Daniilidis K. 6-Dof Object Pose From Semantic Keypoints. In2017 IEEE international conference on robotics and automation (ICRA). 2017: 2011-2018.",
            "ref_ids": [
                "61"
            ],
            "1": "In Semantic keypoint [61] the keypoints are predicted using hourglass [62] network.",
            "2": "Although some techniques are trying to define a deformable shape priors [61] to address the unavailability of CAD models for all the instances, but still not performing well for all the categories, especially the ones with more appearance change within the category.",
            "3": "[61] Pavlakos G, Zhou X, Chan A, Derpanis KG, Daniilidis K."
        },
        "3D Object Detection and Depth Completion for Scene Perception": {
            "authors": [],
            "url": "https://dam-oclc.bac-lac.gc.ca/download?is_thesis=1&oclc_number=1335043843&id=9d2b8e5e-0393-4180-a238-fc304a67b0e8&fileName=Ku_Jason_%20_202003_MAS_thesis.pdf",
            "ref_texts": ""
        },
        "Car Pose in Context: Accurate Pose Estimation with Ground Plane Constraints": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1912.04363",
            "ref_texts": "[35] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u2013",
            "ref_ids": [
                "35"
            ],
            "1": "Motivated by the success of human keypoint localization, several methods [22, 33, 35] localize semantic keypoints with a stacked-hourglass [32] model.",
            "2": "Because the baseline methods [35, 35] require known camera intrinsics, in the following pose estimation evaluation experiments, the focal length is given as input.",
            "3": "[35] 0.",
            "4": "[35] is given in Section 4.",
            "5": "[35] method, we directly use the opensource code.",
            "6": "[35] 4.",
            "7": "[35] 0."
        },
        "Not Only Look But Observe: Variational Observation Model of Scene-Level 3D Multi-Object Understanding for Probabilistic SLAM": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1907.09760.pdf)[J",
            "ref_texts": "[32] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In Robotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "32"
            ],
            "1": "In addition, 3D bounding box regression has been carried out to obtain the object location and orientation [42, 46, 32, 28].",
            "2": "15\n[32] G."
        },
        "Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial Keypoint Voting (Supplementary Material)": {
            "authors": [],
            "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700331-supp.pdf",
            "ref_texts": "[S.16] Pavlakos, G., Zhou, X., Chan, A., Derpanis, K.G., Daniilidis, K.: 6-dof object pose from semantic keypoints. In: 2017 IEEE international conference on robotics and automation (ICRA). pp. 2011\u20132018. IEEE (2017)",
            "ref_ids": [
                "S\\.16"
            ]
        },
        "Unsupervised Part Discovery via Feature Alignment": {
            "authors": [],
            "url": "https://arxiv.org/pdf/2012.00313",
            "ref_texts": "[17] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE international conference on robotics and automation (ICRA) , pages 2011\u20132018. IEEE, 2017. 1",
            "ref_ids": [
                "17"
            ],
            "1": "As a result, part detectors have become of central importance for many visual understanding tasks, including viewpoint estimation [17], human pose estimation [3], action recognition [14], feature matching [13], image classification [30], and 3D reconstruction [9]."
        },
        "Fast 3D Pose Refinement with RGB Images": {
            "authors": [],
            "url": "https://arxiv.org/pdf/1911.07347",
            "ref_texts": "[10] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "10"
            ],
            "1": "This method, used by [17] and [10], is quite computationally demanding.",
            "2": "[10] G."
        },
        "Object pose estimation in monocular image using modified FDCM": {
            "authors": [],
            "url": "https://yadda.icm.edu.pl/baztech/element/bwmeta1.element.baztech-02b24250-3d7e-48bf-b48c-144c54fb793a/c/CS_1_2020_Dabbour.pdf",
            "ref_texts": "[26] Pavlakos G., Zhou X., Chan A., Derpanis K.G., Daniilidis K.: 6-DoF Object Pose from Semantic Keypoints. In: IEEE International Conference on Robotics and Automation (ICRA) , 2017. https://doi.org/10.1109/ICRA.2017.7989233.",
            "ref_ids": [
                "26"
            ],
            "1": "Object pose estimation in monocular image using modified FDCM 99 The feature-based methods used feature-matching techniques between the query image and 3D object features, which are called feature-based methods [1, 5, 20, 26, 40].",
            "2": "Object pose estimation in monocular image using modified FDCM 111\n[26] Pavlakos G."
        },
        "Probabilistic Online Learning of Appearance and Structure for Robotics": {
            "authors": [
                "Bhoram Lee"
            ],
            "url": "https://core.ac.uk/download/pdf/237601696.pdf",
            "ref_texts": "[139] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE International Conference on Robotics and Automation , 2017.",
            "ref_ids": [
                "139"
            ],
            "1": "[139], semantic keypoints are found using a CNN (\u2018stacked hourglass\u2019[129]) and the 3D pose is recovered by a optimization procedure for finding the best linear combination of basis models."
        },
        "Hybrid optical and magnetic manipulation of microrobots": {
            "authors": [],
            "url": "https://spiral.imperial.ac.uk/bitstream/10044/1/96764/1/Grammatikopoulou-M-2020-PhD-Thesis.pdf",
            "ref_texts": "[50] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \\6dof object pose from semantic keypoints,\" in 2017 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "50"
            ],
            "1": "Other approaches include combination of feature extraction using CNNs combined with inference models to estimate ob21 ject pose [50].",
            "2": "[50] G."
        },
        "Structured Deep Visual Dynamics Models for Robot Manipulation": {
            "authors": [],
            "url": "https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/44768/Byravan_washington_0250E_20761.pdf?sequence=1",
            "ref_texts": "[122]Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic keypoints. In ICRA, pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "122"
            ],
            "1": "Pose estimation: There has also been a lot of recent work on object and camera pose estimation from RGB/D data using learning methods [122,86,20] including approaches that use structured deep networks [171]."
        },
        "Applied Deep Learning in Orthopaedics": {
            "authors": [
                "William Stewart",
                "Burton I"
            ],
            "url": "https://digitalcommons.du.edu/cgi/viewcontent.cgi?article=2568&context=etd",
            "ref_texts": " Pavlakos, G., Zhou, X., Chan, A., D erpanis, K. G., Daniilidis, K. (2017). 6 -DoF object pose from semantic keypoints. IEEE International Conference on Robotics and Automation . 2011 -2018 . "
        },
        "MONOCULAR RECONSTRUCTION OF DYNAMIC VEHICLES ON ARBITRARY ROAD PROFILES FROM A MOVING CAMERA": {
            "authors": [],
            "url": "https://junaidcs032.github.io/data/MyThesis_compressed.pdf",
            "ref_texts": "[34] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. In 2017 IEEE International Conference on Robotics and Automation (ICRA) , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "34"
            ],
            "1": "[30, 31, 34, 19, 4, 53] use shape priors to estimate the shape and pose of the object.",
            "2": "[34] proposes an approach that is agnostic to texture of the object image.",
            "3": "Shape priors have been widely used in many works [30, 31, 34, 19, 4, 53] to tackle the ill-posedness of the problem.",
            "4": "[34] G."
        },
        "Deep object 6-DoF pose estimation using instance segmentation": {
            "authors": [],
            "url": "https://alife-robotics.co.jp/members2020/icarob/data/html/data/OS/OS24/OS24-1.pdf",
            "ref_texts": "2.Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G. Derpanis & Kostas Daniilidis, 6-DoF Object Pose from Semantic Key points, IEEE ICRA, 2017. ",
            "ref_ids": [
                "2"
            ]
        },
        "PARTS-BASED 3D OBJECT POSE ESTIMATION": {
            "authors": [],
            "url": "https://zhengyiluo.github.io/assets/pdf/PARTS_BASED_3D_OBJECT_POSE_ESTIMATION.pdf",
            "ref_texts": "52 G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DoF object pose from semantic keypoints. Proceedings IEEE International Conference on Robotics and Automation , pages 2011{2018, 2017. ISSN 10504729. doi: 10.1109/ ICRA.2017.7989233. M. Pilu and R. B. Fisher. Equal-distance sampling of superellipse models. pages 257{266, 1995. C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classiffcation and segmentation. Proceedings 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017 , 2017-Janua:77{85, 2017. doi: 10.1109/CVPR.2017.16. S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. IEEE Transactions on Pattern Analysis and Machine Intelligence , 39(6):1137{1149, 2017. ISSN 01628828. doi: 10.1109/ TPAMI.2016.2577031. ShapeNet. Shapenet dataset. URL https://www.shapenet.org/ . H. Su, C. R. Qi, Y. Li, and L. J. Guibas. Render for CNN: Viewpoint estimation in images using CNNs trained with rendered 3D model views. Proceedings of the IEEE International Conference on Computer Vision , 2015 Inter(Sec 2):2686{2694, 2015. ISSN 15505499. doi: 10.1109/ICCV.2015.308. M. Sundermeyer, Z. C. Marton, M. Durner, M. Brucker, and R. Triebel. Implicit 3D orientation learning for 6D object detection from RGB images. Lecture Notes in Computer Science (including subseries Lecture Notes in Artiffcial Intelligence and Lecture Notes in Bioinformatics) , 11210 LNCS(2010):712{729, 2018. ISSN"
        },
        "6D Object Pose Estimation With Color/Geometry Attention Fusion": {
            "authors": [],
            "url": "https://webspace.science.uu.nl/~veltk101/publications/art/icarv2020.pdf",
            "ref_texts": "[10] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6dof object pose from semantic keypoints,\u201d in 2017 IEEE international conference on robotics and automation (ICRA) . IEEE, 2017, pp.",
            "ref_ids": [
                "10"
            ],
            "1": "Based on these correspondences, 6D poses are estimated by solving PnP problems [9], [10].",
            "2": "[10] G."
        },
        "Reactive Mobile Manipulation with Legged Robots": {
            "authors": [],
            "url": "https://www.vassilisvasilopoulos.com/pdf/rss-pioneers-2020.pdf",
            "ref_texts": "[31] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-DoF object pose from semantic keypoints. In IEEE International Conference on Robotics and Automation , pages 2011\u20132018, 2017.",
            "ref_ids": [
                "31"
            ],
            "1": ", through legged state estimation methods [17]), and to possess a LIDAR for local obstacle avoidance and a camera for familiar object/obstacle recognition, using either deep learning perception schemes [31] or conventional methods like AprilTags [53].",
            "2": "At the same time, this research also exploits recent developments in semantic SLAM [11] and object pose and triangular mesh extraction using convolutional neural net architectures [31, 22, 24] to provide an avenue for incorporating partial prior knowledge within a deterministic framework well suited to existing vector field planning methods [4].",
            "3": "[31] G."
        },
        "Enhancing Accuracy and Scalability of Perception Via Search Using RGB Data": {
            "authors": [],
            "url": "https://adityaagarwal.in/publications/files/icra_20.pdf",
            "ref_texts": "[11] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-DOF object pose from semantic keypoints,\u201d in 2017 IEEE International Conference on Robotics and Automation (ICRA) . IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "11"
            ],
            "1": "Others localize object keypoints in image space [10], [11], [14], [16], [18], [19], [23] which often results in ambiguities for objects with symmetries or requires explicit handling of symmetries.",
            "2": "[11] G."
        },
        "Few-Shot Viewpoint Estimation": {
            "authors": [],
            "url": "https://openreview.net/pdf?id=S4g6NkXR9f",
            "ref_texts": "[20] Georgios Pavlakos, Xiaowei Zhou, Aaron Chan, Konstantinos G Derpanis, and Kostas Daniilidis. 6-dof object pose from semantic key-points. In ICRA , 2017.",
            "ref_ids": [
                "20"
            ],
            "1": "With convolutional neural networks (CNNs) and the availability of many labeled examples [3, 41, 42], much progress has been made in estimating the viewpoint of known categories of objects [5, 15, 20].",
            "2": "They use different network architectures, including those that estimate angular values directly [10, 15, 30, 36, 40]; encode images in latent spaces to match them against a dictionary of ground truth viewpoints [14, 31]; or detect projections of 3D bounding boxes [5, 21, 33, 34] or of semantic keypoints [20, 43], which along with known [20] or estimated [5, 43] 3D object structures are used to compute viewpoint."
        },
        "Image processing method and apparatus, and storage medium": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/06/09/a5/d9b5c79bb1b421/US11450080.pdf"
        },
        "Learning disentangled invariant representations for one shot instance recognition": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/eb/4e/76/8f57b91f84cf81/US11080886.pdf"
        },
        "Gradient normalization systems and methods for adaptive loss balancing in deep multitask networks": {
            "authors": [],
            "url": "https://patentimages.storage.googleapis.com/ae/a2/46/665ac62e300776/US11537895.pdf",
            "ref_texts": ""
        },
        "Dense Spatial Segmentation from Sparse Semantic Information": {
            "authors": [],
            "url": "http://erl.ucsd.edu/ref/Feng_SpatialSegmentation_RSS18_Workshop.pdf",
            "ref_texts": "[19] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis. 6-dof object pose from semantic keypoints. InRobotics and Automation (ICRA), 2017 IEEE International Conference on , pages 2011\u20132018. IEEE, 2017.",
            "ref_ids": [
                "19"
            ],
            "1": "Our technical approach is to detect objects in streaming image data and extract semantic keypoints corresponding to mid-level object parts [19] such as the windshield, doors, and wheels of a car.",
            "2": "[16, 26, 19] discuss about how to detect and classify keypoints of specific categories.",
            "3": ", left front wheel of a bus) from each bounding box using the approach of [19].",
            "4": "Also, deformable shape object models generated from annotated CAD models [19] can add additional constraints to this inference process.",
            "5": "[19] G."
        },
        "\u751f\u6210\u7684\u7279\u5fb4\u91cf\u306e\u89d2\u5ea6\u4f9d\u5b58\u6027\u306b\u7740\u76ee\u3057\u305f\u8996\u70b9\u89d2\u5ea6\u63a8\u5b9a\u306e\u7cbe\u5ea6\u5411\u4e0a": {
            "authors": [],
            "url": "https://d-itlab.c.titech.ac.jp/wp-content/uploads/2023/04/Chen_CVIM2022.pdf",
            "ref_texts": "[14] Pavlakos, G., Zhou, X., Chan, A., Derpanis, K. G. and Daniilidis, K.: 6-dof object pose from semantic keypoints, 2017 IEEE international conference on robotics and automation (ICRA) , IEEE, pp. 2011\u20132018 (2017).",
            "ref_ids": [
                "14"
            ],
            "1": "0 1\u20137 (??? 1959)\n\u03cf\u03ef\u0374\u0dfc\u035a\u036f\u0dfc\u0fa8\u0ef0\u0b4a\u0371\u0360\u036f\u047b\u034f\u0e4d\u0e4f [6], [7]\u0ce5\n\u07f4\n\u0936\u0370\n\u0c53\u027e\u03cc\u03a2\u03ef\u03c3\u039f\u03ef\u03ac\u03d8\u03bf\u03ab\u03b5\u027e\u0c9b\u0bc3\u0c3a\u0377\n\u034f\u0e4d\u0e4f [8]\u038d RGB\u0b8b\u0374\u0543\u0351\u036f\u0a02\u0c53\u09d8\u0e43\u038b\u0f3b\u034d\u0394\u0e4d\u0e4f [9]\u0374\n\u0388\u0ada\n\u039b\u0f3b\u034d\u0394\u0e4d\u0e4f [10]\u0373\u0372\u0355\u034b\u0394\u027d\n\u035e\u0395\n\u0c53\u0373\u0372\u0377\u03e5\u03d5\u03e7\u0dc7\u035a\u0374\u0378\u0d32\u0b47\u0373\u03af\u03b5\n\u0392\u0395\u036f\u034d\u0394\u0368\n\u0936\u0374\u0f3b\u034d\u0394\u0e4d\u0e4f\u0374\u0b30\u0362\u0394\u0927\u0f41\u0355\u0b47\n\u0398\u0373\u034d\u0e4d\u0e4f\n\u0680\u075a\n\u0370\n\u0378\u027c\u0fab\u0351\u0379 [6]\u0ab6\u0374\u0f3b\u034d\u0363\u0374\u027c\u0f27\u038a\n\u0c3a\u0354\u0392\u0377\u0568\u0afe\u039b\u0f27\u038a\u0c06\u038a\u0368\u0971\u0d6a\u0370\u0cd6\u0f97\u0360\u027c\n\u0358\u0373\u0394\u0391\u034f\u0374\n\u0936\u0362\u0394\u027d\u0387\u0368\u027c [1]\u0dc7\u0356\u03a6\u0294\u03c4\u03a4\u03ef\u03af\u0294\u03bc\u0374\u0391\u0394\n\u0c53\u0374\u0b30\u0362\u0394\u0d52\n\u0c53\u048e\n\u0a52\u0568\u0afe\u039b\u0a5c\n\u0936\u0374\u0391\u036c\u036f\u0e8a\u0dfa\u0377\u0568\u0afe\u039b\n\u0362\u0394\u035c\u0371\u0370\u03e5\u03d5\u03e7\u0dc7\n\u0362\u0394 [7], [11]\u035c\u0371\u038d\u027c\u0568\u0afe\u0377\n\u0398\u0363 RGB\u0b8b\u0377\u0388\u039b\u0f3b\u034d\u0394 [12]\u0351\u0392\n\u0395\u0394\u027d\n\u0f3b\u0355\n\u075a\n\u0c53\u0a2a\u0c06\u0370\u0377\u03da\u03e7\u03bd\u03bb\u03b5\u03ab\u0377\u0c8b\n\u0cd6\u0377\u0fab\u0371\u0360\u036f\u0378\u027c\u0dfa\u0b2e\u0377\u03ab\u03e5\u03b5\u0dfc\u0fa8 [10], [13] \u027c\u0c9b\u0bc3\u0c3a\u0ba8\n\u095a[8], [14]\u095a [10], [15]\u0a52 [1], [16]\u027c3D\n\u0a52 [17], [18]\u0378\u035c\u0377\u0ba4\u0370\n\u0c53\u0a2a\u0c06\u0ef0\u0b4a\u039b\u03da\u03e7\u03bd\u03bb\u03b5\u03ab\u0370\n\u0572\u0358\u0e4d\u0e4f\u0374\u034b\u0368\u0394\u027d\n2.",
            "2": "[14] Pavlakos, G."
        },
        "THE PURDUE UNIVERSITY GRADUATE SCHOOL STATEMENT OF DISSERTATION APPROVAL": {
            "authors": [],
            "url": "https://hammer.purdue.edu/articles/thesis/Utilizing_Data-Driven_Approaches_to_Evaluate_and_Develop_Air_Traffic_Controller_Action_Prediction_Models/12635891/files/23764568.pdf"
        },
        "Positionnement visuel pour la r\u00e9alit\u00e9 augment\u00e9e en environnement plan": {
            "authors": [],
            "url": "https://inria.hal.science/tel-02403014/document",
            "ref_texts": ""
        },
        "The RGB-D Triathlon Challenge: Towards Agile Visual Toolboxes for Robots": {
            "authors": [],
            "url": "https://webthesis.biblio.polito.it/secure/9532/1/tesi.pdf",
            "ref_texts": "[57] G. Pavlakos, X. Zhou, A. Chan, K. G. Derpanis, and K. Daniilidis, \u201c6-dof object pose from semantic keypoints\u201d, in Robotics and Automation (ICRA), 2017 IEEE International Conference on , IEEE, 2017, pp. 2011\u20132018.",
            "ref_ids": [
                "57"
            ],
            "1": "In the literature there are many works that address this task, from [20], [58], [73] to more recent methods that use Convolutional Neural Networks (CNN) [44], [57], [81], [88], [90], [92].",
            "2": "These methods can be divided into two groups: the first contains those that predict 2D keypoints from the image and then 15\n3 \u2013 The Landscape use a 3D model to evaluate the 3D pose given these keypoints [57], [92]; the second group contains those methods that predict directly the pose given the image [81], [88].",
            "3": "[57] G."
        }
    }
}